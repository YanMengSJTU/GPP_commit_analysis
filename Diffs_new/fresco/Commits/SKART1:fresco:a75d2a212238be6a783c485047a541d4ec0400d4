diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCache.java b/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCache.java
index c6f14d34d..903460ac1 100644
--- a/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCache.java
+++ b/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCache.java
@@ -22,12 +22,13 @@
  */
 public class DiskCache implements DiskCacheInterface {
   private static final String DISK_CACHE_SUBDIR = "thumbnails";
+  public static final String TAG = DiskCache.class.getName();
 
   //Singleton
   private static volatile DiskCache diskCache = null;
 
   private Semaphore writeLock = new Semaphore(1);
-  private final ConcurrentHashMap<Integer, Boolean> concurrentHashMap = new ConcurrentHashMap<>(6);
+  private final ConcurrentHashMap<Integer, Boolean> fileLocks = new ConcurrentHashMap<>(6);
 
   private File cacheDir;
 
@@ -53,7 +54,7 @@ private DiskCache(Context context) {
       File[] files = cacheDir.listFiles();
       for (File file : files) {
         if (!file.isDirectory()) {
-          concurrentHashMap.putIfAbsent(file.getName().hashCode(), false);
+          fileLocks.put(file.getName().hashCode(), false);
         }
       }
     } catch (InterruptedException e) {
@@ -73,10 +74,27 @@ public CacheInfo getCacheInfo(String url) {
     //
     File fileInp = new File(cacheDir, String.valueOf(cacheInfo.getFileName()));
 
-
-    if(fileInp.length() < Integer.MAX_VALUE) {
-      cacheInfo.setFileOffset((int) fileInp.length());
+    if(fileInp.exists()) {
+      try {
+        writeLock.acquire();
+        Boolean isProcessing = fileLocks.putIfAbsent(cacheInfo.getFileName(), false);
+
+        //Somebody have taken this file before us
+        if (isProcessing != null && isProcessing) {
+          FLog.e(TAG, " File already lock readers for one file!");
+          cacheInfo.setFileOffset(0);
+        } else {
+          fileLocks.put(cacheInfo.getFileName(), true);
+          cacheInfo.setFileOffset(fileInp.length());
+        }
+      } catch (InterruptedException e) {
+        e.printStackTrace();
+      } finally {
+        writeLock.release();
+      }
     } else {
+      //Atomic fileCreate will deal with this if there are multiply
+      // simultaneously not created files
       cacheInfo.setFileOffset(0);
     }
 
@@ -119,10 +137,10 @@ public OutputStream getOutputStream(CacheInfo cacheInfo) {
       File file = cacheInfo.getFile();
       if (!file.exists()) {
         if (file.createNewFile()) {
-          fileOutputStream = getOutputStreamMonopole(cacheInfo);
+          fileOutputStream = new FileOutputStream(cacheInfo.getFile());
         }
       } else {
-        fileOutputStream = getOutputStreamMonopole(cacheInfo);
+        fileOutputStream = new FileOutputStream(cacheInfo.getFile());
       }
     } catch (IOException e) {
       e.printStackTrace();
@@ -130,27 +148,6 @@ public OutputStream getOutputStream(CacheInfo cacheInfo) {
     return fileOutputStream;
   }
 
-  @Nullable
-  private FileOutputStream getOutputStreamMonopole(CacheInfo cacheInfo) throws FileNotFoundException {
-    try {
-      writeLock.acquire();
-      Boolean isProcessing = concurrentHashMap.putIfAbsent(cacheInfo.getFileName(), false);
-
-      if (isProcessing != null && isProcessing) {
-        FLog.e(DiskCache.class.getName(), " Multiply writers to one file!");
-      } else {
-        return new FileOutputStream(cacheInfo.getFile(), true);
-      }
-
-    } catch (InterruptedException e) {
-      e.printStackTrace();
-    } finally {
-      writeLock.release();
-    }
-    return null;
-  }
-
-
   @Override
   public void clearCache() {
     deleteAllInsideRecursively(cacheDir);
@@ -162,7 +159,7 @@ public void onFinished(CacheInfo cacheInfo) {
       writeLock.acquire();
 
       if (cacheInfo.getFile().delete()) {
-        concurrentHashMap.remove(cacheInfo.getFileName());
+        fileLocks.remove(cacheInfo.getFileName());
       }
     } catch (InterruptedException e) {
       e.printStackTrace();
@@ -176,7 +173,7 @@ public void onError(CacheInfo cacheInfo, Throwable throwable) {
     try {
       writeLock.acquire();
 
-      concurrentHashMap.put(cacheInfo.getFileName(), false);
+      fileLocks.put(cacheInfo.getFileName(), false);
     } catch (InterruptedException e) {
       e.printStackTrace();
     } finally {
diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCacheInterface.java b/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCacheInterface.java
index d6412df0c..53c389ccd 100644
--- a/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCacheInterface.java
+++ b/imagepipeline/src/main/java/com/facebook/imagepipeline/cache/DiskCacheInterface.java
@@ -4,6 +4,18 @@
 import java.io.InputStream;
 import java.io.OutputStream;
 
+/**
+ * DiskCacheInterface is responsible for storing, managing and cleaning intermediate downloaded progress
+ * locally and providing all necessary information about it. There are some things that you should
+ * store in your mind when implementing it:
+ *  * One file must give one output stream
+ *  * One file must always give one output stream - seriously, dude, if two streams will open same
+ *    file ugly things may happen. Multiply outputStreams have shared position in file, so if writing batches
+ *    after batches to multiply output streams there will be mess in output
+ *    (nevertheless Java provide with atomic write).
+ *  * Provide correct file size
+ *  * Closing files is also important.
+ */
 public interface DiskCacheInterface {
   CacheInfo getCacheInfo(String url);
 
@@ -22,7 +34,7 @@
     public static final int NO_FILENAME = -8;
 
     private int fileName;
-    private int fileOffset;
+    private long fileOffset;
     private File file;
 
     public CacheInfo() {
@@ -39,11 +51,11 @@ public void setFileName(int fileName) {
       this.fileName = fileName;
     }
 
-    public int getFileOffset() {
+    public long getFileOffset() {
       return fileOffset;
     }
 
-    public void setFileOffset(int fileOffset) {
+    public void setFileOffset(long fileOffset) {
       this.fileOffset = fileOffset;
     }
 
@@ -57,7 +69,10 @@ public void setFile(File file) {
   }
 
 
-  public static class DumbDiskCahce implements DiskCacheInterface {
+  /**
+   * Cache which do nothing but still works!
+   */
+  public static class DumbDiskCache implements DiskCacheInterface {
     @Override
     public CacheInfo getCacheInfo(String url) {
       return new CacheInfo();
diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DoubleSourceStream.java b/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DoubleSourceStream.java
index d243aa8b8..16c79034e 100644
--- a/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DoubleSourceStream.java
+++ b/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/DoubleSourceStream.java
@@ -15,7 +15,10 @@
 public class DoubleSourceStream extends InputStream {
   private static final String TAG = DoubleSourceStream.class.getName();
 
+  private static final int INFINITY_LENGTH = -4567;
+
   private InputStream firstInputStream;
+  private final int firstInputStreamLength;
   private InputStream secondInputStream;
 
   private OutputStream firstOutputStream;
@@ -25,9 +28,11 @@
   private int secondInputStreamTotalRead = 0;
 
   public DoubleSourceStream(InputStream firstInputStream,
-                            @NonNull InputStream secondInputStream,
+                            int firstInputStreamLength, @NonNull InputStream secondInputStream,
                             OutputStream firstOutputStream) {
     this.firstInputStream = firstInputStream;
+    this.firstInputStreamLength = firstInputStreamLength;
+
     this.secondInputStream = secondInputStream;
 
     this.firstOutputStream = firstOutputStream;
@@ -71,14 +76,23 @@ public int read() throws IOException {
     if (!firstEnds) {
       value = firstInputStream.read();
       if (value != -1) {
+        firstInputStreamTotalRead++;
+
+        if(firstInputStreamTotalRead == firstInputStreamLength) {
+          firstEnds = true;
+        }
         return value;
       }
       firstEnds = true;
     }
     value = secondInputStream.read();
 
-    if (firstOutputStream != null && value != -1) {
-      firstOutputStream.write(value);
+    if (value != -1) {
+      secondInputStreamTotalRead++;
+
+      if (firstOutputStream != null) {
+        firstOutputStream.write(value);
+      }
     }
 
     return value;
@@ -90,14 +104,23 @@ public int read(@NonNull byte[] buffer, int byteOffset, int byteCount) throws IO
 
     int bytesRead;
     if (!firstEnds) {
-      bytesRead = firstInputStream.read(buffer, byteOffset, byteCount);
+      int byteCountCorrected = byteCount;
+
+      if(firstInputStreamTotalRead + byteCount >= firstInputStreamLength) {
+        byteCountCorrected = firstInputStreamLength - firstInputStreamTotalRead;
+        firstEnds = true;
+
+        FLog.w(TAG, "FirstInputStream ended. Totally read " + firstInputStreamTotalRead);
+      }
+
+      bytesRead = firstInputStream.read(buffer, byteOffset, byteCountCorrected);
       if (bytesRead != -1) {
         firstInputStreamTotalRead += bytesRead;
         FLog.w(TAG, "Read from firstInputStream " + bytesRead + " bytes. Totally read from source: " + firstInputStreamTotalRead + " bytes");
 
         return bytesRead;
       }
-      FLog.w(TAG, "FirstInputStream ended. Totally read " + firstInputStreamTotalRead);
+
       firstEnds = true;
     }
 
diff --git a/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/ResumeDownloadFetcher.java b/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/ResumeDownloadFetcher.java
index 02ef4d1f4..d1e7673a2 100644
--- a/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/ResumeDownloadFetcher.java
+++ b/imagepipeline/src/main/java/com/facebook/imagepipeline/producers/ResumeDownloadFetcher.java
@@ -15,7 +15,20 @@
 import java.util.concurrent.Future;
 
 /**
- * This class
+ * This class is a special fetcher which will try:
+ *    * When new request come, fetcher asks #DiskCacheInterface if any intermediate progress is saved
+ *      locally. #DiskCacheInterface provide with all necessary information about previous progress,
+ *      allowing this fetcher to set required HTTP v1.1+ headers to continue just from the same position
+ *      it have stop before. Fetcher deals with cases when server do not support download resuming -
+ *      its just returns standard #InputStream. But when servers response it support such thing - then
+ *      all the stuff is done :)
+ *      Using #DoubleSourceStream information fetched from internet will be saved in output stream
+ *
+ *    * Save intermediate download progress in #OutputStream provided by #DiskCacheInterface.
+ *      While downloading media from internet it`s bytes will be appended just at the end of #OutputStream.
+ *      Actually this action is done by {@see #DoubleSourceStream}. About cache which provide streams and manage files see
+ *      interface {@see #com.facebook.imagepipeline.cache.DiskCacheInterface} and its implementation
+ *      {@see #com.facebook.imagepipeline.cache.DiskCache} and {@see #com.facebook.imagepipeline.cache.DiskCacheInterface.DumbDiskCache}.
  *
  */
 public class ResumeDownloadFetcher extends BaseNetworkFetcher<FetchState> {
@@ -87,7 +100,8 @@ public void run() {
                         secondInputStream = connection.getInputStream();
 
                         outputStream = diskCache.getOutputStream(cacheInfo);
-                        is = new DoubleSourceStream(firstInputStream, secondInputStream, outputStream);
+                        is = new DoubleSourceStream(firstInputStream, cacheInfo.getFileOffset(),
+                                secondInputStream, outputStream);
                       } else {
                         is = connection.getInputStream();
                       }
diff --git a/samples/redownloadingapp/src/main/java/com/facebook/samples/redownloadingapp/MainActivity.java b/samples/redownloadingapp/src/main/java/com/facebook/samples/redownloadingapp/MainActivity.java
index 88cfa328e..31c5850ec 100644
--- a/samples/redownloadingapp/src/main/java/com/facebook/samples/redownloadingapp/MainActivity.java
+++ b/samples/redownloadingapp/src/main/java/com/facebook/samples/redownloadingapp/MainActivity.java
@@ -54,7 +54,7 @@ protected void onCreate(Bundle savedInstanceState) {
     Set<RequestListener> listeners = new HashSet<>();
     listeners.add(new RequestLoggingListener());
 
-    final DiskCacheInterface diskCache = new DiskCacheInterface.DumbDiskCahce();//DiskCache.getInstance(this);
+    final DiskCacheInterface diskCache = DiskCache.getInstance(this);
 
     ImagePipelineConfig config = ImagePipelineConfig.newBuilder(this)
             .setNetworkFetcher(new ResumeDownloadFetcher(diskCache))
