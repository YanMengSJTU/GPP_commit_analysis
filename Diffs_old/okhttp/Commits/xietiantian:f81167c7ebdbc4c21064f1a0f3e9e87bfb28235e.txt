diff --git a/okhttp/src/main/java/okhttp3/Cache.java b/okhttp/src/main/java/okhttp3/Cache.java
index d43d91d257..ba113cfc4c 100644
--- a/okhttp/src/main/java/okhttp3/Cache.java
+++ b/okhttp/src/main/java/okhttp3/Cache.java
@@ -29,6 +29,7 @@
 import java.util.List;
 import java.util.NoSuchElementException;
 import javax.annotation.Nullable;
+
 import okhttp3.internal.Util;
 import okhttp3.internal.cache.CacheRequest;
 import okhttp3.internal.cache.CacheStrategy;
@@ -52,44 +53,44 @@
 /**
  * Caches HTTP and HTTPS responses to the filesystem so they may be reused, saving time and
  * bandwidth.
- *
+ * <p>
  * <h3>Cache Optimization</h3>
- *
+ * <p>
  * <p>To measure cache effectiveness, this class tracks three statistics:
  * <ul>
- *     <li><strong>{@linkplain #requestCount() Request Count:}</strong> the number of HTTP
- *         requests issued since this cache was created.
- *     <li><strong>{@linkplain #networkCount() Network Count:}</strong> the number of those
- *         requests that required network use.
- *     <li><strong>{@linkplain #hitCount() Hit Count:}</strong> the number of those requests
- *         whose responses were served by the cache.
+ * <li><strong>{@linkplain #requestCount() Request Count:}</strong> the number of HTTP
+ * requests issued since this cache was created.
+ * <li><strong>{@linkplain #networkCount() Network Count:}</strong> the number of those
+ * requests that required network use.
+ * <li><strong>{@linkplain #hitCount() Hit Count:}</strong> the number of those requests
+ * whose responses were served by the cache.
  * </ul>
- *
+ * <p>
  * Sometimes a request will result in a conditional cache hit. If the cache contains a stale copy of
  * the response, the client will issue a conditional {@code GET}. The server will then send either
  * the updated response if it has changed, or a short 'not modified' response if the client's copy
  * is still valid. Such responses increment both the network count and hit count.
- *
+ * <p>
  * <p>The best way to improve the cache hit rate is by configuring the web server to return
  * cacheable responses. Although this client honors all <a
  * href="http://tools.ietf.org/html/rfc7234">HTTP/1.1 (RFC 7234)</a> cache headers, it doesn't cache
  * partial responses.
- *
+ * <p>
  * <h3>Force a Network Response</h3>
- *
+ * <p>
  * <p>In some situations, such as after a user clicks a 'refresh' button, it may be necessary to
  * skip the cache, and fetch data directly from the server. To force a full refresh, add the {@code
  * no-cache} directive: <pre>   {@code
- *
+ * <p>
  *   Request request = new Request.Builder()
  *       .cacheControl(new CacheControl.Builder().noCache().build())
  *       .url("http://publicobject.com/helloworld.txt")
  *       .build();
  * }</pre>
- *
+ * <p>
  * If it is only necessary to force a cached response to be validated by the server, use the more
  * efficient {@code max-age=0} directive instead: <pre>   {@code
- *
+ * <p>
  *   Request request = new Request.Builder()
  *       .cacheControl(new CacheControl.Builder()
  *           .maxAge(0, TimeUnit.SECONDS)
@@ -97,14 +98,14 @@
  *       .url("http://publicobject.com/helloworld.txt")
  *       .build();
  * }</pre>
- *
+ * <p>
  * <h3>Force a Cache Response</h3>
- *
+ * <p>
  * <p>Sometimes you'll want to show resources if they are available immediately, but not otherwise.
  * This can be used so your application can show <i>something</i> while waiting for the latest data
  * to be downloaded. To restrict a request to locally-cached resources, add the {@code
  * only-if-cached} directive: <pre>   {@code
- *
+ * <p>
  *     Request request = new Request.Builder()
  *         .cacheControl(new CacheControl.Builder()
  *             .onlyIfCached()
@@ -121,7 +122,7 @@
  * This technique works even better in situations where a stale response is better than no response.
  * To permit stale cached responses, use the {@code max-stale} directive with the maximum staleness
  * in seconds: <pre>   {@code
- *
+ * <p>
  *   Request request = new Request.Builder()
  *       .cacheControl(new CacheControl.Builder()
  *           .maxStale(365, TimeUnit.DAYS)
@@ -129,642 +130,675 @@
  *       .url("http://publicobject.com/helloworld.txt")
  *       .build();
  * }</pre>
- *
+ * <p>
  * <p>The {@link CacheControl} class can configure request caching directives and parse response
  * caching directives. It even offers convenient constants {@link CacheControl#FORCE_NETWORK} and
  * {@link CacheControl#FORCE_CACHE} that address the use cases above.
+ * <p>
+ * 被上级代码调用，提供透明的put/get操作，封装了缓存检查条件与DiskLruCache，开发者只用配置大小即可，不需要手动管理
  */
 public final class Cache implements Closeable, Flushable {
-  private static final int VERSION = 201105;
-  private static final int ENTRY_METADATA = 0;
-  private static final int ENTRY_BODY = 1;
-  private static final int ENTRY_COUNT = 2;
-
-  final InternalCache internalCache = new InternalCache() {
-    @Override public Response get(Request request) throws IOException {
-      return Cache.this.get(request);
-    }
+    private static final int VERSION = 201105;
+    private static final int ENTRY_METADATA = 0;
+    private static final int ENTRY_BODY = 1;
+    private static final int ENTRY_COUNT = 2;
+
+    final InternalCache internalCache = new InternalCache() {
+        @Override
+        public Response get(Request request) throws IOException {
+            return Cache.this.get(request);
+        }
 
-    @Override public CacheRequest put(Response response) throws IOException {
-      return Cache.this.put(response);
-    }
+        @Override
+        public CacheRequest put(Response response) throws IOException {
+            return Cache.this.put(response);
+        }
 
-    @Override public void remove(Request request) throws IOException {
-      Cache.this.remove(request);
-    }
+        @Override
+        public void remove(Request request) throws IOException {
+            Cache.this.remove(request);
+        }
 
-    @Override public void update(Response cached, Response network) {
-      Cache.this.update(cached, network);
-    }
+        @Override
+        public void update(Response cached, Response network) {
+            Cache.this.update(cached, network);
+        }
 
-    @Override public void trackConditionalCacheHit() {
-      Cache.this.trackConditionalCacheHit();
-    }
+        @Override
+        public void trackConditionalCacheHit() {
+            Cache.this.trackConditionalCacheHit();
+        }
 
-    @Override public void trackResponse(CacheStrategy cacheStrategy) {
-      Cache.this.trackResponse(cacheStrategy);
-    }
-  };
-
-  final DiskLruCache cache;
-
-  /* read and write statistics, all guarded by 'this' */
-  int writeSuccessCount;
-  int writeAbortCount;
-  private int networkCount;
-  private int hitCount;
-  private int requestCount;
-
-  public Cache(File directory, long maxSize) {
-    this(directory, maxSize, FileSystem.SYSTEM);
-  }
-
-  Cache(File directory, long maxSize, FileSystem fileSystem) {
-    this.cache = DiskLruCache.create(fileSystem, directory, VERSION, ENTRY_COUNT, maxSize);
-  }
-
-  public static String key(HttpUrl url) {
-    return ByteString.encodeUtf8(url.toString()).md5().hex();
-  }
-
-  @Nullable Response get(Request request) {
-    String key = key(request.url());
-    DiskLruCache.Snapshot snapshot;
-    Entry entry;
-    try {
-      snapshot = cache.get(key);
-      if (snapshot == null) {
-        return null;
-      }
-    } catch (IOException e) {
-      // Give up because the cache cannot be read.
-      return null;
-    }
+        @Override
+        public void trackResponse(CacheStrategy cacheStrategy) {
+            Cache.this.trackResponse(cacheStrategy);
+        }
+    };
 
-    try {
-      entry = new Entry(snapshot.getSource(ENTRY_METADATA));
-    } catch (IOException e) {
-      Util.closeQuietly(snapshot);
-      return null;
-    }
+    final DiskLruCache cache;
 
-    Response response = entry.response(snapshot);
+    /* read and write statistics, all guarded by 'this' */
+    int writeSuccessCount;
+    int writeAbortCount;
+    private int networkCount;
+    private int hitCount;
+    private int requestCount;
 
-    if (!entry.matches(request, response)) {
-      Util.closeQuietly(response.body());
-      return null;
+    public Cache(File directory, long maxSize) {
+        this(directory, maxSize, FileSystem.SYSTEM);
     }
 
-    return response;
-  }
-
-  @Nullable CacheRequest put(Response response) {
-    String requestMethod = response.request().method();
-
-    if (HttpMethod.invalidatesCache(response.request().method())) {
-      try {
-        remove(response.request());
-      } catch (IOException ignored) {
-        // The cache cannot be written.
-      }
-      return null;
-    }
-    if (!requestMethod.equals("GET")) {
-      // Don't cache non-GET responses. We're technically allowed to cache
-      // HEAD requests and some POST requests, but the complexity of doing
-      // so is high and the benefit is low.
-      return null;
+    Cache(File directory, long maxSize, FileSystem fileSystem) {
+        this.cache = DiskLruCache.create(fileSystem, directory, VERSION, ENTRY_COUNT, maxSize);
     }
 
-    if (HttpHeaders.hasVaryAll(response)) {
-      return null;
+    public static String key(HttpUrl url) {
+        return ByteString.encodeUtf8(url.toString()).md5().hex();
     }
 
-    Entry entry = new Entry(response);
-    DiskLruCache.Editor editor = null;
-    try {
-      editor = cache.edit(key(response.request().url()));
-      if (editor == null) {
-        return null;
-      }
-      entry.writeTo(editor);
-      return new CacheRequestImpl(editor);
-    } catch (IOException e) {
-      abortQuietly(editor);
-      return null;
-    }
-  }
-
-  void remove(Request request) throws IOException {
-    cache.remove(key(request.url()));
-  }
-
-  void update(Response cached, Response network) {
-    Entry entry = new Entry(network);
-    DiskLruCache.Snapshot snapshot = ((CacheResponseBody) cached.body()).snapshot;
-    DiskLruCache.Editor editor = null;
-    try {
-      editor = snapshot.edit(); // Returns null if snapshot is not current.
-      if (editor != null) {
-        entry.writeTo(editor);
-        editor.commit();
-      }
-    } catch (IOException e) {
-      abortQuietly(editor);
-    }
-  }
-
-  private void abortQuietly(@Nullable DiskLruCache.Editor editor) {
-    // Give up because the cache cannot be written.
-    try {
-      if (editor != null) {
-        editor.abort();
-      }
-    } catch (IOException ignored) {
-    }
-  }
-
-  /**
-   * Initialize the cache. This will include reading the journal files from the storage and building
-   * up the necessary in-memory cache information.
-   *
-   * <p>The initialization time may vary depending on the journal file size and the current actual
-   * cache size. The application needs to be aware of calling this function during the
-   * initialization phase and preferably in a background worker thread.
-   *
-   * <p>Note that if the application chooses to not call this method to initialize the cache. By
-   * default, the okhttp will perform lazy initialization upon the first usage of the cache.
-   */
-  public void initialize() throws IOException {
-    cache.initialize();
-  }
-
-  /**
-   * Closes the cache and deletes all of its stored values. This will delete all files in the cache
-   * directory including files that weren't created by the cache.
-   */
-  public void delete() throws IOException {
-    cache.delete();
-  }
-
-  /**
-   * Deletes all values stored in the cache. In-flight writes to the cache will complete normally,
-   * but the corresponding responses will not be stored.
-   */
-  public void evictAll() throws IOException {
-    cache.evictAll();
-  }
-
-  /**
-   * Returns an iterator over the URLs in this cache. This iterator doesn't throw {@code
-   * ConcurrentModificationException}, but if new responses are added while iterating, their URLs
-   * will not be returned. If existing responses are evicted during iteration, they will be absent
-   * (unless they were already returned).
-   *
-   * <p>The iterator supports {@linkplain Iterator#remove}. Removing a URL from the iterator evicts
-   * the corresponding response from the cache. Use this to evict selected responses.
-   */
-  public Iterator<String> urls() throws IOException {
-    return new Iterator<String>() {
-      final Iterator<DiskLruCache.Snapshot> delegate = cache.snapshots();
-
-      @Nullable String nextUrl;
-      boolean canRemove;
-
-      @Override public boolean hasNext() {
-        if (nextUrl != null) return true;
-
-        canRemove = false; // Prevent delegate.remove() on the wrong item!
-        while (delegate.hasNext()) {
-          DiskLruCache.Snapshot snapshot = delegate.next();
-          try {
-            BufferedSource metadata = Okio.buffer(snapshot.getSource(ENTRY_METADATA));
-            nextUrl = metadata.readUtf8LineStrict();
-            return true;
-          } catch (IOException ignored) {
-            // We couldn't read the metadata for this snapshot; possibly because the host filesystem
-            // has disappeared! Skip it.
-          } finally {
-            snapshot.close();
-          }
-        }
-
-        return false;
-      }
-
-      @Override public String next() {
-        if (!hasNext()) throw new NoSuchElementException();
-        String result = nextUrl;
-        nextUrl = null;
-        canRemove = true;
-        return result;
-      }
-
-      @Override public void remove() {
-        if (!canRemove) throw new IllegalStateException("remove() before next()");
-        delegate.remove();
-      }
-    };
-  }
+    @Nullable
+    Response get(Request request) {
+        String key = key(request.url());
+        DiskLruCache.Snapshot snapshot;
+        Entry entry;
+        try {
+            snapshot = cache.get(key);
+            if (snapshot == null) {
+                return null;
+            }
+        } catch (IOException e) {
+            // Give up because the cache cannot be read.
+            return null;
+        }
 
-  public synchronized int writeAbortCount() {
-    return writeAbortCount;
-  }
+        try {
+            entry = new Entry(snapshot.getSource(ENTRY_METADATA));
+        } catch (IOException e) {
+            Util.closeQuietly(snapshot);
+            return null;
+        }
 
-  public synchronized int writeSuccessCount() {
-    return writeSuccessCount;
-  }
+        Response response = entry.response(snapshot);
 
-  public long size() throws IOException {
-    return cache.size();
-  }
+        if (!entry.matches(request, response)) {
+            Util.closeQuietly(response.body());
+            return null;
+        }
 
-  public long maxSize() {
-    return cache.getMaxSize();
-  }
+        return response;
+    }
 
-  @Override public void flush() throws IOException {
-    cache.flush();
-  }
+    @Nullable
+    CacheRequest put(Response response) {
+        String requestMethod = response.request().method();
 
-  @Override public void close() throws IOException {
-    cache.close();
-  }
+        if (HttpMethod.invalidatesCache(response.request().method())) {
+            try {
+                remove(response.request());
+            } catch (IOException ignored) {
+                // The cache cannot be written.
+            }
+            return null;
+        }
+        if (!requestMethod.equals("GET")) {
+            // Don't cache non-GET responses. We're technically allowed to cache
+            // HEAD requests and some POST requests, but the complexity of doing
+            // so is high and the benefit is low.
+            return null;
+        }
 
-  public File directory() {
-    return cache.getDirectory();
-  }
+        if (HttpHeaders.hasVaryAll(response)) {
+            return null;
+        }
 
-  public boolean isClosed() {
-    return cache.isClosed();
-  }
+        Entry entry = new Entry(response);
+        DiskLruCache.Editor editor = null;
+        try {
+            editor = cache.edit(key(response.request().url()));
+            if (editor == null) {
+                return null;
+            }
+            entry.writeTo(editor);
+            return new CacheRequestImpl(editor);
+        } catch (IOException e) {
+            abortQuietly(editor);
+            return null;
+        }
+    }
 
-  synchronized void trackResponse(CacheStrategy cacheStrategy) {
-    requestCount++;
+    void remove(Request request) throws IOException {
+        cache.remove(key(request.url()));
+    }
 
-    if (cacheStrategy.networkRequest != null) {
-      // If this is a conditional request, we'll increment hitCount if/when it hits.
-      networkCount++;
-    } else if (cacheStrategy.cacheResponse != null) {
-      // This response uses the cache and not the network. That's a cache hit.
-      hitCount++;
+    void update(Response cached, Response network) {
+        Entry entry = new Entry(network);
+        DiskLruCache.Snapshot snapshot = ((CacheResponseBody) cached.body()).snapshot;
+        DiskLruCache.Editor editor = null;
+        try {
+            editor = snapshot.edit(); // Returns null if snapshot is not current.
+            if (editor != null) {
+                entry.writeTo(editor);
+                editor.commit();
+            }
+        } catch (IOException e) {
+            abortQuietly(editor);
+        }
     }
-  }
-
-  synchronized void trackConditionalCacheHit() {
-    hitCount++;
-  }
-
-  public synchronized int networkCount() {
-    return networkCount;
-  }
-
-  public synchronized int hitCount() {
-    return hitCount;
-  }
-
-  public synchronized int requestCount() {
-    return requestCount;
-  }
-
-  private final class CacheRequestImpl implements CacheRequest {
-    private final DiskLruCache.Editor editor;
-    private Sink cacheOut;
-    private Sink body;
-    boolean done;
-
-    CacheRequestImpl(final DiskLruCache.Editor editor) {
-      this.editor = editor;
-      this.cacheOut = editor.newSink(ENTRY_BODY);
-      this.body = new ForwardingSink(cacheOut) {
-        @Override public void close() throws IOException {
-          synchronized (Cache.this) {
-            if (done) {
-              return;
+
+    private void abortQuietly(@Nullable DiskLruCache.Editor editor) {
+        // Give up because the cache cannot be written.
+        try {
+            if (editor != null) {
+                editor.abort();
             }
-            done = true;
-            writeSuccessCount++;
-          }
-          super.close();
-          editor.commit();
+        } catch (IOException ignored) {
         }
-      };
     }
 
-    @Override public void abort() {
-      synchronized (Cache.this) {
-        if (done) {
-          return;
-        }
-        done = true;
-        writeAbortCount++;
-      }
-      Util.closeQuietly(cacheOut);
-      try {
-        editor.abort();
-      } catch (IOException ignored) {
-      }
+    /**
+     * Initialize the cache. This will include reading the journal files from the storage and building
+     * up the necessary in-memory cache information.
+     * <p>
+     * <p>The initialization time may vary depending on the journal file size and the current actual
+     * cache size. The application needs to be aware of calling this function during the
+     * initialization phase and preferably in a background worker thread.
+     * <p>
+     * <p>Note that if the application chooses to not call this method to initialize the cache. By
+     * default, the okhttp will perform lazy initialization upon the first usage of the cache.
+     */
+    public void initialize() throws IOException {
+        cache.initialize();
     }
 
-    @Override public Sink body() {
-      return body;
+    /**
+     * Closes the cache and deletes all of its stored values. This will delete all files in the cache
+     * directory including files that weren't created by the cache.
+     */
+    public void delete() throws IOException {
+        cache.delete();
+    }
+
+    /**
+     * Deletes all values stored in the cache. In-flight writes to the cache will complete normally,
+     * but the corresponding responses will not be stored.
+     */
+    public void evictAll() throws IOException {
+        cache.evictAll();
     }
-  }
-
-  private static final class Entry {
-    /** Synthetic response header: the local time when the request was sent. */
-    private static final String SENT_MILLIS = Platform.get().getPrefix() + "-Sent-Millis";
-
-    /** Synthetic response header: the local time when the response was received. */
-    private static final String RECEIVED_MILLIS = Platform.get().getPrefix() + "-Received-Millis";
-
-    private final String url;
-    private final Headers varyHeaders;
-    private final String requestMethod;
-    private final Protocol protocol;
-    private final int code;
-    private final String message;
-    private final Headers responseHeaders;
-    private final @Nullable Handshake handshake;
-    private final long sentRequestMillis;
-    private final long receivedResponseMillis;
 
     /**
-     * Reads an entry from an input stream. A typical entry looks like this:
-     * <pre>{@code
-     *   http://google.com/foo
-     *   GET
-     *   2
-     *   Accept-Language: fr-CA
-     *   Accept-Charset: UTF-8
-     *   HTTP/1.1 200 OK
-     *   3
-     *   Content-Type: image/png
-     *   Content-Length: 100
-     *   Cache-Control: max-age=600
-     * }</pre>
-     *
-     * <p>A typical HTTPS file looks like this:
-     * <pre>{@code
-     *   https://google.com/foo
-     *   GET
-     *   2
-     *   Accept-Language: fr-CA
-     *   Accept-Charset: UTF-8
-     *   HTTP/1.1 200 OK
-     *   3
-     *   Content-Type: image/png
-     *   Content-Length: 100
-     *   Cache-Control: max-age=600
-     *
-     *   AES_256_WITH_MD5
-     *   2
-     *   base64-encoded peerCertificate[0]
-     *   base64-encoded peerCertificate[1]
-     *   -1
-     *   TLSv1.2
-     * }</pre>
-     * The file is newline separated. The first two lines are the URL and the request method. Next
-     * is the number of HTTP Vary request header lines, followed by those lines.
-     *
-     * <p>Next is the response status line, followed by the number of HTTP response header lines,
-     * followed by those lines.
-     *
-     * <p>HTTPS responses also contain SSL session information. This begins with a blank line, and
-     * then a line containing the cipher suite. Next is the length of the peer certificate chain.
-     * These certificates are base64-encoded and appear each on their own line. The next line
-     * contains the length of the local certificate chain. These certificates are also
-     * base64-encoded and appear each on their own line. A length of -1 is used to encode a null
-     * array. The last line is optional. If present, it contains the TLS version.
+     * Returns an iterator over the URLs in this cache. This iterator doesn't throw {@code
+     * ConcurrentModificationException}, but if new responses are added while iterating, their URLs
+     * will not be returned. If existing responses are evicted during iteration, they will be absent
+     * (unless they were already returned).
+     * <p>
+     * <p>The iterator supports {@linkplain Iterator#remove}. Removing a URL from the iterator evicts
+     * the corresponding response from the cache. Use this to evict selected responses.
      */
-    Entry(Source in) throws IOException {
-      try {
-        BufferedSource source = Okio.buffer(in);
-        url = source.readUtf8LineStrict();
-        requestMethod = source.readUtf8LineStrict();
-        Headers.Builder varyHeadersBuilder = new Headers.Builder();
-        int varyRequestHeaderLineCount = readInt(source);
-        for (int i = 0; i < varyRequestHeaderLineCount; i++) {
-          varyHeadersBuilder.addLenient(source.readUtf8LineStrict());
-        }
-        varyHeaders = varyHeadersBuilder.build();
-
-        StatusLine statusLine = StatusLine.parse(source.readUtf8LineStrict());
-        protocol = statusLine.protocol;
-        code = statusLine.code;
-        message = statusLine.message;
-        Headers.Builder responseHeadersBuilder = new Headers.Builder();
-        int responseHeaderLineCount = readInt(source);
-        for (int i = 0; i < responseHeaderLineCount; i++) {
-          responseHeadersBuilder.addLenient(source.readUtf8LineStrict());
-        }
-        String sendRequestMillisString = responseHeadersBuilder.get(SENT_MILLIS);
-        String receivedResponseMillisString = responseHeadersBuilder.get(RECEIVED_MILLIS);
-        responseHeadersBuilder.removeAll(SENT_MILLIS);
-        responseHeadersBuilder.removeAll(RECEIVED_MILLIS);
-        sentRequestMillis = sendRequestMillisString != null
-            ? Long.parseLong(sendRequestMillisString)
-            : 0L;
-        receivedResponseMillis = receivedResponseMillisString != null
-            ? Long.parseLong(receivedResponseMillisString)
-            : 0L;
-        responseHeaders = responseHeadersBuilder.build();
-
-        if (isHttps()) {
-          String blank = source.readUtf8LineStrict();
-          if (blank.length() > 0) {
-            throw new IOException("expected \"\" but was \"" + blank + "\"");
-          }
-          String cipherSuiteString = source.readUtf8LineStrict();
-          CipherSuite cipherSuite = CipherSuite.forJavaName(cipherSuiteString);
-          List<Certificate> peerCertificates = readCertificateList(source);
-          List<Certificate> localCertificates = readCertificateList(source);
-          TlsVersion tlsVersion = !source.exhausted()
-              ? TlsVersion.forJavaName(source.readUtf8LineStrict())
-              : TlsVersion.SSL_3_0;
-          handshake = Handshake.get(tlsVersion, cipherSuite, peerCertificates, localCertificates);
-        } else {
-          handshake = null;
-        }
-      } finally {
-        in.close();
-      }
+    public Iterator<String> urls() throws IOException {
+        return new Iterator<String>() {
+            final Iterator<DiskLruCache.Snapshot> delegate = cache.snapshots();
+
+            @Nullable
+            String nextUrl;
+            boolean canRemove;
+
+            @Override
+            public boolean hasNext() {
+                if (nextUrl != null) return true;
+
+                canRemove = false; // Prevent delegate.remove() on the wrong item!
+                while (delegate.hasNext()) {
+                    DiskLruCache.Snapshot snapshot = delegate.next();
+                    try {
+                        BufferedSource metadata = Okio.buffer(snapshot.getSource(ENTRY_METADATA));
+                        nextUrl = metadata.readUtf8LineStrict();
+                        return true;
+                    } catch (IOException ignored) {
+                        // We couldn't read the metadata for this snapshot; possibly because the host filesystem
+                        // has disappeared! Skip it.
+                    } finally {
+                        snapshot.close();
+                    }
+                }
+
+                return false;
+            }
+
+            @Override
+            public String next() {
+                if (!hasNext()) throw new NoSuchElementException();
+                String result = nextUrl;
+                nextUrl = null;
+                canRemove = true;
+                return result;
+            }
+
+            @Override
+            public void remove() {
+                if (!canRemove) throw new IllegalStateException("remove() before next()");
+                delegate.remove();
+            }
+        };
+    }
+
+    public synchronized int writeAbortCount() {
+        return writeAbortCount;
+    }
+
+    public synchronized int writeSuccessCount() {
+        return writeSuccessCount;
     }
 
-    Entry(Response response) {
-      this.url = response.request().url().toString();
-      this.varyHeaders = HttpHeaders.varyHeaders(response);
-      this.requestMethod = response.request().method();
-      this.protocol = response.protocol();
-      this.code = response.code();
-      this.message = response.message();
-      this.responseHeaders = response.headers();
-      this.handshake = response.handshake();
-      this.sentRequestMillis = response.sentRequestAtMillis();
-      this.receivedResponseMillis = response.receivedResponseAtMillis();
+    public long size() throws IOException {
+        return cache.size();
     }
 
-    public void writeTo(DiskLruCache.Editor editor) throws IOException {
-      BufferedSink sink = Okio.buffer(editor.newSink(ENTRY_METADATA));
-
-      sink.writeUtf8(url)
-          .writeByte('\n');
-      sink.writeUtf8(requestMethod)
-          .writeByte('\n');
-      sink.writeDecimalLong(varyHeaders.size())
-          .writeByte('\n');
-      for (int i = 0, size = varyHeaders.size(); i < size; i++) {
-        sink.writeUtf8(varyHeaders.name(i))
-            .writeUtf8(": ")
-            .writeUtf8(varyHeaders.value(i))
-            .writeByte('\n');
-      }
-
-      sink.writeUtf8(new StatusLine(protocol, code, message).toString())
-          .writeByte('\n');
-      sink.writeDecimalLong(responseHeaders.size() + 2)
-          .writeByte('\n');
-      for (int i = 0, size = responseHeaders.size(); i < size; i++) {
-        sink.writeUtf8(responseHeaders.name(i))
-            .writeUtf8(": ")
-            .writeUtf8(responseHeaders.value(i))
-            .writeByte('\n');
-      }
-      sink.writeUtf8(SENT_MILLIS)
-          .writeUtf8(": ")
-          .writeDecimalLong(sentRequestMillis)
-          .writeByte('\n');
-      sink.writeUtf8(RECEIVED_MILLIS)
-          .writeUtf8(": ")
-          .writeDecimalLong(receivedResponseMillis)
-          .writeByte('\n');
-
-      if (isHttps()) {
-        sink.writeByte('\n');
-        sink.writeUtf8(handshake.cipherSuite().javaName())
-            .writeByte('\n');
-        writeCertList(sink, handshake.peerCertificates());
-        writeCertList(sink, handshake.localCertificates());
-        sink.writeUtf8(handshake.tlsVersion().javaName()).writeByte('\n');
-      }
-      sink.close();
+    public long maxSize() {
+        return cache.getMaxSize();
     }
 
-    private boolean isHttps() {
-      return url.startsWith("https://");
+    @Override
+    public void flush() throws IOException {
+        cache.flush();
     }
 
-    private List<Certificate> readCertificateList(BufferedSource source) throws IOException {
-      int length = readInt(source);
-      if (length == -1) return Collections.emptyList(); // OkHttp v1.2 used -1 to indicate null.
-
-      try {
-        CertificateFactory certificateFactory = CertificateFactory.getInstance("X.509");
-        List<Certificate> result = new ArrayList<>(length);
-        for (int i = 0; i < length; i++) {
-          String line = source.readUtf8LineStrict();
-          Buffer bytes = new Buffer();
-          bytes.write(ByteString.decodeBase64(line));
-          result.add(certificateFactory.generateCertificate(bytes.inputStream()));
-        }
-        return result;
-      } catch (CertificateException e) {
-        throw new IOException(e.getMessage());
-      }
+    @Override
+    public void close() throws IOException {
+        cache.close();
     }
 
-    private void writeCertList(BufferedSink sink, List<Certificate> certificates)
-        throws IOException {
-      try {
-        sink.writeDecimalLong(certificates.size())
-            .writeByte('\n');
-        for (int i = 0, size = certificates.size(); i < size; i++) {
-          byte[] bytes = certificates.get(i).getEncoded();
-          String line = ByteString.of(bytes).base64();
-          sink.writeUtf8(line)
-              .writeByte('\n');
-        }
-      } catch (CertificateEncodingException e) {
-        throw new IOException(e.getMessage());
-      }
+    public File directory() {
+        return cache.getDirectory();
     }
 
-    public boolean matches(Request request, Response response) {
-      return url.equals(request.url().toString())
-          && requestMethod.equals(request.method())
-          && HttpHeaders.varyMatches(response, varyHeaders, request);
+    public boolean isClosed() {
+        return cache.isClosed();
     }
 
-    public Response response(DiskLruCache.Snapshot snapshot) {
-      String contentType = responseHeaders.get("Content-Type");
-      String contentLength = responseHeaders.get("Content-Length");
-      Request cacheRequest = new Request.Builder()
-          .url(url)
-          .method(requestMethod, null)
-          .headers(varyHeaders)
-          .build();
-      return new Response.Builder()
-          .request(cacheRequest)
-          .protocol(protocol)
-          .code(code)
-          .message(message)
-          .headers(responseHeaders)
-          .body(new CacheResponseBody(snapshot, contentType, contentLength))
-          .handshake(handshake)
-          .sentRequestAtMillis(sentRequestMillis)
-          .receivedResponseAtMillis(receivedResponseMillis)
-          .build();
+    synchronized void trackResponse(CacheStrategy cacheStrategy) {
+        requestCount++;
+
+        if (cacheStrategy.networkRequest != null) {
+            // If this is a conditional request, we'll increment hitCount if/when it hits.
+            networkCount++;
+        } else if (cacheStrategy.cacheResponse != null) {
+            // This response uses the cache and not the network. That's a cache hit.
+            hitCount++;
+        }
     }
-  }
-
-  static int readInt(BufferedSource source) throws IOException {
-    try {
-      long result = source.readDecimalLong();
-      String line = source.readUtf8LineStrict();
-      if (result < 0 || result > Integer.MAX_VALUE || !line.isEmpty()) {
-        throw new IOException("expected an int but was \"" + result + line + "\"");
-      }
-      return (int) result;
-    } catch (NumberFormatException e) {
-      throw new IOException(e.getMessage());
+
+    synchronized void trackConditionalCacheHit() {
+        hitCount++;
     }
-  }
-
-  private static class CacheResponseBody extends ResponseBody {
-    final DiskLruCache.Snapshot snapshot;
-    private final BufferedSource bodySource;
-    private final @Nullable String contentType;
-    private final @Nullable String contentLength;
-
-    CacheResponseBody(final DiskLruCache.Snapshot snapshot,
-        String contentType, String contentLength) {
-      this.snapshot = snapshot;
-      this.contentType = contentType;
-      this.contentLength = contentLength;
-
-      Source source = snapshot.getSource(ENTRY_BODY);
-      bodySource = Okio.buffer(new ForwardingSource(source) {
-        @Override public void close() throws IOException {
-          snapshot.close();
-          super.close();
-        }
-      });
+
+    public synchronized int networkCount() {
+        return networkCount;
     }
 
-    @Override public MediaType contentType() {
-      return contentType != null ? MediaType.parse(contentType) : null;
+    public synchronized int hitCount() {
+        return hitCount;
     }
 
-    @Override public long contentLength() {
-      try {
-        return contentLength != null ? Long.parseLong(contentLength) : -1;
-      } catch (NumberFormatException e) {
-        return -1;
-      }
+    public synchronized int requestCount() {
+        return requestCount;
     }
 
-    @Override public BufferedSource source() {
-      return bodySource;
+    private final class CacheRequestImpl implements CacheRequest {
+        private final DiskLruCache.Editor editor;
+        private Sink cacheOut;
+        private Sink body;
+        boolean done;
+
+        CacheRequestImpl(final DiskLruCache.Editor editor) {
+            this.editor = editor;
+            this.cacheOut = editor.newSink(ENTRY_BODY);
+            this.body = new ForwardingSink(cacheOut) {
+                @Override
+                public void close() throws IOException {
+                    synchronized (Cache.this) {
+                        if (done) {
+                            return;
+                        }
+                        done = true;
+                        writeSuccessCount++;
+                    }
+                    super.close();
+                    editor.commit();
+                }
+            };
+        }
+
+        @Override
+        public void abort() {
+            synchronized (Cache.this) {
+                if (done) {
+                    return;
+                }
+                done = true;
+                writeAbortCount++;
+            }
+            Util.closeQuietly(cacheOut);
+            try {
+                editor.abort();
+            } catch (IOException ignored) {
+            }
+        }
+
+        @Override
+        public Sink body() {
+            return body;
+        }
+    }
+
+    /**
+     * Response对象与Okio流的序列化/反序列化类
+     */
+    private static final class Entry {
+        /**
+         * Synthetic response header: the local time when the request was sent.
+         */
+        private static final String SENT_MILLIS = Platform.get().getPrefix() + "-Sent-Millis";
+
+        /**
+         * Synthetic response header: the local time when the response was received.
+         */
+        private static final String RECEIVED_MILLIS = Platform.get().getPrefix() + "-Received-Millis";
+
+        private final String url;
+        private final Headers varyHeaders;
+        private final String requestMethod;
+        private final Protocol protocol;
+        private final int code;
+        private final String message;
+        private final Headers responseHeaders;
+        private final @Nullable
+        Handshake handshake;
+        private final long sentRequestMillis;
+        private final long receivedResponseMillis;
+
+        /**
+         * Reads an entry from an input stream. A typical entry looks like this:
+         * <pre>{@code
+         *   http://google.com/foo
+         *   GET
+         *   2
+         *   Accept-Language: fr-CA
+         *   Accept-Charset: UTF-8
+         *   HTTP/1.1 200 OK
+         *   3
+         *   Content-Type: image/png
+         *   Content-Length: 100
+         *   Cache-Control: max-age=600
+         * }</pre>
+         * <p>
+         * <p>A typical HTTPS file looks like this:
+         * <pre>{@code
+         *   https://google.com/foo
+         *   GET
+         *   2
+         *   Accept-Language: fr-CA
+         *   Accept-Charset: UTF-8
+         *   HTTP/1.1 200 OK
+         *   3
+         *   Content-Type: image/png
+         *   Content-Length: 100
+         *   Cache-Control: max-age=600
+         *
+         *   AES_256_WITH_MD5
+         *   2
+         *   base64-encoded peerCertificate[0]
+         *   base64-encoded peerCertificate[1]
+         *   -1
+         *   TLSv1.2
+         * }</pre>
+         * The file is newline separated. The first two lines are the URL and the request method. Next
+         * is the number of HTTP Vary request header lines, followed by those lines.
+         * <p>
+         * <p>Next is the response status line, followed by the number of HTTP response header lines,
+         * followed by those lines.
+         * <p>
+         * <p>HTTPS responses also contain SSL session information. This begins with a blank line, and
+         * then a line containing the cipher suite. Next is the length of the peer certificate chain.
+         * These certificates are base64-encoded and appear each on their own line. The next line
+         * contains the length of the local certificate chain. These certificates are also
+         * base64-encoded and appear each on their own line. A length of -1 is used to encode a null
+         * array. The last line is optional. If present, it contains the TLS version.
+         */
+        Entry(Source in) throws IOException {
+            try {
+                BufferedSource source = Okio.buffer(in);
+                url = source.readUtf8LineStrict();
+                requestMethod = source.readUtf8LineStrict();
+                Headers.Builder varyHeadersBuilder = new Headers.Builder();
+                int varyRequestHeaderLineCount = readInt(source);
+                for (int i = 0; i < varyRequestHeaderLineCount; i++) {
+                    varyHeadersBuilder.addLenient(source.readUtf8LineStrict());
+                }
+                varyHeaders = varyHeadersBuilder.build();
+
+                StatusLine statusLine = StatusLine.parse(source.readUtf8LineStrict());
+                protocol = statusLine.protocol;
+                code = statusLine.code;
+                message = statusLine.message;
+                Headers.Builder responseHeadersBuilder = new Headers.Builder();
+                int responseHeaderLineCount = readInt(source);
+                for (int i = 0; i < responseHeaderLineCount; i++) {
+                    responseHeadersBuilder.addLenient(source.readUtf8LineStrict());
+                }
+                String sendRequestMillisString = responseHeadersBuilder.get(SENT_MILLIS);
+                String receivedResponseMillisString = responseHeadersBuilder.get(RECEIVED_MILLIS);
+                responseHeadersBuilder.removeAll(SENT_MILLIS);
+                responseHeadersBuilder.removeAll(RECEIVED_MILLIS);
+                sentRequestMillis = sendRequestMillisString != null
+                        ? Long.parseLong(sendRequestMillisString)
+                        : 0L;
+                receivedResponseMillis = receivedResponseMillisString != null
+                        ? Long.parseLong(receivedResponseMillisString)
+                        : 0L;
+                responseHeaders = responseHeadersBuilder.build();
+
+                if (isHttps()) {
+                    String blank = source.readUtf8LineStrict();
+                    if (blank.length() > 0) {
+                        throw new IOException("expected \"\" but was \"" + blank + "\"");
+                    }
+                    String cipherSuiteString = source.readUtf8LineStrict();
+                    CipherSuite cipherSuite = CipherSuite.forJavaName(cipherSuiteString);
+                    List<Certificate> peerCertificates = readCertificateList(source);
+                    List<Certificate> localCertificates = readCertificateList(source);
+                    TlsVersion tlsVersion = !source.exhausted()
+                            ? TlsVersion.forJavaName(source.readUtf8LineStrict())
+                            : TlsVersion.SSL_3_0;
+                    handshake = Handshake.get(tlsVersion, cipherSuite, peerCertificates, localCertificates);
+                } else {
+                    handshake = null;
+                }
+            } finally {
+                in.close();
+            }
+        }
+
+        Entry(Response response) {
+            this.url = response.request().url().toString();
+            this.varyHeaders = HttpHeaders.varyHeaders(response);
+            this.requestMethod = response.request().method();
+            this.protocol = response.protocol();
+            this.code = response.code();
+            this.message = response.message();
+            this.responseHeaders = response.headers();
+            this.handshake = response.handshake();
+            this.sentRequestMillis = response.sentRequestAtMillis();
+            this.receivedResponseMillis = response.receivedResponseAtMillis();
+        }
+
+        public void writeTo(DiskLruCache.Editor editor) throws IOException {
+            BufferedSink sink = Okio.buffer(editor.newSink(ENTRY_METADATA));
+
+            sink.writeUtf8(url)
+                    .writeByte('\n');
+            sink.writeUtf8(requestMethod)
+                    .writeByte('\n');
+            sink.writeDecimalLong(varyHeaders.size())
+                    .writeByte('\n');
+            for (int i = 0, size = varyHeaders.size(); i < size; i++) {
+                sink.writeUtf8(varyHeaders.name(i))
+                        .writeUtf8(": ")
+                        .writeUtf8(varyHeaders.value(i))
+                        .writeByte('\n');
+            }
+
+            sink.writeUtf8(new StatusLine(protocol, code, message).toString())
+                    .writeByte('\n');
+            sink.writeDecimalLong(responseHeaders.size() + 2)
+                    .writeByte('\n');
+            for (int i = 0, size = responseHeaders.size(); i < size; i++) {
+                sink.writeUtf8(responseHeaders.name(i))
+                        .writeUtf8(": ")
+                        .writeUtf8(responseHeaders.value(i))
+                        .writeByte('\n');
+            }
+            sink.writeUtf8(SENT_MILLIS)
+                    .writeUtf8(": ")
+                    .writeDecimalLong(sentRequestMillis)
+                    .writeByte('\n');
+            sink.writeUtf8(RECEIVED_MILLIS)
+                    .writeUtf8(": ")
+                    .writeDecimalLong(receivedResponseMillis)
+                    .writeByte('\n');
+
+            if (isHttps()) {
+                sink.writeByte('\n');
+                sink.writeUtf8(handshake.cipherSuite().javaName())
+                        .writeByte('\n');
+                writeCertList(sink, handshake.peerCertificates());
+                writeCertList(sink, handshake.localCertificates());
+                sink.writeUtf8(handshake.tlsVersion().javaName()).writeByte('\n');
+            }
+            sink.close();
+        }
+
+        private boolean isHttps() {
+            return url.startsWith("https://");
+        }
+
+        private List<Certificate> readCertificateList(BufferedSource source) throws IOException {
+            int length = readInt(source);
+            if (length == -1) return Collections.emptyList(); // OkHttp v1.2 used -1 to indicate null.
+
+            try {
+                CertificateFactory certificateFactory = CertificateFactory.getInstance("X.509");
+                List<Certificate> result = new ArrayList<>(length);
+                for (int i = 0; i < length; i++) {
+                    String line = source.readUtf8LineStrict();
+                    Buffer bytes = new Buffer();
+                    bytes.write(ByteString.decodeBase64(line));
+                    result.add(certificateFactory.generateCertificate(bytes.inputStream()));
+                }
+                return result;
+            } catch (CertificateException e) {
+                throw new IOException(e.getMessage());
+            }
+        }
+
+        private void writeCertList(BufferedSink sink, List<Certificate> certificates)
+                throws IOException {
+            try {
+                sink.writeDecimalLong(certificates.size())
+                        .writeByte('\n');
+                for (int i = 0, size = certificates.size(); i < size; i++) {
+                    byte[] bytes = certificates.get(i).getEncoded();
+                    String line = ByteString.of(bytes).base64();
+                    sink.writeUtf8(line)
+                            .writeByte('\n');
+                }
+            } catch (CertificateEncodingException e) {
+                throw new IOException(e.getMessage());
+            }
+        }
+
+        public boolean matches(Request request, Response response) {
+            return url.equals(request.url().toString())
+                    && requestMethod.equals(request.method())
+                    && HttpHeaders.varyMatches(response, varyHeaders, request);
+        }
+
+        public Response response(DiskLruCache.Snapshot snapshot) {
+            String contentType = responseHeaders.get("Content-Type");
+            String contentLength = responseHeaders.get("Content-Length");
+            Request cacheRequest = new Request.Builder()
+                    .url(url)
+                    .method(requestMethod, null)
+                    .headers(varyHeaders)
+                    .build();
+            return new Response.Builder()
+                    .request(cacheRequest)
+                    .protocol(protocol)
+                    .code(code)
+                    .message(message)
+                    .headers(responseHeaders)
+                    .body(new CacheResponseBody(snapshot, contentType, contentLength))
+                    .handshake(handshake)
+                    .sentRequestAtMillis(sentRequestMillis)
+                    .receivedResponseAtMillis(receivedResponseMillis)
+                    .build();
+        }
+    }
+
+    static int readInt(BufferedSource source) throws IOException {
+        try {
+            long result = source.readDecimalLong();
+            String line = source.readUtf8LineStrict();
+            if (result < 0 || result > Integer.MAX_VALUE || !line.isEmpty()) {
+                throw new IOException("expected an int but was \"" + result + line + "\"");
+            }
+            return (int) result;
+        } catch (NumberFormatException e) {
+            throw new IOException(e.getMessage());
+        }
+    }
+
+    private static class CacheResponseBody extends ResponseBody {
+        final DiskLruCache.Snapshot snapshot;
+        private final BufferedSource bodySource;
+        private final @Nullable
+        String contentType;
+        private final @Nullable
+        String contentLength;
+
+        CacheResponseBody(final DiskLruCache.Snapshot snapshot,
+                          String contentType, String contentLength) {
+            this.snapshot = snapshot;
+            this.contentType = contentType;
+            this.contentLength = contentLength;
+
+            Source source = snapshot.getSource(ENTRY_BODY);
+            bodySource = Okio.buffer(new ForwardingSource(source) {
+                @Override
+                public void close() throws IOException {
+                    snapshot.close();
+                    super.close();
+                }
+            });
+        }
+
+        @Override
+        public MediaType contentType() {
+            return contentType != null ? MediaType.parse(contentType) : null;
+        }
+
+        @Override
+        public long contentLength() {
+            try {
+                return contentLength != null ? Long.parseLong(contentLength) : -1;
+            } catch (NumberFormatException e) {
+                return -1;
+            }
+        }
+
+        @Override
+        public BufferedSource source() {
+            return bodySource;
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/ConnectionPool.java b/okhttp/src/main/java/okhttp3/ConnectionPool.java
index 605f275661..1e4a10e055 100644
--- a/okhttp/src/main/java/okhttp3/ConnectionPool.java
+++ b/okhttp/src/main/java/okhttp3/ConnectionPool.java
@@ -28,6 +28,7 @@
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.Nullable;
+
 import okhttp3.internal.Util;
 import okhttp3.internal.connection.RealConnection;
 import okhttp3.internal.connection.RouteDatabase;
@@ -37,249 +38,303 @@
 import static okhttp3.internal.Util.closeQuietly;
 
 /**
+ * Socket连接池，对连接缓存进行回收与管理
+ * <p>
  * Manages reuse of HTTP and HTTP/2 connections for reduced network latency. HTTP requests that
  * share the same {@link Address} may share a {@link Connection}. This class implements the policy
  * of which connections to keep open for future use.
  */
 public final class ConnectionPool {
-  /**
-   * Background threads are used to cleanup expired connections. There will be at most a single
-   * thread running per connection pool. The thread pool executor permits the pool itself to be
-   * garbage collected.
-   */
-  private static final Executor executor = new ThreadPoolExecutor(0 /* corePoolSize */,
-      Integer.MAX_VALUE /* maximumPoolSize */, 60L /* keepAliveTime */, TimeUnit.SECONDS,
-      new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp ConnectionPool", true));
-
-  /** The maximum number of idle connections for each address. */
-  private final int maxIdleConnections;
-  private final long keepAliveDurationNs;
-  private final Runnable cleanupRunnable = new Runnable() {
-    @Override public void run() {
-      while (true) {
-        long waitNanos = cleanup(System.nanoTime());
-        if (waitNanos == -1) return;
-        if (waitNanos > 0) {
-          long waitMillis = waitNanos / 1000000L;
-          waitNanos -= (waitMillis * 1000000L);
-          synchronized (ConnectionPool.this) {
-            try {
-              ConnectionPool.this.wait(waitMillis, (int) waitNanos);
-            } catch (InterruptedException ignored) {
+    /**
+     * Background threads are used to cleanup expired connections. There will be at most a single
+     * thread running per connection pool. The thread pool executor permits the pool itself to be
+     * garbage collected.
+     */
+    private static final Executor executor = new ThreadPoolExecutor(0 /* corePoolSize */,
+            Integer.MAX_VALUE /* maximumPoolSize */, 60L /* keepAliveTime */, TimeUnit.SECONDS,
+            new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp ConnectionPool", true));
+
+    /**
+     * The maximum number of idle connections for each address.
+     */
+    private final int maxIdleConnections;
+    private final long keepAliveDurationNs;
+
+    /**
+     * Socket清理的Runnable，每当put操作时，就会被主动调用
+     * 注意put操作是在网络线程，而清理线程在线程池{@link ConnectionPool#executor}中调用
+     */
+    private final Runnable cleanupRunnable = new Runnable() {
+        @Override
+        public void run() {
+            while (true) {
+                // 执行清理并返回下次需要清理的间隔时间
+                long waitNanos = cleanup(System.nanoTime());
+                if (waitNanos == -1) return;//没有connection的情况，跳出循环
+                if (waitNanos > 0) {
+                    long waitMillis = waitNanos / 1000000L;
+                    waitNanos -= (waitMillis * 1000000L);
+                    synchronized (ConnectionPool.this) {
+                        try {
+                            //在timeout内释放锁与时间片
+                            ConnectionPool.this.wait(waitMillis, (int) waitNanos);
+                        } catch (InterruptedException ignored) {
+                        }
+                    }
+                }
             }
-          }
         }
-      }
-    }
-  };
-
-  private final Deque<RealConnection> connections = new ArrayDeque<>();
-  final RouteDatabase routeDatabase = new RouteDatabase();
-  boolean cleanupRunning;
-
-  /**
-   * Create a new connection pool with tuning parameters appropriate for a single-user application.
-   * The tuning parameters in this pool are subject to change in future OkHttp releases. Currently
-   * this pool holds up to 5 idle connections which will be evicted after 5 minutes of inactivity.
-   */
-  public ConnectionPool() {
-    this(5, 5, TimeUnit.MINUTES);
-  }
-
-  public ConnectionPool(int maxIdleConnections, long keepAliveDuration, TimeUnit timeUnit) {
-    this.maxIdleConnections = maxIdleConnections;
-    this.keepAliveDurationNs = timeUnit.toNanos(keepAliveDuration);
-
-    // Put a floor on the keep alive duration, otherwise cleanup will spin loop.
-    if (keepAliveDuration <= 0) {
-      throw new IllegalArgumentException("keepAliveDuration <= 0: " + keepAliveDuration);
-    }
-  }
+    };
+
+    private final Deque<RealConnection> connections = new ArrayDeque<>();
+    /**
+     * 记录连接失败的Route的黑名单，当连接失败的时候就会把失败的线路加进去
+     */
+    final RouteDatabase routeDatabase = new RouteDatabase();
+    boolean cleanupRunning;
 
-  /** Returns the number of idle connections in the pool. */
-  public synchronized int idleConnectionCount() {
-    int total = 0;
-    for (RealConnection connection : connections) {
-      if (connection.allocations.isEmpty()) total++;
+    /**
+     * Create a new connection pool with tuning parameters appropriate for a single-user application.
+     * The tuning parameters in this pool are subject to change in future OkHttp releases. Currently
+     * this pool holds up to 5 idle connections which will be evicted after 5 minutes of inactivity.
+     */
+    public ConnectionPool() {
+        this(5, 5, TimeUnit.MINUTES);
     }
-    return total;
-  }
-
-  /**
-   * Returns total number of connections in the pool. Note that prior to OkHttp 2.7 this included
-   * only idle connections and HTTP/2 connections. Since OkHttp 2.7 this includes all connections,
-   * both active and inactive. Use {@link #idleConnectionCount()} to count connections not currently
-   * in use.
-   */
-  public synchronized int connectionCount() {
-    return connections.size();
-  }
-
-  /**
-   * Returns a recycled connection to {@code address}, or null if no such connection exists. The
-   * route is null if the address has not yet been routed.
-   */
-  @Nullable RealConnection get(Address address, StreamAllocation streamAllocation, Route route) {
-    assert (Thread.holdsLock(this));
-    for (RealConnection connection : connections) {
-      if (connection.isEligible(address, route)) {
-        streamAllocation.acquire(connection, true);
-        return connection;
-      }
+
+    public ConnectionPool(int maxIdleConnections, long keepAliveDuration, TimeUnit timeUnit) {
+        this.maxIdleConnections = maxIdleConnections;
+        this.keepAliveDurationNs = timeUnit.toNanos(keepAliveDuration);
+
+        // Put a floor on the keep alive duration, otherwise cleanup will spin loop.
+        if (keepAliveDuration <= 0) {
+            throw new IllegalArgumentException("keepAliveDuration <= 0: " + keepAliveDuration);
+        }
     }
-    return null;
-  }
-
-  /**
-   * Replaces the connection held by {@code streamAllocation} with a shared connection if possible.
-   * This recovers when multiple multiplexed connections are created concurrently.
-   */
-  @Nullable Socket deduplicate(Address address, StreamAllocation streamAllocation) {
-    assert (Thread.holdsLock(this));
-    for (RealConnection connection : connections) {
-      if (connection.isEligible(address, null)
-          && connection.isMultiplexed()
-          && connection != streamAllocation.connection()) {
-        return streamAllocation.releaseAndAcquire(connection);
-      }
+
+    /**
+     * Returns the number of idle connections in the pool.
+     */
+    public synchronized int idleConnectionCount() {
+        int total = 0;
+        for (RealConnection connection : connections) {
+            if (connection.allocations.isEmpty()) total++;
+        }
+        return total;
     }
-    return null;
-  }
-
-  void put(RealConnection connection) {
-    assert (Thread.holdsLock(this));
-    if (!cleanupRunning) {
-      cleanupRunning = true;
-      executor.execute(cleanupRunnable);
+
+    /**
+     * Returns total number of connections in the pool. Note that prior to OkHttp 2.7 this included
+     * only idle connections and HTTP/2 connections. Since OkHttp 2.7 this includes all connections,
+     * both active and inactive. Use {@link #idleConnectionCount()} to count connections not currently
+     * in use.
+     */
+    public synchronized int connectionCount() {
+        return connections.size();
     }
-    connections.add(connection);
-  }
-
-  /**
-   * Notify this pool that {@code connection} has become idle. Returns true if the connection has
-   * been removed from the pool and should be closed.
-   */
-  boolean connectionBecameIdle(RealConnection connection) {
-    assert (Thread.holdsLock(this));
-    if (connection.noNewStreams || maxIdleConnections == 0) {
-      connections.remove(connection);
-      return true;
-    } else {
-      notifyAll(); // Awake the cleanup thread: we may have exceeded the idle connection limit.
-      return false;
+
+    /**
+     * Returns a recycled connection to {@code address}, or null if no such connection exists. The
+     * route is null if the address has not yet been routed.
+     */
+    @Nullable
+    RealConnection get(Address address, StreamAllocation streamAllocation, Route route) {
+        assert (Thread.holdsLock(this));
+        for (RealConnection connection : connections) {
+            //如果这个connection可用
+            if (connection.isEligible(address, route)) {
+                // 在connection的allocations（引用记录列表List<Reference<StreamAllocation>>）
+                // 中加入streamAllocation
+                streamAllocation.acquire(connection, true);
+                return connection;
+            }
+        }
+        return null;
     }
-  }
-
-  /** Close and remove all idle connections in the pool. */
-  public void evictAll() {
-    List<RealConnection> evictedConnections = new ArrayList<>();
-    synchronized (this) {
-      for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
-        RealConnection connection = i.next();
-        if (connection.allocations.isEmpty()) {
-          connection.noNewStreams = true;
-          evictedConnections.add(connection);
-          i.remove();
+
+    /**
+     * Replaces the connection held by {@code streamAllocation} with a shared connection if possible.
+     * This recovers when multiple multiplexed connections are created concurrently.
+     */
+    @Nullable
+    Socket deduplicate(Address address, StreamAllocation streamAllocation) {
+        assert (Thread.holdsLock(this));
+        for (RealConnection connection : connections) {
+            if (connection.isEligible(address, null)
+                    && connection.isMultiplexed()
+                    && connection != streamAllocation.connection()) {
+                return streamAllocation.releaseAndAcquire(connection);
+            }
         }
-      }
+        return null;
     }
 
-    for (RealConnection connection : evictedConnections) {
-      closeQuietly(connection.socket());
+    /**
+     * 用户socket连接成功，向连接池中put新的socket
+     * 会调用回收函数，线程池就会执行cleanupRunnable
+     *
+     * @param connection
+     */
+    void put(RealConnection connection) {
+        assert (Thread.holdsLock(this));
+        if (!cleanupRunning) {
+            cleanupRunning = true;
+            executor.execute(cleanupRunnable);
+        }
+        connections.add(connection);
     }
-  }
-
-  /**
-   * Performs maintenance on this pool, evicting the connection that has been idle the longest if
-   * either it has exceeded the keep alive limit or the idle connections limit.
-   *
-   * <p>Returns the duration in nanos to sleep until the next scheduled call to this method. Returns
-   * -1 if no further cleanups are required.
-   */
-  long cleanup(long now) {
-    int inUseConnectionCount = 0;
-    int idleConnectionCount = 0;
-    RealConnection longestIdleConnection = null;
-    long longestIdleDurationNs = Long.MIN_VALUE;
-
-    // Find either a connection to evict, or the time that the next eviction is due.
-    synchronized (this) {
-      for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
-        RealConnection connection = i.next();
-
-        // If the connection is in use, keep searching.
-        if (pruneAndGetAllocationCount(connection, now) > 0) {
-          inUseConnectionCount++;
-          continue;
+
+    /**
+     * Notify this pool that {@code connection} has become idle. Returns true if the connection has
+     * been removed from the pool and should be closed.
+     * <p>
+     * connection变成空闲。在{@link StreamAllocation#deallocate(boolean, boolean, boolean)}中调用。
+     * 返回true表示connection已经从连接池中移除，需要进行关闭。
+     * 只是空闲，还不需要立即关闭的，唤醒清理线程池线程，返回false
+     */
+    boolean connectionBecameIdle(RealConnection connection) {
+        assert (Thread.holdsLock(this));
+        if (connection.noNewStreams || maxIdleConnections == 0) {
+            connections.remove(connection);
+            return true;
+        } else {
+            notifyAll(); // Awake the cleanup thread: we may have exceeded the idle connection limit.
+            return false;
         }
+    }
 
-        idleConnectionCount++;
+    /**
+     * Close and remove all idle connections in the pool.
+     * 关闭和清理所有空闲的连接
+     */
+    public void evictAll() {
+        List<RealConnection> evictedConnections = new ArrayList<>();
+        synchronized (this) {
+            for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
+                RealConnection connection = i.next();
+                if (connection.allocations.isEmpty()) {
+                    connection.noNewStreams = true;
+                    evictedConnections.add(connection);
+                    i.remove();
+                }
+            }
+        }
 
-        // If the connection is ready to be evicted, we're done.
-        long idleDurationNs = now - connection.idleAtNanos;
-        if (idleDurationNs > longestIdleDurationNs) {
-          longestIdleDurationNs = idleDurationNs;
-          longestIdleConnection = connection;
+        for (RealConnection connection : evictedConnections) {
+            closeQuietly(connection.socket());
         }
-      }
-
-      if (longestIdleDurationNs >= this.keepAliveDurationNs
-          || idleConnectionCount > this.maxIdleConnections) {
-        // We've found a connection to evict. Remove it from the list, then close it below (outside
-        // of the synchronized block).
-        connections.remove(longestIdleConnection);
-      } else if (idleConnectionCount > 0) {
-        // A connection will be ready to evict soon.
-        return keepAliveDurationNs - longestIdleDurationNs;
-      } else if (inUseConnectionCount > 0) {
-        // All connections are in use. It'll be at least the keep alive duration 'til we run again.
-        return keepAliveDurationNs;
-      } else {
-        // No connections, idle or in use.
-        cleanupRunning = false;
-        return -1;
-      }
     }
 
-    closeQuietly(longestIdleConnection.socket());
-
-    // Cleanup again immediately.
-    return 0;
-  }
-
-  /**
-   * Prunes any leaked allocations and then returns the number of remaining live allocations on
-   * {@code connection}. Allocations are leaked if the connection is tracking them but the
-   * application code has abandoned them. Leak detection is imprecise and relies on garbage
-   * collection.
-   */
-  private int pruneAndGetAllocationCount(RealConnection connection, long now) {
-    List<Reference<StreamAllocation>> references = connection.allocations;
-    for (int i = 0; i < references.size(); ) {
-      Reference<StreamAllocation> reference = references.get(i);
-
-      if (reference.get() != null) {
-        i++;
-        continue;
-      }
-
-      // We've discovered a leaked allocation. This is an application bug.
-      StreamAllocation.StreamAllocationReference streamAllocRef =
-          (StreamAllocation.StreamAllocationReference) reference;
-      String message = "A connection to " + connection.route().address().url()
-          + " was leaked. Did you forget to close a response body?";
-      Platform.get().logCloseableLeak(message, streamAllocRef.callStackTrace);
-
-      references.remove(i);
-      connection.noNewStreams = true;
-
-      // If this was the last allocation, the connection is eligible for immediate eviction.
-      if (references.isEmpty()) {
-        connection.idleAtNanos = now - keepAliveDurationNs;
+    /**
+     * Performs maintenance on this pool, evicting the connection that has been idle the longest if
+     * either it has exceeded the keep alive limit or the idle connections limit.
+     * <p>
+     * <p>Returns the duration in nanos to sleep until the next scheduled call to this method. Returns
+     * -1 if no further cleanups are required.
+     * <p>
+     * 使用了类似于GC的标记-清除算法，也就是首先标记出最不活跃的连接(我们可以叫做泄漏连接，或者空闲连接)，
+     * 接着进行清除
+     */
+    long cleanup(long now) {
+        int inUseConnectionCount = 0;
+        int idleConnectionCount = 0;
+        // 记录空闲时间最长的connection
+        RealConnection longestIdleConnection = null;
+        // 记录空闲时间最长的connection空闲的时间
+        long longestIdleDurationNs = Long.MIN_VALUE;
+
+        // Find either a connection to evict, or the time that the next eviction is due.
+        synchronized (this) {
+            // 遍历Deque中所有的RealConnection
+            for (Iterator<RealConnection> i = connections.iterator(); i.hasNext(); ) {
+                RealConnection connection = i.next();
+
+                // If the connection is in use, keep searching.
+                // 查询此连接内部StreamAllocation的引用数量，大于0就是in use，否则为空闲
+                if (pruneAndGetAllocationCount(connection, now) > 0) {
+                    inUseConnectionCount++;
+                    continue;
+                }
+
+                idleConnectionCount++;
+
+                // If the connection is ready to be evicted, we're done.
+                // 找出空闲时间最长的connection
+                long idleDurationNs = now - connection.idleAtNanos;
+                if (idleDurationNs > longestIdleDurationNs) {
+                    longestIdleDurationNs = idleDurationNs;
+                    longestIdleConnection = connection;
+                }
+            }
+
+            // 如果最长空闲时间大于keepAliveDurationNs（默认是5min）
+            // 或者空闲connection数大于maxIdleConnections（默认为5）
+            // 从connections中移除，并在下面关闭，返回0，即需要立即再次清理
+            // 其他情况返回下次执行清理的时间，没有connection返回-1
+            if (longestIdleDurationNs >= this.keepAliveDurationNs
+                    || idleConnectionCount > this.maxIdleConnections) {
+                // We've found a connection to evict. Remove it from the list, then close it below (outside
+                // of the synchronized block).
+                connections.remove(longestIdleConnection);
+            } else if (idleConnectionCount > 0) {
+                // A connection will be ready to evict soon.
+                return keepAliveDurationNs - longestIdleDurationNs;
+            } else if (inUseConnectionCount > 0) {
+                // All connections are in use. It'll be at least the keep alive duration 'til we run again.
+                return keepAliveDurationNs;
+            } else {
+                // No connections, idle or in use.
+                cleanupRunning = false;
+                return -1;
+            }
+        }
+
+        closeQuietly(longestIdleConnection.socket());
+
+        // Cleanup again immediately.
         return 0;
-      }
     }
 
-    return references.size();
-  }
+    /**
+     * Prunes any leaked allocations and then returns the number of remaining live allocations on
+     * {@code connection}. Allocations are leaked if the connection is tracking them but the
+     * application code has abandoned them. Leak detection is imprecise and relies on garbage
+     * collection.
+     * <p>
+     * 清理connection中的allocation列表中已经为空（泄漏）的弱引用，返回非空的引用数
+     */
+    private int pruneAndGetAllocationCount(RealConnection connection, long now) {
+        List<Reference<StreamAllocation>> references = connection.allocations;
+        for (int i = 0; i < references.size(); ) {
+            Reference<StreamAllocation> reference = references.get(i);
+
+            //如果正在被使用，计数，跳过，接着循环
+            if (reference.get() != null) {
+                i++;
+                continue;
+            }
+
+            // We've discovered a leaked allocation. This is an application bug.
+            StreamAllocation.StreamAllocationReference streamAllocRef =
+                    (StreamAllocation.StreamAllocationReference) reference;
+            String message = "A connection to " + connection.route().address().url()
+                    + " was leaked. Did you forget to close a response body?";
+            Platform.get().logCloseableLeak(message, streamAllocRef.callStackTrace);
+
+            //否则移除引用，且不再给这个connection分配新的Stream
+            references.remove(i);
+            connection.noNewStreams = true;
+
+            // If this was the last allocation, the connection is eligible for immediate eviction.
+            // 如果所有分配的流都泄漏然后被remove了
+            // （这不是正常的空闲）标记已经空闲时间为keepAliveDurationNs（表示需要立即清理）
+            if (references.isEmpty()) {
+                connection.idleAtNanos = now - keepAliveDurationNs;
+                return 0;
+            }
+        }
+
+        // 返回清理后的引用数
+        return references.size();
+    }
 }
diff --git a/okhttp/src/main/java/okhttp3/Dispatcher.java b/okhttp/src/main/java/okhttp3/Dispatcher.java
index 43f5aa48e7..4089d83bed 100644
--- a/okhttp/src/main/java/okhttp3/Dispatcher.java
+++ b/okhttp/src/main/java/okhttp3/Dispatcher.java
@@ -26,211 +26,253 @@
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 import javax.annotation.Nullable;
+
 import okhttp3.RealCall.AsyncCall;
 import okhttp3.internal.Util;
 
 /**
  * Policy on when async requests are executed.
- *
+ * <p>
  * <p>Each dispatcher uses an {@link ExecutorService} to run calls internally. If you supply your
  * own executor, it should be able to run {@linkplain #getMaxRequests the configured maximum} number
  * of calls concurrently.
  */
 public final class Dispatcher {
-  private int maxRequests = 64;
-  private int maxRequestsPerHost = 5;
-  private @Nullable Runnable idleCallback;
-
-  /** Executes calls. Created lazily. */
-  private @Nullable ExecutorService executorService;
-
-  /** Ready async calls in the order they'll be run. */
-  private final Deque<AsyncCall> readyAsyncCalls = new ArrayDeque<>();
-
-  /** Running asynchronous calls. Includes canceled calls that haven't finished yet. */
-  private final Deque<AsyncCall> runningAsyncCalls = new ArrayDeque<>();
-
-  /** Running synchronous calls. Includes canceled calls that haven't finished yet. */
-  private final Deque<RealCall> runningSyncCalls = new ArrayDeque<>();
-
-  public Dispatcher(ExecutorService executorService) {
-    this.executorService = executorService;
-  }
-
-  public Dispatcher() {
-  }
-
-  public synchronized ExecutorService executorService() {
-    if (executorService == null) {
-      executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS,
-          new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp Dispatcher", false));
-    }
-    return executorService;
-  }
-
-  /**
-   * Set the maximum number of requests to execute concurrently. Above this requests queue in
-   * memory, waiting for the running calls to complete.
-   *
-   * <p>If more than {@code maxRequests} requests are in flight when this is invoked, those requests
-   * will remain in flight.
-   */
-  public synchronized void setMaxRequests(int maxRequests) {
-    if (maxRequests < 1) {
-      throw new IllegalArgumentException("max < 1: " + maxRequests);
-    }
-    this.maxRequests = maxRequests;
-    promoteCalls();
-  }
-
-  public synchronized int getMaxRequests() {
-    return maxRequests;
-  }
-
-  /**
-   * Set the maximum number of requests for each host to execute concurrently. This limits requests
-   * by the URL's host name. Note that concurrent requests to a single IP address may still exceed
-   * this limit: multiple hostnames may share an IP address or be routed through the same HTTP
-   * proxy.
-   *
-   * <p>If more than {@code maxRequestsPerHost} requests are in flight when this is invoked, those
-   * requests will remain in flight.
-   */
-  public synchronized void setMaxRequestsPerHost(int maxRequestsPerHost) {
-    if (maxRequestsPerHost < 1) {
-      throw new IllegalArgumentException("max < 1: " + maxRequestsPerHost);
-    }
-    this.maxRequestsPerHost = maxRequestsPerHost;
-    promoteCalls();
-  }
-
-  public synchronized int getMaxRequestsPerHost() {
-    return maxRequestsPerHost;
-  }
-
-  /**
-   * Set a callback to be invoked each time the dispatcher becomes idle (when the number of running
-   * calls returns to zero).
-   *
-   * <p>Note: The time at which a {@linkplain Call call} is considered idle is different depending
-   * on whether it was run {@linkplain Call#enqueue(Callback) asynchronously} or
-   * {@linkplain Call#execute() synchronously}. Asynchronous calls become idle after the
-   * {@link Callback#onResponse onResponse} or {@link Callback#onFailure onFailure} callback has
-   * returned. Synchronous calls become idle once {@link Call#execute() execute()} returns. This
-   * means that if you are doing synchronous calls the network layer will not truly be idle until
-   * every returned {@link Response} has been closed.
-   */
-  public synchronized void setIdleCallback(@Nullable Runnable idleCallback) {
-    this.idleCallback = idleCallback;
-  }
-
-  synchronized void enqueue(AsyncCall call) {
-    if (runningAsyncCalls.size() < maxRequests && runningCallsForHost(call) < maxRequestsPerHost) {
-      runningAsyncCalls.add(call);
-      executorService().execute(call);
-    } else {
-      readyAsyncCalls.add(call);
-    }
-  }
-
-  /**
-   * Cancel all calls currently enqueued or executing. Includes calls executed both {@linkplain
-   * Call#execute() synchronously} and {@linkplain Call#enqueue asynchronously}.
-   */
-  public synchronized void cancelAll() {
-    for (AsyncCall call : readyAsyncCalls) {
-      call.get().cancel();
-    }
-
-    for (AsyncCall call : runningAsyncCalls) {
-      call.get().cancel();
-    }
-
-    for (RealCall call : runningSyncCalls) {
-      call.cancel();
-    }
-  }
-
-  private void promoteCalls() {
-    if (runningAsyncCalls.size() >= maxRequests) return; // Already running max capacity.
-    if (readyAsyncCalls.isEmpty()) return; // No ready calls to promote.
-
-    for (Iterator<AsyncCall> i = readyAsyncCalls.iterator(); i.hasNext(); ) {
-      AsyncCall call = i.next();
-
-      if (runningCallsForHost(call) < maxRequestsPerHost) {
-        i.remove();
-        runningAsyncCalls.add(call);
-        executorService().execute(call);
-      }
-
-      if (runningAsyncCalls.size() >= maxRequests) return; // Reached max capacity.
-    }
-  }
-
-  /** Returns the number of running calls that share a host with {@code call}. */
-  private int runningCallsForHost(AsyncCall call) {
-    int result = 0;
-    for (AsyncCall c : runningAsyncCalls) {
-      if (c.host().equals(call.host())) result++;
-    }
-    return result;
-  }
-
-  /** Used by {@code Call#execute} to signal it is in-flight. */
-  synchronized void executed(RealCall call) {
-    runningSyncCalls.add(call);
-  }
-
-  /** Used by {@code AsyncCall#run} to signal completion. */
-  void finished(AsyncCall call) {
-    finished(runningAsyncCalls, call, true);
-  }
-
-  /** Used by {@code Call#execute} to signal completion. */
-  void finished(RealCall call) {
-    finished(runningSyncCalls, call, false);
-  }
-
-  private <T> void finished(Deque<T> calls, T call, boolean promoteCalls) {
-    int runningCallsCount;
+    /**
+     * 最大并发请求数
+     */
+    private int maxRequests = 64;
+    /**
+     * 每个主机最大请求数
+     */
+    private int maxRequestsPerHost = 5;
+    private @Nullable
     Runnable idleCallback;
-    synchronized (this) {
-      if (!calls.remove(call)) throw new AssertionError("Call wasn't in-flight!");
-      if (promoteCalls) promoteCalls();
-      runningCallsCount = runningCallsCount();
-      idleCallback = this.idleCallback;
+
+    /**
+     * Executes calls. Created lazily.
+     * 消费者线程池
+     */
+    private @Nullable
+    ExecutorService executorService;
+
+    /**
+     * Ready async calls in the order they'll be run.
+     */
+    private final Deque<AsyncCall> readyAsyncCalls = new ArrayDeque<>();
+
+    /**
+     * Running asynchronous calls. Includes canceled calls that haven't finished yet.
+     */
+    private final Deque<AsyncCall> runningAsyncCalls = new ArrayDeque<>();
+
+    /**
+     * Running synchronous calls. Includes canceled calls that haven't finished yet.
+     */
+    private final Deque<RealCall> runningSyncCalls = new ArrayDeque<>();
+
+    public Dispatcher(ExecutorService executorService) {
+        this.executorService = executorService;
     }
 
-    if (runningCallsCount == 0 && idleCallback != null) {
-      idleCallback.run();
+    public Dispatcher() {
     }
-  }
 
-  /** Returns a snapshot of the calls currently awaiting execution. */
-  public synchronized List<Call> queuedCalls() {
-    List<Call> result = new ArrayList<>();
-    for (AsyncCall asyncCall : readyAsyncCalls) {
-      result.add(asyncCall.get());
+    public synchronized ExecutorService executorService() {
+        if (executorService == null) {
+            executorService = new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60, TimeUnit.SECONDS,
+                    new SynchronousQueue<Runnable>(), Util.threadFactory("OkHttp Dispatcher", false));
+        }
+        return executorService;
     }
-    return Collections.unmodifiableList(result);
-  }
 
-  /** Returns a snapshot of the calls currently being executed. */
-  public synchronized List<Call> runningCalls() {
-    List<Call> result = new ArrayList<>();
-    result.addAll(runningSyncCalls);
-    for (AsyncCall asyncCall : runningAsyncCalls) {
-      result.add(asyncCall.get());
+    /**
+     * Set the maximum number of requests to execute concurrently. Above this requests queue in
+     * memory, waiting for the running calls to complete.
+     * <p>
+     * <p>If more than {@code maxRequests} requests are in flight when this is invoked, those requests
+     * will remain in flight.
+     */
+    public synchronized void setMaxRequests(int maxRequests) {
+        if (maxRequests < 1) {
+            throw new IllegalArgumentException("max < 1: " + maxRequests);
+        }
+        this.maxRequests = maxRequests;
+        promoteCalls();
     }
-    return Collections.unmodifiableList(result);
-  }
 
-  public synchronized int queuedCallsCount() {
-    return readyAsyncCalls.size();
-  }
+    public synchronized int getMaxRequests() {
+        return maxRequests;
+    }
 
-  public synchronized int runningCallsCount() {
-    return runningAsyncCalls.size() + runningSyncCalls.size();
-  }
+    /**
+     * Set the maximum number of requests for each host to execute concurrently. This limits requests
+     * by the URL's host name. Note that concurrent requests to a single IP address may still exceed
+     * this limit: multiple hostnames may share an IP address or be routed through the same HTTP
+     * proxy.
+     * <p>
+     * <p>If more than {@code maxRequestsPerHost} requests are in flight when this is invoked, those
+     * requests will remain in flight.
+     */
+    public synchronized void setMaxRequestsPerHost(int maxRequestsPerHost) {
+        if (maxRequestsPerHost < 1) {
+            throw new IllegalArgumentException("max < 1: " + maxRequestsPerHost);
+        }
+        this.maxRequestsPerHost = maxRequestsPerHost;
+        promoteCalls();
+    }
+
+    public synchronized int getMaxRequestsPerHost() {
+        return maxRequestsPerHost;
+    }
+
+    /**
+     * Set a callback to be invoked each time the dispatcher becomes idle (when the number of running
+     * calls returns to zero).
+     * <p>
+     * <p>Note: The time at which a {@linkplain Call call} is considered idle is different depending
+     * on whether it was run {@linkplain Call#enqueue(Callback) asynchronously} or
+     * {@linkplain Call#execute() synchronously}. Asynchronous calls become idle after the
+     * {@link Callback#onResponse onResponse} or {@link Callback#onFailure onFailure} callback has
+     * returned. Synchronous calls become idle once {@link Call#execute() execute()} returns. This
+     * means that if you are doing synchronous calls the network layer will not truly be idle until
+     * every returned {@link Response} has been closed.
+     */
+    public synchronized void setIdleCallback(@Nullable Runnable idleCallback) {
+        this.idleCallback = idleCallback;
+    }
+
+    /**
+     * 如果满足条件，那么就直接把AsyncCall直接加到runningCalls的队列中，并在线程池中执行
+     * （线程池会根据当前负载自动创建，销毁，缓存相应的线程）。
+     * 反之就放入readyAsyncCalls进行缓存等待。
+     *
+     * @param call
+     */
+    synchronized void enqueue(AsyncCall call) {
+        if (runningAsyncCalls.size() < maxRequests && runningCallsForHost(call) < maxRequestsPerHost) {
+            runningAsyncCalls.add(call);
+            executorService().execute(call);
+        } else {
+            readyAsyncCalls.add(call);
+        }
+    }
+
+    /**
+     * Cancel all calls currently enqueued or executing. Includes calls executed both {@linkplain
+     * Call#execute() synchronously} and {@linkplain Call#enqueue asynchronously}.
+     */
+    public synchronized void cancelAll() {
+        for (AsyncCall call : readyAsyncCalls) {
+            call.get().cancel();
+        }
+
+        for (AsyncCall call : runningAsyncCalls) {
+            call.get().cancel();
+        }
+
+        for (RealCall call : runningSyncCalls) {
+            call.cancel();
+        }
+    }
+
+    private void promoteCalls() {
+        //如果目前是最大负荷运转，接着等
+        if (runningAsyncCalls.size() >= maxRequests) return; // Already running max capacity.
+        //如果缓存等待区是空的，接着等
+        if (readyAsyncCalls.isEmpty()) return; // No ready calls to promote.
+
+        for (Iterator<AsyncCall> i = readyAsyncCalls.iterator(); i.hasNext(); ) {
+            AsyncCall call = i.next();
+
+            // call的目标主机的正在执行的请求数 < maxRequestsPerHost
+            if (runningCallsForHost(call) < maxRequestsPerHost) {
+                // 将call移动到running的队列，并执行
+                i.remove();
+                runningAsyncCalls.add(call);
+                executorService().execute(call);
+            }
+
+            if (runningAsyncCalls.size() >= maxRequests) return; // Reached max capacity.
+        }
+    }
+
+    /**
+     * Returns the number of running calls that share a host with {@code call}.
+     */
+    private int runningCallsForHost(AsyncCall call) {
+        int result = 0;
+        for (AsyncCall c : runningAsyncCalls) {
+            if (c.host().equals(call.host())) result++;
+        }
+        return result;
+    }
+
+    /**
+     * Used by {@code Call#execute} to signal it is in-flight.
+     */
+    synchronized void executed(RealCall call) {
+        runningSyncCalls.add(call);
+    }
+
+    /**
+     * Used by {@code AsyncCall#run} to signal completion.
+     * 从runningSyncCalls中移除call，并调用{@link #promoteCalls()}，将开始一些正在等待的任务
+     */
+    void finished(AsyncCall call) {
+        finished(runningAsyncCalls, call, true);
+    }
+
+    /**
+     * Used by {@code Call#execute} to signal completion.
+     */
+    void finished(RealCall call) {
+        finished(runningSyncCalls, call, false);
+    }
+
+    private <T> void finished(Deque<T> calls, T call, boolean promoteCalls) {
+        int runningCallsCount;
+        Runnable idleCallback;
+        synchronized (this) {
+            if (!calls.remove(call)) throw new AssertionError("Call wasn't in-flight!");
+            if (promoteCalls) promoteCalls();
+            runningCallsCount = runningCallsCount();
+            idleCallback = this.idleCallback;
+        }
+
+        if (runningCallsCount == 0 && idleCallback != null) {
+            idleCallback.run();
+        }
+    }
+
+    /**
+     * Returns a snapshot of the calls currently awaiting execution.
+     */
+    public synchronized List<Call> queuedCalls() {
+        List<Call> result = new ArrayList<>();
+        for (AsyncCall asyncCall : readyAsyncCalls) {
+            result.add(asyncCall.get());
+        }
+        return Collections.unmodifiableList(result);
+    }
+
+    /**
+     * Returns a snapshot of the calls currently being executed.
+     */
+    public synchronized List<Call> runningCalls() {
+        List<Call> result = new ArrayList<>();
+        result.addAll(runningSyncCalls);
+        for (AsyncCall asyncCall : runningAsyncCalls) {
+            result.add(asyncCall.get());
+        }
+        return Collections.unmodifiableList(result);
+    }
+
+    public synchronized int queuedCallsCount() {
+        return readyAsyncCalls.size();
+    }
+
+    public synchronized int runningCallsCount() {
+        return runningAsyncCalls.size() + runningSyncCalls.size();
+    }
 }
diff --git a/okhttp/src/main/java/okhttp3/OkHttpClient.java b/okhttp/src/main/java/okhttp3/OkHttpClient.java
index f69cab89ba..7a7309c75c 100644
--- a/okhttp/src/main/java/okhttp3/OkHttpClient.java
+++ b/okhttp/src/main/java/okhttp3/OkHttpClient.java
@@ -38,6 +38,7 @@
 import javax.net.ssl.TrustManager;
 import javax.net.ssl.TrustManagerFactory;
 import javax.net.ssl.X509TrustManager;
+
 import okhttp3.internal.Internal;
 import okhttp3.internal.Util;
 import okhttp3.internal.cache.InternalCache;
@@ -55,21 +56,21 @@
 /**
  * Factory for {@linkplain Call calls}, which can be used to send HTTP requests and read their
  * responses.
- *
+ * <p>
  * <h3>OkHttpClients should be shared</h3>
- *
+ * <p>
  * <p>OkHttp performs best when you create a single {@code OkHttpClient} instance and reuse it for
  * all of your HTTP calls. This is because each client holds its own connection pool and thread
  * pools. Reusing connections and threads reduces latency and saves memory. Conversely, creating a
  * client for each request wastes resources on idle pools.
- *
+ * <p>
  * <p>Use {@code new OkHttpClient()} to create a shared instance with the default settings:
  * <pre>   {@code
  *
  *   // The singleton HTTP client.
  *   public final OkHttpClient client = new OkHttpClient();
  * }</pre>
- *
+ * <p>
  * <p>Or use {@code new OkHttpClient.Builder()} to create a shared instance with custom settings:
  * <pre>   {@code
  *
@@ -79,839 +80,878 @@
  *       .cache(new Cache(cacheDir, cacheSize))
  *       .build();
  * }</pre>
- *
+ * <p>
  * <h3>Customize your client with newBuilder()</h3>
- *
+ * <p>
  * <p>You can customize a shared OkHttpClient instance with {@link #newBuilder()}. This builds a
  * client that shares the same connection pool, thread pools, and configuration. Use the builder
  * methods to configure the derived client for a specific purpose.
- *
+ * <p>
  * <p>This example shows a call with a short 500 millisecond timeout: <pre>   {@code
- *
+ * <p>
  *   OkHttpClient eagerClient = client.newBuilder()
  *       .readTimeout(500, TimeUnit.MILLISECONDS)
  *       .build();
  *   Response response = eagerClient.newCall(request).execute();
  * }</pre>
- *
+ * <p>
  * <h3>Shutdown isn't necessary</h3>
- *
+ * <p>
  * <p>The threads and connections that are held will be released automatically if they remain idle.
  * But if you are writing a application that needs to aggressively release unused resources you may
  * do so.
- *
+ * <p>
  * <p>Shutdown the dispatcher's executor service with {@link ExecutorService#shutdown shutdown()}.
  * This will also cause future calls to the client to be rejected. <pre>   {@code
- *
+ * <p>
  *     client.dispatcher().executorService().shutdown();
  * }</pre>
- *
+ * <p>
  * <p>Clear the connection pool with {@link ConnectionPool#evictAll() evictAll()}. Note that the
  * connection pool's daemon thread may not exit immediately. <pre>   {@code
- *
+ * <p>
  *     client.connectionPool().evictAll();
  * }</pre>
- *
+ * <p>
  * <p>If your client has a cache, call {@link Cache#close close()}. Note that it is an error to
  * create calls against a cache that is closed, and doing so will cause the call to crash.
  * <pre>   {@code
  *
  *     client.cache().close();
  * }</pre>
- *
+ * <p>
  * <p>OkHttp also uses daemon threads for HTTP/2 connections. These will exit automatically if they
  * remain idle.
  */
 public class OkHttpClient implements Cloneable, Call.Factory, WebSocket.Factory {
-  static final List<Protocol> DEFAULT_PROTOCOLS = Util.immutableList(
-      Protocol.HTTP_2, Protocol.HTTP_1_1);
-
-  static final List<ConnectionSpec> DEFAULT_CONNECTION_SPECS = Util.immutableList(
-      ConnectionSpec.MODERN_TLS, ConnectionSpec.CLEARTEXT);
-
-  static {
-    Internal.instance = new Internal() {
-      @Override public void addLenient(Headers.Builder builder, String line) {
-        builder.addLenient(line);
-      }
-
-      @Override public void addLenient(Headers.Builder builder, String name, String value) {
-        builder.addLenient(name, value);
-      }
-
-      @Override public void setCache(OkHttpClient.Builder builder, InternalCache internalCache) {
-        builder.setInternalCache(internalCache);
-      }
-
-      @Override public boolean connectionBecameIdle(
-          ConnectionPool pool, RealConnection connection) {
-        return pool.connectionBecameIdle(connection);
-      }
-
-      @Override public RealConnection get(ConnectionPool pool, Address address,
-          StreamAllocation streamAllocation, Route route) {
-        return pool.get(address, streamAllocation, route);
-      }
-
-      @Override public boolean equalsNonHost(Address a, Address b) {
-        return a.equalsNonHost(b);
-      }
-
-      @Override public Socket deduplicate(
-          ConnectionPool pool, Address address, StreamAllocation streamAllocation) {
-        return pool.deduplicate(address, streamAllocation);
-      }
-
-      @Override public void put(ConnectionPool pool, RealConnection connection) {
-        pool.put(connection);
-      }
-
-      @Override public RouteDatabase routeDatabase(ConnectionPool connectionPool) {
-        return connectionPool.routeDatabase;
-      }
-
-      @Override public int code(Response.Builder responseBuilder) {
-        return responseBuilder.code;
-      }
-
-      @Override
-      public void apply(ConnectionSpec tlsConfiguration, SSLSocket sslSocket, boolean isFallback) {
-        tlsConfiguration.apply(sslSocket, isFallback);
-      }
-
-      @Override public HttpUrl getHttpUrlChecked(String url)
-          throws MalformedURLException, UnknownHostException {
-        return HttpUrl.getChecked(url);
-      }
-
-      @Override public StreamAllocation streamAllocation(Call call) {
-        return ((RealCall) call).streamAllocation();
-      }
-
-      @Override public Call newWebSocketCall(OkHttpClient client, Request originalRequest) {
-        return RealCall.newRealCall(client, originalRequest, true);
-      }
-    };
-  }
-
-  final Dispatcher dispatcher;
-  final @Nullable Proxy proxy;
-  final List<Protocol> protocols;
-  final List<ConnectionSpec> connectionSpecs;
-  final List<Interceptor> interceptors;
-  final List<Interceptor> networkInterceptors;
-  final EventListener.Factory eventListenerFactory;
-  final ProxySelector proxySelector;
-  final CookieJar cookieJar;
-  final @Nullable Cache cache;
-  final @Nullable InternalCache internalCache;
-  final SocketFactory socketFactory;
-  final @Nullable SSLSocketFactory sslSocketFactory;
-  final @Nullable CertificateChainCleaner certificateChainCleaner;
-  final HostnameVerifier hostnameVerifier;
-  final CertificatePinner certificatePinner;
-  final Authenticator proxyAuthenticator;
-  final Authenticator authenticator;
-  final ConnectionPool connectionPool;
-  final Dns dns;
-  final boolean followSslRedirects;
-  final boolean followRedirects;
-  final boolean retryOnConnectionFailure;
-  final int connectTimeout;
-  final int readTimeout;
-  final int writeTimeout;
-  final int pingInterval;
-
-  public OkHttpClient() {
-    this(new Builder());
-  }
-
-  OkHttpClient(Builder builder) {
-    this.dispatcher = builder.dispatcher;
-    this.proxy = builder.proxy;
-    this.protocols = builder.protocols;
-    this.connectionSpecs = builder.connectionSpecs;
-    this.interceptors = Util.immutableList(builder.interceptors);
-    this.networkInterceptors = Util.immutableList(builder.networkInterceptors);
-    this.eventListenerFactory = builder.eventListenerFactory;
-    this.proxySelector = builder.proxySelector;
-    this.cookieJar = builder.cookieJar;
-    this.cache = builder.cache;
-    this.internalCache = builder.internalCache;
-    this.socketFactory = builder.socketFactory;
-
-    boolean isTLS = false;
-    for (ConnectionSpec spec : connectionSpecs) {
-      isTLS = isTLS || spec.isTls();
-    }
-
-    if (builder.sslSocketFactory != null || !isTLS) {
-      this.sslSocketFactory = builder.sslSocketFactory;
-      this.certificateChainCleaner = builder.certificateChainCleaner;
-    } else {
-      X509TrustManager trustManager = systemDefaultTrustManager();
-      this.sslSocketFactory = systemDefaultSslSocketFactory(trustManager);
-      this.certificateChainCleaner = CertificateChainCleaner.get(trustManager);
-    }
-
-    this.hostnameVerifier = builder.hostnameVerifier;
-    this.certificatePinner = builder.certificatePinner.withCertificateChainCleaner(
-        certificateChainCleaner);
-    this.proxyAuthenticator = builder.proxyAuthenticator;
-    this.authenticator = builder.authenticator;
-    this.connectionPool = builder.connectionPool;
-    this.dns = builder.dns;
-    this.followSslRedirects = builder.followSslRedirects;
-    this.followRedirects = builder.followRedirects;
-    this.retryOnConnectionFailure = builder.retryOnConnectionFailure;
-    this.connectTimeout = builder.connectTimeout;
-    this.readTimeout = builder.readTimeout;
-    this.writeTimeout = builder.writeTimeout;
-    this.pingInterval = builder.pingInterval;
-
-    if (interceptors.contains(null)) {
-      throw new IllegalStateException("Null interceptor: " + interceptors);
-    }
-    if (networkInterceptors.contains(null)) {
-      throw new IllegalStateException("Null network interceptor: " + networkInterceptors);
-    }
-  }
-
-  private X509TrustManager systemDefaultTrustManager() {
-    try {
-      TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(
-          TrustManagerFactory.getDefaultAlgorithm());
-      trustManagerFactory.init((KeyStore) null);
-      TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();
-      if (trustManagers.length != 1 || !(trustManagers[0] instanceof X509TrustManager)) {
-        throw new IllegalStateException("Unexpected default trust managers:"
-            + Arrays.toString(trustManagers));
-      }
-      return (X509TrustManager) trustManagers[0];
-    } catch (GeneralSecurityException e) {
-      throw assertionError("No System TLS", e); // The system has no TLS. Just give up.
-    }
-  }
-
-  private SSLSocketFactory systemDefaultSslSocketFactory(X509TrustManager trustManager) {
-    try {
-      SSLContext sslContext = SSLContext.getInstance("TLS");
-      sslContext.init(null, new TrustManager[] { trustManager }, null);
-      return sslContext.getSocketFactory();
-    } catch (GeneralSecurityException e) {
-      throw assertionError("No System TLS", e); // The system has no TLS. Just give up.
-    }
-  }
-
-  /** Default connect timeout (in milliseconds). */
-  public int connectTimeoutMillis() {
-    return connectTimeout;
-  }
-
-  /** Default read timeout (in milliseconds). */
-  public int readTimeoutMillis() {
-    return readTimeout;
-  }
-
-  /** Default write timeout (in milliseconds). */
-  public int writeTimeoutMillis() {
-    return writeTimeout;
-  }
-
-  /** Web socket ping interval (in milliseconds). */
-  public int pingIntervalMillis() {
-    return pingInterval;
-  }
-
-  public Proxy proxy() {
-    return proxy;
-  }
-
-  public ProxySelector proxySelector() {
-    return proxySelector;
-  }
-
-  public CookieJar cookieJar() {
-    return cookieJar;
-  }
-
-  public Cache cache() {
-    return cache;
-  }
-
-  InternalCache internalCache() {
-    return cache != null ? cache.internalCache : internalCache;
-  }
-
-  public Dns dns() {
-    return dns;
-  }
-
-  public SocketFactory socketFactory() {
-    return socketFactory;
-  }
-
-  public SSLSocketFactory sslSocketFactory() {
-    return sslSocketFactory;
-  }
-
-  public HostnameVerifier hostnameVerifier() {
-    return hostnameVerifier;
-  }
-
-  public CertificatePinner certificatePinner() {
-    return certificatePinner;
-  }
-
-  public Authenticator authenticator() {
-    return authenticator;
-  }
-
-  public Authenticator proxyAuthenticator() {
-    return proxyAuthenticator;
-  }
-
-  public ConnectionPool connectionPool() {
-    return connectionPool;
-  }
-
-  public boolean followSslRedirects() {
-    return followSslRedirects;
-  }
-
-  public boolean followRedirects() {
-    return followRedirects;
-  }
-
-  public boolean retryOnConnectionFailure() {
-    return retryOnConnectionFailure;
-  }
-
-  public Dispatcher dispatcher() {
-    return dispatcher;
-  }
-
-  public List<Protocol> protocols() {
-    return protocols;
-  }
-
-  public List<ConnectionSpec> connectionSpecs() {
-    return connectionSpecs;
-  }
-
-  /**
-   * Returns an immutable list of interceptors that observe the full span of each call: from before
-   * the connection is established (if any) until after the response source is selected (either the
-   * origin server, cache, or both).
-   */
-  public List<Interceptor> interceptors() {
-    return interceptors;
-  }
-
-  /**
-   * Returns an immutable list of interceptors that observe a single network request and response.
-   * These interceptors must call {@link Interceptor.Chain#proceed} exactly once: it is an error for
-   * a network interceptor to short-circuit or repeat a network request.
-   */
-  public List<Interceptor> networkInterceptors() {
-    return networkInterceptors;
-  }
-
-  public EventListener.Factory eventListenerFactory() {
-    return eventListenerFactory;
-  }
-
-  /**
-   * Prepares the {@code request} to be executed at some point in the future.
-   */
-  @Override public Call newCall(Request request) {
-    return RealCall.newRealCall(this, request, false /* for web socket */);
-  }
-
-  /**
-   * Uses {@code request} to connect a new web socket.
-   */
-  @Override public WebSocket newWebSocket(Request request, WebSocketListener listener) {
-    RealWebSocket webSocket = new RealWebSocket(request, listener, new Random());
-    webSocket.connect(this);
-    return webSocket;
-  }
-
-  public Builder newBuilder() {
-    return new Builder(this);
-  }
-
-  public static final class Builder {
-    Dispatcher dispatcher;
-    @Nullable Proxy proxy;
-    List<Protocol> protocols;
-    List<ConnectionSpec> connectionSpecs;
-    final List<Interceptor> interceptors = new ArrayList<>();
-    final List<Interceptor> networkInterceptors = new ArrayList<>();
-    EventListener.Factory eventListenerFactory;
-    ProxySelector proxySelector;
-    CookieJar cookieJar;
-    @Nullable Cache cache;
-    @Nullable InternalCache internalCache;
-    SocketFactory socketFactory;
-    @Nullable SSLSocketFactory sslSocketFactory;
-    @Nullable CertificateChainCleaner certificateChainCleaner;
-    HostnameVerifier hostnameVerifier;
-    CertificatePinner certificatePinner;
-    Authenticator proxyAuthenticator;
-    Authenticator authenticator;
-    ConnectionPool connectionPool;
-    Dns dns;
-    boolean followSslRedirects;
-    boolean followRedirects;
-    boolean retryOnConnectionFailure;
-    int connectTimeout;
-    int readTimeout;
-    int writeTimeout;
-    int pingInterval;
-
-    public Builder() {
-      dispatcher = new Dispatcher();
-      protocols = DEFAULT_PROTOCOLS;
-      connectionSpecs = DEFAULT_CONNECTION_SPECS;
-      eventListenerFactory = EventListener.factory(EventListener.NONE);
-      proxySelector = ProxySelector.getDefault();
-      cookieJar = CookieJar.NO_COOKIES;
-      socketFactory = SocketFactory.getDefault();
-      hostnameVerifier = OkHostnameVerifier.INSTANCE;
-      certificatePinner = CertificatePinner.DEFAULT;
-      proxyAuthenticator = Authenticator.NONE;
-      authenticator = Authenticator.NONE;
-      connectionPool = new ConnectionPool();
-      dns = Dns.SYSTEM;
-      followSslRedirects = true;
-      followRedirects = true;
-      retryOnConnectionFailure = true;
-      connectTimeout = 10_000;
-      readTimeout = 10_000;
-      writeTimeout = 10_000;
-      pingInterval = 0;
-    }
-
-    Builder(OkHttpClient okHttpClient) {
-      this.dispatcher = okHttpClient.dispatcher;
-      this.proxy = okHttpClient.proxy;
-      this.protocols = okHttpClient.protocols;
-      this.connectionSpecs = okHttpClient.connectionSpecs;
-      this.interceptors.addAll(okHttpClient.interceptors);
-      this.networkInterceptors.addAll(okHttpClient.networkInterceptors);
-      this.eventListenerFactory = okHttpClient.eventListenerFactory;
-      this.proxySelector = okHttpClient.proxySelector;
-      this.cookieJar = okHttpClient.cookieJar;
-      this.internalCache = okHttpClient.internalCache;
-      this.cache = okHttpClient.cache;
-      this.socketFactory = okHttpClient.socketFactory;
-      this.sslSocketFactory = okHttpClient.sslSocketFactory;
-      this.certificateChainCleaner = okHttpClient.certificateChainCleaner;
-      this.hostnameVerifier = okHttpClient.hostnameVerifier;
-      this.certificatePinner = okHttpClient.certificatePinner;
-      this.proxyAuthenticator = okHttpClient.proxyAuthenticator;
-      this.authenticator = okHttpClient.authenticator;
-      this.connectionPool = okHttpClient.connectionPool;
-      this.dns = okHttpClient.dns;
-      this.followSslRedirects = okHttpClient.followSslRedirects;
-      this.followRedirects = okHttpClient.followRedirects;
-      this.retryOnConnectionFailure = okHttpClient.retryOnConnectionFailure;
-      this.connectTimeout = okHttpClient.connectTimeout;
-      this.readTimeout = okHttpClient.readTimeout;
-      this.writeTimeout = okHttpClient.writeTimeout;
-      this.pingInterval = okHttpClient.pingInterval;
+    static final List<Protocol> DEFAULT_PROTOCOLS = Util.immutableList(
+            Protocol.HTTP_2, Protocol.HTTP_1_1);
+
+    static final List<ConnectionSpec> DEFAULT_CONNECTION_SPECS = Util.immutableList(
+            ConnectionSpec.MODERN_TLS, ConnectionSpec.CLEARTEXT);
+
+    static {
+        Internal.instance = new Internal() {
+            @Override
+            public void addLenient(Headers.Builder builder, String line) {
+                builder.addLenient(line);
+            }
+
+            @Override
+            public void addLenient(Headers.Builder builder, String name, String value) {
+                builder.addLenient(name, value);
+            }
+
+            @Override
+            public void setCache(OkHttpClient.Builder builder, InternalCache internalCache) {
+                builder.setInternalCache(internalCache);
+            }
+
+            @Override
+            public boolean connectionBecameIdle(
+                    ConnectionPool pool, RealConnection connection) {
+                return pool.connectionBecameIdle(connection);
+            }
+
+            @Override
+            public RealConnection get(ConnectionPool pool, Address address,
+                                      StreamAllocation streamAllocation, Route route) {
+                return pool.get(address, streamAllocation, route);
+            }
+
+            @Override
+            public boolean equalsNonHost(Address a, Address b) {
+                return a.equalsNonHost(b);
+            }
+
+            @Override
+            public Socket deduplicate(
+                    ConnectionPool pool, Address address, StreamAllocation streamAllocation) {
+                return pool.deduplicate(address, streamAllocation);
+            }
+
+            @Override
+            public void put(ConnectionPool pool, RealConnection connection) {
+                pool.put(connection);
+            }
+
+            @Override
+            public RouteDatabase routeDatabase(ConnectionPool connectionPool) {
+                return connectionPool.routeDatabase;
+            }
+
+            @Override
+            public int code(Response.Builder responseBuilder) {
+                return responseBuilder.code;
+            }
+
+            @Override
+            public void apply(ConnectionSpec tlsConfiguration, SSLSocket sslSocket, boolean isFallback) {
+                tlsConfiguration.apply(sslSocket, isFallback);
+            }
+
+            @Override
+            public HttpUrl getHttpUrlChecked(String url)
+                    throws MalformedURLException, UnknownHostException {
+                return HttpUrl.getChecked(url);
+            }
+
+            @Override
+            public StreamAllocation streamAllocation(Call call) {
+                return ((RealCall) call).streamAllocation();
+            }
+
+            @Override
+            public Call newWebSocketCall(OkHttpClient client, Request originalRequest) {
+                return RealCall.newRealCall(client, originalRequest, true);
+            }
+        };
+    }
+
+    final Dispatcher dispatcher;
+    final @Nullable
+    Proxy proxy;
+    final List<Protocol> protocols;
+    final List<ConnectionSpec> connectionSpecs;
+    final List<Interceptor> interceptors;
+    final List<Interceptor> networkInterceptors;
+    final EventListener.Factory eventListenerFactory;
+    final ProxySelector proxySelector;
+    final CookieJar cookieJar;
+    final @Nullable
+    Cache cache;
+    final @Nullable
+    InternalCache internalCache;
+    final SocketFactory socketFactory;
+    final @Nullable
+    SSLSocketFactory sslSocketFactory;
+    final @Nullable
+    CertificateChainCleaner certificateChainCleaner;
+    final HostnameVerifier hostnameVerifier;
+    final CertificatePinner certificatePinner;
+    final Authenticator proxyAuthenticator;
+    final Authenticator authenticator;
+    final ConnectionPool connectionPool;
+    final Dns dns;
+    final boolean followSslRedirects;
+    final boolean followRedirects;
+    final boolean retryOnConnectionFailure;
+    final int connectTimeout;
+    final int readTimeout;
+    final int writeTimeout;
+    final int pingInterval;
+
+    public OkHttpClient() {
+        this(new Builder());
+    }
+
+    OkHttpClient(Builder builder) {
+        this.dispatcher = builder.dispatcher;
+        this.proxy = builder.proxy;
+        this.protocols = builder.protocols;
+        this.connectionSpecs = builder.connectionSpecs;
+        this.interceptors = Util.immutableList(builder.interceptors);
+        this.networkInterceptors = Util.immutableList(builder.networkInterceptors);
+        this.eventListenerFactory = builder.eventListenerFactory;
+        this.proxySelector = builder.proxySelector;
+        this.cookieJar = builder.cookieJar;
+        this.cache = builder.cache;
+        this.internalCache = builder.internalCache;
+        this.socketFactory = builder.socketFactory;
+
+        boolean isTLS = false;
+        for (ConnectionSpec spec : connectionSpecs) {
+            isTLS = isTLS || spec.isTls();
+        }
+
+        if (builder.sslSocketFactory != null || !isTLS) {
+            this.sslSocketFactory = builder.sslSocketFactory;
+            this.certificateChainCleaner = builder.certificateChainCleaner;
+        } else {
+            X509TrustManager trustManager = systemDefaultTrustManager();
+            this.sslSocketFactory = systemDefaultSslSocketFactory(trustManager);
+            this.certificateChainCleaner = CertificateChainCleaner.get(trustManager);
+        }
+
+        this.hostnameVerifier = builder.hostnameVerifier;
+        this.certificatePinner = builder.certificatePinner.withCertificateChainCleaner(
+                certificateChainCleaner);
+        this.proxyAuthenticator = builder.proxyAuthenticator;
+        this.authenticator = builder.authenticator;
+        this.connectionPool = builder.connectionPool;
+        this.dns = builder.dns;
+        this.followSslRedirects = builder.followSslRedirects;
+        this.followRedirects = builder.followRedirects;
+        this.retryOnConnectionFailure = builder.retryOnConnectionFailure;
+        this.connectTimeout = builder.connectTimeout;
+        this.readTimeout = builder.readTimeout;
+        this.writeTimeout = builder.writeTimeout;
+        this.pingInterval = builder.pingInterval;
+
+        if (interceptors.contains(null)) {
+            throw new IllegalStateException("Null interceptor: " + interceptors);
+        }
+        if (networkInterceptors.contains(null)) {
+            throw new IllegalStateException("Null network interceptor: " + networkInterceptors);
+        }
+    }
+
+    private X509TrustManager systemDefaultTrustManager() {
+        try {
+            TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(
+                    TrustManagerFactory.getDefaultAlgorithm());
+            trustManagerFactory.init((KeyStore) null);
+            TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();
+            if (trustManagers.length != 1 || !(trustManagers[0] instanceof X509TrustManager)) {
+                throw new IllegalStateException("Unexpected default trust managers:"
+                        + Arrays.toString(trustManagers));
+            }
+            return (X509TrustManager) trustManagers[0];
+        } catch (GeneralSecurityException e) {
+            throw assertionError("No System TLS", e); // The system has no TLS. Just give up.
+        }
+    }
+
+    private SSLSocketFactory systemDefaultSslSocketFactory(X509TrustManager trustManager) {
+        try {
+            SSLContext sslContext = SSLContext.getInstance("TLS");
+            sslContext.init(null, new TrustManager[]{trustManager}, null);
+            return sslContext.getSocketFactory();
+        } catch (GeneralSecurityException e) {
+            throw assertionError("No System TLS", e); // The system has no TLS. Just give up.
+        }
     }
 
     /**
-     * Sets the default connect timeout for new connections. A value of 0 means no timeout,
-     * otherwise values must be between 1 and {@link Integer#MAX_VALUE} when converted to
-     * milliseconds.
+     * Default connect timeout (in milliseconds).
      */
-    public Builder connectTimeout(long timeout, TimeUnit unit) {
-      connectTimeout = checkDuration("timeout", timeout, unit);
-      return this;
+    public int connectTimeoutMillis() {
+        return connectTimeout;
     }
 
     /**
-     * Sets the default read timeout for new connections. A value of 0 means no timeout, otherwise
-     * values must be between 1 and {@link Integer#MAX_VALUE} when converted to milliseconds.
+     * Default read timeout (in milliseconds).
      */
-    public Builder readTimeout(long timeout, TimeUnit unit) {
-      readTimeout = checkDuration("timeout", timeout, unit);
-      return this;
+    public int readTimeoutMillis() {
+        return readTimeout;
     }
 
     /**
-     * Sets the default write timeout for new connections. A value of 0 means no timeout, otherwise
-     * values must be between 1 and {@link Integer#MAX_VALUE} when converted to milliseconds.
+     * Default write timeout (in milliseconds).
      */
-    public Builder writeTimeout(long timeout, TimeUnit unit) {
-      writeTimeout = checkDuration("timeout", timeout, unit);
-      return this;
+    public int writeTimeoutMillis() {
+        return writeTimeout;
     }
 
     /**
-     * Sets the interval between web socket pings initiated by this client. Use this to
-     * automatically send web socket ping frames until either the web socket fails or it is closed.
-     * This keeps the connection alive and may detect connectivity failures early. No timeouts are
-     * enforced on the acknowledging pongs.
-     *
-     * <p>The default value of 0 disables client-initiated pings.
+     * Web socket ping interval (in milliseconds).
      */
-    public Builder pingInterval(long interval, TimeUnit unit) {
-      pingInterval = checkDuration("interval", interval, unit);
-      return this;
+    public int pingIntervalMillis() {
+        return pingInterval;
     }
 
-    /**
-     * Sets the HTTP proxy that will be used by connections created by this client. This takes
-     * precedence over {@link #proxySelector}, which is only honored when this proxy is null (which
-     * it is by default). To disable proxy use completely, call {@code setProxy(Proxy.NO_PROXY)}.
-     */
-    public Builder proxy(@Nullable Proxy proxy) {
-      this.proxy = proxy;
-      return this;
-    }
-
-    /**
-     * Sets the proxy selection policy to be used if no {@link #proxy proxy} is specified
-     * explicitly. The proxy selector may return multiple proxies; in that case they will be tried
-     * in sequence until a successful connection is established.
-     *
-     * <p>If unset, the {@link ProxySelector#getDefault() system-wide default} proxy selector will
-     * be used.
-     */
-    public Builder proxySelector(ProxySelector proxySelector) {
-      this.proxySelector = proxySelector;
-      return this;
+    public Proxy proxy() {
+        return proxy;
     }
 
-    /**
-     * Sets the handler that can accept cookies from incoming HTTP responses and provides cookies to
-     * outgoing HTTP requests.
-     *
-     * <p>If unset, {@linkplain CookieJar#NO_COOKIES no cookies} will be accepted nor provided.
-     */
-    public Builder cookieJar(CookieJar cookieJar) {
-      if (cookieJar == null) throw new NullPointerException("cookieJar == null");
-      this.cookieJar = cookieJar;
-      return this;
+    public ProxySelector proxySelector() {
+        return proxySelector;
     }
 
-    /** Sets the response cache to be used to read and write cached responses. */
-    void setInternalCache(@Nullable InternalCache internalCache) {
-      this.internalCache = internalCache;
-      this.cache = null;
+    public CookieJar cookieJar() {
+        return cookieJar;
     }
 
-    /** Sets the response cache to be used to read and write cached responses. */
-    public Builder cache(@Nullable Cache cache) {
-      this.cache = cache;
-      this.internalCache = null;
-      return this;
+    public Cache cache() {
+        return cache;
     }
 
-    /**
-     * Sets the DNS service used to lookup IP addresses for hostnames.
-     *
-     * <p>If unset, the {@link Dns#SYSTEM system-wide default} DNS will be used.
-     */
-    public Builder dns(Dns dns) {
-      if (dns == null) throw new NullPointerException("dns == null");
-      this.dns = dns;
-      return this;
+    InternalCache internalCache() {
+        return cache != null ? cache.internalCache : internalCache;
     }
 
-    /**
-     * Sets the socket factory used to create connections. OkHttp only uses the parameterless {@link
-     * SocketFactory#createSocket() createSocket()} method to create unconnected sockets. Overriding
-     * this method, e. g., allows the socket to be bound to a specific local address.
-     *
-     * <p>If unset, the {@link SocketFactory#getDefault() system-wide default} socket factory will
-     * be used.
-     */
-    public Builder socketFactory(SocketFactory socketFactory) {
-      if (socketFactory == null) throw new NullPointerException("socketFactory == null");
-      this.socketFactory = socketFactory;
-      return this;
+    public Dns dns() {
+        return dns;
     }
 
-    /**
-     * Sets the socket factory used to secure HTTPS connections. If unset, the system default will
-     * be used.
-     *
-     * @deprecated {@code SSLSocketFactory} does not expose its {@link X509TrustManager}, which is
-     *     a field that OkHttp needs to build a clean certificate chain. This method instead must
-     *     use reflection to extract the trust manager. Applications should prefer to call {@link
-     *     #sslSocketFactory(SSLSocketFactory, X509TrustManager)}, which avoids such reflection.
-     */
-    public Builder sslSocketFactory(SSLSocketFactory sslSocketFactory) {
-      if (sslSocketFactory == null) throw new NullPointerException("sslSocketFactory == null");
-      this.sslSocketFactory = sslSocketFactory;
-      this.certificateChainCleaner = Platform.get().buildCertificateChainCleaner(sslSocketFactory);
-      return this;
+    public SocketFactory socketFactory() {
+        return socketFactory;
     }
 
-    /**
-     * Sets the socket factory and trust manager used to secure HTTPS connections. If unset, the
-     * system defaults will be used.
-     *
-     * <p>Most applications should not call this method, and instead use the system defaults. Those
-     * classes include special optimizations that can be lost if the implementations are decorated.
-     *
-     * <p>If necessary, you can create and configure the defaults yourself with the following code:
-     *
-     * <pre>   {@code
-     *
-     *   TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(
-     *       TrustManagerFactory.getDefaultAlgorithm());
-     *   trustManagerFactory.init((KeyStore) null);
-     *   TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();
-     *   if (trustManagers.length != 1 || !(trustManagers[0] instanceof X509TrustManager)) {
-     *     throw new IllegalStateException("Unexpected default trust managers:"
-     *         + Arrays.toString(trustManagers));
-     *   }
-     *   X509TrustManager trustManager = (X509TrustManager) trustManagers[0];
-     *
-     *   SSLContext sslContext = SSLContext.getInstance("TLS");
-     *   sslContext.init(null, new TrustManager[] { trustManager }, null);
-     *   SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();
-     *
-     *   OkHttpClient client = new OkHttpClient.Builder()
-     *       .sslSocketFactory(sslSocketFactory, trustManager);
-     *       .build();
-     * }</pre>
-     */
-    public Builder sslSocketFactory(
-        SSLSocketFactory sslSocketFactory, X509TrustManager trustManager) {
-      if (sslSocketFactory == null) throw new NullPointerException("sslSocketFactory == null");
-      if (trustManager == null) throw new NullPointerException("trustManager == null");
-      this.sslSocketFactory = sslSocketFactory;
-      this.certificateChainCleaner = CertificateChainCleaner.get(trustManager);
-      return this;
+    public SSLSocketFactory sslSocketFactory() {
+        return sslSocketFactory;
     }
 
-    /**
-     * Sets the verifier used to confirm that response certificates apply to requested hostnames for
-     * HTTPS connections.
-     *
-     * <p>If unset, a default hostname verifier will be used.
-     */
-    public Builder hostnameVerifier(HostnameVerifier hostnameVerifier) {
-      if (hostnameVerifier == null) throw new NullPointerException("hostnameVerifier == null");
-      this.hostnameVerifier = hostnameVerifier;
-      return this;
+    public HostnameVerifier hostnameVerifier() {
+        return hostnameVerifier;
     }
 
-    /**
-     * Sets the certificate pinner that constrains which certificates are trusted. By default HTTPS
-     * connections rely on only the {@link #sslSocketFactory SSL socket factory} to establish trust.
-     * Pinning certificates avoids the need to trust certificate authorities.
-     */
-    public Builder certificatePinner(CertificatePinner certificatePinner) {
-      if (certificatePinner == null) throw new NullPointerException("certificatePinner == null");
-      this.certificatePinner = certificatePinner;
-      return this;
+    public CertificatePinner certificatePinner() {
+        return certificatePinner;
     }
 
-    /**
-     * Sets the authenticator used to respond to challenges from origin servers. Use {@link
-     * #proxyAuthenticator} to set the authenticator for proxy servers.
-     *
-     * <p>If unset, the {@linkplain Authenticator#NONE no authentication will be attempted}.
-     */
-    public Builder authenticator(Authenticator authenticator) {
-      if (authenticator == null) throw new NullPointerException("authenticator == null");
-      this.authenticator = authenticator;
-      return this;
+    public Authenticator authenticator() {
+        return authenticator;
     }
 
-    /**
-     * Sets the authenticator used to respond to challenges from proxy servers. Use {@link
-     * #authenticator} to set the authenticator for origin servers.
-     *
-     * <p>If unset, the {@linkplain Authenticator#NONE no authentication will be attempted}.
-     */
-    public Builder proxyAuthenticator(Authenticator proxyAuthenticator) {
-      if (proxyAuthenticator == null) throw new NullPointerException("proxyAuthenticator == null");
-      this.proxyAuthenticator = proxyAuthenticator;
-      return this;
+    public Authenticator proxyAuthenticator() {
+        return proxyAuthenticator;
     }
 
-    /**
-     * Sets the connection pool used to recycle HTTP and HTTPS connections.
-     *
-     * <p>If unset, a new connection pool will be used.
-     */
-    public Builder connectionPool(ConnectionPool connectionPool) {
-      if (connectionPool == null) throw new NullPointerException("connectionPool == null");
-      this.connectionPool = connectionPool;
-      return this;
+    public ConnectionPool connectionPool() {
+        return connectionPool;
     }
 
-    /**
-     * Configure this client to follow redirects from HTTPS to HTTP and from HTTP to HTTPS.
-     *
-     * <p>If unset, protocol redirects will be followed. This is different than the built-in {@code
-     * HttpURLConnection}'s default.
-     */
-    public Builder followSslRedirects(boolean followProtocolRedirects) {
-      this.followSslRedirects = followProtocolRedirects;
-      return this;
+    public boolean followSslRedirects() {
+        return followSslRedirects;
     }
 
-    /** Configure this client to follow redirects. If unset, redirects will be followed. */
-    public Builder followRedirects(boolean followRedirects) {
-      this.followRedirects = followRedirects;
-      return this;
+    public boolean followRedirects() {
+        return followRedirects;
     }
 
-    /**
-     * Configure this client to retry or not when a connectivity problem is encountered. By default,
-     * this client silently recovers from the following problems:
-     *
-     * <ul>
-     *   <li><strong>Unreachable IP addresses.</strong> If the URL's host has multiple IP addresses,
-     *       failure to reach any individual IP address doesn't fail the overall request. This can
-     *       increase availability of multi-homed services.
-     *   <li><strong>Stale pooled connections.</strong> The {@link ConnectionPool} reuses sockets
-     *       to decrease request latency, but these connections will occasionally time out.
-     *   <li><strong>Unreachable proxy servers.</strong> A {@link ProxySelector} can be used to
-     *       attempt multiple proxy servers in sequence, eventually falling back to a direct
-     *       connection.
-     * </ul>
-     *
-     * Set this to false to avoid retrying requests when doing so is destructive. In this case the
-     * calling application should do its own recovery of connectivity failures.
-     */
-    public Builder retryOnConnectionFailure(boolean retryOnConnectionFailure) {
-      this.retryOnConnectionFailure = retryOnConnectionFailure;
-      return this;
+    public boolean retryOnConnectionFailure() {
+        return retryOnConnectionFailure;
     }
 
-    /**
-     * Sets the dispatcher used to set policy and execute asynchronous requests. Must not be null.
-     */
-    public Builder dispatcher(Dispatcher dispatcher) {
-      if (dispatcher == null) throw new IllegalArgumentException("dispatcher == null");
-      this.dispatcher = dispatcher;
-      return this;
+    public Dispatcher dispatcher() {
+        return dispatcher;
     }
 
-    /**
-     * Configure the protocols used by this client to communicate with remote servers. By default
-     * this client will prefer the most efficient transport available, falling back to more
-     * ubiquitous protocols. Applications should only call this method to avoid specific
-     * compatibility problems, such as web servers that behave incorrectly when HTTP/2 is enabled.
-     *
-     * <p>The following protocols are currently supported:
-     *
-     * <ul>
-     *     <li><a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html">http/1.1</a>
-     *     <li><a href="http://tools.ietf.org/html/draft-ietf-httpbis-http2-17">h2</a>
-     * </ul>
-     *
-     * <p><strong>This is an evolving set.</strong> Future releases include support for transitional
-     * protocols. The http/1.1 transport will never be dropped.
-     *
-     * <p>If multiple protocols are specified, <a
-     * href="http://tools.ietf.org/html/draft-ietf-tls-applayerprotoneg">ALPN</a> will be used to
-     * negotiate a transport.
-     *
-     * <p>{@link Protocol#HTTP_1_0} is not supported in this set. Requests are initiated with {@code
-     * HTTP/1.1} only. If the server responds with {@code HTTP/1.0}, that will be exposed by {@link
-     * Response#protocol()}.
-     *
-     * @param protocols the protocols to use, in order of preference. The list must contain {@link
-     * Protocol#HTTP_1_1}. It must not contain null or {@link Protocol#HTTP_1_0}.
-     */
-    public Builder protocols(List<Protocol> protocols) {
-      // Create a private copy of the list.
-      protocols = new ArrayList<>(protocols);
-
-      // Validate that the list has everything we require and nothing we forbid.
-      if (!protocols.contains(Protocol.HTTP_1_1)) {
-        throw new IllegalArgumentException("protocols doesn't contain http/1.1: " + protocols);
-      }
-      if (protocols.contains(Protocol.HTTP_1_0)) {
-        throw new IllegalArgumentException("protocols must not contain http/1.0: " + protocols);
-      }
-      if (protocols.contains(null)) {
-        throw new IllegalArgumentException("protocols must not contain null");
-      }
-
-      // Remove protocols that we no longer support.
-      protocols.remove(Protocol.SPDY_3);
-
-      // Assign as an unmodifiable list. This is effectively immutable.
-      this.protocols = Collections.unmodifiableList(protocols);
-      return this;
+    public List<Protocol> protocols() {
+        return protocols;
     }
 
-    public Builder connectionSpecs(List<ConnectionSpec> connectionSpecs) {
-      this.connectionSpecs = Util.immutableList(connectionSpecs);
-      return this;
+    public List<ConnectionSpec> connectionSpecs() {
+        return connectionSpecs;
     }
 
     /**
-     * Returns a modifiable list of interceptors that observe the full span of each call: from
-     * before the connection is established (if any) until after the response source is selected
-     * (either the origin server, cache, or both).
+     * Returns an immutable list of interceptors that observe the full span of each call: from before
+     * the connection is established (if any) until after the response source is selected (either the
+     * origin server, cache, or both).
      */
     public List<Interceptor> interceptors() {
-      return interceptors;
-    }
-
-    public Builder addInterceptor(Interceptor interceptor) {
-      if (interceptor == null) throw new IllegalArgumentException("interceptor == null");
-      interceptors.add(interceptor);
-      return this;
+        return interceptors;
     }
 
     /**
-     * Returns a modifiable list of interceptors that observe a single network request and response.
-     * These interceptors must call {@link Interceptor.Chain#proceed} exactly once: it is an error
-     * for a network interceptor to short-circuit or repeat a network request.
+     * Returns an immutable list of interceptors that observe a single network request and response.
+     * These interceptors must call {@link Interceptor.Chain#proceed} exactly once: it is an error for
+     * a network interceptor to short-circuit or repeat a network request.
      */
     public List<Interceptor> networkInterceptors() {
-      return networkInterceptors;
+        return networkInterceptors;
     }
 
-    public Builder addNetworkInterceptor(Interceptor interceptor) {
-      if (interceptor == null) throw new IllegalArgumentException("interceptor == null");
-      networkInterceptors.add(interceptor);
-      return this;
+    public EventListener.Factory eventListenerFactory() {
+        return eventListenerFactory;
     }
 
     /**
-     * Configure a single client scoped listener that will receive all analytic events
-     * for this client.
-     *
-     * @see EventListener for semantics and restrictions on listener implementations.
+     * Prepares the {@code request} to be executed at some point in the future.
      */
-    public Builder eventListener(EventListener eventListener) {
-      if (eventListener == null) throw new NullPointerException("eventListener == null");
-      this.eventListenerFactory = EventListener.factory(eventListener);
-      return this;
+    @Override
+    public Call newCall(Request request) {
+        return RealCall.newRealCall(this, request, false /* for web socket */);
     }
 
     /**
-     * Configure a factory to provide per-call scoped listeners that will receive analytic events
-     * for this client.
-     *
-     * @see EventListener for semantics and restrictions on listener implementations.
+     * Uses {@code request} to connect a new web socket.
      */
-    public Builder eventListenerFactory(EventListener.Factory eventListenerFactory) {
-      if (eventListenerFactory == null) {
-        throw new NullPointerException("eventListenerFactory == null");
-      }
-      this.eventListenerFactory = eventListenerFactory;
-      return this;
-    }
-
-    public OkHttpClient build() {
-      return new OkHttpClient(this);
+    @Override
+    public WebSocket newWebSocket(Request request, WebSocketListener listener) {
+        RealWebSocket webSocket = new RealWebSocket(request, listener, new Random());
+        webSocket.connect(this);
+        return webSocket;
+    }
+
+    public Builder newBuilder() {
+        return new Builder(this);
+    }
+
+    public static final class Builder {
+        Dispatcher dispatcher;
+        @Nullable
+        Proxy proxy;
+        List<Protocol> protocols;
+        List<ConnectionSpec> connectionSpecs;
+        final List<Interceptor> interceptors = new ArrayList<>();
+        final List<Interceptor> networkInterceptors = new ArrayList<>();
+        EventListener.Factory eventListenerFactory;
+        ProxySelector proxySelector;
+        CookieJar cookieJar;
+        @Nullable
+        Cache cache;
+        @Nullable
+        InternalCache internalCache;
+        SocketFactory socketFactory;
+        @Nullable
+        SSLSocketFactory sslSocketFactory;
+        @Nullable
+        CertificateChainCleaner certificateChainCleaner;
+        HostnameVerifier hostnameVerifier;
+        CertificatePinner certificatePinner;
+        Authenticator proxyAuthenticator;
+        Authenticator authenticator;
+        ConnectionPool connectionPool;
+        Dns dns;
+        boolean followSslRedirects;
+        boolean followRedirects;
+        boolean retryOnConnectionFailure;
+        int connectTimeout;
+        int readTimeout;
+        int writeTimeout;
+        int pingInterval;
+
+        public Builder() {
+            dispatcher = new Dispatcher();
+            protocols = DEFAULT_PROTOCOLS;
+            connectionSpecs = DEFAULT_CONNECTION_SPECS;
+            eventListenerFactory = EventListener.factory(EventListener.NONE);
+            proxySelector = ProxySelector.getDefault();
+            cookieJar = CookieJar.NO_COOKIES;
+            socketFactory = SocketFactory.getDefault();
+            hostnameVerifier = OkHostnameVerifier.INSTANCE;
+            certificatePinner = CertificatePinner.DEFAULT;
+            proxyAuthenticator = Authenticator.NONE;
+            authenticator = Authenticator.NONE;
+            connectionPool = new ConnectionPool();
+            dns = Dns.SYSTEM;
+            followSslRedirects = true;
+            followRedirects = true;
+            retryOnConnectionFailure = true;
+            connectTimeout = 10_000;
+            readTimeout = 10_000;
+            writeTimeout = 10_000;
+            pingInterval = 0;
+        }
+
+        Builder(OkHttpClient okHttpClient) {
+            this.dispatcher = okHttpClient.dispatcher;
+            this.proxy = okHttpClient.proxy;
+            this.protocols = okHttpClient.protocols;
+            this.connectionSpecs = okHttpClient.connectionSpecs;
+            this.interceptors.addAll(okHttpClient.interceptors);
+            this.networkInterceptors.addAll(okHttpClient.networkInterceptors);
+            this.eventListenerFactory = okHttpClient.eventListenerFactory;
+            this.proxySelector = okHttpClient.proxySelector;
+            this.cookieJar = okHttpClient.cookieJar;
+            this.internalCache = okHttpClient.internalCache;
+            this.cache = okHttpClient.cache;
+            this.socketFactory = okHttpClient.socketFactory;
+            this.sslSocketFactory = okHttpClient.sslSocketFactory;
+            this.certificateChainCleaner = okHttpClient.certificateChainCleaner;
+            this.hostnameVerifier = okHttpClient.hostnameVerifier;
+            this.certificatePinner = okHttpClient.certificatePinner;
+            this.proxyAuthenticator = okHttpClient.proxyAuthenticator;
+            this.authenticator = okHttpClient.authenticator;
+            this.connectionPool = okHttpClient.connectionPool;
+            this.dns = okHttpClient.dns;
+            this.followSslRedirects = okHttpClient.followSslRedirects;
+            this.followRedirects = okHttpClient.followRedirects;
+            this.retryOnConnectionFailure = okHttpClient.retryOnConnectionFailure;
+            this.connectTimeout = okHttpClient.connectTimeout;
+            this.readTimeout = okHttpClient.readTimeout;
+            this.writeTimeout = okHttpClient.writeTimeout;
+            this.pingInterval = okHttpClient.pingInterval;
+        }
+
+        /**
+         * Sets the default connect timeout for new connections. A value of 0 means no timeout,
+         * otherwise values must be between 1 and {@link Integer#MAX_VALUE} when converted to
+         * milliseconds.
+         */
+        public Builder connectTimeout(long timeout, TimeUnit unit) {
+            connectTimeout = checkDuration("timeout", timeout, unit);
+            return this;
+        }
+
+        /**
+         * Sets the default read timeout for new connections. A value of 0 means no timeout, otherwise
+         * values must be between 1 and {@link Integer#MAX_VALUE} when converted to milliseconds.
+         */
+        public Builder readTimeout(long timeout, TimeUnit unit) {
+            readTimeout = checkDuration("timeout", timeout, unit);
+            return this;
+        }
+
+        /**
+         * Sets the default write timeout for new connections. A value of 0 means no timeout, otherwise
+         * values must be between 1 and {@link Integer#MAX_VALUE} when converted to milliseconds.
+         */
+        public Builder writeTimeout(long timeout, TimeUnit unit) {
+            writeTimeout = checkDuration("timeout", timeout, unit);
+            return this;
+        }
+
+        /**
+         * Sets the interval between web socket pings initiated by this client. Use this to
+         * automatically send web socket ping frames until either the web socket fails or it is closed.
+         * This keeps the connection alive and may detect connectivity failures early. No timeouts are
+         * enforced on the acknowledging pongs.
+         * <p>
+         * <p>The default value of 0 disables client-initiated pings.
+         */
+        public Builder pingInterval(long interval, TimeUnit unit) {
+            pingInterval = checkDuration("interval", interval, unit);
+            return this;
+        }
+
+        /**
+         * Sets the HTTP proxy that will be used by connections created by this client. This takes
+         * precedence over {@link #proxySelector}, which is only honored when this proxy is null (which
+         * it is by default). To disable proxy use completely, call {@code setProxy(Proxy.NO_PROXY)}.
+         */
+        public Builder proxy(@Nullable Proxy proxy) {
+            this.proxy = proxy;
+            return this;
+        }
+
+        /**
+         * Sets the proxy selection policy to be used if no {@link #proxy proxy} is specified
+         * explicitly. The proxy selector may return multiple proxies; in that case they will be tried
+         * in sequence until a successful connection is established.
+         * <p>
+         * <p>If unset, the {@link ProxySelector#getDefault() system-wide default} proxy selector will
+         * be used.
+         */
+        public Builder proxySelector(ProxySelector proxySelector) {
+            this.proxySelector = proxySelector;
+            return this;
+        }
+
+        /**
+         * Sets the handler that can accept cookies from incoming HTTP responses and provides cookies to
+         * outgoing HTTP requests.
+         * <p>
+         * <p>If unset, {@linkplain CookieJar#NO_COOKIES no cookies} will be accepted nor provided.
+         */
+        public Builder cookieJar(CookieJar cookieJar) {
+            if (cookieJar == null) throw new NullPointerException("cookieJar == null");
+            this.cookieJar = cookieJar;
+            return this;
+        }
+
+        /**
+         * Sets the response cache to be used to read and write cached responses.
+         */
+        void setInternalCache(@Nullable InternalCache internalCache) {
+            this.internalCache = internalCache;
+            this.cache = null;
+        }
+
+        /**
+         * Sets the response cache to be used to read and write cached responses.
+         */
+        public Builder cache(@Nullable Cache cache) {
+            this.cache = cache;
+            this.internalCache = null;
+            return this;
+        }
+
+        /**
+         * Sets the DNS service used to lookup IP addresses for hostnames.
+         * <p>
+         * <p>If unset, the {@link Dns#SYSTEM system-wide default} DNS will be used.
+         */
+        public Builder dns(Dns dns) {
+            if (dns == null) throw new NullPointerException("dns == null");
+            this.dns = dns;
+            return this;
+        }
+
+        /**
+         * Sets the socket factory used to create connections. OkHttp only uses the parameterless {@link
+         * SocketFactory#createSocket() createSocket()} method to create unconnected sockets. Overriding
+         * this method, e. g., allows the socket to be bound to a specific local address.
+         * <p>
+         * <p>If unset, the {@link SocketFactory#getDefault() system-wide default} socket factory will
+         * be used.
+         */
+        public Builder socketFactory(SocketFactory socketFactory) {
+            if (socketFactory == null) throw new NullPointerException("socketFactory == null");
+            this.socketFactory = socketFactory;
+            return this;
+        }
+
+        /**
+         * Sets the socket factory used to secure HTTPS connections. If unset, the system default will
+         * be used.
+         *
+         * @deprecated {@code SSLSocketFactory} does not expose its {@link X509TrustManager}, which is
+         * a field that OkHttp needs to build a clean certificate chain. This method instead must
+         * use reflection to extract the trust manager. Applications should prefer to call {@link
+         * #sslSocketFactory(SSLSocketFactory, X509TrustManager)}, which avoids such reflection.
+         */
+        public Builder sslSocketFactory(SSLSocketFactory sslSocketFactory) {
+            if (sslSocketFactory == null) throw new NullPointerException("sslSocketFactory == null");
+            this.sslSocketFactory = sslSocketFactory;
+            this.certificateChainCleaner = Platform.get().buildCertificateChainCleaner(sslSocketFactory);
+            return this;
+        }
+
+        /**
+         * Sets the socket factory and trust manager used to secure HTTPS connections. If unset, the
+         * system defaults will be used.
+         * <p>
+         * <p>Most applications should not call this method, and instead use the system defaults. Those
+         * classes include special optimizations that can be lost if the implementations are decorated.
+         * <p>
+         * <p>If necessary, you can create and configure the defaults yourself with the following code:
+         * <p>
+         * <pre>   {@code
+         *
+         *   TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(
+         *       TrustManagerFactory.getDefaultAlgorithm());
+         *   trustManagerFactory.init((KeyStore) null);
+         *   TrustManager[] trustManagers = trustManagerFactory.getTrustManagers();
+         *   if (trustManagers.length != 1 || !(trustManagers[0] instanceof X509TrustManager)) {
+         *     throw new IllegalStateException("Unexpected default trust managers:"
+         *         + Arrays.toString(trustManagers));
+         *   }
+         *   X509TrustManager trustManager = (X509TrustManager) trustManagers[0];
+         *
+         *   SSLContext sslContext = SSLContext.getInstance("TLS");
+         *   sslContext.init(null, new TrustManager[] { trustManager }, null);
+         *   SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();
+         *
+         *   OkHttpClient client = new OkHttpClient.Builder()
+         *       .sslSocketFactory(sslSocketFactory, trustManager);
+         *       .build();
+         * }</pre>
+         */
+        public Builder sslSocketFactory(
+                SSLSocketFactory sslSocketFactory, X509TrustManager trustManager) {
+            if (sslSocketFactory == null) throw new NullPointerException("sslSocketFactory == null");
+            if (trustManager == null) throw new NullPointerException("trustManager == null");
+            this.sslSocketFactory = sslSocketFactory;
+            this.certificateChainCleaner = CertificateChainCleaner.get(trustManager);
+            return this;
+        }
+
+        /**
+         * Sets the verifier used to confirm that response certificates apply to requested hostnames for
+         * HTTPS connections.
+         * <p>
+         * <p>If unset, a default hostname verifier will be used.
+         */
+        public Builder hostnameVerifier(HostnameVerifier hostnameVerifier) {
+            if (hostnameVerifier == null) throw new NullPointerException("hostnameVerifier == null");
+            this.hostnameVerifier = hostnameVerifier;
+            return this;
+        }
+
+        /**
+         * Sets the certificate pinner that constrains which certificates are trusted. By default HTTPS
+         * connections rely on only the {@link #sslSocketFactory SSL socket factory} to establish trust.
+         * Pinning certificates avoids the need to trust certificate authorities.
+         */
+        public Builder certificatePinner(CertificatePinner certificatePinner) {
+            if (certificatePinner == null) throw new NullPointerException("certificatePinner == null");
+            this.certificatePinner = certificatePinner;
+            return this;
+        }
+
+        /**
+         * Sets the authenticator used to respond to challenges from origin servers. Use {@link
+         * #proxyAuthenticator} to set the authenticator for proxy servers.
+         * <p>
+         * <p>If unset, the {@linkplain Authenticator#NONE no authentication will be attempted}.
+         */
+        public Builder authenticator(Authenticator authenticator) {
+            if (authenticator == null) throw new NullPointerException("authenticator == null");
+            this.authenticator = authenticator;
+            return this;
+        }
+
+        /**
+         * Sets the authenticator used to respond to challenges from proxy servers. Use {@link
+         * #authenticator} to set the authenticator for origin servers.
+         * <p>
+         * <p>If unset, the {@linkplain Authenticator#NONE no authentication will be attempted}.
+         */
+        public Builder proxyAuthenticator(Authenticator proxyAuthenticator) {
+            if (proxyAuthenticator == null) throw new NullPointerException("proxyAuthenticator == null");
+            this.proxyAuthenticator = proxyAuthenticator;
+            return this;
+        }
+
+        /**
+         * Sets the connection pool used to recycle HTTP and HTTPS connections.
+         * <p>
+         * <p>If unset, a new connection pool will be used.
+         */
+        public Builder connectionPool(ConnectionPool connectionPool) {
+            if (connectionPool == null) throw new NullPointerException("connectionPool == null");
+            this.connectionPool = connectionPool;
+            return this;
+        }
+
+        /**
+         * Configure this client to follow redirects from HTTPS to HTTP and from HTTP to HTTPS.
+         * <p>
+         * <p>If unset, protocol redirects will be followed. This is different than the built-in {@code
+         * HttpURLConnection}'s default.
+         */
+        public Builder followSslRedirects(boolean followProtocolRedirects) {
+            this.followSslRedirects = followProtocolRedirects;
+            return this;
+        }
+
+        /**
+         * Configure this client to follow redirects. If unset, redirects will be followed.
+         */
+        public Builder followRedirects(boolean followRedirects) {
+            this.followRedirects = followRedirects;
+            return this;
+        }
+
+        /**
+         * Configure this client to retry or not when a connectivity problem is encountered. By default,
+         * this client silently recovers from the following problems:
+         * <p>
+         * <ul>
+         * <li><strong>Unreachable IP addresses.</strong> If the URL's host has multiple IP addresses,
+         * failure to reach any individual IP address doesn't fail the overall request. This can
+         * increase availability of multi-homed services.
+         * <li><strong>Stale pooled connections.</strong> The {@link ConnectionPool} reuses sockets
+         * to decrease request latency, but these connections will occasionally time out.
+         * <li><strong>Unreachable proxy servers.</strong> A {@link ProxySelector} can be used to
+         * attempt multiple proxy servers in sequence, eventually falling back to a direct
+         * connection.
+         * </ul>
+         * <p>
+         * Set this to false to avoid retrying requests when doing so is destructive. In this case the
+         * calling application should do its own recovery of connectivity failures.
+         */
+        public Builder retryOnConnectionFailure(boolean retryOnConnectionFailure) {
+            this.retryOnConnectionFailure = retryOnConnectionFailure;
+            return this;
+        }
+
+        /**
+         * Sets the dispatcher used to set policy and execute asynchronous requests. Must not be null.
+         */
+        public Builder dispatcher(Dispatcher dispatcher) {
+            if (dispatcher == null) throw new IllegalArgumentException("dispatcher == null");
+            this.dispatcher = dispatcher;
+            return this;
+        }
+
+        /**
+         * Configure the protocols used by this client to communicate with remote servers. By default
+         * this client will prefer the most efficient transport available, falling back to more
+         * ubiquitous protocols. Applications should only call this method to avoid specific
+         * compatibility problems, such as web servers that behave incorrectly when HTTP/2 is enabled.
+         * <p>
+         * <p>The following protocols are currently supported:
+         * <p>
+         * <ul>
+         * <li><a href="http://www.w3.org/Protocols/rfc2616/rfc2616.html">http/1.1</a>
+         * <li><a href="http://tools.ietf.org/html/draft-ietf-httpbis-http2-17">h2</a>
+         * </ul>
+         * <p>
+         * <p><strong>This is an evolving set.</strong> Future releases include support for transitional
+         * protocols. The http/1.1 transport will never be dropped.
+         * <p>
+         * <p>If multiple protocols are specified, <a
+         * href="http://tools.ietf.org/html/draft-ietf-tls-applayerprotoneg">ALPN</a> will be used to
+         * negotiate a transport.
+         * <p>
+         * <p>{@link Protocol#HTTP_1_0} is not supported in this set. Requests are initiated with {@code
+         * HTTP/1.1} only. If the server responds with {@code HTTP/1.0}, that will be exposed by {@link
+         * Response#protocol()}.
+         *
+         * @param protocols the protocols to use, in order of preference. The list must contain {@link
+         *                  Protocol#HTTP_1_1}. It must not contain null or {@link Protocol#HTTP_1_0}.
+         */
+        public Builder protocols(List<Protocol> protocols) {
+            // Create a private copy of the list.
+            protocols = new ArrayList<>(protocols);
+
+            // Validate that the list has everything we require and nothing we forbid.
+            if (!protocols.contains(Protocol.HTTP_1_1)) {
+                throw new IllegalArgumentException("protocols doesn't contain http/1.1: " + protocols);
+            }
+            if (protocols.contains(Protocol.HTTP_1_0)) {
+                throw new IllegalArgumentException("protocols must not contain http/1.0: " + protocols);
+            }
+            if (protocols.contains(null)) {
+                throw new IllegalArgumentException("protocols must not contain null");
+            }
+
+            // Remove protocols that we no longer support.
+            protocols.remove(Protocol.SPDY_3);
+
+            // Assign as an unmodifiable list. This is effectively immutable.
+            this.protocols = Collections.unmodifiableList(protocols);
+            return this;
+        }
+
+        public Builder connectionSpecs(List<ConnectionSpec> connectionSpecs) {
+            this.connectionSpecs = Util.immutableList(connectionSpecs);
+            return this;
+        }
+
+        /**
+         * Returns a modifiable list of interceptors that observe the full span of each call: from
+         * before the connection is established (if any) until after the response source is selected
+         * (either the origin server, cache, or both).
+         */
+        public List<Interceptor> interceptors() {
+            return interceptors;
+        }
+
+        public Builder addInterceptor(Interceptor interceptor) {
+            if (interceptor == null) throw new IllegalArgumentException("interceptor == null");
+            interceptors.add(interceptor);
+            return this;
+        }
+
+        /**
+         * Returns a modifiable list of interceptors that observe a single network request and response.
+         * These interceptors must call {@link Interceptor.Chain#proceed} exactly once: it is an error
+         * for a network interceptor to short-circuit or repeat a network request.
+         */
+        public List<Interceptor> networkInterceptors() {
+            return networkInterceptors;
+        }
+
+        public Builder addNetworkInterceptor(Interceptor interceptor) {
+            if (interceptor == null) throw new IllegalArgumentException("interceptor == null");
+            networkInterceptors.add(interceptor);
+            return this;
+        }
+
+        /**
+         * Configure a single client scoped listener that will receive all analytic events
+         * for this client.
+         *
+         * @see EventListener for semantics and restrictions on listener implementations.
+         */
+        public Builder eventListener(EventListener eventListener) {
+            if (eventListener == null) throw new NullPointerException("eventListener == null");
+            this.eventListenerFactory = EventListener.factory(eventListener);
+            return this;
+        }
+
+        /**
+         * Configure a factory to provide per-call scoped listeners that will receive analytic events
+         * for this client.
+         *
+         * @see EventListener for semantics and restrictions on listener implementations.
+         */
+        public Builder eventListenerFactory(EventListener.Factory eventListenerFactory) {
+            if (eventListenerFactory == null) {
+                throw new NullPointerException("eventListenerFactory == null");
+            }
+            this.eventListenerFactory = eventListenerFactory;
+            return this;
+        }
+
+        public OkHttpClient build() {
+            return new OkHttpClient(this);
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/RealCall.java b/okhttp/src/main/java/okhttp3/RealCall.java
index 808b3dc7ba..755270e588 100644
--- a/okhttp/src/main/java/okhttp3/RealCall.java
+++ b/okhttp/src/main/java/okhttp3/RealCall.java
@@ -18,6 +18,7 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
+
 import okhttp3.internal.NamedRunnable;
 import okhttp3.internal.cache.CacheInterceptor;
 import okhttp3.internal.connection.ConnectInterceptor;
@@ -30,173 +31,204 @@
 
 import static okhttp3.internal.platform.Platform.INFO;
 
+/**
+ * Call接口的实现类，对http的请求封装
+ */
 final class RealCall implements Call {
-  final OkHttpClient client;
-  final RetryAndFollowUpInterceptor retryAndFollowUpInterceptor;
-
-  /**
-   * There is a cycle between the {@link Call} and {@link EventListener} that makes this awkward.
-   * This will be set after we create the call instance then create the event listener instance.
-   */
-  private EventListener eventListener;
-
-  /** The application's original request unadulterated by redirects or auth headers. */
-  final Request originalRequest;
-  final boolean forWebSocket;
-
-  // Guarded by this.
-  private boolean executed;
-
-  private RealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) {
-    this.client = client;
-    this.originalRequest = originalRequest;
-    this.forWebSocket = forWebSocket;
-    this.retryAndFollowUpInterceptor = new RetryAndFollowUpInterceptor(client, forWebSocket);
-  }
-
-  static RealCall newRealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) {
-    // Safely publish the Call instance to the EventListener.
-    RealCall call = new RealCall(client, originalRequest, forWebSocket);
-    call.eventListener = client.eventListenerFactory().create(call);
-    return call;
-  }
-
-  @Override public Request request() {
-    return originalRequest;
-  }
-
-  @Override public Response execute() throws IOException {
-    synchronized (this) {
-      if (executed) throw new IllegalStateException("Already Executed");
-      executed = true;
+    final OkHttpClient client;
+    final RetryAndFollowUpInterceptor retryAndFollowUpInterceptor;
+
+    /**
+     * There is a cycle between the {@link Call} and {@link EventListener} that makes this awkward.
+     * This will be set after we create the call instance then create the event listener instance.
+     */
+    private EventListener eventListener;
+
+    /**
+     * The application's original request unadulterated by redirects or auth headers.
+     */
+    final Request originalRequest;
+    final boolean forWebSocket;
+
+    // Guarded by this.
+    private boolean executed;
+
+    private RealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) {
+        this.client = client;
+        this.originalRequest = originalRequest;
+        this.forWebSocket = forWebSocket;
+        this.retryAndFollowUpInterceptor = new RetryAndFollowUpInterceptor(client, forWebSocket);
     }
-    captureCallStackTrace();
-    eventListener.callStart(this);
-    try {
-      client.dispatcher().executed(this);
-      Response result = getResponseWithInterceptorChain();
-      if (result == null) throw new IOException("Canceled");
-      return result;
-    } catch (IOException e) {
-      eventListener.callFailed(this, e);
-      throw e;
-    } finally {
-      client.dispatcher().finished(this);
+
+    static RealCall newRealCall(OkHttpClient client, Request originalRequest, boolean forWebSocket) {
+        // Safely publish the Call instance to the EventListener.
+        RealCall call = new RealCall(client, originalRequest, forWebSocket);
+        call.eventListener = client.eventListenerFactory().create(call);
+        return call;
     }
-  }
 
-  private void captureCallStackTrace() {
-    Object callStackTrace = Platform.get().getStackTraceForCloseable("response.body().close()");
-    retryAndFollowUpInterceptor.setCallStackTrace(callStackTrace);
-  }
+    @Override
+    public Request request() {
+        return originalRequest;
+    }
+
+    @Override
+    public Response execute() throws IOException {
+        synchronized (this) {
+            if (executed) throw new IllegalStateException("Already Executed");
+            executed = true;
+        }
+        captureCallStackTrace();
+        eventListener.callStart(this);
+        try {
+            client.dispatcher().executed(this);
+            Response result = getResponseWithInterceptorChain();
+            if (result == null) throw new IOException("Canceled");
+            return result;
+        } catch (IOException e) {
+            eventListener.callFailed(this, e);
+            throw e;
+        } finally {
+            client.dispatcher().finished(this);
+        }
+    }
+
+    private void captureCallStackTrace() {
+        Object callStackTrace = Platform.get().getStackTraceForCloseable("response.body().close()");
+        retryAndFollowUpInterceptor.setCallStackTrace(callStackTrace);
+    }
+
+    @Override
+    public void enqueue(Callback responseCallback) {
+        synchronized (this) {
+            if (executed) throw new IllegalStateException("Already Executed");
+            executed = true;
+        }
+        captureCallStackTrace();
+        eventListener.callStart(this);
+        client.dispatcher().enqueue(new AsyncCall(responseCallback));
+    }
 
-  @Override public void enqueue(Callback responseCallback) {
-    synchronized (this) {
-      if (executed) throw new IllegalStateException("Already Executed");
-      executed = true;
+    @Override
+    public void cancel() {
+        retryAndFollowUpInterceptor.cancel();
     }
-    captureCallStackTrace();
-    eventListener.callStart(this);
-    client.dispatcher().enqueue(new AsyncCall(responseCallback));
-  }
-
-  @Override public void cancel() {
-    retryAndFollowUpInterceptor.cancel();
-  }
-
-  @Override public synchronized boolean isExecuted() {
-    return executed;
-  }
-
-  @Override public boolean isCanceled() {
-    return retryAndFollowUpInterceptor.isCanceled();
-  }
-
-  @SuppressWarnings("CloneDoesntCallSuperClone") // We are a final type & this saves clearing state.
-  @Override public RealCall clone() {
-    return RealCall.newRealCall(client, originalRequest, forWebSocket);
-  }
-
-  StreamAllocation streamAllocation() {
-    return retryAndFollowUpInterceptor.streamAllocation();
-  }
-
-  final class AsyncCall extends NamedRunnable {
-    private final Callback responseCallback;
-
-    AsyncCall(Callback responseCallback) {
-      super("OkHttp %s", redactedUrl());
-      this.responseCallback = responseCallback;
+
+    @Override
+    public synchronized boolean isExecuted() {
+        return executed;
     }
 
-    String host() {
-      return originalRequest.url().host();
+    @Override
+    public boolean isCanceled() {
+        return retryAndFollowUpInterceptor.isCanceled();
     }
 
-    Request request() {
-      return originalRequest;
+    @SuppressWarnings("CloneDoesntCallSuperClone") // We are a final type & this saves clearing state.
+    @Override
+    public RealCall clone() {
+        return RealCall.newRealCall(client, originalRequest, forWebSocket);
     }
 
-    RealCall get() {
-      return RealCall.this;
+    StreamAllocation streamAllocation() {
+        return retryAndFollowUpInterceptor.streamAllocation();
     }
 
-    @Override protected void execute() {
-      boolean signalledCallback = false;
-      try {
-        Response response = getResponseWithInterceptorChain();
-        if (retryAndFollowUpInterceptor.isCanceled()) {
-          signalledCallback = true;
-          responseCallback.onFailure(RealCall.this, new IOException("Canceled"));
-        } else {
-          signalledCallback = true;
-          responseCallback.onResponse(RealCall.this, response);
+    final class AsyncCall extends NamedRunnable {
+        private final Callback responseCallback;
+
+        AsyncCall(Callback responseCallback) {
+            super("OkHttp %s", redactedUrl());
+            this.responseCallback = responseCallback;
+        }
+
+        String host() {
+            return originalRequest.url().host();
         }
-      } catch (IOException e) {
-        if (signalledCallback) {
-          // Do not signal the callback twice!
-          Platform.get().log(INFO, "Callback failure for " + toLoggableString(), e);
-        } else {
-          eventListener.callFailed(RealCall.this, e);
-          responseCallback.onFailure(RealCall.this, e);
+
+        Request request() {
+            return originalRequest;
+        }
+
+        RealCall get() {
+            return RealCall.this;
+        }
+
+        @Override
+        protected void execute() {
+            boolean signalledCallback = false;
+            try {
+                // 执行耗时IO任务
+                // 经过拦截器链的处理得到response
+                Response response = getResponseWithInterceptorChain();
+                if (retryAndFollowUpInterceptor.isCanceled()) {
+                    signalledCallback = true;
+                    //回调，注意这里回调是在线程池中，而不是想当然的主线程回调
+                    responseCallback.onFailure(RealCall.this, new IOException("Canceled"));
+                } else {
+                    signalledCallback = true;
+                    //回调，同上
+                    responseCallback.onResponse(RealCall.this, response);
+                }
+            } catch (IOException e) {
+                if (signalledCallback) {
+                    // Do not signal the callback twice!
+                    Platform.get().log(INFO, "Callback failure for " + toLoggableString(), e);
+                } else {
+                    eventListener.callFailed(RealCall.this, e);
+                    responseCallback.onFailure(RealCall.this, e);
+                }
+            } finally {
+                client.dispatcher().finished(this);
+            }
         }
-      } finally {
-        client.dispatcher().finished(this);
-      }
     }
-  }
-
-  /**
-   * Returns a string that describes this call. Doesn't include a full URL as that might contain
-   * sensitive information.
-   */
-  String toLoggableString() {
-    return (isCanceled() ? "canceled " : "")
-        + (forWebSocket ? "web socket" : "call")
-        + " to " + redactedUrl();
-  }
-
-  String redactedUrl() {
-    return originalRequest.url().redact();
-  }
-
-  Response getResponseWithInterceptorChain() throws IOException {
-    // Build a full stack of interceptors.
-    List<Interceptor> interceptors = new ArrayList<>();
-    interceptors.addAll(client.interceptors());
-    interceptors.add(retryAndFollowUpInterceptor);
-    interceptors.add(new BridgeInterceptor(client.cookieJar()));
-    interceptors.add(new CacheInterceptor(client.internalCache()));
-    interceptors.add(new ConnectInterceptor(client));
-    if (!forWebSocket) {
-      interceptors.addAll(client.networkInterceptors());
+
+    /**
+     * Returns a string that describes this call. Doesn't include a full URL as that might contain
+     * sensitive information.
+     */
+    String toLoggableString() {
+        return (isCanceled() ? "canceled " : "")
+                + (forWebSocket ? "web socket" : "call")
+                + " to " + redactedUrl();
     }
-    interceptors.add(new CallServerInterceptor(forWebSocket));
 
-    Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0,
-        originalRequest, this, eventListener, client.connectTimeoutMillis(),
-        client.readTimeoutMillis(), client.writeTimeoutMillis());
+    String redactedUrl() {
+        return originalRequest.url().redact();
+    }
 
-    return chain.proceed(originalRequest);
-  }
+    /**
+     * 拦截器是okhttp中强大的流程装置，它可以用来监控log，修改/消费请求，修改结果，甚至是对用户透明的GZIP压缩。
+     * 这个方法中递归调用拦截器，然后得到response
+     *
+     * @return
+     * @throws IOException
+     */
+    Response getResponseWithInterceptorChain() throws IOException {
+        // Build a full stack of interceptors.
+        List<Interceptor> interceptors = new ArrayList<>();
+        interceptors.addAll(client.interceptors());
+        interceptors.add(retryAndFollowUpInterceptor);
+        interceptors.add(new BridgeInterceptor(client.cookieJar()));
+        interceptors.add(new CacheInterceptor(client.internalCache()));
+        // 其拦截方法中会调用streamAllocation.newStream的创建httpCodec
+        interceptors.add(new ConnectInterceptor(client));
+        if (!forWebSocket) {
+            interceptors.addAll(client.networkInterceptors());
+        }
+        // CallServerInterceptor是最后一个拦截器，其intercept方法中会调用
+        // httpCodec.writeRequestHeaders 和
+        // httpCodec.readResponseHeaders
+        interceptors.add(new CallServerInterceptor(forWebSocket));
+
+        // index为0的RealInterceptorChain中，httpCodec为空
+        // ConnectInterceptor的intercept中调用RealInterceptorChain的proceed方法时
+        // 传入了httpCodec，即再为下一个拦截器创建链的时候httpCodec不为null
+        Interceptor.Chain chain = new RealInterceptorChain(interceptors, null, null, null, 0,
+                originalRequest, this, eventListener, client.connectTimeoutMillis(),
+                client.readTimeoutMillis(), client.writeTimeoutMillis());
+
+        return chain.proceed(originalRequest);
+    }
 }
diff --git a/okhttp/src/main/java-templates/okhttp3/internal/Version.java b/okhttp/src/main/java/okhttp3/internal/Version.java
similarity index 100%
rename from okhttp/src/main/java-templates/okhttp3/internal/Version.java
rename to okhttp/src/main/java/okhttp3/internal/Version.java
diff --git a/okhttp/src/main/java/okhttp3/internal/cache/CacheInterceptor.java b/okhttp/src/main/java/okhttp3/internal/cache/CacheInterceptor.java
index 787e6b31a9..f92da46749 100644
--- a/okhttp/src/main/java/okhttp3/internal/cache/CacheInterceptor.java
+++ b/okhttp/src/main/java/okhttp3/internal/cache/CacheInterceptor.java
@@ -17,6 +17,7 @@
 package okhttp3.internal.cache;
 
 import java.io.IOException;
+
 import okhttp3.Headers;
 import okhttp3.Interceptor;
 import okhttp3.Protocol;
@@ -41,219 +42,235 @@
 import static okhttp3.internal.Util.closeQuietly;
 import static okhttp3.internal.Util.discard;
 
-/** Serves requests from the cache and writes responses to the cache. */
+/**
+ * Serves requests from the cache and writes responses to the cache.
+ */
 public final class CacheInterceptor implements Interceptor {
-  final InternalCache cache;
-
-  public CacheInterceptor(InternalCache cache) {
-    this.cache = cache;
-  }
-
-  @Override public Response intercept(Chain chain) throws IOException {
-    Response cacheCandidate = cache != null
-        ? cache.get(chain.request())
-        : null;
+    final InternalCache cache;
 
-    long now = System.currentTimeMillis();
-
-    CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get();
-    Request networkRequest = strategy.networkRequest;
-    Response cacheResponse = strategy.cacheResponse;
-
-    if (cache != null) {
-      cache.trackResponse(strategy);
+    public CacheInterceptor(InternalCache cache) {
+        this.cache = cache;
     }
 
-    if (cacheCandidate != null && cacheResponse == null) {
-      closeQuietly(cacheCandidate.body()); // The cache candidate wasn't applicable. Close it.
-    }
+    @Override
+    public Response intercept(Chain chain) throws IOException {
+        // 从cache中获取cacheCandidate（将作为CacheStrategy.Factory的cacheResponse）
+        Response cacheCandidate = cache != null
+                ? cache.get(chain.request())
+                : null;
 
-    // If we're forbidden from using the network and the cache is insufficient, fail.
-    if (networkRequest == null && cacheResponse == null) {
-      return new Response.Builder()
-          .request(chain.request())
-          .protocol(Protocol.HTTP_1_1)
-          .code(504)
-          .message("Unsatisfiable Request (only-if-cached)")
-          .body(Util.EMPTY_RESPONSE)
-          .sentRequestAtMillis(-1L)
-          .receivedResponseAtMillis(System.currentTimeMillis())
-          .build();
-    }
+        long now = System.currentTimeMillis();
 
-    // If we don't need the network, we're done.
-    if (networkRequest == null) {
-      return cacheResponse.newBuilder()
-          .cacheResponse(stripBody(cacheResponse))
-          .build();
-    }
+        // CacheStrategy.Factory构造方法中解析cacheCandidate（cacheResponse）的header然后把解析到的
+        // value保存到Factory的相应属性里。主要是缓存相关的字段。
+        CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate)
+                .get();//根据request（部分情况会给request添加缓存的header字段）和response返回strategy
+        Request networkRequest = strategy.networkRequest;
+        Response cacheResponse = strategy.cacheResponse;
 
-    Response networkResponse = null;
-    try {
-      networkResponse = chain.proceed(networkRequest);
-    } finally {
-      // If we're crashing on I/O or otherwise, don't leak the cache body.
-      if (networkResponse == null && cacheCandidate != null) {
-        closeQuietly(cacheCandidate.body());
-      }
-    }
+        if (cache != null) {
+            cache.trackResponse(strategy);
+        }
 
-    // If we have a cache response too, then we're doing a conditional get.
-    if (cacheResponse != null) {
-      if (networkResponse.code() == HTTP_NOT_MODIFIED) {
-        Response response = cacheResponse.newBuilder()
-            .headers(combine(cacheResponse.headers(), networkResponse.headers()))
-            .sentRequestAtMillis(networkResponse.sentRequestAtMillis())
-            .receivedResponseAtMillis(networkResponse.receivedResponseAtMillis())
-            .cacheResponse(stripBody(cacheResponse))
-            .networkResponse(stripBody(networkResponse))
-            .build();
-        networkResponse.body().close();
-
-        // Update the cache after combining headers but before stripping the
-        // Content-Encoding header (as performed by initContentStream()).
-        cache.trackConditionalCacheHit();
-        cache.update(cacheResponse, response);
-        return response;
-      } else {
-        closeQuietly(cacheResponse.body());
-      }
-    }
+        if (cacheCandidate != null && cacheResponse == null) {
+            closeQuietly(cacheCandidate.body()); // The cache candidate wasn't applicable. Close it.
+        }
 
-    Response response = networkResponse.newBuilder()
-        .cacheResponse(stripBody(cacheResponse))
-        .networkResponse(stripBody(networkResponse))
-        .build();
+        // If we're forbidden from using the network and the cache is insufficient, fail.
+        // only-if-cached(表明不进行网络请求，且缓存不存在或者过期，返回504错误)
+        if (networkRequest == null && cacheResponse == null) {
+            return new Response.Builder()
+                    .request(chain.request())
+                    .protocol(Protocol.HTTP_1_1)
+                    .code(504)
+                    .message("Unsatisfiable Request (only-if-cached)")
+                    .body(Util.EMPTY_RESPONSE)
+                    .sentRequestAtMillis(-1L)
+                    .receivedResponseAtMillis(System.currentTimeMillis())
+                    .build();
+        }
 
-    if (cache != null) {
-      if (HttpHeaders.hasBody(response) && CacheStrategy.isCacheable(response, networkRequest)) {
-        // Offer this request to the cache.
-        CacheRequest cacheRequest = cache.put(response);
-        return cacheWritingResponse(cacheRequest, response);
-      }
+        // If we don't need the network, we're done.
+        // 不进行网络请求，而且缓存可以使用，直接返回缓存，不用请求网络
+        // 不再创建下一个拦截器的链，递归不再深入，开始一路返回
+        if (networkRequest == null) {
+            return cacheResponse.newBuilder()
+                    .cacheResponse(stripBody(cacheResponse))
+                    .build();
+        }
 
-      if (HttpMethod.invalidatesCache(networkRequest.method())) {
+        // 下面是需要网络访问的情况
+        Response networkResponse = null;
         try {
-          cache.remove(networkRequest);
-        } catch (IOException ignored) {
-          // The cache cannot be written.
+            networkResponse = chain.proceed(networkRequest);
+        } finally {
+            // If we're crashing on I/O or otherwise, don't leak the cache body.
+            if (networkResponse == null && cacheCandidate != null) {
+                closeQuietly(cacheCandidate.body());
+            }
         }
-      }
-    }
 
-    return response;
-  }
-
-  private static Response stripBody(Response response) {
-    return response != null && response.body() != null
-        ? response.newBuilder().body(null).build()
-        : response;
-  }
-
-  /**
-   * Returns a new source that writes bytes to {@code cacheRequest} as they are read by the source
-   * consumer. This is careful to discard bytes left over when the stream is closed; otherwise we
-   * may never exhaust the source stream and therefore not complete the cached response.
-   */
-  private Response cacheWritingResponse(final CacheRequest cacheRequest, Response response)
-      throws IOException {
-    // Some apps return a null body; for compatibility we treat that like a null cache request.
-    if (cacheRequest == null) return response;
-    Sink cacheBodyUnbuffered = cacheRequest.body();
-    if (cacheBodyUnbuffered == null) return response;
-
-    final BufferedSource source = response.body().source();
-    final BufferedSink cacheBody = Okio.buffer(cacheBodyUnbuffered);
-
-    Source cacheWritingSource = new Source() {
-      boolean cacheRequestClosed;
-
-      @Override public long read(Buffer sink, long byteCount) throws IOException {
-        long bytesRead;
-        try {
-          bytesRead = source.read(sink, byteCount);
-        } catch (IOException e) {
-          if (!cacheRequestClosed) {
-            cacheRequestClosed = true;
-            cacheRequest.abort(); // Failed to write a complete cache response.
-          }
-          throw e;
+        // If we have a cache response too, then we're doing a conditional get.
+        if (cacheResponse != null) {
+            if (networkResponse.code() == HTTP_NOT_MODIFIED) {
+                Response response = cacheResponse.newBuilder()
+                        .headers(combine(cacheResponse.headers(), networkResponse.headers()))
+                        .sentRequestAtMillis(networkResponse.sentRequestAtMillis())
+                        .receivedResponseAtMillis(networkResponse.receivedResponseAtMillis())
+                        .cacheResponse(stripBody(cacheResponse))
+                        .networkResponse(stripBody(networkResponse))
+                        .build();
+                networkResponse.body().close();
+
+                // Update the cache after combining headers but before stripping the
+                // Content-Encoding header (as performed by initContentStream()).
+                cache.trackConditionalCacheHit();
+                cache.update(cacheResponse, response);
+                return response;
+            } else {
+                closeQuietly(cacheResponse.body());
+            }
         }
 
-        if (bytesRead == -1) {
-          if (!cacheRequestClosed) {
-            cacheRequestClosed = true;
-            cacheBody.close(); // The cache response is complete!
-          }
-          return -1;
+        Response response = networkResponse.newBuilder()
+                .cacheResponse(stripBody(cacheResponse))
+                .networkResponse(stripBody(networkResponse))
+                .build();
+
+        if (cache != null) {
+            if (HttpHeaders.hasBody(response) && CacheStrategy.isCacheable(response, networkRequest)) {
+                // Offer this request to the cache.
+                CacheRequest cacheRequest = cache.put(response);
+                return cacheWritingResponse(cacheRequest, response);
+            }
+
+            if (HttpMethod.invalidatesCache(networkRequest.method())) {
+                try {
+                    cache.remove(networkRequest);
+                } catch (IOException ignored) {
+                    // The cache cannot be written.
+                }
+            }
         }
 
-        sink.copyTo(cacheBody.buffer(), sink.size() - bytesRead, bytesRead);
-        cacheBody.emitCompleteSegments();
-        return bytesRead;
-      }
+        return response;
+    }
 
-      @Override public Timeout timeout() {
-        return source.timeout();
-      }
+    private static Response stripBody(Response response) {
+        return response != null && response.body() != null
+                ? response.newBuilder().body(null).build()
+                : response;
+    }
 
-      @Override public void close() throws IOException {
-        if (!cacheRequestClosed
-            && !discard(this, HttpCodec.DISCARD_STREAM_TIMEOUT_MILLIS, MILLISECONDS)) {
-          cacheRequestClosed = true;
-          cacheRequest.abort();
-        }
-        source.close();
-      }
-    };
-
-    String contentType = response.header("Content-Type");
-    long contentLength = response.body().contentLength();
-    return response.newBuilder()
-        .body(new RealResponseBody(contentType, contentLength, Okio.buffer(cacheWritingSource)))
-        .build();
-  }
-
-  /** Combines cached headers with a network headers as defined by RFC 7234, 4.3.4. */
-  private static Headers combine(Headers cachedHeaders, Headers networkHeaders) {
-    Headers.Builder result = new Headers.Builder();
-
-    for (int i = 0, size = cachedHeaders.size(); i < size; i++) {
-      String fieldName = cachedHeaders.name(i);
-      String value = cachedHeaders.value(i);
-      if ("Warning".equalsIgnoreCase(fieldName) && value.startsWith("1")) {
-        continue; // Drop 100-level freshness warnings.
-      }
-      if (!isEndToEnd(fieldName) || networkHeaders.get(fieldName) == null) {
-        Internal.instance.addLenient(result, fieldName, value);
-      }
+    /**
+     * Returns a new source that writes bytes to {@code cacheRequest} as they are read by the source
+     * consumer. This is careful to discard bytes left over when the stream is closed; otherwise we
+     * may never exhaust the source stream and therefore not complete the cached response.
+     */
+    private Response cacheWritingResponse(final CacheRequest cacheRequest, Response response)
+            throws IOException {
+        // Some apps return a null body; for compatibility we treat that like a null cache request.
+        if (cacheRequest == null) return response;
+        Sink cacheBodyUnbuffered = cacheRequest.body();
+        if (cacheBodyUnbuffered == null) return response;
+
+        final BufferedSource source = response.body().source();
+        final BufferedSink cacheBody = Okio.buffer(cacheBodyUnbuffered);
+
+        Source cacheWritingSource = new Source() {
+            boolean cacheRequestClosed;
+
+            @Override
+            public long read(Buffer sink, long byteCount) throws IOException {
+                long bytesRead;
+                try {
+                    bytesRead = source.read(sink, byteCount);
+                } catch (IOException e) {
+                    if (!cacheRequestClosed) {
+                        cacheRequestClosed = true;
+                        cacheRequest.abort(); // Failed to write a complete cache response.
+                    }
+                    throw e;
+                }
+
+                if (bytesRead == -1) {
+                    if (!cacheRequestClosed) {
+                        cacheRequestClosed = true;
+                        cacheBody.close(); // The cache response is complete!
+                    }
+                    return -1;
+                }
+
+                sink.copyTo(cacheBody.buffer(), sink.size() - bytesRead, bytesRead);
+                cacheBody.emitCompleteSegments();
+                return bytesRead;
+            }
+
+            @Override
+            public Timeout timeout() {
+                return source.timeout();
+            }
+
+            @Override
+            public void close() throws IOException {
+                if (!cacheRequestClosed
+                        && !discard(this, HttpCodec.DISCARD_STREAM_TIMEOUT_MILLIS, MILLISECONDS)) {
+                    cacheRequestClosed = true;
+                    cacheRequest.abort();
+                }
+                source.close();
+            }
+        };
+
+        String contentType = response.header("Content-Type");
+        long contentLength = response.body().contentLength();
+        return response.newBuilder()
+                .body(new RealResponseBody(contentType, contentLength, Okio.buffer(cacheWritingSource)))
+                .build();
     }
 
-    for (int i = 0, size = networkHeaders.size(); i < size; i++) {
-      String fieldName = networkHeaders.name(i);
-      if ("Content-Length".equalsIgnoreCase(fieldName)) {
-        continue; // Ignore content-length headers of validating responses.
-      }
-      if (isEndToEnd(fieldName)) {
-        Internal.instance.addLenient(result, fieldName, networkHeaders.value(i));
-      }
+    /**
+     * Combines cached headers with a network headers as defined by RFC 7234, 4.3.4.
+     */
+    private static Headers combine(Headers cachedHeaders, Headers networkHeaders) {
+        Headers.Builder result = new Headers.Builder();
+
+        for (int i = 0, size = cachedHeaders.size(); i < size; i++) {
+            String fieldName = cachedHeaders.name(i);
+            String value = cachedHeaders.value(i);
+            if ("Warning".equalsIgnoreCase(fieldName) && value.startsWith("1")) {
+                continue; // Drop 100-level freshness warnings.
+            }
+            if (!isEndToEnd(fieldName) || networkHeaders.get(fieldName) == null) {
+                Internal.instance.addLenient(result, fieldName, value);
+            }
+        }
+
+        for (int i = 0, size = networkHeaders.size(); i < size; i++) {
+            String fieldName = networkHeaders.name(i);
+            if ("Content-Length".equalsIgnoreCase(fieldName)) {
+                continue; // Ignore content-length headers of validating responses.
+            }
+            if (isEndToEnd(fieldName)) {
+                Internal.instance.addLenient(result, fieldName, networkHeaders.value(i));
+            }
+        }
+
+        return result.build();
     }
 
-    return result.build();
-  }
-
-  /**
-   * Returns true if {@code fieldName} is an end-to-end HTTP header, as defined by RFC 2616,
-   * 13.5.1.
-   */
-  static boolean isEndToEnd(String fieldName) {
-    return !"Connection".equalsIgnoreCase(fieldName)
-        && !"Keep-Alive".equalsIgnoreCase(fieldName)
-        && !"Proxy-Authenticate".equalsIgnoreCase(fieldName)
-        && !"Proxy-Authorization".equalsIgnoreCase(fieldName)
-        && !"TE".equalsIgnoreCase(fieldName)
-        && !"Trailers".equalsIgnoreCase(fieldName)
-        && !"Transfer-Encoding".equalsIgnoreCase(fieldName)
-        && !"Upgrade".equalsIgnoreCase(fieldName);
-  }
+    /**
+     * Returns true if {@code fieldName} is an end-to-end HTTP header, as defined by RFC 2616,
+     * 13.5.1.
+     */
+    static boolean isEndToEnd(String fieldName) {
+        return !"Connection".equalsIgnoreCase(fieldName)
+                && !"Keep-Alive".equalsIgnoreCase(fieldName)
+                && !"Proxy-Authenticate".equalsIgnoreCase(fieldName)
+                && !"Proxy-Authorization".equalsIgnoreCase(fieldName)
+                && !"TE".equalsIgnoreCase(fieldName)
+                && !"Trailers".equalsIgnoreCase(fieldName)
+                && !"Transfer-Encoding".equalsIgnoreCase(fieldName)
+                && !"Upgrade".equalsIgnoreCase(fieldName);
+    }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/cache/CacheStrategy.java b/okhttp/src/main/java/okhttp3/internal/cache/CacheStrategy.java
index 3ae1926650..c94abe88e4 100644
--- a/okhttp/src/main/java/okhttp3/internal/cache/CacheStrategy.java
+++ b/okhttp/src/main/java/okhttp3/internal/cache/CacheStrategy.java
@@ -17,6 +17,7 @@
 
 import java.util.Date;
 import javax.annotation.Nullable;
+
 import okhttp3.CacheControl;
 import okhttp3.Headers;
 import okhttp3.Request;
@@ -42,288 +43,306 @@
 /**
  * Given a request and cached response, this figures out whether to use the network, the cache, or
  * both.
- *
+ * <p>
  * <p>Selecting a cache strategy may add conditions to the request (like the "If-Modified-Since"
  * header for conditional GETs) or warnings to the cached response (if the cached data is
  * potentially stale).
  */
 public final class CacheStrategy {
-  /** The request to send on the network, or null if this call doesn't use the network. */
-  public final @Nullable Request networkRequest;
-
-  /** The cached response to return or validate; or null if this call doesn't use a cache. */
-  public final @Nullable Response cacheResponse;
-
-  CacheStrategy(Request networkRequest, Response cacheResponse) {
-    this.networkRequest = networkRequest;
-    this.cacheResponse = cacheResponse;
-  }
-
-  /** Returns true if {@code response} can be stored to later serve another request. */
-  public static boolean isCacheable(Response response, Request request) {
-    // Always go to network for uncacheable response codes (RFC 7231 section 6.1),
-    // This implementation doesn't support caching partial content.
-    switch (response.code()) {
-      case HTTP_OK:
-      case HTTP_NOT_AUTHORITATIVE:
-      case HTTP_NO_CONTENT:
-      case HTTP_MULT_CHOICE:
-      case HTTP_MOVED_PERM:
-      case HTTP_NOT_FOUND:
-      case HTTP_BAD_METHOD:
-      case HTTP_GONE:
-      case HTTP_REQ_TOO_LONG:
-      case HTTP_NOT_IMPLEMENTED:
-      case StatusLine.HTTP_PERM_REDIRECT:
-        // These codes can be cached unless headers forbid it.
-        break;
-
-      case HTTP_MOVED_TEMP:
-      case StatusLine.HTTP_TEMP_REDIRECT:
-        // These codes can only be cached with the right response headers.
-        // http://tools.ietf.org/html/rfc7234#section-3
-        // s-maxage is not checked because OkHttp is a private cache that should ignore s-maxage.
-        if (response.header("Expires") != null
-            || response.cacheControl().maxAgeSeconds() != -1
-            || response.cacheControl().isPublic()
-            || response.cacheControl().isPrivate()) {
-          break;
-        }
-        // Fall-through.
-
-      default:
-        // All other codes cannot be cached.
-        return false;
-    }
-
-    // A 'no-store' directive on request or response prevents the response from being cached.
-    return !response.cacheControl().noStore() && !request.cacheControl().noStore();
-  }
-
-  public static class Factory {
-    final long nowMillis;
-    final Request request;
-    final Response cacheResponse;
-
-    /** The server's time when the cached response was served, if known. */
-    private Date servedDate;
-    private String servedDateString;
-
-    /** The last modified date of the cached response, if known. */
-    private Date lastModified;
-    private String lastModifiedString;
-
     /**
-     * The expiration date of the cached response, if known. If both this field and the max age are
-     * set, the max age is preferred.
+     * The request to send on the network, or null if this call doesn't use the network.
      */
-    private Date expires;
+    public final @Nullable
+    Request networkRequest;
 
     /**
-     * Extension header set by OkHttp specifying the timestamp when the cached HTTP request was
-     * first initiated.
+     * The cached response to return or validate; or null if this call doesn't use a cache.
      */
-    private long sentRequestMillis;
+    public final @Nullable
+    Response cacheResponse;
+
+    CacheStrategy(Request networkRequest, Response cacheResponse) {
+        this.networkRequest = networkRequest;
+        this.cacheResponse = cacheResponse;
+    }
 
     /**
-     * Extension header set by OkHttp specifying the timestamp when the cached HTTP response was
-     * first received.
+     * Returns true if {@code response} can be stored to later serve another request.
      */
-    private long receivedResponseMillis;
-
-    /** Etag of the cached response. */
-    private String etag;
-
-    /** Age of the cached response. */
-    private int ageSeconds = -1;
-
-    public Factory(long nowMillis, Request request, Response cacheResponse) {
-      this.nowMillis = nowMillis;
-      this.request = request;
-      this.cacheResponse = cacheResponse;
-
-      if (cacheResponse != null) {
-        this.sentRequestMillis = cacheResponse.sentRequestAtMillis();
-        this.receivedResponseMillis = cacheResponse.receivedResponseAtMillis();
-        Headers headers = cacheResponse.headers();
-        for (int i = 0, size = headers.size(); i < size; i++) {
-          String fieldName = headers.name(i);
-          String value = headers.value(i);
-          if ("Date".equalsIgnoreCase(fieldName)) {
-            servedDate = HttpDate.parse(value);
-            servedDateString = value;
-          } else if ("Expires".equalsIgnoreCase(fieldName)) {
-            expires = HttpDate.parse(value);
-          } else if ("Last-Modified".equalsIgnoreCase(fieldName)) {
-            lastModified = HttpDate.parse(value);
-            lastModifiedString = value;
-          } else if ("ETag".equalsIgnoreCase(fieldName)) {
-            etag = value;
-          } else if ("Age".equalsIgnoreCase(fieldName)) {
-            ageSeconds = HttpHeaders.parseSeconds(value, -1);
-          }
+    public static boolean isCacheable(Response response, Request request) {
+        // Always go to network for uncacheable response codes (RFC 7231 section 6.1),
+        // This implementation doesn't support caching partial content.
+        switch (response.code()) {
+            case HTTP_OK:
+            case HTTP_NOT_AUTHORITATIVE:
+            case HTTP_NO_CONTENT:
+            case HTTP_MULT_CHOICE:
+            case HTTP_MOVED_PERM:
+            case HTTP_NOT_FOUND:
+            case HTTP_BAD_METHOD:
+            case HTTP_GONE:
+            case HTTP_REQ_TOO_LONG:
+            case HTTP_NOT_IMPLEMENTED:
+            case StatusLine.HTTP_PERM_REDIRECT:
+                // These codes can be cached unless headers forbid it.
+                break;
+
+            case HTTP_MOVED_TEMP:
+            case StatusLine.HTTP_TEMP_REDIRECT:
+                // These codes can only be cached with the right response headers.
+                // http://tools.ietf.org/html/rfc7234#section-3
+                // s-maxage is not checked because OkHttp is a private cache that should ignore s-maxage.
+                if (response.header("Expires") != null
+                        || response.cacheControl().maxAgeSeconds() != -1
+                        || response.cacheControl().isPublic()
+                        || response.cacheControl().isPrivate()) {
+                    break;
+                }
+                // Fall-through.
+
+            default:
+                // All other codes cannot be cached.
+                return false;
         }
-      }
+
+        // A 'no-store' directive on request or response prevents the response from being cached.
+        return !response.cacheControl().noStore() && !request.cacheControl().noStore();
     }
 
-    /**
-     * Returns a strategy to satisfy {@code request} using the a cached response {@code response}.
-     */
-    public CacheStrategy get() {
-      CacheStrategy candidate = getCandidate();
+    public static class Factory {
+        final long nowMillis;
+        final Request request;
+        final Response cacheResponse;
+
+        /**
+         * The server's time when the cached response was served, if known.
+         */
+        private Date servedDate;
+        private String servedDateString;
+
+        /**
+         * The last modified date of the cached response, if known.
+         */
+        private Date lastModified;
+        private String lastModifiedString;
+
+        /**
+         * The expiration date of the cached response, if known. If both this field and the max age are
+         * set, the max age is preferred.
+         */
+        private Date expires;
+
+        /**
+         * Extension header set by OkHttp specifying the timestamp when the cached HTTP request was
+         * first initiated.
+         */
+        private long sentRequestMillis;
+
+        /**
+         * Extension header set by OkHttp specifying the timestamp when the cached HTTP response was
+         * first received.
+         */
+        private long receivedResponseMillis;
+
+        /**
+         * Etag of the cached response.
+         */
+        private String etag;
+
+        /**
+         * Age of the cached response.
+         */
+        private int ageSeconds = -1;
+
+        public Factory(long nowMillis, Request request, Response cacheResponse) {
+            this.nowMillis = nowMillis;
+            this.request = request;
+            this.cacheResponse = cacheResponse;
+
+            if (cacheResponse != null) {
+                this.sentRequestMillis = cacheResponse.sentRequestAtMillis();
+                this.receivedResponseMillis = cacheResponse.receivedResponseAtMillis();
+                Headers headers = cacheResponse.headers();
+                for (int i = 0, size = headers.size(); i < size; i++) {
+                    String fieldName = headers.name(i);
+                    String value = headers.value(i);
+                    if ("Date".equalsIgnoreCase(fieldName)) {
+                        servedDate = HttpDate.parse(value);
+                        servedDateString = value;
+                    } else if ("Expires".equalsIgnoreCase(fieldName)) {
+                        expires = HttpDate.parse(value);
+                    } else if ("Last-Modified".equalsIgnoreCase(fieldName)) {
+                        lastModified = HttpDate.parse(value);
+                        lastModifiedString = value;
+                    } else if ("ETag".equalsIgnoreCase(fieldName)) {
+                        etag = value;
+                    } else if ("Age".equalsIgnoreCase(fieldName)) {
+                        ageSeconds = HttpHeaders.parseSeconds(value, -1);
+                    }
+                }
+            }
+        }
 
-      if (candidate.networkRequest != null && request.cacheControl().onlyIfCached()) {
-        // We're forbidden from using the network and the cache is insufficient.
-        return new CacheStrategy(null, null);
-      }
+        /**
+         * Returns a strategy to satisfy {@code request} using the a cached response {@code response}.
+         */
+        public CacheStrategy get() {
+            CacheStrategy candidate = getCandidate();
 
-      return candidate;
-    }
+            if (candidate.networkRequest != null && request.cacheControl().onlyIfCached()) {
+                // We're forbidden from using the network and the cache is insufficient.
+                return new CacheStrategy(null, null);
+            }
 
-    /** Returns a strategy to use assuming the request can use the network. */
-    private CacheStrategy getCandidate() {
-      // No cached response.
-      if (cacheResponse == null) {
-        return new CacheStrategy(request, null);
-      }
-
-      // Drop the cached response if it's missing a required handshake.
-      if (request.isHttps() && cacheResponse.handshake() == null) {
-        return new CacheStrategy(request, null);
-      }
-
-      // If this response shouldn't have been stored, it should never be used
-      // as a response source. This check should be redundant as long as the
-      // persistence store is well-behaved and the rules are constant.
-      if (!isCacheable(cacheResponse, request)) {
-        return new CacheStrategy(request, null);
-      }
-
-      CacheControl requestCaching = request.cacheControl();
-      if (requestCaching.noCache() || hasConditions(request)) {
-        return new CacheStrategy(request, null);
-      }
-
-      CacheControl responseCaching = cacheResponse.cacheControl();
-      if (responseCaching.immutable()) {
-        return new CacheStrategy(null, cacheResponse);
-      }
-
-      long ageMillis = cacheResponseAge();
-      long freshMillis = computeFreshnessLifetime();
-
-      if (requestCaching.maxAgeSeconds() != -1) {
-        freshMillis = Math.min(freshMillis, SECONDS.toMillis(requestCaching.maxAgeSeconds()));
-      }
-
-      long minFreshMillis = 0;
-      if (requestCaching.minFreshSeconds() != -1) {
-        minFreshMillis = SECONDS.toMillis(requestCaching.minFreshSeconds());
-      }
-
-      long maxStaleMillis = 0;
-      if (!responseCaching.mustRevalidate() && requestCaching.maxStaleSeconds() != -1) {
-        maxStaleMillis = SECONDS.toMillis(requestCaching.maxStaleSeconds());
-      }
-
-      if (!responseCaching.noCache() && ageMillis + minFreshMillis < freshMillis + maxStaleMillis) {
-        Response.Builder builder = cacheResponse.newBuilder();
-        if (ageMillis + minFreshMillis >= freshMillis) {
-          builder.addHeader("Warning", "110 HttpURLConnection \"Response is stale\"");
+            return candidate;
         }
-        long oneDayMillis = 24 * 60 * 60 * 1000L;
-        if (ageMillis > oneDayMillis && isFreshnessLifetimeHeuristic()) {
-          builder.addHeader("Warning", "113 HttpURLConnection \"Heuristic expiration\"");
+
+        /**
+         * Returns a strategy to use assuming the request can use the network.
+         */
+        private CacheStrategy getCandidate() {
+            // No cached response.
+            if (cacheResponse == null) {
+                return new CacheStrategy(request, null);
+            }
+
+            // Drop the cached response if it's missing a required handshake.
+            if (request.isHttps() && cacheResponse.handshake() == null) {
+                return new CacheStrategy(request, null);
+            }
+
+            // If this response shouldn't have been stored, it should never be used
+            // as a response source. This check should be redundant as long as the
+            // persistence store is well-behaved and the rules are constant.
+            if (!isCacheable(cacheResponse, request)) {
+                return new CacheStrategy(request, null);
+            }
+
+            CacheControl requestCaching = request.cacheControl();
+            if (requestCaching.noCache() || hasConditions(request)) {
+                return new CacheStrategy(request, null);
+            }
+
+            CacheControl responseCaching = cacheResponse.cacheControl();
+            if (responseCaching.immutable()) {
+                return new CacheStrategy(null, cacheResponse);
+            }
+
+            long ageMillis = cacheResponseAge();
+            long freshMillis = computeFreshnessLifetime();
+
+            if (requestCaching.maxAgeSeconds() != -1) {
+                freshMillis = Math.min(freshMillis, SECONDS.toMillis(requestCaching.maxAgeSeconds()));
+            }
+
+            long minFreshMillis = 0;
+            if (requestCaching.minFreshSeconds() != -1) {
+                minFreshMillis = SECONDS.toMillis(requestCaching.minFreshSeconds());
+            }
+
+            long maxStaleMillis = 0;
+            if (!responseCaching.mustRevalidate() && requestCaching.maxStaleSeconds() != -1) {
+                maxStaleMillis = SECONDS.toMillis(requestCaching.maxStaleSeconds());
+            }
+
+            if (!responseCaching.noCache() && ageMillis + minFreshMillis < freshMillis + maxStaleMillis) {
+                Response.Builder builder = cacheResponse.newBuilder();
+                if (ageMillis + minFreshMillis >= freshMillis) {
+                    builder.addHeader("Warning", "110 HttpURLConnection \"Response is stale\"");
+                }
+                long oneDayMillis = 24 * 60 * 60 * 1000L;
+                if (ageMillis > oneDayMillis && isFreshnessLifetimeHeuristic()) {
+                    builder.addHeader("Warning", "113 HttpURLConnection \"Heuristic expiration\"");
+                }
+                return new CacheStrategy(null, builder.build());
+            }
+
+            // Find a condition to add to the request. If the condition is satisfied, the response body
+            // will not be transmitted.
+            String conditionName;
+            String conditionValue;
+            if (etag != null) {
+                conditionName = "If-None-Match";
+                conditionValue = etag;
+            } else if (lastModified != null) {
+                conditionName = "If-Modified-Since";
+                conditionValue = lastModifiedString;
+            } else if (servedDate != null) {
+                conditionName = "If-Modified-Since";
+                conditionValue = servedDateString;
+            } else {
+                return new CacheStrategy(request, null); // No condition! Make a regular request.
+            }
+
+            Headers.Builder conditionalRequestHeaders = request.headers().newBuilder();
+            Internal.instance.addLenient(conditionalRequestHeaders, conditionName, conditionValue);
+
+            Request conditionalRequest = request.newBuilder()
+                    .headers(conditionalRequestHeaders.build())
+                    .build();
+            return new CacheStrategy(conditionalRequest, cacheResponse);
         }
-        return new CacheStrategy(null, builder.build());
-      }
-
-      // Find a condition to add to the request. If the condition is satisfied, the response body
-      // will not be transmitted.
-      String conditionName;
-      String conditionValue;
-      if (etag != null) {
-        conditionName = "If-None-Match";
-        conditionValue = etag;
-      } else if (lastModified != null) {
-        conditionName = "If-Modified-Since";
-        conditionValue = lastModifiedString;
-      } else if (servedDate != null) {
-        conditionName = "If-Modified-Since";
-        conditionValue = servedDateString;
-      } else {
-        return new CacheStrategy(request, null); // No condition! Make a regular request.
-      }
-
-      Headers.Builder conditionalRequestHeaders = request.headers().newBuilder();
-      Internal.instance.addLenient(conditionalRequestHeaders, conditionName, conditionValue);
-
-      Request conditionalRequest = request.newBuilder()
-          .headers(conditionalRequestHeaders.build())
-          .build();
-      return new CacheStrategy(conditionalRequest, cacheResponse);
-    }
 
-    /**
-     * Returns the number of milliseconds that the response was fresh for, starting from the served
-     * date.
-     */
-    private long computeFreshnessLifetime() {
-      CacheControl responseCaching = cacheResponse.cacheControl();
-      if (responseCaching.maxAgeSeconds() != -1) {
-        return SECONDS.toMillis(responseCaching.maxAgeSeconds());
-      } else if (expires != null) {
-        long servedMillis = servedDate != null
-            ? servedDate.getTime()
-            : receivedResponseMillis;
-        long delta = expires.getTime() - servedMillis;
-        return delta > 0 ? delta : 0;
-      } else if (lastModified != null
-          && cacheResponse.request().url().query() == null) {
-        // As recommended by the HTTP RFC and implemented in Firefox, the
-        // max age of a document should be defaulted to 10% of the
-        // document's age at the time it was served. Default expiration
-        // dates aren't used for URIs containing a query.
-        long servedMillis = servedDate != null
-            ? servedDate.getTime()
-            : sentRequestMillis;
-        long delta = servedMillis - lastModified.getTime();
-        return delta > 0 ? (delta / 10) : 0;
-      }
-      return 0;
-    }
+        /**
+         * Returns the number of milliseconds that the response was fresh for, starting from the served
+         * date.
+         */
+        private long computeFreshnessLifetime() {
+            CacheControl responseCaching = cacheResponse.cacheControl();
+            if (responseCaching.maxAgeSeconds() != -1) {
+                return SECONDS.toMillis(responseCaching.maxAgeSeconds());
+            } else if (expires != null) {
+                long servedMillis = servedDate != null
+                        ? servedDate.getTime()
+                        : receivedResponseMillis;
+                long delta = expires.getTime() - servedMillis;
+                return delta > 0 ? delta : 0;
+            } else if (lastModified != null
+                    && cacheResponse.request().url().query() == null) {
+                // As recommended by the HTTP RFC and implemented in Firefox, the
+                // max age of a document should be defaulted to 10% of the
+                // document's age at the time it was served. Default expiration
+                // dates aren't used for URIs containing a query.
+                long servedMillis = servedDate != null
+                        ? servedDate.getTime()
+                        : sentRequestMillis;
+                long delta = servedMillis - lastModified.getTime();
+                return delta > 0 ? (delta / 10) : 0;
+            }
+            return 0;
+        }
 
-    /**
-     * Returns the current age of the response, in milliseconds. The calculation is specified by RFC
-     * 7234, 4.2.3 Calculating Age.
-     */
-    private long cacheResponseAge() {
-      long apparentReceivedAge = servedDate != null
-          ? Math.max(0, receivedResponseMillis - servedDate.getTime())
-          : 0;
-      long receivedAge = ageSeconds != -1
-          ? Math.max(apparentReceivedAge, SECONDS.toMillis(ageSeconds))
-          : apparentReceivedAge;
-      long responseDuration = receivedResponseMillis - sentRequestMillis;
-      long residentDuration = nowMillis - receivedResponseMillis;
-      return receivedAge + responseDuration + residentDuration;
-    }
+        /**
+         * Returns the current age of the response, in milliseconds. The calculation is specified by RFC
+         * 7234, 4.2.3 Calculating Age.
+         */
+        private long cacheResponseAge() {
+            long apparentReceivedAge = servedDate != null
+                    ? Math.max(0, receivedResponseMillis - servedDate.getTime())
+                    : 0;
+            long receivedAge = ageSeconds != -1
+                    ? Math.max(apparentReceivedAge, SECONDS.toMillis(ageSeconds))
+                    : apparentReceivedAge;
+            long responseDuration = receivedResponseMillis - sentRequestMillis;
+            long residentDuration = nowMillis - receivedResponseMillis;
+            return receivedAge + responseDuration + residentDuration;
+        }
 
-    /**
-     * Returns true if computeFreshnessLifetime used a heuristic. If we used a heuristic to serve a
-     * cached response older than 24 hours, we are required to attach a warning.
-     */
-    private boolean isFreshnessLifetimeHeuristic() {
-      return cacheResponse.cacheControl().maxAgeSeconds() == -1 && expires == null;
-    }
+        /**
+         * Returns true if computeFreshnessLifetime used a heuristic. If we used a heuristic to serve a
+         * cached response older than 24 hours, we are required to attach a warning.
+         */
+        private boolean isFreshnessLifetimeHeuristic() {
+            return cacheResponse.cacheControl().maxAgeSeconds() == -1 && expires == null;
+        }
 
-    /**
-     * Returns true if the request contains conditions that save the server from sending a response
-     * that the client has locally. When a request is enqueued with its own conditions, the built-in
-     * response cache won't be used.
-     */
-    private static boolean hasConditions(Request request) {
-      return request.header("If-Modified-Since") != null || request.header("If-None-Match") != null;
+        /**
+         * Returns true if the request contains conditions that save the server from sending a response
+         * that the client has locally. When a request is enqueued with its own conditions, the built-in
+         * response cache won't be used.
+         */
+        private static boolean hasConditions(Request request) {
+            return request.header("If-Modified-Since") != null || request.header("If-None-Match") != null;
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/cache/DiskLruCache.java b/okhttp/src/main/java/okhttp3/internal/cache/DiskLruCache.java
index c3fb740e28..d107234b44 100644
--- a/okhttp/src/main/java/okhttp3/internal/cache/DiskLruCache.java
+++ b/okhttp/src/main/java/okhttp3/internal/cache/DiskLruCache.java
@@ -33,6 +33,7 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import javax.annotation.Nullable;
+
 import okhttp3.internal.Util;
 import okhttp3.internal.io.FileSystem;
 import okhttp3.internal.platform.Platform;
@@ -49,53 +50,55 @@
  * and a fixed number of values. Each key must match the regex <strong>[a-z0-9_-]{1,64}</strong>.
  * Values are byte sequences, accessible as streams or files. Each value must be between {@code 0}
  * and {@code Integer.MAX_VALUE} bytes in length.
- *
+ * <p>
  * <p>The cache stores its data in a directory on the filesystem. This directory must be exclusive
  * to the cache; the cache may delete or overwrite files from its directory. It is an error for
  * multiple processes to use the same cache directory at the same time.
- *
+ * <p>
  * <p>This cache limits the number of bytes that it will store on the filesystem. When the number of
  * stored bytes exceeds the limit, the cache will remove entries in the background until the limit
  * is satisfied. The limit is not strict: the cache may temporarily exceed it while waiting for
  * files to be deleted. The limit does not include filesystem overhead or the cache journal so
  * space-sensitive applications should set a conservative limit.
- *
+ * <p>
  * <p>Clients call {@link #edit} to create or update the values of an entry. An entry may have only
  * one editor at one time; if a value is not available to be edited then {@link #edit} will return
  * null.
- *
+ * <p>
  * <ul>
- *     <li>When an entry is being <strong>created</strong> it is necessary to supply a full set of
- *         values; the empty value should be used as a placeholder if necessary.
- *     <li>When an entry is being <strong>edited</strong>, it is not necessary to supply data for
- *         every value; values default to their previous value.
+ * <li>When an entry is being <strong>created</strong> it is necessary to supply a full set of
+ * values; the empty value should be used as a placeholder if necessary.
+ * <li>When an entry is being <strong>edited</strong>, it is not necessary to supply data for
+ * every value; values default to their previous value.
  * </ul>
- *
+ * <p>
  * <p>Every {@link #edit} call must be matched by a call to {@link Editor#commit} or {@link
  * Editor#abort}. Committing is atomic: a read observes the full set of values as they were before
  * or after the commit, but never a mix of values.
- *
+ * <p>
  * <p>Clients call {@link #get} to read a snapshot of an entry. The read will observe the value at
  * the time that {@link #get} was called. Updates and removals after the call do not impact ongoing
  * reads.
- *
+ * <p>
  * <p>This class is tolerant of some I/O errors. If files are missing from the filesystem, the
  * corresponding entries will be dropped from the cache. If an error occurs while writing a cache
  * value, the edit will fail silently. Callers should handle other problems by catching {@code
  * IOException} and responding appropriately.
+ * <p>
+ * 维护着文件的创建，清理，读取。内部有清理线程池，LinkedHashMap(也就是LruCache)
  */
 public final class DiskLruCache implements Closeable, Flushable {
-  static final String JOURNAL_FILE = "journal";
-  static final String JOURNAL_FILE_TEMP = "journal.tmp";
-  static final String JOURNAL_FILE_BACKUP = "journal.bkp";
-  static final String MAGIC = "libcore.io.DiskLruCache";
-  static final String VERSION_1 = "1";
-  static final long ANY_SEQUENCE_NUMBER = -1;
-  static final Pattern LEGAL_KEY_PATTERN = Pattern.compile("[a-z0-9_-]{1,120}");
-  private static final String CLEAN = "CLEAN";
-  private static final String DIRTY = "DIRTY";
-  private static final String REMOVE = "REMOVE";
-  private static final String READ = "READ";
+    static final String JOURNAL_FILE = "journal";
+    static final String JOURNAL_FILE_TEMP = "journal.tmp";
+    static final String JOURNAL_FILE_BACKUP = "journal.bkp";
+    static final String MAGIC = "libcore.io.DiskLruCache";
+    static final String VERSION_1 = "1";
+    static final long ANY_SEQUENCE_NUMBER = -1;
+    static final Pattern LEGAL_KEY_PATTERN = Pattern.compile("[a-z0-9_-]{1,120}");
+    private static final String CLEAN = "CLEAN";
+    private static final String DIRTY = "DIRTY";
+    private static final String REMOVE = "REMOVE";
+    private static final String READ = "READ";
 
     /*
      * This cache uses a journal file named "journal". A typical journal file
@@ -137,917 +140,964 @@
      * it exists when the cache is opened.
      */
 
-  final FileSystem fileSystem;
-  final File directory;
-  private final File journalFile;
-  private final File journalFileTmp;
-  private final File journalFileBackup;
-  private final int appVersion;
-  private long maxSize;
-  final int valueCount;
-  private long size = 0;
-  BufferedSink journalWriter;
-  final LinkedHashMap<String, Entry> lruEntries = new LinkedHashMap<>(0, 0.75f, true);
-  int redundantOpCount;
-  boolean hasJournalErrors;
-
-  // Must be read and written when synchronized on 'this'.
-  boolean initialized;
-  boolean closed;
-  boolean mostRecentTrimFailed;
-  boolean mostRecentRebuildFailed;
-
-  /**
-   * To differentiate between old and current snapshots, each entry is given a sequence number each
-   * time an edit is committed. A snapshot is stale if its sequence number is not equal to its
-   * entry's sequence number.
-   */
-  private long nextSequenceNumber = 0;
-
-  /** Used to run 'cleanupRunnable' for journal rebuilds. */
-  private final Executor executor;
-  private final Runnable cleanupRunnable = new Runnable() {
-    public void run() {
-      synchronized (DiskLruCache.this) {
-        if (!initialized | closed) {
-          return; // Nothing to do
-        }
+    final FileSystem fileSystem;// 使用Okio对File的封装，简化了IO操作
+    final File directory;
+    private final File journalFile;
+    private final File journalFileTmp;
+    private final File journalFileBackup;
+    private final int appVersion;
+    private long maxSize;
+    final int valueCount;
+    private long size = 0;
+    BufferedSink journalWriter;
+    final LinkedHashMap<String, Entry> lruEntries = new LinkedHashMap<>(0, 0.75f, true);
+    int redundantOpCount;
+    boolean hasJournalErrors;
+
+    // Must be read and written when synchronized on 'this'.
+    boolean initialized;
+    boolean closed;
+    boolean mostRecentTrimFailed;
+    boolean mostRecentRebuildFailed;
 
-        try {
-          trimToSize();
-        } catch (IOException ignored) {
-          mostRecentTrimFailed = true;
-        }
+    /**
+     * To differentiate between old and current snapshots, each entry is given a sequence number each
+     * time an edit is committed. A snapshot is stale if its sequence number is not equal to its
+     * entry's sequence number.
+     */
+    private long nextSequenceNumber = 0;
 
-        try {
-          if (journalRebuildRequired()) {
-            rebuildJournal();
-            redundantOpCount = 0;
-          }
-        } catch (IOException e) {
-          mostRecentRebuildFailed = true;
-          journalWriter = Okio.buffer(Okio.blackhole());
+    /**
+     * Used to run 'cleanupRunnable' for journal rebuilds.
+     */
+    private final Executor executor;
+    private final Runnable cleanupRunnable = new Runnable() {
+        public void run() {
+            synchronized (DiskLruCache.this) {
+                if (!initialized | closed) {
+                    return; // Nothing to do
+                }
+
+                try {
+                    // 遍历LRU缓存(从旧到新进行遍历map),并删除文件
+                    // 直到小于MaxSize为止
+                    trimToSize();
+                } catch (IOException ignored) {
+                    mostRecentTrimFailed = true;
+                }
+
+                try {
+                    if (journalRebuildRequired()) {
+                        rebuildJournal();
+                        redundantOpCount = 0;
+                    }
+                } catch (IOException e) {
+                    mostRecentRebuildFailed = true;
+                    journalWriter = Okio.buffer(Okio.blackhole());
+                }
+            }
         }
-      }
-    }
-  };
-
-  DiskLruCache(FileSystem fileSystem, File directory, int appVersion, int valueCount, long maxSize,
-      Executor executor) {
-    this.fileSystem = fileSystem;
-    this.directory = directory;
-    this.appVersion = appVersion;
-    this.journalFile = new File(directory, JOURNAL_FILE);
-    this.journalFileTmp = new File(directory, JOURNAL_FILE_TEMP);
-    this.journalFileBackup = new File(directory, JOURNAL_FILE_BACKUP);
-    this.valueCount = valueCount;
-    this.maxSize = maxSize;
-    this.executor = executor;
-  }
-
-  public synchronized void initialize() throws IOException {
-    assert Thread.holdsLock(this);
-
-    if (initialized) {
-      return; // Already initialized.
-    }
+    };
 
-    // If a bkp file exists, use it instead.
-    if (fileSystem.exists(journalFileBackup)) {
-      // If journal file also exists just delete backup file.
-      if (fileSystem.exists(journalFile)) {
-        fileSystem.delete(journalFileBackup);
-      } else {
-        fileSystem.rename(journalFileBackup, journalFile);
-      }
+    DiskLruCache(FileSystem fileSystem, File directory, int appVersion, int valueCount, long maxSize,
+                 Executor executor) {
+        this.fileSystem = fileSystem;
+        this.directory = directory;
+        this.appVersion = appVersion;
+        this.journalFile = new File(directory, JOURNAL_FILE);
+        this.journalFileTmp = new File(directory, JOURNAL_FILE_TEMP);
+        this.journalFileBackup = new File(directory, JOURNAL_FILE_BACKUP);
+        this.valueCount = valueCount;
+        this.maxSize = maxSize;
+        this.executor = executor;
     }
 
-    // Prefer to pick up where we left off.
-    if (fileSystem.exists(journalFile)) {
-      try {
-        readJournal();
-        processJournal();
-        initialized = true;
-        return;
-      } catch (IOException journalIsCorrupt) {
-        Platform.get().log(WARN, "DiskLruCache " + directory + " is corrupt: "
-            + journalIsCorrupt.getMessage() + ", removing", journalIsCorrupt);
-      }
-
-      // The cache is corrupted, attempt to delete the contents of the directory. This can throw and
-      // we'll let that propagate out as it likely means there is a severe filesystem problem.
-      try {
-        delete();
-      } finally {
-        closed = false;
-      }
-    }
+    public synchronized void initialize() throws IOException {
+        assert Thread.holdsLock(this);
 
-    rebuildJournal();
-
-    initialized = true;
-  }
-
-  /**
-   * Create a cache which will reside in {@code directory}. This cache is lazily initialized on
-   * first access and will be created if it does not exist.
-   *
-   * @param directory a writable directory
-   * @param valueCount the number of values per cache entry. Must be positive.
-   * @param maxSize the maximum number of bytes this cache should use to store
-   */
-  public static DiskLruCache create(FileSystem fileSystem, File directory, int appVersion,
-      int valueCount, long maxSize) {
-    if (maxSize <= 0) {
-      throw new IllegalArgumentException("maxSize <= 0");
-    }
-    if (valueCount <= 0) {
-      throw new IllegalArgumentException("valueCount <= 0");
-    }
+        if (initialized) {
+            return; // Already initialized.
+        }
 
-    // Use a single background thread to evict entries.
-    Executor executor = new ThreadPoolExecutor(0, 1, 60L, TimeUnit.SECONDS,
-        new LinkedBlockingQueue<Runnable>(), Util.threadFactory("OkHttp DiskLruCache", true));
-
-    return new DiskLruCache(fileSystem, directory, appVersion, valueCount, maxSize, executor);
-  }
-
-  private void readJournal() throws IOException {
-    BufferedSource source = Okio.buffer(fileSystem.source(journalFile));
-    try {
-      String magic = source.readUtf8LineStrict();
-      String version = source.readUtf8LineStrict();
-      String appVersionString = source.readUtf8LineStrict();
-      String valueCountString = source.readUtf8LineStrict();
-      String blank = source.readUtf8LineStrict();
-      if (!MAGIC.equals(magic)
-          || !VERSION_1.equals(version)
-          || !Integer.toString(appVersion).equals(appVersionString)
-          || !Integer.toString(valueCount).equals(valueCountString)
-          || !"".equals(blank)) {
-        throw new IOException("unexpected journal header: [" + magic + ", " + version + ", "
-            + valueCountString + ", " + blank + "]");
-      }
-
-      int lineCount = 0;
-      while (true) {
-        try {
-          readJournalLine(source.readUtf8LineStrict());
-          lineCount++;
-        } catch (EOFException endOfJournal) {
-          break;
+        // If a bkp file exists, use it instead.
+        if (fileSystem.exists(journalFileBackup)) {
+            // If journal file also exists just delete backup file.
+            if (fileSystem.exists(journalFile)) {
+                fileSystem.delete(journalFileBackup);
+            } else {
+                fileSystem.rename(journalFileBackup, journalFile);
+            }
+        }
+
+        // Prefer to pick up where we left off.
+        if (fileSystem.exists(journalFile)) {
+            try {
+                readJournal();
+                processJournal();
+                initialized = true;
+                return;
+            } catch (IOException journalIsCorrupt) {
+                Platform.get().log(WARN, "DiskLruCache " + directory + " is corrupt: "
+                        + journalIsCorrupt.getMessage() + ", removing", journalIsCorrupt);
+            }
+
+            // The cache is corrupted, attempt to delete the contents of the directory. This can throw and
+            // we'll let that propagate out as it likely means there is a severe filesystem problem.
+            try {
+                delete();
+            } finally {
+                closed = false;
+            }
         }
-      }
-      redundantOpCount = lineCount - lruEntries.size();
 
-      // If we ended on a truncated line, rebuild the journal before appending to it.
-      if (!source.exhausted()) {
         rebuildJournal();
-      } else {
-        journalWriter = newJournalWriter();
-      }
-    } finally {
-      Util.closeQuietly(source);
-    }
-  }
-
-  private BufferedSink newJournalWriter() throws FileNotFoundException {
-    Sink fileSink = fileSystem.appendingSink(journalFile);
-    Sink faultHidingSink = new FaultHidingSink(fileSink) {
-      @Override protected void onException(IOException e) {
-        assert (Thread.holdsLock(DiskLruCache.this));
-        hasJournalErrors = true;
-      }
-    };
-    return Okio.buffer(faultHidingSink);
-  }
 
-  private void readJournalLine(String line) throws IOException {
-    int firstSpace = line.indexOf(' ');
-    if (firstSpace == -1) {
-      throw new IOException("unexpected journal line: " + line);
+        initialized = true;
     }
 
-    int keyBegin = firstSpace + 1;
-    int secondSpace = line.indexOf(' ', keyBegin);
-    final String key;
-    if (secondSpace == -1) {
-      key = line.substring(keyBegin);
-      if (firstSpace == REMOVE.length() && line.startsWith(REMOVE)) {
-        lruEntries.remove(key);
-        return;
-      }
-    } else {
-      key = line.substring(keyBegin, secondSpace);
+    /**
+     * Create a cache which will reside in {@code directory}. This cache is lazily initialized on
+     * first access and will be created if it does not exist.
+     *
+     * @param directory  a writable directory
+     * @param valueCount the number of values per cache entry. Must be positive.
+     * @param maxSize    the maximum number of bytes this cache should use to store
+     */
+    public static DiskLruCache create(FileSystem fileSystem, File directory, int appVersion,
+                                      int valueCount, long maxSize) {
+        if (maxSize <= 0) {
+            throw new IllegalArgumentException("maxSize <= 0");
+        }
+        if (valueCount <= 0) {
+            throw new IllegalArgumentException("valueCount <= 0");
+        }
+
+        // Use a single background thread to evict entries.
+        // 在DiskLruCache初始化时，将建立线程池，最少零个线程，最大一个线程，
+        // 线程空闲可以活60s，线程名叫做"OkHttp DiskLruCache"，当JVM退出时，线程自动结束。
+        Executor executor = new ThreadPoolExecutor(0, 1, 60L, TimeUnit.SECONDS,
+                new LinkedBlockingQueue<Runnable>(), Util.threadFactory("OkHttp DiskLruCache", true));
+
+        return new DiskLruCache(fileSystem, directory, appVersion, valueCount, maxSize, executor);
     }
 
-    Entry entry = lruEntries.get(key);
-    if (entry == null) {
-      entry = new Entry(key);
-      lruEntries.put(key, entry);
+    private void readJournal() throws IOException {
+        BufferedSource source = Okio.buffer(fileSystem.source(journalFile));
+        try {
+            String magic = source.readUtf8LineStrict();
+            String version = source.readUtf8LineStrict();
+            String appVersionString = source.readUtf8LineStrict();
+            String valueCountString = source.readUtf8LineStrict();
+            String blank = source.readUtf8LineStrict();
+            if (!MAGIC.equals(magic)
+                    || !VERSION_1.equals(version)
+                    || !Integer.toString(appVersion).equals(appVersionString)
+                    || !Integer.toString(valueCount).equals(valueCountString)
+                    || !"".equals(blank)) {
+                throw new IOException("unexpected journal header: [" + magic + ", " + version + ", "
+                        + valueCountString + ", " + blank + "]");
+            }
+
+            int lineCount = 0;
+            while (true) {
+                try {
+                    readJournalLine(source.readUtf8LineStrict());
+                    lineCount++;
+                } catch (EOFException endOfJournal) {
+                    break;
+                }
+            }
+            redundantOpCount = lineCount - lruEntries.size();
+
+            // If we ended on a truncated line, rebuild the journal before appending to it.
+            if (!source.exhausted()) {
+                rebuildJournal();
+            } else {
+                journalWriter = newJournalWriter();
+            }
+        } finally {
+            Util.closeQuietly(source);
+        }
     }
 
-    if (secondSpace != -1 && firstSpace == CLEAN.length() && line.startsWith(CLEAN)) {
-      String[] parts = line.substring(secondSpace + 1).split(" ");
-      entry.readable = true;
-      entry.currentEditor = null;
-      entry.setLengths(parts);
-    } else if (secondSpace == -1 && firstSpace == DIRTY.length() && line.startsWith(DIRTY)) {
-      entry.currentEditor = new Editor(entry);
-    } else if (secondSpace == -1 && firstSpace == READ.length() && line.startsWith(READ)) {
-      // This work was already done by calling lruEntries.get().
-    } else {
-      throw new IOException("unexpected journal line: " + line);
+    private BufferedSink newJournalWriter() throws FileNotFoundException {
+        Sink fileSink = fileSystem.appendingSink(journalFile);
+        Sink faultHidingSink = new FaultHidingSink(fileSink) {
+            @Override
+            protected void onException(IOException e) {
+                assert (Thread.holdsLock(DiskLruCache.this));
+                hasJournalErrors = true;
+            }
+        };
+        return Okio.buffer(faultHidingSink);
     }
-  }
-
-  /**
-   * Computes the initial size and collects garbage as a part of opening the cache. Dirty entries
-   * are assumed to be inconsistent and will be deleted.
-   */
-  private void processJournal() throws IOException {
-    fileSystem.delete(journalFileTmp);
-    for (Iterator<Entry> i = lruEntries.values().iterator(); i.hasNext(); ) {
-      Entry entry = i.next();
-      if (entry.currentEditor == null) {
-        for (int t = 0; t < valueCount; t++) {
-          size += entry.lengths[t];
+
+    private void readJournalLine(String line) throws IOException {
+        int firstSpace = line.indexOf(' ');
+        if (firstSpace == -1) {
+            throw new IOException("unexpected journal line: " + line);
         }
-      } else {
-        entry.currentEditor = null;
-        for (int t = 0; t < valueCount; t++) {
-          fileSystem.delete(entry.cleanFiles[t]);
-          fileSystem.delete(entry.dirtyFiles[t]);
+
+        int keyBegin = firstSpace + 1;
+        int secondSpace = line.indexOf(' ', keyBegin);
+        final String key;
+        if (secondSpace == -1) {
+            key = line.substring(keyBegin);
+            if (firstSpace == REMOVE.length() && line.startsWith(REMOVE)) {
+                lruEntries.remove(key);
+                return;
+            }
+        } else {
+            key = line.substring(keyBegin, secondSpace);
         }
-        i.remove();
-      }
-    }
-  }
-
-  /**
-   * Creates a new journal that omits redundant information. This replaces the current journal if it
-   * exists.
-   */
-  synchronized void rebuildJournal() throws IOException {
-    if (journalWriter != null) {
-      journalWriter.close();
-    }
 
-    BufferedSink writer = Okio.buffer(fileSystem.sink(journalFileTmp));
-    try {
-      writer.writeUtf8(MAGIC).writeByte('\n');
-      writer.writeUtf8(VERSION_1).writeByte('\n');
-      writer.writeDecimalLong(appVersion).writeByte('\n');
-      writer.writeDecimalLong(valueCount).writeByte('\n');
-      writer.writeByte('\n');
+        Entry entry = lruEntries.get(key);
+        if (entry == null) {
+            entry = new Entry(key);
+            lruEntries.put(key, entry);
+        }
 
-      for (Entry entry : lruEntries.values()) {
-        if (entry.currentEditor != null) {
-          writer.writeUtf8(DIRTY).writeByte(' ');
-          writer.writeUtf8(entry.key);
-          writer.writeByte('\n');
+        if (secondSpace != -1 && firstSpace == CLEAN.length() && line.startsWith(CLEAN)) {
+            String[] parts = line.substring(secondSpace + 1).split(" ");
+            entry.readable = true;
+            entry.currentEditor = null;
+            entry.setLengths(parts);
+        } else if (secondSpace == -1 && firstSpace == DIRTY.length() && line.startsWith(DIRTY)) {
+            entry.currentEditor = new Editor(entry);
+        } else if (secondSpace == -1 && firstSpace == READ.length() && line.startsWith(READ)) {
+            // This work was already done by calling lruEntries.get().
         } else {
-          writer.writeUtf8(CLEAN).writeByte(' ');
-          writer.writeUtf8(entry.key);
-          entry.writeLengths(writer);
-          writer.writeByte('\n');
+            throw new IOException("unexpected journal line: " + line);
         }
-      }
-    } finally {
-      writer.close();
     }
 
-    if (fileSystem.exists(journalFile)) {
-      fileSystem.rename(journalFile, journalFileBackup);
-    }
-    fileSystem.rename(journalFileTmp, journalFile);
-    fileSystem.delete(journalFileBackup);
-
-    journalWriter = newJournalWriter();
-    hasJournalErrors = false;
-    mostRecentRebuildFailed = false;
-  }
-
-  /**
-   * Returns a snapshot of the entry named {@code key}, or null if it doesn't exist is not currently
-   * readable. If a value is returned, it is moved to the head of the LRU queue.
-   */
-  public synchronized Snapshot get(String key) throws IOException {
-    initialize();
-
-    checkNotClosed();
-    validateKey(key);
-    Entry entry = lruEntries.get(key);
-    if (entry == null || !entry.readable) return null;
-
-    Snapshot snapshot = entry.snapshot();
-    if (snapshot == null) return null;
-
-    redundantOpCount++;
-    journalWriter.writeUtf8(READ).writeByte(' ').writeUtf8(key).writeByte('\n');
-    if (journalRebuildRequired()) {
-      executor.execute(cleanupRunnable);
+    /**
+     * Computes the initial size and collects garbage as a part of opening the cache. Dirty entries
+     * are assumed to be inconsistent and will be deleted.
+     */
+    private void processJournal() throws IOException {
+        fileSystem.delete(journalFileTmp);
+        for (Iterator<Entry> i = lruEntries.values().iterator(); i.hasNext(); ) {
+            Entry entry = i.next();
+            if (entry.currentEditor == null) {
+                for (int t = 0; t < valueCount; t++) {
+                    size += entry.lengths[t];
+                }
+            } else {
+                entry.currentEditor = null;
+                for (int t = 0; t < valueCount; t++) {
+                    fileSystem.delete(entry.cleanFiles[t]);
+                    fileSystem.delete(entry.dirtyFiles[t]);
+                }
+                i.remove();
+            }
+        }
     }
 
-    return snapshot;
-  }
-
-  /**
-   * Returns an editor for the entry named {@code key}, or null if another edit is in progress.
-   */
-  public @Nullable Editor edit(String key) throws IOException {
-    return edit(key, ANY_SEQUENCE_NUMBER);
-  }
-
-  synchronized Editor edit(String key, long expectedSequenceNumber) throws IOException {
-    initialize();
-
-    checkNotClosed();
-    validateKey(key);
-    Entry entry = lruEntries.get(key);
-    if (expectedSequenceNumber != ANY_SEQUENCE_NUMBER && (entry == null
-        || entry.sequenceNumber != expectedSequenceNumber)) {
-      return null; // Snapshot is stale.
-    }
-    if (entry != null && entry.currentEditor != null) {
-      return null; // Another edit is in progress.
-    }
-    if (mostRecentTrimFailed || mostRecentRebuildFailed) {
-      // The OS has become our enemy! If the trim job failed, it means we are storing more data than
-      // requested by the user. Do not allow edits so we do not go over that limit any further. If
-      // the journal rebuild failed, the journal writer will not be active, meaning we will not be
-      // able to record the edit, causing file leaks. In both cases, we want to retry the clean up
-      // so we can get out of this state!
-      executor.execute(cleanupRunnable);
-      return null;
-    }
+    /**
+     * Creates a new journal that omits redundant information. This replaces the current journal if it
+     * exists.
+     */
+    synchronized void rebuildJournal() throws IOException {
+        if (journalWriter != null) {
+            journalWriter.close();
+        }
 
-    // Flush the journal before creating files to prevent file leaks.
-    journalWriter.writeUtf8(DIRTY).writeByte(' ').writeUtf8(key).writeByte('\n');
-    journalWriter.flush();
+        BufferedSink writer = Okio.buffer(fileSystem.sink(journalFileTmp));
+        try {
+            writer.writeUtf8(MAGIC).writeByte('\n');
+            writer.writeUtf8(VERSION_1).writeByte('\n');
+            writer.writeDecimalLong(appVersion).writeByte('\n');
+            writer.writeDecimalLong(valueCount).writeByte('\n');
+            writer.writeByte('\n');
+
+            for (Entry entry : lruEntries.values()) {
+                if (entry.currentEditor != null) {
+                    writer.writeUtf8(DIRTY).writeByte(' ');
+                    writer.writeUtf8(entry.key);
+                    writer.writeByte('\n');
+                } else {
+                    writer.writeUtf8(CLEAN).writeByte(' ');
+                    writer.writeUtf8(entry.key);
+                    entry.writeLengths(writer);
+                    writer.writeByte('\n');
+                }
+            }
+        } finally {
+            writer.close();
+        }
 
-    if (hasJournalErrors) {
-      return null; // Don't edit; the journal can't be written.
-    }
+        if (fileSystem.exists(journalFile)) {
+            fileSystem.rename(journalFile, journalFileBackup);
+        }
+        fileSystem.rename(journalFileTmp, journalFile);
+        fileSystem.delete(journalFileBackup);
 
-    if (entry == null) {
-      entry = new Entry(key);
-      lruEntries.put(key, entry);
+        journalWriter = newJournalWriter();
+        hasJournalErrors = false;
+        mostRecentRebuildFailed = false;
     }
-    Editor editor = new Editor(entry);
-    entry.currentEditor = editor;
-    return editor;
-  }
-
-  /** Returns the directory where this cache stores its data. */
-  public File getDirectory() {
-    return directory;
-  }
-
-  /**
-   * Returns the maximum number of bytes that this cache should use to store its data.
-   */
-  public synchronized long getMaxSize() {
-    return maxSize;
-  }
-
-  /**
-   * Changes the maximum number of bytes the cache can store and queues a job to trim the existing
-   * store, if necessary.
-   */
-  public synchronized void setMaxSize(long maxSize) {
-    this.maxSize = maxSize;
-    if (initialized) {
-      executor.execute(cleanupRunnable);
+
+    /**
+     * Returns a snapshot of the entry named {@code key}, or null if it doesn't exist is not currently
+     * readable. If a value is returned, it is moved to the head of the LRU queue.
+     */
+    public synchronized Snapshot get(String key) throws IOException {
+        initialize();
+
+        checkNotClosed();
+        validateKey(key);
+        Entry entry = lruEntries.get(key);
+        if (entry == null || !entry.readable) return null;
+
+        Snapshot snapshot = entry.snapshot();
+        if (snapshot == null) return null;
+
+        redundantOpCount++;
+        journalWriter.writeUtf8(READ).writeByte(' ').writeUtf8(key).writeByte('\n');
+        if (journalRebuildRequired()) {
+            executor.execute(cleanupRunnable);
+        }
+
+        return snapshot;
     }
-  }
-
-  /**
-   * Returns the number of bytes currently being used to store the values in this cache. This may be
-   * greater than the max size if a background deletion is pending.
-   */
-  public synchronized long size() throws IOException {
-    initialize();
-    return size;
-  }
-
-  synchronized void completeEdit(Editor editor, boolean success) throws IOException {
-    Entry entry = editor.entry;
-    if (entry.currentEditor != editor) {
-      throw new IllegalStateException();
+
+    /**
+     * Returns an editor for the entry named {@code key}, or null if another edit is in progress.
+     */
+    public @Nullable
+    Editor edit(String key) throws IOException {
+        return edit(key, ANY_SEQUENCE_NUMBER);
     }
 
-    // If this edit is creating the entry for the first time, every index must have a value.
-    if (success && !entry.readable) {
-      for (int i = 0; i < valueCount; i++) {
-        if (!editor.written[i]) {
-          editor.abort();
-          throw new IllegalStateException("Newly created entry didn't create value for index " + i);
+    synchronized Editor edit(String key, long expectedSequenceNumber) throws IOException {
+        initialize();
+
+        checkNotClosed();
+        validateKey(key);
+        Entry entry = lruEntries.get(key);
+        if (expectedSequenceNumber != ANY_SEQUENCE_NUMBER && (entry == null
+                || entry.sequenceNumber != expectedSequenceNumber)) {
+            return null; // Snapshot is stale.
         }
-        if (!fileSystem.exists(entry.dirtyFiles[i])) {
-          editor.abort();
-          return;
+        if (entry != null && entry.currentEditor != null) {
+            return null; // Another edit is in progress.
+        }
+        if (mostRecentTrimFailed || mostRecentRebuildFailed) {
+            // The OS has become our enemy! If the trim job failed, it means we are storing more data than
+            // requested by the user. Do not allow edits so we do not go over that limit any further. If
+            // the journal rebuild failed, the journal writer will not be active, meaning we will not be
+            // able to record the edit, causing file leaks. In both cases, we want to retry the clean up
+            // so we can get out of this state!
+            executor.execute(cleanupRunnable);
+            return null;
+        }
+
+        // Flush the journal before creating files to prevent file leaks.
+        journalWriter.writeUtf8(DIRTY).writeByte(' ').writeUtf8(key).writeByte('\n');
+        journalWriter.flush();
+
+        if (hasJournalErrors) {
+            return null; // Don't edit; the journal can't be written.
         }
-      }
-    }
 
-    for (int i = 0; i < valueCount; i++) {
-      File dirty = entry.dirtyFiles[i];
-      if (success) {
-        if (fileSystem.exists(dirty)) {
-          File clean = entry.cleanFiles[i];
-          fileSystem.rename(dirty, clean);
-          long oldLength = entry.lengths[i];
-          long newLength = fileSystem.size(clean);
-          entry.lengths[i] = newLength;
-          size = size - oldLength + newLength;
+        if (entry == null) {
+            entry = new Entry(key);
+            lruEntries.put(key, entry);
         }
-      } else {
-        fileSystem.delete(dirty);
-      }
+        Editor editor = new Editor(entry);
+        entry.currentEditor = editor;
+        return editor;
     }
 
-    redundantOpCount++;
-    entry.currentEditor = null;
-    if (entry.readable | success) {
-      entry.readable = true;
-      journalWriter.writeUtf8(CLEAN).writeByte(' ');
-      journalWriter.writeUtf8(entry.key);
-      entry.writeLengths(journalWriter);
-      journalWriter.writeByte('\n');
-      if (success) {
-        entry.sequenceNumber = nextSequenceNumber++;
-      }
-    } else {
-      lruEntries.remove(entry.key);
-      journalWriter.writeUtf8(REMOVE).writeByte(' ');
-      journalWriter.writeUtf8(entry.key);
-      journalWriter.writeByte('\n');
+    /**
+     * Returns the directory where this cache stores its data.
+     */
+    public File getDirectory() {
+        return directory;
     }
-    journalWriter.flush();
 
-    if (size > maxSize || journalRebuildRequired()) {
-      executor.execute(cleanupRunnable);
+    /**
+     * Returns the maximum number of bytes that this cache should use to store its data.
+     */
+    public synchronized long getMaxSize() {
+        return maxSize;
     }
-  }
-
-  /**
-   * We only rebuild the journal when it will halve the size of the journal and eliminate at least
-   * 2000 ops.
-   */
-  boolean journalRebuildRequired() {
-    final int redundantOpCompactThreshold = 2000;
-    return redundantOpCount >= redundantOpCompactThreshold
-        && redundantOpCount >= lruEntries.size();
-  }
-
-  /**
-   * Drops the entry for {@code key} if it exists and can be removed. If the entry for {@code key}
-   * is currently being edited, that edit will complete normally but its value will not be stored.
-   *
-   * @return true if an entry was removed.
-   */
-  public synchronized boolean remove(String key) throws IOException {
-    initialize();
-
-    checkNotClosed();
-    validateKey(key);
-    Entry entry = lruEntries.get(key);
-    if (entry == null) return false;
-    boolean removed = removeEntry(entry);
-    if (removed && size <= maxSize) mostRecentTrimFailed = false;
-    return removed;
-  }
-
-  boolean removeEntry(Entry entry) throws IOException {
-    if (entry.currentEditor != null) {
-      entry.currentEditor.detach(); // Prevent the edit from completing normally.
+
+    /**
+     * Changes the maximum number of bytes the cache can store and queues a job to trim the existing
+     * store, if necessary.
+     */
+    public synchronized void setMaxSize(long maxSize) {
+        this.maxSize = maxSize;
+        if (initialized) {
+            executor.execute(cleanupRunnable);
+        }
     }
 
-    for (int i = 0; i < valueCount; i++) {
-      fileSystem.delete(entry.cleanFiles[i]);
-      size -= entry.lengths[i];
-      entry.lengths[i] = 0;
+    /**
+     * Returns the number of bytes currently being used to store the values in this cache. This may be
+     * greater than the max size if a background deletion is pending.
+     */
+    public synchronized long size() throws IOException {
+        initialize();
+        return size;
     }
 
-    redundantOpCount++;
-    journalWriter.writeUtf8(REMOVE).writeByte(' ').writeUtf8(entry.key).writeByte('\n');
-    lruEntries.remove(entry.key);
+    synchronized void completeEdit(Editor editor, boolean success) throws IOException {
+        Entry entry = editor.entry;
+        if (entry.currentEditor != editor) {
+            throw new IllegalStateException();
+        }
 
-    if (journalRebuildRequired()) {
-      executor.execute(cleanupRunnable);
-    }
+        // If this edit is creating the entry for the first time, every index must have a value.
+        if (success && !entry.readable) {
+            for (int i = 0; i < valueCount; i++) {
+                if (!editor.written[i]) {
+                    editor.abort();
+                    throw new IllegalStateException("Newly created entry didn't create value for index " + i);
+                }
+                if (!fileSystem.exists(entry.dirtyFiles[i])) {
+                    editor.abort();
+                    return;
+                }
+            }
+        }
 
-    return true;
-  }
+        for (int i = 0; i < valueCount; i++) {
+            File dirty = entry.dirtyFiles[i];
+            if (success) {
+                if (fileSystem.exists(dirty)) {
+                    File clean = entry.cleanFiles[i];
+                    fileSystem.rename(dirty, clean);
+                    long oldLength = entry.lengths[i];
+                    long newLength = fileSystem.size(clean);
+                    entry.lengths[i] = newLength;
+                    size = size - oldLength + newLength;
+                }
+            } else {
+                fileSystem.delete(dirty);
+            }
+        }
 
-  /** Returns true if this cache has been closed. */
-  public synchronized boolean isClosed() {
-    return closed;
-  }
+        redundantOpCount++;
+        entry.currentEditor = null;
+        if (entry.readable | success) {
+            entry.readable = true;
+            journalWriter.writeUtf8(CLEAN).writeByte(' ');
+            journalWriter.writeUtf8(entry.key);
+            entry.writeLengths(journalWriter);
+            journalWriter.writeByte('\n');
+            if (success) {
+                entry.sequenceNumber = nextSequenceNumber++;
+            }
+        } else {
+            lruEntries.remove(entry.key);
+            journalWriter.writeUtf8(REMOVE).writeByte(' ');
+            journalWriter.writeUtf8(entry.key);
+            journalWriter.writeByte('\n');
+        }
+        journalWriter.flush();
 
-  private synchronized void checkNotClosed() {
-    if (isClosed()) {
-      throw new IllegalStateException("cache is closed");
-    }
-  }
-
-  /** Force buffered operations to the filesystem. */
-  @Override public synchronized void flush() throws IOException {
-    if (!initialized) return;
-
-    checkNotClosed();
-    trimToSize();
-    journalWriter.flush();
-  }
-
-  /** Closes this cache. Stored values will remain on the filesystem. */
-  @Override public synchronized void close() throws IOException {
-    if (!initialized || closed) {
-      closed = true;
-      return;
-    }
-    // Copying for safe iteration.
-    for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {
-      if (entry.currentEditor != null) {
-        entry.currentEditor.abort();
-      }
-    }
-    trimToSize();
-    journalWriter.close();
-    journalWriter = null;
-    closed = true;
-  }
-
-  void trimToSize() throws IOException {
-    while (size > maxSize) {
-      Entry toEvict = lruEntries.values().iterator().next();
-      removeEntry(toEvict);
+        if (size > maxSize || journalRebuildRequired()) {
+            executor.execute(cleanupRunnable);
+        }
     }
-    mostRecentTrimFailed = false;
-  }
-
-  /**
-   * Closes the cache and deletes all of its stored values. This will delete all files in the cache
-   * directory including files that weren't created by the cache.
-   */
-  public void delete() throws IOException {
-    close();
-    fileSystem.deleteContents(directory);
-  }
-
-  /**
-   * Deletes all stored values from the cache. In-flight edits will complete normally but their
-   * values will not be stored.
-   */
-  public synchronized void evictAll() throws IOException {
-    initialize();
-    // Copying for safe iteration.
-    for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {
-      removeEntry(entry);
+
+    /**
+     * We only rebuild the journal when it will halve the size of the journal and eliminate at least
+     * 2000 ops.
+     */
+    boolean journalRebuildRequired() {
+        final int redundantOpCompactThreshold = 2000;
+        return redundantOpCount >= redundantOpCompactThreshold
+                && redundantOpCount >= lruEntries.size();
     }
-    mostRecentTrimFailed = false;
-  }
-
-  private void validateKey(String key) {
-    Matcher matcher = LEGAL_KEY_PATTERN.matcher(key);
-    if (!matcher.matches()) {
-      throw new IllegalArgumentException(
-          "keys must match regex [a-z0-9_-]{1,120}: \"" + key + "\"");
+
+    /**
+     * Drops the entry for {@code key} if it exists and can be removed. If the entry for {@code key}
+     * is currently being edited, that edit will complete normally but its value will not be stored.
+     *
+     * @return true if an entry was removed.
+     */
+    public synchronized boolean remove(String key) throws IOException {
+        initialize();
+
+        checkNotClosed();
+        validateKey(key);
+        Entry entry = lruEntries.get(key);
+        if (entry == null) return false;
+        boolean removed = removeEntry(entry);
+        if (removed && size <= maxSize) mostRecentTrimFailed = false;
+        return removed;
     }
-  }
-
-  /**
-   * Returns an iterator over the cache's current entries. This iterator doesn't throw {@code
-   * ConcurrentModificationException}, but if new entries are added while iterating, those new
-   * entries will not be returned by the iterator. If existing entries are removed during iteration,
-   * they will be absent (unless they were already returned).
-   *
-   * <p>If there are I/O problems during iteration, this iterator fails silently. For example, if
-   * the hosting filesystem becomes unreachable, the iterator will omit elements rather than
-   * throwing exceptions.
-   *
-   * <p><strong>The caller must {@link Snapshot#close close}</strong> each snapshot returned by
-   * {@link Iterator#next}. Failing to do so leaks open files!
-   *
-   * <p>The returned iterator supports {@link Iterator#remove}.
-   */
-  public synchronized Iterator<Snapshot> snapshots() throws IOException {
-    initialize();
-    return new Iterator<Snapshot>() {
-      /** Iterate a copy of the entries to defend against concurrent modification errors. */
-      final Iterator<Entry> delegate = new ArrayList<>(lruEntries.values()).iterator();
-
-      /** The snapshot to return from {@link #next}. Null if we haven't computed that yet. */
-      Snapshot nextSnapshot;
-
-      /** The snapshot to remove with {@link #remove}. Null if removal is illegal. */
-      Snapshot removeSnapshot;
-
-      @Override public boolean hasNext() {
-        if (nextSnapshot != null) return true;
-
-        synchronized (DiskLruCache.this) {
-          // If the cache is closed, truncate the iterator.
-          if (closed) return false;
-
-          while (delegate.hasNext()) {
-            Entry entry = delegate.next();
-            Snapshot snapshot = entry.snapshot();
-            if (snapshot == null) continue; // Evicted since we copied the entries.
-            nextSnapshot = snapshot;
-            return true;
-          }
+
+    boolean removeEntry(Entry entry) throws IOException {
+        if (entry.currentEditor != null) {
+            entry.currentEditor.detach(); // Prevent the edit from completing normally.
         }
 
-        return false;
-      }
+        for (int i = 0; i < valueCount; i++) {
+            fileSystem.delete(entry.cleanFiles[i]);
+            size -= entry.lengths[i];
+            entry.lengths[i] = 0;
+        }
 
-      @Override public Snapshot next() {
-        if (!hasNext()) throw new NoSuchElementException();
-        removeSnapshot = nextSnapshot;
-        nextSnapshot = null;
-        return removeSnapshot;
-      }
+        redundantOpCount++;
+        journalWriter.writeUtf8(REMOVE).writeByte(' ').writeUtf8(entry.key).writeByte('\n');
+        lruEntries.remove(entry.key);
 
-      @Override public void remove() {
-        if (removeSnapshot == null) throw new IllegalStateException("remove() before next()");
-        try {
-          DiskLruCache.this.remove(removeSnapshot.key);
-        } catch (IOException ignored) {
-          // Nothing useful to do here. We failed to remove from the cache. Most likely that's
-          // because we couldn't update the journal, but the cached entry will still be gone.
-        } finally {
-          removeSnapshot = null;
+        if (journalRebuildRequired()) {
+            executor.execute(cleanupRunnable);
         }
-      }
-    };
-  }
-
-  /** A snapshot of the values for an entry. */
-  public final class Snapshot implements Closeable {
-    private final String key;
-    private final long sequenceNumber;
-    private final Source[] sources;
-    private final long[] lengths;
-
-    Snapshot(String key, long sequenceNumber, Source[] sources, long[] lengths) {
-      this.key = key;
-      this.sequenceNumber = sequenceNumber;
-      this.sources = sources;
-      this.lengths = lengths;
-    }
 
-    public String key() {
-      return key;
+        return true;
     }
 
     /**
-     * Returns an editor for this snapshot's entry, or null if either the entry has changed since
-     * this snapshot was created or if another edit is in progress.
+     * Returns true if this cache has been closed.
      */
-    public @Nullable Editor edit() throws IOException {
-      return DiskLruCache.this.edit(key, sequenceNumber);
+    public synchronized boolean isClosed() {
+        return closed;
     }
 
-    /** Returns the unbuffered stream with the value for {@code index}. */
-    public Source getSource(int index) {
-      return sources[index];
+    private synchronized void checkNotClosed() {
+        if (isClosed()) {
+            throw new IllegalStateException("cache is closed");
+        }
     }
 
-    /** Returns the byte length of the value for {@code index}. */
-    public long getLength(int index) {
-      return lengths[index];
-    }
+    /**
+     * Force buffered operations to the filesystem.
+     */
+    @Override
+    public synchronized void flush() throws IOException {
+        if (!initialized) return;
 
-    public void close() {
-      for (Source in : sources) {
-        Util.closeQuietly(in);
-      }
+        checkNotClosed();
+        trimToSize();
+        journalWriter.flush();
     }
-  }
 
-  /** Edits the values for an entry. */
-  public final class Editor {
-    final Entry entry;
-    final boolean[] written;
-    private boolean done;
+    /**
+     * Closes this cache. Stored values will remain on the filesystem.
+     */
+    @Override
+    public synchronized void close() throws IOException {
+        if (!initialized || closed) {
+            closed = true;
+            return;
+        }
+        // Copying for safe iteration.
+        for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {
+            if (entry.currentEditor != null) {
+                entry.currentEditor.abort();
+            }
+        }
+        trimToSize();
+        journalWriter.close();
+        journalWriter = null;
+        closed = true;
+    }
 
-    Editor(Entry entry) {
-      this.entry = entry;
-      this.written = (entry.readable) ? null : new boolean[valueCount];
+    void trimToSize() throws IOException {
+        while (size > maxSize) {
+            Entry toEvict = lruEntries.values().iterator().next();
+            removeEntry(toEvict);
+        }
+        mostRecentTrimFailed = false;
     }
 
     /**
-     * Prevents this editor from completing normally. This is necessary either when the edit causes
-     * an I/O error, or if the target entry is evicted while this editor is active. In either case
-     * we delete the editor's created files and prevent new files from being created. Note that once
-     * an editor has been detached it is possible for another editor to edit the entry.
+     * Closes the cache and deletes all of its stored values. This will delete all files in the cache
+     * directory including files that weren't created by the cache.
      */
-    void detach() {
-      if (entry.currentEditor == this) {
-        for (int i = 0; i < valueCount; i++) {
-          try {
-            fileSystem.delete(entry.dirtyFiles[i]);
-          } catch (IOException e) {
-            // This file is potentially leaked. Not much we can do about that.
-          }
-        }
-        entry.currentEditor = null;
-      }
+    public void delete() throws IOException {
+        close();
+        fileSystem.deleteContents(directory);
     }
 
     /**
-     * Returns an unbuffered input stream to read the last committed value, or null if no value has
-     * been committed.
+     * Deletes all stored values from the cache. In-flight edits will complete normally but their
+     * values will not be stored.
      */
-    public Source newSource(int index) {
-      synchronized (DiskLruCache.this) {
-        if (done) {
-          throw new IllegalStateException();
-        }
-        if (!entry.readable || entry.currentEditor != this) {
-          return null;
+    public synchronized void evictAll() throws IOException {
+        initialize();
+        // Copying for safe iteration.
+        for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {
+            removeEntry(entry);
         }
-        try {
-          return fileSystem.source(entry.cleanFiles[index]);
-        } catch (FileNotFoundException e) {
-          return null;
+        mostRecentTrimFailed = false;
+    }
+
+    private void validateKey(String key) {
+        Matcher matcher = LEGAL_KEY_PATTERN.matcher(key);
+        if (!matcher.matches()) {
+            throw new IllegalArgumentException(
+                    "keys must match regex [a-z0-9_-]{1,120}: \"" + key + "\"");
         }
-      }
     }
 
     /**
-     * Returns a new unbuffered output stream to write the value at {@code index}. If the underlying
-     * output stream encounters errors when writing to the filesystem, this edit will be aborted
-     * when {@link #commit} is called. The returned output stream does not throw IOExceptions.
+     * Returns an iterator over the cache's current entries. This iterator doesn't throw {@code
+     * ConcurrentModificationException}, but if new entries are added while iterating, those new
+     * entries will not be returned by the iterator. If existing entries are removed during iteration,
+     * they will be absent (unless they were already returned).
+     * <p>
+     * <p>If there are I/O problems during iteration, this iterator fails silently. For example, if
+     * the hosting filesystem becomes unreachable, the iterator will omit elements rather than
+     * throwing exceptions.
+     * <p>
+     * <p><strong>The caller must {@link Snapshot#close close}</strong> each snapshot returned by
+     * {@link Iterator#next}. Failing to do so leaks open files!
+     * <p>
+     * <p>The returned iterator supports {@link Iterator#remove}.
      */
-    public Sink newSink(int index) {
-      synchronized (DiskLruCache.this) {
-        if (done) {
-          throw new IllegalStateException();
-        }
-        if (entry.currentEditor != this) {
-          return Okio.blackhole();
-        }
-        if (!entry.readable) {
-          written[index] = true;
-        }
-        File dirtyFile = entry.dirtyFiles[index];
-        Sink sink;
-        try {
-          sink = fileSystem.sink(dirtyFile);
-        } catch (FileNotFoundException e) {
-          return Okio.blackhole();
-        }
-        return new FaultHidingSink(sink) {
-          @Override protected void onException(IOException e) {
-            synchronized (DiskLruCache.this) {
-              detach();
+    public synchronized Iterator<Snapshot> snapshots() throws IOException {
+        initialize();
+        return new Iterator<Snapshot>() {
+            /** Iterate a copy of the entries to defend against concurrent modification errors. */
+            final Iterator<Entry> delegate = new ArrayList<>(lruEntries.values()).iterator();
+
+            /** The snapshot to return from {@link #next}. Null if we haven't computed that yet. */
+            Snapshot nextSnapshot;
+
+            /** The snapshot to remove with {@link #remove}. Null if removal is illegal. */
+            Snapshot removeSnapshot;
+
+            @Override
+            public boolean hasNext() {
+                if (nextSnapshot != null) return true;
+
+                synchronized (DiskLruCache.this) {
+                    // If the cache is closed, truncate the iterator.
+                    if (closed) return false;
+
+                    while (delegate.hasNext()) {
+                        Entry entry = delegate.next();
+                        Snapshot snapshot = entry.snapshot();
+                        if (snapshot == null) continue; // Evicted since we copied the entries.
+                        nextSnapshot = snapshot;
+                        return true;
+                    }
+                }
+
+                return false;
+            }
+
+            @Override
+            public Snapshot next() {
+                if (!hasNext()) throw new NoSuchElementException();
+                removeSnapshot = nextSnapshot;
+                nextSnapshot = null;
+                return removeSnapshot;
+            }
+
+            @Override
+            public void remove() {
+                if (removeSnapshot == null) throw new IllegalStateException("remove() before next()");
+                try {
+                    DiskLruCache.this.remove(removeSnapshot.key);
+                } catch (IOException ignored) {
+                    // Nothing useful to do here. We failed to remove from the cache. Most likely that's
+                    // because we couldn't update the journal, but the cached entry will still be gone.
+                } finally {
+                    removeSnapshot = null;
+                }
             }
-          }
         };
-      }
     }
 
     /**
-     * Commits this edit so it is visible to readers.  This releases the edit lock so another edit
-     * may be started on the same key.
+     * A snapshot of the values for an entry.
      */
-    public void commit() throws IOException {
-      synchronized (DiskLruCache.this) {
-        if (done) {
-          throw new IllegalStateException();
+    public final class Snapshot implements Closeable {
+        private final String key;
+        private final long sequenceNumber;
+        private final Source[] sources;
+        private final long[] lengths;
+
+        Snapshot(String key, long sequenceNumber, Source[] sources, long[] lengths) {
+            this.key = key;
+            this.sequenceNumber = sequenceNumber;
+            this.sources = sources;
+            this.lengths = lengths;
+        }
+
+        public String key() {
+            return key;
         }
-        if (entry.currentEditor == this) {
-          completeEdit(this, true);
+
+        /**
+         * Returns an editor for this snapshot's entry, or null if either the entry has changed since
+         * this snapshot was created or if another edit is in progress.
+         */
+        public @Nullable
+        Editor edit() throws IOException {
+            return DiskLruCache.this.edit(key, sequenceNumber);
+        }
+
+        /**
+         * Returns the unbuffered stream with the value for {@code index}.
+         */
+        public Source getSource(int index) {
+            return sources[index];
+        }
+
+        /**
+         * Returns the byte length of the value for {@code index}.
+         */
+        public long getLength(int index) {
+            return lengths[index];
+        }
+
+        public void close() {
+            for (Source in : sources) {
+                Util.closeQuietly(in);
+            }
         }
-        done = true;
-      }
     }
 
     /**
-     * Aborts this edit. This releases the edit lock so another edit may be started on the same
-     * key.
+     * Edits the values for an entry.
+     * 添加了同步锁，并对FileSystem进行高度封装
      */
-    public void abort() throws IOException {
-      synchronized (DiskLruCache.this) {
-        if (done) {
-          throw new IllegalStateException();
+    public final class Editor {
+        final Entry entry;
+        final boolean[] written;
+        private boolean done;
+
+        Editor(Entry entry) {
+            this.entry = entry;
+            this.written = (entry.readable) ? null : new boolean[valueCount];
         }
-        if (entry.currentEditor == this) {
-          completeEdit(this, false);
+
+        /**
+         * Prevents this editor from completing normally. This is necessary either when the edit causes
+         * an I/O error, or if the target entry is evicted while this editor is active. In either case
+         * we delete the editor's created files and prevent new files from being created. Note that once
+         * an editor has been detached it is possible for another editor to edit the entry.
+         */
+        void detach() {
+            if (entry.currentEditor == this) {
+                for (int i = 0; i < valueCount; i++) {
+                    try {
+                        fileSystem.delete(entry.dirtyFiles[i]);
+                    } catch (IOException e) {
+                        // This file is potentially leaked. Not much we can do about that.
+                    }
+                }
+                entry.currentEditor = null;
+            }
         }
-        done = true;
-      }
-    }
 
-    public void abortUnlessCommitted() {
-      synchronized (DiskLruCache.this) {
-        if (!done && entry.currentEditor == this) {
-          try {
-            completeEdit(this, false);
-          } catch (IOException ignored) {
-          }
+        /**
+         * Returns an unbuffered input stream to read the last committed value, or null if no value has
+         * been committed.
+         */
+        public Source newSource(int index) {
+            synchronized (DiskLruCache.this) {
+                if (done) {
+                    throw new IllegalStateException();
+                }
+                if (!entry.readable || entry.currentEditor != this) {
+                    return null;
+                }
+                try {
+                    return fileSystem.source(entry.cleanFiles[index]);
+                } catch (FileNotFoundException e) {
+                    return null;
+                }
+            }
         }
-      }
-    }
-  }
-
-  private final class Entry {
-    final String key;
-
-    /** Lengths of this entry's files. */
-    final long[] lengths;
-    final File[] cleanFiles;
-    final File[] dirtyFiles;
-
-    /** True if this entry has ever been published. */
-    boolean readable;
-
-    /** The ongoing edit or null if this entry is not being edited. */
-    Editor currentEditor;
-
-    /** The sequence number of the most recently committed edit to this entry. */
-    long sequenceNumber;
-
-    Entry(String key) {
-      this.key = key;
-
-      lengths = new long[valueCount];
-      cleanFiles = new File[valueCount];
-      dirtyFiles = new File[valueCount];
-
-      // The names are repetitive so re-use the same builder to avoid allocations.
-      StringBuilder fileBuilder = new StringBuilder(key).append('.');
-      int truncateTo = fileBuilder.length();
-      for (int i = 0; i < valueCount; i++) {
-        fileBuilder.append(i);
-        cleanFiles[i] = new File(directory, fileBuilder.toString());
-        fileBuilder.append(".tmp");
-        dirtyFiles[i] = new File(directory, fileBuilder.toString());
-        fileBuilder.setLength(truncateTo);
-      }
-    }
 
-    /** Set lengths using decimal numbers like "10123". */
-    void setLengths(String[] strings) throws IOException {
-      if (strings.length != valueCount) {
-        throw invalidLengths(strings);
-      }
+        /**
+         * Returns a new unbuffered output stream to write the value at {@code index}. If the underlying
+         * output stream encounters errors when writing to the filesystem, this edit will be aborted
+         * when {@link #commit} is called. The returned output stream does not throw IOExceptions.
+         */
+        public Sink newSink(int index) {
+            synchronized (DiskLruCache.this) {
+                if (done) {
+                    throw new IllegalStateException();
+                }
+                if (entry.currentEditor != this) {
+                    return Okio.blackhole();
+                }
+                if (!entry.readable) {
+                    written[index] = true;
+                }
+                File dirtyFile = entry.dirtyFiles[index];
+                Sink sink;
+                try {
+                    sink = fileSystem.sink(dirtyFile);
+                } catch (FileNotFoundException e) {
+                    return Okio.blackhole();
+                }
+                return new FaultHidingSink(sink) {
+                    @Override
+                    protected void onException(IOException e) {
+                        synchronized (DiskLruCache.this) {
+                            detach();
+                        }
+                    }
+                };
+            }
+        }
 
-      try {
-        for (int i = 0; i < strings.length; i++) {
-          lengths[i] = Long.parseLong(strings[i]);
+        /**
+         * Commits this edit so it is visible to readers.  This releases the edit lock so another edit
+         * may be started on the same key.
+         */
+        public void commit() throws IOException {
+            synchronized (DiskLruCache.this) {
+                if (done) {
+                    throw new IllegalStateException();
+                }
+                if (entry.currentEditor == this) {
+                    completeEdit(this, true);
+                }
+                done = true;
+            }
         }
-      } catch (NumberFormatException e) {
-        throw invalidLengths(strings);
-      }
-    }
 
-    /** Append space-prefixed lengths to {@code writer}. */
-    void writeLengths(BufferedSink writer) throws IOException {
-      for (long length : lengths) {
-        writer.writeByte(' ').writeDecimalLong(length);
-      }
-    }
+        /**
+         * Aborts this edit. This releases the edit lock so another edit may be started on the same
+         * key.
+         */
+        public void abort() throws IOException {
+            synchronized (DiskLruCache.this) {
+                if (done) {
+                    throw new IllegalStateException();
+                }
+                if (entry.currentEditor == this) {
+                    completeEdit(this, false);
+                }
+                done = true;
+            }
+        }
 
-    private IOException invalidLengths(String[] strings) throws IOException {
-      throw new IOException("unexpected journal line: " + Arrays.toString(strings));
+        public void abortUnlessCommitted() {
+            synchronized (DiskLruCache.this) {
+                if (!done && entry.currentEditor == this) {
+                    try {
+                        completeEdit(this, false);
+                    } catch (IOException ignored) {
+                    }
+                }
+            }
+        }
     }
 
     /**
-     * Returns a snapshot of this entry. This opens all streams eagerly to guarantee that we see a
-     * single published snapshot. If we opened streams lazily then the streams could come from
-     * different edits.
+     * 维护着key对应的多个文件
      */
-    Snapshot snapshot() {
-      if (!Thread.holdsLock(DiskLruCache.this)) throw new AssertionError();
+    private final class Entry {
+        final String key;
+
+        /**
+         * Lengths of this entry's files.
+         */
+        final long[] lengths;
+        final File[] cleanFiles;
+        final File[] dirtyFiles;
+
+        /**
+         * True if this entry has ever been published.
+         */
+        boolean readable;
+
+        /**
+         * The ongoing edit or null if this entry is not being edited.
+         */
+        Editor currentEditor;
+
+        /**
+         * The sequence number of the most recently committed edit to this entry.
+         */
+        long sequenceNumber;
+
+        Entry(String key) {
+            this.key = key;
+
+            lengths = new long[valueCount];
+            cleanFiles = new File[valueCount];
+            dirtyFiles = new File[valueCount];
+
+            // The names are repetitive so re-use the same builder to avoid allocations.
+            StringBuilder fileBuilder = new StringBuilder(key).append('.');
+            int truncateTo = fileBuilder.length();
+            for (int i = 0; i < valueCount; i++) {
+                fileBuilder.append(i);
+                cleanFiles[i] = new File(directory, fileBuilder.toString());
+                fileBuilder.append(".tmp");
+                dirtyFiles[i] = new File(directory, fileBuilder.toString());
+                fileBuilder.setLength(truncateTo);
+            }
+        }
 
-      Source[] sources = new Source[valueCount];
-      long[] lengths = this.lengths.clone(); // Defensive copy since these can be zeroed out.
-      try {
-        for (int i = 0; i < valueCount; i++) {
-          sources[i] = fileSystem.source(cleanFiles[i]);
+        /**
+         * Set lengths using decimal numbers like "10123".
+         */
+        void setLengths(String[] strings) throws IOException {
+            if (strings.length != valueCount) {
+                throw invalidLengths(strings);
+            }
+
+            try {
+                for (int i = 0; i < strings.length; i++) {
+                    lengths[i] = Long.parseLong(strings[i]);
+                }
+            } catch (NumberFormatException e) {
+                throw invalidLengths(strings);
+            }
         }
-        return new Snapshot(key, sequenceNumber, sources, lengths);
-      } catch (FileNotFoundException e) {
-        // A file must have been deleted manually!
-        for (int i = 0; i < valueCount; i++) {
-          if (sources[i] != null) {
-            Util.closeQuietly(sources[i]);
-          } else {
-            break;
-          }
+
+        /**
+         * Append space-prefixed lengths to {@code writer}.
+         */
+        void writeLengths(BufferedSink writer) throws IOException {
+            for (long length : lengths) {
+                writer.writeByte(' ').writeDecimalLong(length);
+            }
         }
-        // Since the entry is no longer valid, remove it so the metadata is accurate (i.e. the cache
-        // size.)
-        try {
-          removeEntry(this);
-        } catch (IOException ignored) {
+
+        private IOException invalidLengths(String[] strings) throws IOException {
+            throw new IOException("unexpected journal line: " + Arrays.toString(strings));
+        }
+
+        /**
+         * Returns a snapshot of this entry. This opens all streams eagerly to guarantee that we see a
+         * single published snapshot. If we opened streams lazily then the streams could come from
+         * different edits.
+         */
+        Snapshot snapshot() {
+            if (!Thread.holdsLock(DiskLruCache.this)) throw new AssertionError();
+
+            Source[] sources = new Source[valueCount];
+            long[] lengths = this.lengths.clone(); // Defensive copy since these can be zeroed out.
+            try {
+                for (int i = 0; i < valueCount; i++) {
+                    sources[i] = fileSystem.source(cleanFiles[i]);
+                }
+                return new Snapshot(key, sequenceNumber, sources, lengths);
+            } catch (FileNotFoundException e) {
+                // A file must have been deleted manually!
+                for (int i = 0; i < valueCount; i++) {
+                    if (sources[i] != null) {
+                        Util.closeQuietly(sources[i]);
+                    } else {
+                        break;
+                    }
+                }
+                // Since the entry is no longer valid, remove it so the metadata is accurate (i.e. the cache
+                // size.)
+                try {
+                    removeEntry(this);
+                } catch (IOException ignored) {
+                }
+                return null;
+            }
         }
-        return null;
-      }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/connection/RealConnection.java b/okhttp/src/main/java/okhttp3/internal/connection/RealConnection.java
index 6afb0fd017..c975a0ba75 100644
--- a/okhttp/src/main/java/okhttp3/internal/connection/RealConnection.java
+++ b/okhttp/src/main/java/okhttp3/internal/connection/RealConnection.java
@@ -33,6 +33,7 @@
 import javax.net.ssl.SSLPeerUnverifiedException;
 import javax.net.ssl.SSLSocket;
 import javax.net.ssl.SSLSocketFactory;
+
 import okhttp3.Address;
 import okhttp3.Call;
 import okhttp3.CertificatePinner;
@@ -71,504 +72,546 @@
 import static java.util.concurrent.TimeUnit.MILLISECONDS;
 import static okhttp3.internal.Util.closeQuietly;
 
+/**
+ * Connection的实现类，对jdk的socket物理连接的包装
+ */
 public final class RealConnection extends Http2Connection.Listener implements Connection {
-  private static final String NPE_THROW_WITH_NULL = "throw with null exception";
-  private static final int MAX_TUNNEL_ATTEMPTS = 21;
-
-  private final ConnectionPool connectionPool;
-  private final Route route;
-
-  // The fields below are initialized by connect() and never reassigned.
-
-  /** The low-level TCP socket. */
-  private Socket rawSocket;
-
-  /**
-   * The application layer socket. Either an {@link SSLSocket} layered over {@link #rawSocket}, or
-   * {@link #rawSocket} itself if this connection does not use SSL.
-   */
-  private Socket socket;
-  private Handshake handshake;
-  private Protocol protocol;
-  private Http2Connection http2Connection;
-  private BufferedSource source;
-  private BufferedSink sink;
-
-  // The fields below track connection state and are guarded by connectionPool.
-
-  /** If true, no new streams can be created on this connection. Once true this is always true. */
-  public boolean noNewStreams;
-
-  public int successCount;
-
-  /**
-   * The maximum number of concurrent streams that can be carried by this connection. If {@code
-   * allocations.size() < allocationLimit} then new streams can be created on this connection.
-   */
-  public int allocationLimit = 1;
-
-  /** Current streams carried by this connection. */
-  public final List<Reference<StreamAllocation>> allocations = new ArrayList<>();
-
-  /** Nanotime timestamp when {@code allocations.size()} reached zero. */
-  public long idleAtNanos = Long.MAX_VALUE;
-
-  public RealConnection(ConnectionPool connectionPool, Route route) {
-    this.connectionPool = connectionPool;
-    this.route = route;
-  }
-
-  public static RealConnection testConnection(
-      ConnectionPool connectionPool, Route route, Socket socket, long idleAtNanos) {
-    RealConnection result = new RealConnection(connectionPool, route);
-    result.socket = socket;
-    result.idleAtNanos = idleAtNanos;
-    return result;
-  }
-
-  public void connect(int connectTimeout, int readTimeout, int writeTimeout,
-      boolean connectionRetryEnabled, Call call, EventListener eventListener) {
-    if (protocol != null) throw new IllegalStateException("already connected");
-
-    RouteException routeException = null;
-    List<ConnectionSpec> connectionSpecs = route.address().connectionSpecs();
-    ConnectionSpecSelector connectionSpecSelector = new ConnectionSpecSelector(connectionSpecs);
-
-    if (route.address().sslSocketFactory() == null) {
-      if (!connectionSpecs.contains(ConnectionSpec.CLEARTEXT)) {
-        throw new RouteException(new UnknownServiceException(
-            "CLEARTEXT communication not enabled for client"));
-      }
-      String host = route.address().url().host();
-      if (!Platform.get().isCleartextTrafficPermitted(host)) {
-        throw new RouteException(new UnknownServiceException(
-            "CLEARTEXT communication to " + host + " not permitted by network security policy"));
-      }
+    private static final String NPE_THROW_WITH_NULL = "throw with null exception";
+    private static final int MAX_TUNNEL_ATTEMPTS = 21;
+
+    private final ConnectionPool connectionPool;
+    private final Route route;
+
+    // The fields below are initialized by connect() and never reassigned.
+
+    /**
+     * The low-level TCP socket.
+     */
+    private Socket rawSocket;
+
+    /**
+     * The application layer socket. Either an {@link SSLSocket} layered over {@link #rawSocket}, or
+     * {@link #rawSocket} itself if this connection does not use SSL.
+     */
+    private Socket socket;
+    private Handshake handshake;
+    private Protocol protocol;
+    private Http2Connection http2Connection;
+    private BufferedSource source;
+    private BufferedSink sink;
+
+    // The fields below track connection state and are guarded by connectionPool.
+
+    /**
+     * If true, no new streams can be created on this connection. Once true this is always true.
+     */
+    public boolean noNewStreams;
+
+    public int successCount;
+
+    /**
+     * The maximum number of concurrent streams that can be carried by this connection. If {@code
+     * allocations.size() < allocationLimit} then new streams can be created on this connection.
+     */
+    public int allocationLimit = 1;
+
+    /**
+     * Current streams carried by this connection.
+     * 以下三个方法会修改这个list
+     * {@link StreamAllocation#release()}
+     * {@link StreamAllocation#acquire(RealConnection, boolean)}
+     * {@link StreamAllocation#releaseAndAcquire(RealConnection)}
+     */
+    public final List<Reference<StreamAllocation>> allocations = new ArrayList<>();
+
+    /**
+     * Nanotime timestamp when {@code allocations.size()} reached zero.
+     */
+    public long idleAtNanos = Long.MAX_VALUE;
+
+    public RealConnection(ConnectionPool connectionPool, Route route) {
+        this.connectionPool = connectionPool;
+        this.route = route;
     }
 
-    while (true) {
-      try {
-        if (route.requiresTunnel()) {
-          connectTunnel(connectTimeout, readTimeout, writeTimeout, call, eventListener);
-          if (rawSocket == null) {
-            // We were unable to connect the tunnel but properly closed down our resources.
-            break;
-          }
-        } else {
-          connectSocket(connectTimeout, readTimeout, call, eventListener);
+    public static RealConnection testConnection(
+            ConnectionPool connectionPool, Route route, Socket socket, long idleAtNanos) {
+        RealConnection result = new RealConnection(connectionPool, route);
+        result.socket = socket;
+        result.idleAtNanos = idleAtNanos;
+        return result;
+    }
+
+    public void connect(int connectTimeout, int readTimeout, int writeTimeout,
+                        boolean connectionRetryEnabled, Call call, EventListener eventListener) {
+        if (protocol != null) throw new IllegalStateException("already connected");
+
+        RouteException routeException = null;
+        List<ConnectionSpec> connectionSpecs = route.address().connectionSpecs();
+        ConnectionSpecSelector connectionSpecSelector = new ConnectionSpecSelector(connectionSpecs);
+
+        if (route.address().sslSocketFactory() == null) {
+            if (!connectionSpecs.contains(ConnectionSpec.CLEARTEXT)) {
+                throw new RouteException(new UnknownServiceException(
+                        "CLEARTEXT communication not enabled for client"));
+            }
+            String host = route.address().url().host();
+            if (!Platform.get().isCleartextTrafficPermitted(host)) {
+                throw new RouteException(new UnknownServiceException(
+                        "CLEARTEXT communication to " + host + " not permitted by network security policy"));
+            }
         }
-        establishProtocol(connectionSpecSelector, call, eventListener);
-        eventListener.connectEnd(call, route.socketAddress(), route.proxy(), protocol);
-        break;
-      } catch (IOException e) {
-        closeQuietly(socket);
-        closeQuietly(rawSocket);
-        socket = null;
-        rawSocket = null;
-        source = null;
-        sink = null;
-        handshake = null;
-        protocol = null;
-        http2Connection = null;
-
-        eventListener.connectFailed(call, route.socketAddress(), route.proxy(), null, e);
-
-        if (routeException == null) {
-          routeException = new RouteException(e);
-        } else {
-          routeException.addConnectException(e);
+
+        while (true) {
+            try {
+                if (route.requiresTunnel()) {
+                    connectTunnel(connectTimeout, readTimeout, writeTimeout, call, eventListener);
+                    if (rawSocket == null) {
+                        // We were unable to connect the tunnel but properly closed down our resources.
+                        break;
+                    }
+                } else {
+                    connectSocket(connectTimeout, readTimeout, call, eventListener);
+                }
+                establishProtocol(connectionSpecSelector, call, eventListener);
+                eventListener.connectEnd(call, route.socketAddress(), route.proxy(), protocol);
+                break;
+            } catch (IOException e) {
+                closeQuietly(socket);
+                closeQuietly(rawSocket);
+                socket = null;
+                rawSocket = null;
+                source = null;
+                sink = null;
+                handshake = null;
+                protocol = null;
+                http2Connection = null;
+
+                eventListener.connectFailed(call, route.socketAddress(), route.proxy(), null, e);
+
+                if (routeException == null) {
+                    routeException = new RouteException(e);
+                } else {
+                    routeException.addConnectException(e);
+                }
+
+                if (!connectionRetryEnabled || !connectionSpecSelector.connectionFailed(e)) {
+                    throw routeException;
+                }
+            }
         }
 
-        if (!connectionRetryEnabled || !connectionSpecSelector.connectionFailed(e)) {
-          throw routeException;
+        if (route.requiresTunnel() && rawSocket == null) {
+            ProtocolException exception = new ProtocolException("Too many tunnel connections attempted: "
+                    + MAX_TUNNEL_ATTEMPTS);
+            throw new RouteException(exception);
         }
-      }
-    }
 
-    if (route.requiresTunnel() && rawSocket == null) {
-      ProtocolException exception = new ProtocolException("Too many tunnel connections attempted: "
-          + MAX_TUNNEL_ATTEMPTS);
-      throw new RouteException(exception);
+        if (http2Connection != null) {
+            synchronized (connectionPool) {
+                allocationLimit = http2Connection.maxConcurrentStreams();
+            }
+        }
     }
 
-    if (http2Connection != null) {
-      synchronized (connectionPool) {
-        allocationLimit = http2Connection.maxConcurrentStreams();
-      }
-    }
-  }
-
-  /**
-   * Does all the work to build an HTTPS connection over a proxy tunnel. The catch here is that a
-   * proxy server can issue an auth challenge and then close the connection.
-   */
-  private void connectTunnel(int connectTimeout, int readTimeout, int writeTimeout, Call call,
-      EventListener eventListener) throws IOException {
-    Request tunnelRequest = createTunnelRequest();
-    HttpUrl url = tunnelRequest.url();
-    for (int i = 0; i < MAX_TUNNEL_ATTEMPTS; i++) {
-      connectSocket(connectTimeout, readTimeout, call, eventListener);
-      tunnelRequest = createTunnel(readTimeout, writeTimeout, tunnelRequest, url);
-
-      if (tunnelRequest == null) break; // Tunnel successfully created.
-
-      // The proxy decided to close the connection after an auth challenge. We need to create a new
-      // connection, but this time with the auth credentials.
-      closeQuietly(rawSocket);
-      rawSocket = null;
-      sink = null;
-      source = null;
-      eventListener.connectEnd(call, route.socketAddress(), route.proxy(), null);
+    /**
+     * Does all the work to build an HTTPS connection over a proxy tunnel. The catch here is that a
+     * proxy server can issue an auth challenge and then close the connection.
+     */
+    private void connectTunnel(int connectTimeout, int readTimeout, int writeTimeout, Call call,
+                               EventListener eventListener) throws IOException {
+        Request tunnelRequest = createTunnelRequest();
+        HttpUrl url = tunnelRequest.url();
+        for (int i = 0; i < MAX_TUNNEL_ATTEMPTS; i++) {
+            connectSocket(connectTimeout, readTimeout, call, eventListener);
+            tunnelRequest = createTunnel(readTimeout, writeTimeout, tunnelRequest, url);
+
+            if (tunnelRequest == null) break; // Tunnel successfully created.
+
+            // The proxy decided to close the connection after an auth challenge. We need to create a new
+            // connection, but this time with the auth credentials.
+            closeQuietly(rawSocket);
+            rawSocket = null;
+            sink = null;
+            source = null;
+            eventListener.connectEnd(call, route.socketAddress(), route.proxy(), null);
+        }
     }
-  }
-
-  /** Does all the work necessary to build a full HTTP or HTTPS connection on a raw socket. */
-  private void connectSocket(int connectTimeout, int readTimeout, Call call,
-      EventListener eventListener) throws IOException {
-    Proxy proxy = route.proxy();
-    Address address = route.address();
-
-    rawSocket = proxy.type() == Proxy.Type.DIRECT || proxy.type() == Proxy.Type.HTTP
-        ? address.socketFactory().createSocket()
-        : new Socket(proxy);
-
-    eventListener.connectStart(call, route.socketAddress(), proxy);
-    rawSocket.setSoTimeout(readTimeout);
-    try {
-      Platform.get().connectSocket(rawSocket, route.socketAddress(), connectTimeout);
-    } catch (ConnectException e) {
-      ConnectException ce = new ConnectException("Failed to connect to " + route.socketAddress());
-      ce.initCause(e);
-      throw ce;
+
+    /**
+     * Does all the work necessary to build a full HTTP or HTTPS connection on a raw socket.
+     * 构造HttpStream对象?并建立套接字连接（完成三次握手）
+     */
+    private void connectSocket(int connectTimeout, int readTimeout, Call call,
+                               EventListener eventListener) throws IOException {
+        Proxy proxy = route.proxy();
+        Address address = route.address();
+
+        rawSocket = proxy.type() == Proxy.Type.DIRECT || proxy.type() == Proxy.Type.HTTP
+                ? address.socketFactory().createSocket()
+                : new Socket(proxy);
+
+        eventListener.connectStart(call, route.socketAddress(), proxy);
+        rawSocket.setSoTimeout(readTimeout);
+        try {
+            // 选择当前平台Runtime下最好的socket库进行握手
+            Platform.get().connectSocket(rawSocket, route.socketAddress(), connectTimeout);
+        } catch (ConnectException e) {
+            ConnectException ce = new ConnectException("Failed to connect to " + route.socketAddress());
+            ce.initCause(e);
+            throw ce;
+        }
+
+        // The following try/catch block is a pseudo hacky way to get around a crash on Android 7.0
+        // More details:
+        // https://github.com/square/okhttp/issues/3245
+        // https://android-review.googlesource.com/#/c/271775/
+        try {
+            // 通过okio库与远程socket建立了I/O连接，为了更好的理解，我们可以把它看成管道
+            //Sink -> Socket/File
+            // Source <- Socket/File
+            // source 用于获取response
+            // Source是okio库中的输入组件，类似于inputstream，经常在下载中用到。
+            // 它的重要方法是read(Buffer sink, long byteCount)，从流中读取数据。
+            source = Okio.buffer(Okio.source(rawSocket));
+            // sink 用于write buffer 到server
+            // Sink是okio库中的io输出组件，类似于outputstream，经常用于写到file/Socket。
+            // 它的最重要方法是void write(Buffer source, long byteCount)，写数据到Buffer中
+            sink = Okio.buffer(Okio.sink(rawSocket));
+        } catch (NullPointerException npe) {
+            if (NPE_THROW_WITH_NULL.equals(npe.getMessage())) {
+                throw new IOException(npe);
+            }
+        }
     }
 
-    // The following try/catch block is a pseudo hacky way to get around a crash on Android 7.0
-    // More details:
-    // https://github.com/square/okhttp/issues/3245
-    // https://android-review.googlesource.com/#/c/271775/
-    try {
-      source = Okio.buffer(Okio.source(rawSocket));
-      sink = Okio.buffer(Okio.sink(rawSocket));
-    } catch (NullPointerException npe) {
-      if (NPE_THROW_WITH_NULL.equals(npe.getMessage())) {
-        throw new IOException(npe);
-      }
+    private void establishProtocol(ConnectionSpecSelector connectionSpecSelector, Call call,
+                                   EventListener eventListener) throws IOException {
+        if (route.address().sslSocketFactory() == null) {
+            protocol = Protocol.HTTP_1_1;
+            socket = rawSocket;
+            return;
+        }
+
+        eventListener.secureConnectStart(call);
+        connectTls(connectionSpecSelector);
+        eventListener.secureConnectEnd(call, handshake);
+
+        if (protocol == Protocol.HTTP_2) {
+            socket.setSoTimeout(0); // HTTP/2 connection timeouts are set per-stream.
+            http2Connection = new Http2Connection.Builder(true)
+                    .socket(socket, route.address().url().host(), source, sink)
+                    .listener(this)
+                    .build();
+            http2Connection.start();
+        }
     }
-  }
-
-  private void establishProtocol(ConnectionSpecSelector connectionSpecSelector, Call call,
-      EventListener eventListener) throws IOException {
-    if (route.address().sslSocketFactory() == null) {
-      protocol = Protocol.HTTP_1_1;
-      socket = rawSocket;
-      return;
+
+    private void connectTls(ConnectionSpecSelector connectionSpecSelector) throws IOException {
+        Address address = route.address();
+        SSLSocketFactory sslSocketFactory = address.sslSocketFactory();
+        boolean success = false;
+        SSLSocket sslSocket = null;
+        try {
+            // Create the wrapper over the connected socket.
+            sslSocket = (SSLSocket) sslSocketFactory.createSocket(
+                    rawSocket, address.url().host(), address.url().port(), true /* autoClose */);
+
+            // Configure the socket's ciphers, TLS versions, and extensions.
+            ConnectionSpec connectionSpec = connectionSpecSelector.configureSecureSocket(sslSocket);
+            if (connectionSpec.supportsTlsExtensions()) {
+                Platform.get().configureTlsExtensions(
+                        sslSocket, address.url().host(), address.protocols());
+            }
+
+            // Force handshake. This can throw!
+            sslSocket.startHandshake();
+            Handshake unverifiedHandshake = Handshake.get(sslSocket.getSession());
+
+            // Verify that the socket's certificates are acceptable for the target host.
+            if (!address.hostnameVerifier().verify(address.url().host(), sslSocket.getSession())) {
+                X509Certificate cert = (X509Certificate) unverifiedHandshake.peerCertificates().get(0);
+                throw new SSLPeerUnverifiedException("Hostname " + address.url().host() + " not verified:"
+                        + "\n    certificate: " + CertificatePinner.pin(cert)
+                        + "\n    DN: " + cert.getSubjectDN().getName()
+                        + "\n    subjectAltNames: " + OkHostnameVerifier.allSubjectAltNames(cert));
+            }
+
+            // Check that the certificate pinner is satisfied by the certificates presented.
+            address.certificatePinner().check(address.url().host(),
+                    unverifiedHandshake.peerCertificates());
+
+            // Success! Save the handshake and the ALPN protocol.
+            String maybeProtocol = connectionSpec.supportsTlsExtensions()
+                    ? Platform.get().getSelectedProtocol(sslSocket)
+                    : null;
+            socket = sslSocket;
+            source = Okio.buffer(Okio.source(socket));
+            sink = Okio.buffer(Okio.sink(socket));
+            handshake = unverifiedHandshake;
+            protocol = maybeProtocol != null
+                    ? Protocol.get(maybeProtocol)
+                    : Protocol.HTTP_1_1;
+            success = true;
+        } catch (AssertionError e) {
+            if (Util.isAndroidGetsocknameError(e)) throw new IOException(e);
+            throw e;
+        } finally {
+            if (sslSocket != null) {
+                Platform.get().afterHandshake(sslSocket);
+            }
+            if (!success) {
+                closeQuietly(sslSocket);
+            }
+        }
     }
 
-    eventListener.secureConnectStart(call);
-    connectTls(connectionSpecSelector);
-    eventListener.secureConnectEnd(call, handshake);
-
-    if (protocol == Protocol.HTTP_2) {
-      socket.setSoTimeout(0); // HTTP/2 connection timeouts are set per-stream.
-      http2Connection = new Http2Connection.Builder(true)
-          .socket(socket, route.address().url().host(), source, sink)
-          .listener(this)
-          .build();
-      http2Connection.start();
+    /**
+     * To make an HTTPS connection over an HTTP proxy, send an unencrypted CONNECT request to create
+     * the proxy connection. This may need to be retried if the proxy requires authorization.
+     */
+    private Request createTunnel(int readTimeout, int writeTimeout, Request tunnelRequest,
+                                 HttpUrl url) throws IOException {
+        // Make an SSL Tunnel on the first message pair of each SSL + proxy connection.
+        String requestLine = "CONNECT " + Util.hostHeader(url, true) + " HTTP/1.1";
+        while (true) {
+            Http1Codec tunnelConnection = new Http1Codec(null, null, source, sink);
+            source.timeout().timeout(readTimeout, MILLISECONDS);
+            sink.timeout().timeout(writeTimeout, MILLISECONDS);
+            tunnelConnection.writeRequest(tunnelRequest.headers(), requestLine);
+            tunnelConnection.finishRequest();
+            Response response = tunnelConnection.readResponseHeaders(false)
+                    .request(tunnelRequest)
+                    .build();
+            // The response body from a CONNECT should be empty, but if it is not then we should consume
+            // it before proceeding.
+            long contentLength = HttpHeaders.contentLength(response);
+            if (contentLength == -1L) {
+                contentLength = 0L;
+            }
+            Source body = tunnelConnection.newFixedLengthSource(contentLength);
+            Util.skipAll(body, Integer.MAX_VALUE, TimeUnit.MILLISECONDS);
+            body.close();
+
+            switch (response.code()) {
+                case HTTP_OK:
+                    // Assume the server won't send a TLS ServerHello until we send a TLS ClientHello. If
+                    // that happens, then we will have buffered bytes that are needed by the SSLSocket!
+                    // This check is imperfect: it doesn't tell us whether a handshake will succeed, just
+                    // that it will almost certainly fail because the proxy has sent unexpected data.
+                    if (!source.buffer().exhausted() || !sink.buffer().exhausted()) {
+                        throw new IOException("TLS tunnel buffered too many bytes!");
+                    }
+                    return null;
+
+                case HTTP_PROXY_AUTH:
+                    tunnelRequest = route.address().proxyAuthenticator().authenticate(route, response);
+                    if (tunnelRequest == null) throw new IOException("Failed to authenticate with proxy");
+
+                    if ("close".equalsIgnoreCase(response.header("Connection"))) {
+                        return tunnelRequest;
+                    }
+                    break;
+
+                default:
+                    throw new IOException(
+                            "Unexpected response code for CONNECT: " + response.code());
+            }
+        }
     }
-  }
-
-  private void connectTls(ConnectionSpecSelector connectionSpecSelector) throws IOException {
-    Address address = route.address();
-    SSLSocketFactory sslSocketFactory = address.sslSocketFactory();
-    boolean success = false;
-    SSLSocket sslSocket = null;
-    try {
-      // Create the wrapper over the connected socket.
-      sslSocket = (SSLSocket) sslSocketFactory.createSocket(
-          rawSocket, address.url().host(), address.url().port(), true /* autoClose */);
-
-      // Configure the socket's ciphers, TLS versions, and extensions.
-      ConnectionSpec connectionSpec = connectionSpecSelector.configureSecureSocket(sslSocket);
-      if (connectionSpec.supportsTlsExtensions()) {
-        Platform.get().configureTlsExtensions(
-            sslSocket, address.url().host(), address.protocols());
-      }
-
-      // Force handshake. This can throw!
-      sslSocket.startHandshake();
-      Handshake unverifiedHandshake = Handshake.get(sslSocket.getSession());
-
-      // Verify that the socket's certificates are acceptable for the target host.
-      if (!address.hostnameVerifier().verify(address.url().host(), sslSocket.getSession())) {
-        X509Certificate cert = (X509Certificate) unverifiedHandshake.peerCertificates().get(0);
-        throw new SSLPeerUnverifiedException("Hostname " + address.url().host() + " not verified:"
-            + "\n    certificate: " + CertificatePinner.pin(cert)
-            + "\n    DN: " + cert.getSubjectDN().getName()
-            + "\n    subjectAltNames: " + OkHostnameVerifier.allSubjectAltNames(cert));
-      }
-
-      // Check that the certificate pinner is satisfied by the certificates presented.
-      address.certificatePinner().check(address.url().host(),
-          unverifiedHandshake.peerCertificates());
-
-      // Success! Save the handshake and the ALPN protocol.
-      String maybeProtocol = connectionSpec.supportsTlsExtensions()
-          ? Platform.get().getSelectedProtocol(sslSocket)
-          : null;
-      socket = sslSocket;
-      source = Okio.buffer(Okio.source(socket));
-      sink = Okio.buffer(Okio.sink(socket));
-      handshake = unverifiedHandshake;
-      protocol = maybeProtocol != null
-          ? Protocol.get(maybeProtocol)
-          : Protocol.HTTP_1_1;
-      success = true;
-    } catch (AssertionError e) {
-      if (Util.isAndroidGetsocknameError(e)) throw new IOException(e);
-      throw e;
-    } finally {
-      if (sslSocket != null) {
-        Platform.get().afterHandshake(sslSocket);
-      }
-      if (!success) {
-        closeQuietly(sslSocket);
-      }
+
+    /**
+     * Returns a request that creates a TLS tunnel via an HTTP proxy. Everything in the tunnel request
+     * is sent unencrypted to the proxy server, so tunnels include only the minimum set of headers.
+     * This avoids sending potentially sensitive data like HTTP cookies to the proxy unencrypted.
+     */
+    private Request createTunnelRequest() {
+        return new Request.Builder()
+                .url(route.address().url())
+                .header("Host", Util.hostHeader(route.address().url(), true))
+                .header("Proxy-Connection", "Keep-Alive") // For HTTP/1.0 proxies like Squid.
+                .header("User-Agent", Version.userAgent())
+                .build();
     }
-  }
-
-  /**
-   * To make an HTTPS connection over an HTTP proxy, send an unencrypted CONNECT request to create
-   * the proxy connection. This may need to be retried if the proxy requires authorization.
-   */
-  private Request createTunnel(int readTimeout, int writeTimeout, Request tunnelRequest,
-      HttpUrl url) throws IOException {
-    // Make an SSL Tunnel on the first message pair of each SSL + proxy connection.
-    String requestLine = "CONNECT " + Util.hostHeader(url, true) + " HTTP/1.1";
-    while (true) {
-      Http1Codec tunnelConnection = new Http1Codec(null, null, source, sink);
-      source.timeout().timeout(readTimeout, MILLISECONDS);
-      sink.timeout().timeout(writeTimeout, MILLISECONDS);
-      tunnelConnection.writeRequest(tunnelRequest.headers(), requestLine);
-      tunnelConnection.finishRequest();
-      Response response = tunnelConnection.readResponseHeaders(false)
-          .request(tunnelRequest)
-          .build();
-      // The response body from a CONNECT should be empty, but if it is not then we should consume
-      // it before proceeding.
-      long contentLength = HttpHeaders.contentLength(response);
-      if (contentLength == -1L) {
-        contentLength = 0L;
-      }
-      Source body = tunnelConnection.newFixedLengthSource(contentLength);
-      Util.skipAll(body, Integer.MAX_VALUE, TimeUnit.MILLISECONDS);
-      body.close();
-
-      switch (response.code()) {
-        case HTTP_OK:
-          // Assume the server won't send a TLS ServerHello until we send a TLS ClientHello. If
-          // that happens, then we will have buffered bytes that are needed by the SSLSocket!
-          // This check is imperfect: it doesn't tell us whether a handshake will succeed, just
-          // that it will almost certainly fail because the proxy has sent unexpected data.
-          if (!source.buffer().exhausted() || !sink.buffer().exhausted()) {
-            throw new IOException("TLS tunnel buffered too many bytes!");
-          }
-          return null;
-
-        case HTTP_PROXY_AUTH:
-          tunnelRequest = route.address().proxyAuthenticator().authenticate(route, response);
-          if (tunnelRequest == null) throw new IOException("Failed to authenticate with proxy");
-
-          if ("close".equalsIgnoreCase(response.header("Connection"))) {
-            return tunnelRequest;
-          }
-          break;
-
-        default:
-          throw new IOException(
-              "Unexpected response code for CONNECT: " + response.code());
-      }
+
+    /**
+     * Returns true if this connection can carry a stream allocation to {@code address}. If non-null
+     * {@code route} is the resolved route for a connection.
+     */
+    public boolean isEligible(Address address, @Nullable Route route) {
+        // If this connection is not accepting new streams, we're done.
+        if (allocations.size() >= allocationLimit || noNewStreams) return false;
+
+        // If the non-host fields of the address don't overlap, we're done.
+        if (!Internal.instance.equalsNonHost(this.route.address(), address)) return false;
+
+        // If the host exactly matches, we're done: this connection can carry the address.
+        if (address.url().host().equals(this.route().address().url().host())) {
+            return true; // This connection is a perfect match.
+        }
+
+        // At this point we don't have a hostname match. But we still be able to carry the request if
+        // our connection coalescing requirements are met. See also:
+        // https://hpbn.co/optimizing-application-delivery/#eliminate-domain-sharding
+        // https://daniel.haxx.se/blog/2016/08/18/http2-connection-coalescing/
+
+        // 1. This connection must be HTTP/2.
+        if (http2Connection == null) return false;
+
+        // 2. The routes must share an IP address. This requires us to have a DNS address for both
+        // hosts, which only happens after route planning. We can't coalesce connections that use a
+        // proxy, since proxies don't tell us the origin server's IP address.
+        if (route == null) return false;
+        if (route.proxy().type() != Proxy.Type.DIRECT) return false;
+        if (this.route.proxy().type() != Proxy.Type.DIRECT) return false;
+        if (!this.route.socketAddress().equals(route.socketAddress())) return false;
+
+        // 3. This connection's server certificate's must cover the new host.
+        if (route.address().hostnameVerifier() != OkHostnameVerifier.INSTANCE) return false;
+        if (!supportsUrl(address.url())) return false;
+
+        // 4. Certificate pinning must match the host.
+        try {
+            address.certificatePinner().check(address.url().host(), handshake().peerCertificates());
+        } catch (SSLPeerUnverifiedException e) {
+            return false;
+        }
+
+        return true; // The caller's address can be carried by this connection.
     }
-  }
-
-  /**
-   * Returns a request that creates a TLS tunnel via an HTTP proxy. Everything in the tunnel request
-   * is sent unencrypted to the proxy server, so tunnels include only the minimum set of headers.
-   * This avoids sending potentially sensitive data like HTTP cookies to the proxy unencrypted.
-   */
-  private Request createTunnelRequest() {
-    return new Request.Builder()
-        .url(route.address().url())
-        .header("Host", Util.hostHeader(route.address().url(), true))
-        .header("Proxy-Connection", "Keep-Alive") // For HTTP/1.0 proxies like Squid.
-        .header("User-Agent", Version.userAgent())
-        .build();
-  }
-
-  /**
-   * Returns true if this connection can carry a stream allocation to {@code address}. If non-null
-   * {@code route} is the resolved route for a connection.
-   */
-  public boolean isEligible(Address address, @Nullable Route route) {
-    // If this connection is not accepting new streams, we're done.
-    if (allocations.size() >= allocationLimit || noNewStreams) return false;
-
-    // If the non-host fields of the address don't overlap, we're done.
-    if (!Internal.instance.equalsNonHost(this.route.address(), address)) return false;
-
-    // If the host exactly matches, we're done: this connection can carry the address.
-    if (address.url().host().equals(this.route().address().url().host())) {
-      return true; // This connection is a perfect match.
+
+    public boolean supportsUrl(HttpUrl url) {
+        if (url.port() != route.address().url().port()) {
+            return false; // Port mismatch.
+        }
+
+        if (!url.host().equals(route.address().url().host())) {
+            // We have a host mismatch. But if the certificate matches, we're still good.
+            return handshake != null && OkHostnameVerifier.INSTANCE.verify(
+                    url.host(), (X509Certificate) handshake.peerCertificates().get(0));
+        }
+
+        return true; // Success. The URL is supported.
     }
 
-    // At this point we don't have a hostname match. But we still be able to carry the request if
-    // our connection coalescing requirements are met. See also:
-    // https://hpbn.co/optimizing-application-delivery/#eliminate-domain-sharding
-    // https://daniel.haxx.se/blog/2016/08/18/http2-connection-coalescing/
-
-    // 1. This connection must be HTTP/2.
-    if (http2Connection == null) return false;
-
-    // 2. The routes must share an IP address. This requires us to have a DNS address for both
-    // hosts, which only happens after route planning. We can't coalesce connections that use a
-    // proxy, since proxies don't tell us the origin server's IP address.
-    if (route == null) return false;
-    if (route.proxy().type() != Proxy.Type.DIRECT) return false;
-    if (this.route.proxy().type() != Proxy.Type.DIRECT) return false;
-    if (!this.route.socketAddress().equals(route.socketAddress())) return false;
-
-    // 3. This connection's server certificate's must cover the new host.
-    if (route.address().hostnameVerifier() != OkHostnameVerifier.INSTANCE) return false;
-    if (!supportsUrl(address.url())) return false;
-
-    // 4. Certificate pinning must match the host.
-    try {
-      address.certificatePinner().check(address.url().host(), handshake().peerCertificates());
-    } catch (SSLPeerUnverifiedException e) {
-      return false;
+    public HttpCodec newCodec(OkHttpClient client, Interceptor.Chain chain,
+                              StreamAllocation streamAllocation) throws SocketException {
+        if (http2Connection != null) {
+            return new Http2Codec(client, chain, streamAllocation, http2Connection);
+        } else {
+            socket.setSoTimeout(chain.readTimeoutMillis());
+            source.timeout().timeout(chain.readTimeoutMillis(), MILLISECONDS);
+            sink.timeout().timeout(chain.writeTimeoutMillis(), MILLISECONDS);
+            return new Http1Codec(client, streamAllocation, source, sink);
+        }
     }
 
-    return true; // The caller's address can be carried by this connection.
-  }
+    public RealWebSocket.Streams newWebSocketStreams(final StreamAllocation streamAllocation) {
+        return new RealWebSocket.Streams(true, source, sink) {
+            @Override
+            public void close() throws IOException {
+                streamAllocation.streamFinished(true, streamAllocation.codec(), -1L, null);
+            }
+        };
+    }
 
-  public boolean supportsUrl(HttpUrl url) {
-    if (url.port() != route.address().url().port()) {
-      return false; // Port mismatch.
+    @Override
+    public Route route() {
+        return route;
     }
 
-    if (!url.host().equals(route.address().url().host())) {
-      // We have a host mismatch. But if the certificate matches, we're still good.
-      return handshake != null && OkHostnameVerifier.INSTANCE.verify(
-          url.host(), (X509Certificate) handshake.peerCertificates().get(0));
+    public void cancel() {
+        // Close the raw socket so we don't end up doing synchronous I/O.
+        closeQuietly(rawSocket);
     }
 
-    return true; // Success. The URL is supported.
-  }
-
-  public HttpCodec newCodec(OkHttpClient client, Interceptor.Chain chain,
-      StreamAllocation streamAllocation) throws SocketException {
-    if (http2Connection != null) {
-      return new Http2Codec(client, chain, streamAllocation, http2Connection);
-    } else {
-      socket.setSoTimeout(chain.readTimeoutMillis());
-      source.timeout().timeout(chain.readTimeoutMillis(), MILLISECONDS);
-      sink.timeout().timeout(chain.writeTimeoutMillis(), MILLISECONDS);
-      return new Http1Codec(client, streamAllocation, source, sink);
+    @Override
+    public Socket socket() {
+        return socket;
     }
-  }
-
-  public RealWebSocket.Streams newWebSocketStreams(final StreamAllocation streamAllocation) {
-    return new RealWebSocket.Streams(true, source, sink) {
-      @Override public void close() throws IOException {
-        streamAllocation.streamFinished(true, streamAllocation.codec(), -1L, null);
-      }
-    };
-  }
-
-  @Override public Route route() {
-    return route;
-  }
-
-  public void cancel() {
-    // Close the raw socket so we don't end up doing synchronous I/O.
-    closeQuietly(rawSocket);
-  }
-
-  @Override public Socket socket() {
-    return socket;
-  }
-
-  /** Returns true if this connection is ready to host new streams. */
-  public boolean isHealthy(boolean doExtensiveChecks) {
-    if (socket.isClosed() || socket.isInputShutdown() || socket.isOutputShutdown()) {
-      return false;
+
+    /**
+     * Returns true if this connection is ready to host new streams.
+     */
+    public boolean isHealthy(boolean doExtensiveChecks) {
+        if (socket.isClosed() || socket.isInputShutdown() || socket.isOutputShutdown()) {
+            return false;
+        }
+
+        if (http2Connection != null) {
+            return !http2Connection.isShutdown();
+        }
+
+        if (doExtensiveChecks) {
+            try {
+                int readTimeout = socket.getSoTimeout();
+                try {
+                    socket.setSoTimeout(1);
+                    if (source.exhausted()) {
+                        return false; // Stream is exhausted; socket is closed.
+                    }
+                    return true;
+                } finally {
+                    socket.setSoTimeout(readTimeout);
+                }
+            } catch (SocketTimeoutException ignored) {
+                // Read timed out; socket is good.
+            } catch (IOException e) {
+                return false; // Couldn't read; socket is closed.
+            }
+        }
+
+        return true;
     }
 
-    if (http2Connection != null) {
-      return !http2Connection.isShutdown();
+    /**
+     * Refuse incoming streams.
+     */
+    @Override
+    public void onStream(Http2Stream stream) throws IOException {
+        stream.close(ErrorCode.REFUSED_STREAM);
     }
 
-    if (doExtensiveChecks) {
-      try {
-        int readTimeout = socket.getSoTimeout();
-        try {
-          socket.setSoTimeout(1);
-          if (source.exhausted()) {
-            return false; // Stream is exhausted; socket is closed.
-          }
-          return true;
-        } finally {
-          socket.setSoTimeout(readTimeout);
+    /**
+     * When settings are received, adjust the allocation limit.
+     */
+    @Override
+    public void onSettings(Http2Connection connection) {
+        synchronized (connectionPool) {
+            allocationLimit = connection.maxConcurrentStreams();
         }
-      } catch (SocketTimeoutException ignored) {
-        // Read timed out; socket is good.
-      } catch (IOException e) {
-        return false; // Couldn't read; socket is closed.
-      }
     }
 
-    return true;
-  }
+    @Override
+    public Handshake handshake() {
+        return handshake;
+    }
 
-  /** Refuse incoming streams. */
-  @Override public void onStream(Http2Stream stream) throws IOException {
-    stream.close(ErrorCode.REFUSED_STREAM);
-  }
+    /**
+     * Returns true if this is an HTTP/2 connection. Such connections can be used in multiple HTTP
+     * requests simultaneously.
+     */
+    public boolean isMultiplexed() {
+        return http2Connection != null;
+    }
+
+    @Override
+    public Protocol protocol() {
+        return protocol;
+    }
 
-  /** When settings are received, adjust the allocation limit. */
-  @Override public void onSettings(Http2Connection connection) {
-    synchronized (connectionPool) {
-      allocationLimit = connection.maxConcurrentStreams();
+    @Override
+    public String toString() {
+        return "Connection{"
+                + route.address().url().host() + ":" + route.address().url().port()
+                + ", proxy="
+                + route.proxy()
+                + " hostAddress="
+                + route.socketAddress()
+                + " cipherSuite="
+                + (handshake != null ? handshake.cipherSuite() : "none")
+                + " protocol="
+                + protocol
+                + '}';
     }
-  }
-
-  @Override public Handshake handshake() {
-    return handshake;
-  }
-
-  /**
-   * Returns true if this is an HTTP/2 connection. Such connections can be used in multiple HTTP
-   * requests simultaneously.
-   */
-  public boolean isMultiplexed() {
-    return http2Connection != null;
-  }
-
-  @Override public Protocol protocol() {
-    return protocol;
-  }
-
-  @Override public String toString() {
-    return "Connection{"
-        + route.address().url().host() + ":" + route.address().url().port()
-        + ", proxy="
-        + route.proxy()
-        + " hostAddress="
-        + route.socketAddress()
-        + " cipherSuite="
-        + (handshake != null ? handshake.cipherSuite() : "none")
-        + " protocol="
-        + protocol
-        + '}';
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/connection/StreamAllocation.java b/okhttp/src/main/java/okhttp3/internal/connection/StreamAllocation.java
index 2e5e043a15..656d7fc986 100644
--- a/okhttp/src/main/java/okhttp3/internal/connection/StreamAllocation.java
+++ b/okhttp/src/main/java/okhttp3/internal/connection/StreamAllocation.java
@@ -20,6 +20,7 @@
 import java.lang.ref.WeakReference;
 import java.net.Socket;
 import java.util.List;
+
 import okhttp3.Address;
 import okhttp3.Call;
 import okhttp3.Connection;
@@ -39,491 +40,500 @@
 
 /**
  * This class coordinates the relationship between three entities:
- *
+ * <p>
  * <ul>
- *     <li><strong>Connections:</strong> physical socket connections to remote servers. These are
- *         potentially slow to establish so it is necessary to be able to cancel a connection
- *         currently being connected.
- *     <li><strong>Streams:</strong> logical HTTP request/response pairs that are layered on
- *         connections. Each connection has its own allocation limit, which defines how many
- *         concurrent streams that connection can carry. HTTP/1.x connections can carry 1 stream
- *         at a time, HTTP/2 typically carry multiple.
- *     <li><strong>Calls:</strong> a logical sequence of streams, typically an initial request and
- *         its follow up requests. We prefer to keep all streams of a single call on the same
- *         connection for better behavior and locality.
+ * <li><strong>Connections:</strong> physical socket connections to remote servers. These are
+ * potentially slow to establish so it is necessary to be able to cancel a connection
+ * currently being connected.
+ * <li><strong>Streams:</strong> logical HTTP request/response pairs that are layered on
+ * connections. Each connection has its own allocation limit, which defines how many
+ * concurrent streams that connection can carry. HTTP/1.x connections can carry 1 stream
+ * at a time, HTTP/2 typically carry multiple.
+ * <li><strong>Calls:</strong> a logical sequence of streams, typically an initial request and
+ * its follow up requests. We prefer to keep all streams of a single call on the same
+ * connection for better behavior and locality.
  * </ul>
- *
+ * <p>
  * <p>Instances of this class act on behalf of the call, using one or more streams over one or more
  * connections. This class has APIs to release each of the above resources:
- *
+ * <p>
  * <ul>
- *     <li>{@link #noNewStreams()} prevents the connection from being used for new streams in the
- *         future. Use this after a {@code Connection: close} header, or when the connection may be
- *         inconsistent.
- *     <li>{@link #streamFinished streamFinished()} releases the active stream from this allocation.
- *         Note that only one stream may be active at a given time, so it is necessary to call
- *         {@link #streamFinished streamFinished()} before creating a subsequent stream with {@link
- *         #newStream newStream()}.
- *     <li>{@link #release()} removes the call's hold on the connection. Note that this won't
- *         immediately free the connection if there is a stream still lingering. That happens when a
- *         call is complete but its response body has yet to be fully consumed.
+ * <li>{@link #noNewStreams()} prevents the connection from being used for new streams in the
+ * future. Use this after a {@code Connection: close} header, or when the connection may be
+ * inconsistent.
+ * <li>{@link #streamFinished streamFinished()} releases the active stream from this allocation.
+ * Note that only one stream may be active at a given time, so it is necessary to call
+ * {@link #streamFinished streamFinished()} before creating a subsequent stream with {@link
+ * #newStream newStream()}.
+ * <li>{@link #release()} removes the call's hold on the connection. Note that this won't
+ * immediately free the connection if there is a stream still lingering. That happens when a
+ * call is complete but its response body has yet to be fully consumed.
  * </ul>
- *
+ * <p>
  * <p>This class supports {@linkplain #cancel asynchronous canceling}. This is intended to have the
  * smallest blast radius possible. If an HTTP/2 stream is active, canceling will cancel that stream
  * but not the other streams sharing its connection. But if the TLS handshake is still in progress
  * then canceling may break the entire connection.
  */
 public final class StreamAllocation {
-  public final Address address;
-  private RouteSelector.Selection routeSelection;
-  private Route route;
-  private final ConnectionPool connectionPool;
-  public final Call call;
-  public final EventListener eventListener;
-  private final Object callStackTrace;
-
-  // State guarded by connectionPool.
-  private final RouteSelector routeSelector;
-  private int refusedStreamCount;
-  private RealConnection connection;
-  private boolean reportedAcquired;
-  private boolean released;
-  private boolean canceled;
-  private HttpCodec codec;
-
-  public StreamAllocation(ConnectionPool connectionPool, Address address, Call call,
-      EventListener eventListener, Object callStackTrace) {
-    this.connectionPool = connectionPool;
-    this.address = address;
-    this.call = call;
-    this.eventListener = eventListener;
-    this.routeSelector = new RouteSelector(address, routeDatabase(), call, eventListener);
-    this.callStackTrace = callStackTrace;
-  }
-
-  public HttpCodec newStream(
-      OkHttpClient client, Interceptor.Chain chain, boolean doExtensiveHealthChecks) {
-    int connectTimeout = chain.connectTimeoutMillis();
-    int readTimeout = chain.readTimeoutMillis();
-    int writeTimeout = chain.writeTimeoutMillis();
-    boolean connectionRetryEnabled = client.retryOnConnectionFailure();
-
-    try {
-      RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout,
-          writeTimeout, connectionRetryEnabled, doExtensiveHealthChecks);
-      HttpCodec resultCodec = resultConnection.newCodec(client, chain, this);
-
-      synchronized (connectionPool) {
-        codec = resultCodec;
-        return resultCodec;
-      }
-    } catch (IOException e) {
-      throw new RouteException(e);
+    public final Address address;
+    private RouteSelector.Selection routeSelection;
+    private Route route;
+    private final ConnectionPool connectionPool;
+    public final Call call;
+    public final EventListener eventListener;
+    private final Object callStackTrace;
+
+    // State guarded by connectionPool.
+    private final RouteSelector routeSelector;
+    private int refusedStreamCount;
+    private RealConnection connection;
+    private boolean reportedAcquired;
+    private boolean released;
+    private boolean canceled;
+    private HttpCodec codec;
+
+    public StreamAllocation(ConnectionPool connectionPool, Address address, Call call,
+                            EventListener eventListener, Object callStackTrace) {
+        this.connectionPool = connectionPool;
+        this.address = address;
+        this.call = call;
+        this.eventListener = eventListener;
+        this.routeSelector = new RouteSelector(address, routeDatabase(), call, eventListener);
+        this.callStackTrace = callStackTrace;
     }
-  }
-
-  /**
-   * Finds a connection and returns it if it is healthy. If it is unhealthy the process is repeated
-   * until a healthy connection is found.
-   */
-  private RealConnection findHealthyConnection(int connectTimeout, int readTimeout,
-      int writeTimeout, boolean connectionRetryEnabled, boolean doExtensiveHealthChecks)
-      throws IOException {
-    while (true) {
-      RealConnection candidate = findConnection(connectTimeout, readTimeout, writeTimeout,
-          connectionRetryEnabled);
-
-      // If this is a brand new connection, we can skip the extensive health checks.
-      synchronized (connectionPool) {
-        if (candidate.successCount == 0) {
-          return candidate;
-        }
-      }
 
-      // Do a (potentially slow) check to confirm that the pooled connection is still good. If it
-      // isn't, take it out of the pool and start again.
-      if (!candidate.isHealthy(doExtensiveHealthChecks)) {
-        noNewStreams();
-        continue;
-      }
-
-      return candidate;
-    }
-  }
-
-  /**
-   * Returns a connection to host a new stream. This prefers the existing connection if it exists,
-   * then the pool, finally building a new connection.
-   */
-  private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout,
-      boolean connectionRetryEnabled) throws IOException {
-    boolean foundPooledConnection = false;
-    RealConnection result = null;
-    Route selectedRoute = null;
-    Connection releasedConnection;
-    Socket toClose;
-    synchronized (connectionPool) {
-      if (released) throw new IllegalStateException("released");
-      if (codec != null) throw new IllegalStateException("codec != null");
-      if (canceled) throw new IOException("Canceled");
-
-      // Attempt to use an already-allocated connection. We need to be careful here because our
-      // already-allocated connection may have been restricted from creating new streams.
-      releasedConnection = this.connection;
-      toClose = releaseIfNoNewStreams();
-      if (this.connection != null) {
-        // We had an already-allocated connection and it's good.
-        result = this.connection;
-        releasedConnection = null;
-      }
-      if (!reportedAcquired) {
-        // If the connection was never reported acquired, don't report it as released!
-        releasedConnection = null;
-      }
-
-      if (result == null) {
-        // Attempt to get a connection from the pool.
-        Internal.instance.get(connectionPool, address, this, null);
-        if (connection != null) {
-          foundPooledConnection = true;
-          result = connection;
-        } else {
-          selectedRoute = route;
+    public HttpCodec newStream(
+            OkHttpClient client, Interceptor.Chain chain, boolean doExtensiveHealthChecks) {
+        int connectTimeout = chain.connectTimeoutMillis();
+        int readTimeout = chain.readTimeoutMillis();
+        int writeTimeout = chain.writeTimeoutMillis();
+        boolean connectionRetryEnabled = client.retryOnConnectionFailure();
+
+        try {
+            RealConnection resultConnection = findHealthyConnection(connectTimeout, readTimeout,
+                    writeTimeout, connectionRetryEnabled, doExtensiveHealthChecks);
+            HttpCodec resultCodec = resultConnection.newCodec(client, chain, this);
+
+            synchronized (connectionPool) {
+                codec = resultCodec;
+                return resultCodec;
+            }
+        } catch (IOException e) {
+            throw new RouteException(e);
         }
-      }
     }
-    closeQuietly(toClose);
 
-    if (releasedConnection != null) {
-      eventListener.connectionReleased(call, releasedConnection);
-    }
-    if (foundPooledConnection) {
-      eventListener.connectionAcquired(call, result);
-    }
-    if (result != null) {
-      // If we found an already-allocated or pooled connection, we're done.
-      return result;
-    }
-
-    // If we need a route selection, make one. This is a blocking operation.
-    boolean newRouteSelection = false;
-    if (selectedRoute == null && (routeSelection == null || !routeSelection.hasNext())) {
-      newRouteSelection = true;
-      routeSelection = routeSelector.next();
+    /**
+     * Finds a connection and returns it if it is healthy. If it is unhealthy the process is repeated
+     * until a healthy connection is found.
+     */
+    private RealConnection findHealthyConnection(int connectTimeout, int readTimeout,
+                                                 int writeTimeout, boolean connectionRetryEnabled, boolean doExtensiveHealthChecks)
+            throws IOException {
+        while (true) {
+            RealConnection candidate = findConnection(connectTimeout, readTimeout, writeTimeout,
+                    connectionRetryEnabled);
+
+            // If this is a brand new connection, we can skip the extensive health checks.
+            synchronized (connectionPool) {
+                if (candidate.successCount == 0) {
+                    return candidate;
+                }
+            }
+
+            // Do a (potentially slow) check to confirm that the pooled connection is still good. If it
+            // isn't, take it out of the pool and start again.
+            if (!candidate.isHealthy(doExtensiveHealthChecks)) {
+                noNewStreams();
+                continue;
+            }
+
+            return candidate;
+        }
     }
 
-    synchronized (connectionPool) {
-      if (canceled) throw new IOException("Canceled");
-
-      if (newRouteSelection) {
-        // Now that we have a set of IP addresses, make another attempt at getting a connection from
-        // the pool. This could match due to connection coalescing.
-        List<Route> routes = routeSelection.getAll();
-        for (int i = 0, size = routes.size(); i < size; i++) {
-          Route route = routes.get(i);
-          Internal.instance.get(connectionPool, address, this, route);
-          if (connection != null) {
-            foundPooledConnection = true;
-            result = connection;
-            this.route = route;
-            break;
-          }
+    /**
+     * Returns a connection to host a new stream. This prefers the existing connection if it exists,
+     * then the pool, finally building a new connection.
+     */
+    private RealConnection findConnection(int connectTimeout, int readTimeout, int writeTimeout,
+                                          boolean connectionRetryEnabled) throws IOException {
+        boolean foundPooledConnection = false;
+        RealConnection result = null;
+        Route selectedRoute = null;
+        Connection releasedConnection;
+        Socket toClose;
+        synchronized (connectionPool) {
+            if (released) throw new IllegalStateException("released");
+            if (codec != null) throw new IllegalStateException("codec != null");
+            if (canceled) throw new IOException("Canceled");
+
+            // Attempt to use an already-allocated connection. We need to be careful here because our
+            // already-allocated connection may have been restricted from creating new streams.
+            releasedConnection = this.connection;
+            toClose = releaseIfNoNewStreams();
+            if (this.connection != null) {
+                // We had an already-allocated connection and it's good.
+                result = this.connection;
+                releasedConnection = null;
+            }
+            if (!reportedAcquired) {
+                // If the connection was never reported acquired, don't report it as released!
+                releasedConnection = null;
+            }
+
+            if (result == null) {
+                // Attempt to get a connection from the pool.
+                Internal.instance.get(connectionPool, address, this, null);
+                if (connection != null) {
+                    foundPooledConnection = true;
+                    result = connection;
+                } else {
+                    selectedRoute = route;
+                }
+            }
         }
-      }
+        closeQuietly(toClose);
 
-      if (!foundPooledConnection) {
-        if (selectedRoute == null) {
-          selectedRoute = routeSelection.next();
+        if (releasedConnection != null) {
+            eventListener.connectionReleased(call, releasedConnection);
+        }
+        if (foundPooledConnection) {
+            eventListener.connectionAcquired(call, result);
+        }
+        if (result != null) {
+            // If we found an already-allocated or pooled connection, we're done.
+            return result;
         }
 
-        // Create a connection and assign it to this allocation immediately. This makes it possible
-        // for an asynchronous cancel() to interrupt the handshake we're about to do.
-        route = selectedRoute;
-        refusedStreamCount = 0;
-        result = new RealConnection(connectionPool, selectedRoute);
-        acquire(result, false);
-      }
-    }
-
-    // If we found a pooled connection on the 2nd time around, we're done.
-    if (foundPooledConnection) {
-      eventListener.connectionAcquired(call, result);
-      return result;
-    }
+        // If we need a route selection, make one. This is a blocking operation.
+        boolean newRouteSelection = false;
+        if (selectedRoute == null && (routeSelection == null || !routeSelection.hasNext())) {
+            newRouteSelection = true;
+            routeSelection = routeSelector.next();
+        }
 
-    // Do TCP + TLS handshakes. This is a blocking operation.
-    result.connect(
-        connectTimeout, readTimeout, writeTimeout, connectionRetryEnabled, call, eventListener);
-    routeDatabase().connected(result.route());
+        synchronized (connectionPool) {
+            if (canceled) throw new IOException("Canceled");
+
+            if (newRouteSelection) {
+                // Now that we have a set of IP addresses, make another attempt at getting a connection from
+                // the pool. This could match due to connection coalescing.
+                List<Route> routes = routeSelection.getAll();
+                for (int i = 0, size = routes.size(); i < size; i++) {
+                    Route route = routes.get(i);
+                    Internal.instance.get(connectionPool, address, this, route);
+                    if (connection != null) {
+                        foundPooledConnection = true;
+                        result = connection;
+                        this.route = route;
+                        break;
+                    }
+                }
+            }
+
+            if (!foundPooledConnection) {
+                if (selectedRoute == null) {
+                    selectedRoute = routeSelection.next();
+                }
+
+                // Create a connection and assign it to this allocation immediately. This makes it possible
+                // for an asynchronous cancel() to interrupt the handshake we're about to do.
+                route = selectedRoute;
+                refusedStreamCount = 0;
+                result = new RealConnection(connectionPool, selectedRoute);
+                acquire(result, false);
+            }
+        }
 
-    Socket socket = null;
-    synchronized (connectionPool) {
-      reportedAcquired = true;
+        // If we found a pooled connection on the 2nd time around, we're done.
+        if (foundPooledConnection) {
+            eventListener.connectionAcquired(call, result);
+            return result;
+        }
 
-      // Pool the connection.
-      Internal.instance.put(connectionPool, result);
+        // Do TCP + TLS handshakes. This is a blocking operation.
+        result.connect(
+                connectTimeout, readTimeout, writeTimeout, connectionRetryEnabled, call, eventListener);
+        routeDatabase().connected(result.route());
+
+        Socket socket = null;
+        synchronized (connectionPool) {
+            reportedAcquired = true;
+
+            // Pool the connection.
+            // 将成功建立的连接放入连接池
+            Internal.instance.put(connectionPool, result);
+
+            // If another multiplexed connection to the same address was created concurrently, then
+            // release this connection and acquire that one.
+            if (result.isMultiplexed()) {
+                socket = Internal.instance.deduplicate(connectionPool, address, this);
+                result = connection;
+            }
+        }
+        closeQuietly(socket);
 
-      // If another multiplexed connection to the same address was created concurrently, then
-      // release this connection and acquire that one.
-      if (result.isMultiplexed()) {
-        socket = Internal.instance.deduplicate(connectionPool, address, this);
-        result = connection;
-      }
-    }
-    closeQuietly(socket);
-
-    eventListener.connectionAcquired(call, result);
-    return result;
-  }
-
-  /**
-   * Releases the currently held connection and returns a socket to close if the held connection
-   * restricts new streams from being created. With HTTP/2 multiple requests share the same
-   * connection so it's possible that our connection is restricted from creating new streams during
-   * a follow-up request.
-   */
-  private Socket releaseIfNoNewStreams() {
-    assert (Thread.holdsLock(connectionPool));
-    RealConnection allocatedConnection = this.connection;
-    if (allocatedConnection != null && allocatedConnection.noNewStreams) {
-      return deallocate(false, false, true);
-    }
-    return null;
-  }
-
-  public void streamFinished(boolean noNewStreams, HttpCodec codec, long bytesRead, IOException e) {
-    eventListener.responseBodyEnd(call, bytesRead);
-
-    Socket socket;
-    Connection releasedConnection;
-    boolean callEnd;
-    synchronized (connectionPool) {
-      if (codec == null || codec != this.codec) {
-        throw new IllegalStateException("expected " + this.codec + " but was " + codec);
-      }
-      if (!noNewStreams) {
-        connection.successCount++;
-      }
-      releasedConnection = connection;
-      socket = deallocate(noNewStreams, false, true);
-      if (connection != null) releasedConnection = null;
-      callEnd = this.released;
-    }
-    closeQuietly(socket);
-    if (releasedConnection != null) {
-      eventListener.connectionReleased(call, releasedConnection);
+        eventListener.connectionAcquired(call, result);
+        return result;
     }
 
-    if (e != null) {
-      eventListener.callFailed(call, e);
-    } else if (callEnd) {
-      eventListener.callEnd(call);
+    /**
+     * Releases the currently held connection and returns a socket to close if the held connection
+     * restricts new streams from being created. With HTTP/2 multiple requests share the same
+     * connection so it's possible that our connection is restricted from creating new streams during
+     * a follow-up request.
+     */
+    private Socket releaseIfNoNewStreams() {
+        assert (Thread.holdsLock(connectionPool));
+        RealConnection allocatedConnection = this.connection;
+        if (allocatedConnection != null && allocatedConnection.noNewStreams) {
+            return deallocate(false, false, true);
+        }
+        return null;
     }
-  }
 
-  public HttpCodec codec() {
-    synchronized (connectionPool) {
-      return codec;
-    }
-  }
-
-  private RouteDatabase routeDatabase() {
-    return Internal.instance.routeDatabase(connectionPool);
-  }
-
-  public synchronized RealConnection connection() {
-    return connection;
-  }
-
-  public void release() {
-    Socket socket;
-    Connection releasedConnection;
-    synchronized (connectionPool) {
-      releasedConnection = connection;
-      socket = deallocate(false, true, false);
-      if (connection != null) releasedConnection = null;
-    }
-    closeQuietly(socket);
-    if (releasedConnection != null) {
-      eventListener.connectionReleased(call, releasedConnection);
-    }
-  }
-
-  /** Forbid new streams from being created on the connection that hosts this allocation. */
-  public void noNewStreams() {
-    Socket socket;
-    Connection releasedConnection;
-    synchronized (connectionPool) {
-      releasedConnection = connection;
-      socket = deallocate(true, false, false);
-      if (connection != null) releasedConnection = null;
+    public void streamFinished(boolean noNewStreams, HttpCodec codec, long bytesRead, IOException e) {
+        eventListener.responseBodyEnd(call, bytesRead);
+
+        Socket socket;
+        Connection releasedConnection;
+        boolean callEnd;
+        synchronized (connectionPool) {
+            if (codec == null || codec != this.codec) {
+                throw new IllegalStateException("expected " + this.codec + " but was " + codec);
+            }
+            if (!noNewStreams) {
+                connection.successCount++;
+            }
+            releasedConnection = connection;
+            socket = deallocate(noNewStreams, false, true);
+            if (connection != null) releasedConnection = null;
+            callEnd = this.released;
+        }
+        closeQuietly(socket);
+        if (releasedConnection != null) {
+            eventListener.connectionReleased(call, releasedConnection);
+        }
+
+        if (e != null) {
+            eventListener.callFailed(call, e);
+        } else if (callEnd) {
+            eventListener.callEnd(call);
+        }
     }
-    closeQuietly(socket);
-    if (releasedConnection != null) {
-      eventListener.connectionReleased(call, releasedConnection);
+
+    public HttpCodec codec() {
+        synchronized (connectionPool) {
+            return codec;
+        }
     }
-  }
-
-  /**
-   * Releases resources held by this allocation. If sufficient resources are allocated, the
-   * connection will be detached or closed. Callers must be synchronized on the connection pool.
-   *
-   * <p>Returns a closeable that the caller should pass to {@link Util#closeQuietly} upon completion
-   * of the synchronized block. (We don't do I/O while synchronized on the connection pool.)
-   */
-  private Socket deallocate(boolean noNewStreams, boolean released, boolean streamFinished) {
-    assert (Thread.holdsLock(connectionPool));
-
-    if (streamFinished) {
-      this.codec = null;
+
+    private RouteDatabase routeDatabase() {
+        return Internal.instance.routeDatabase(connectionPool);
     }
-    if (released) {
-      this.released = true;
+
+    public synchronized RealConnection connection() {
+        return connection;
     }
-    Socket socket = null;
-    if (connection != null) {
-      if (noNewStreams) {
-        connection.noNewStreams = true;
-      }
-      if (this.codec == null && (this.released || connection.noNewStreams)) {
-        release(connection);
-        if (connection.allocations.isEmpty()) {
-          connection.idleAtNanos = System.nanoTime();
-          if (Internal.instance.connectionBecameIdle(connectionPool, connection)) {
-            socket = connection.socket();
-          }
+
+    public void release() {
+        Socket socket;
+        Connection releasedConnection;
+        synchronized (connectionPool) {
+            releasedConnection = connection;
+            socket = deallocate(false, true, false);
+            if (connection != null) releasedConnection = null;
+        }
+        closeQuietly(socket);
+        if (releasedConnection != null) {
+            eventListener.connectionReleased(call, releasedConnection);
         }
-        connection = null;
-      }
     }
-    return socket;
-  }
-
-  public void cancel() {
-    HttpCodec codecToCancel;
-    RealConnection connectionToCancel;
-    synchronized (connectionPool) {
-      canceled = true;
-      codecToCancel = codec;
-      connectionToCancel = connection;
+
+    /**
+     * Forbid new streams from being created on the connection that hosts this allocation.
+     */
+    public void noNewStreams() {
+        Socket socket;
+        Connection releasedConnection;
+        synchronized (connectionPool) {
+            releasedConnection = connection;
+            socket = deallocate(true, false, false);
+            if (connection != null) releasedConnection = null;
+        }
+        closeQuietly(socket);
+        if (releasedConnection != null) {
+            eventListener.connectionReleased(call, releasedConnection);
+        }
     }
-    if (codecToCancel != null) {
-      codecToCancel.cancel();
-    } else if (connectionToCancel != null) {
-      connectionToCancel.cancel();
+
+    /**
+     * Releases resources held by this allocation. If sufficient resources are allocated, the
+     * connection will be detached or closed. Callers must be synchronized on the connection pool.
+     * <p>
+     * <p>Returns a closeable that the caller should pass to {@link Util#closeQuietly} upon completion
+     * of the synchronized block. (We don't do I/O while synchronized on the connection pool.)
+     */
+    private Socket deallocate(boolean noNewStreams, boolean released, boolean streamFinished) {
+        assert (Thread.holdsLock(connectionPool));
+
+        if (streamFinished) {
+            this.codec = null;
+        }
+        if (released) {
+            this.released = true;
+        }
+        Socket socket = null;
+        if (connection != null) {
+            if (noNewStreams) {
+                connection.noNewStreams = true;
+            }
+            if (this.codec == null && (this.released || connection.noNewStreams)) {
+                //将当前流从connection的allocations弱引用列表中移除
+                release(connection);
+                // allocations弱引用列表为空，连接变为空闲状态
+                if (connection.allocations.isEmpty()) {
+                    connection.idleAtNanos = System.nanoTime();
+                    if (Internal.instance.connectionBecameIdle(connectionPool, connection)) {
+                        // 需要关闭的socket
+                        socket = connection.socket();
+                    }
+                }
+                connection = null;
+            }
+        }
+        return socket;
     }
-  }
-
-  public void streamFailed(IOException e) {
-    Socket socket;
-    Connection releasedConnection;
-    boolean noNewStreams = false;
-
-    synchronized (connectionPool) {
-      if (e instanceof StreamResetException) {
-        StreamResetException streamResetException = (StreamResetException) e;
-        if (streamResetException.errorCode == ErrorCode.REFUSED_STREAM) {
-          refusedStreamCount++;
+
+    public void cancel() {
+        HttpCodec codecToCancel;
+        RealConnection connectionToCancel;
+        synchronized (connectionPool) {
+            canceled = true;
+            codecToCancel = codec;
+            connectionToCancel = connection;
         }
-        // On HTTP/2 stream errors, retry REFUSED_STREAM errors once on the same connection. All
-        // other errors must be retried on a new connection.
-        if (streamResetException.errorCode != ErrorCode.REFUSED_STREAM || refusedStreamCount > 1) {
-          noNewStreams = true;
-          route = null;
+        if (codecToCancel != null) {
+            codecToCancel.cancel();
+        } else if (connectionToCancel != null) {
+            connectionToCancel.cancel();
         }
-      } else if (connection != null
-          && (!connection.isMultiplexed() || e instanceof ConnectionShutdownException)) {
-        noNewStreams = true;
-
-        // If this route hasn't completed a call, avoid it for new connections.
-        if (connection.successCount == 0) {
-          if (route != null && e != null) {
-            routeSelector.connectFailed(route, e);
-          }
-          route = null;
+    }
+
+    public void streamFailed(IOException e) {
+        Socket socket;
+        Connection releasedConnection;
+        boolean noNewStreams = false;
+
+        synchronized (connectionPool) {
+            if (e instanceof StreamResetException) {
+                StreamResetException streamResetException = (StreamResetException) e;
+                if (streamResetException.errorCode == ErrorCode.REFUSED_STREAM) {
+                    refusedStreamCount++;
+                }
+                // On HTTP/2 stream errors, retry REFUSED_STREAM errors once on the same connection. All
+                // other errors must be retried on a new connection.
+                if (streamResetException.errorCode != ErrorCode.REFUSED_STREAM || refusedStreamCount > 1) {
+                    noNewStreams = true;
+                    route = null;
+                }
+            } else if (connection != null
+                    && (!connection.isMultiplexed() || e instanceof ConnectionShutdownException)) {
+                noNewStreams = true;
+
+                // If this route hasn't completed a call, avoid it for new connections.
+                if (connection.successCount == 0) {
+                    if (route != null && e != null) {
+                        routeSelector.connectFailed(route, e);
+                    }
+                    route = null;
+                }
+            }
+            releasedConnection = connection;
+            socket = deallocate(noNewStreams, false, true);
+            if (connection != null || !reportedAcquired) releasedConnection = null;
+        }
+
+        closeQuietly(socket);
+        if (releasedConnection != null) {
+            eventListener.connectionReleased(call, releasedConnection);
         }
-      }
-      releasedConnection = connection;
-      socket = deallocate(noNewStreams, false, true);
-      if (connection != null || !reportedAcquired) releasedConnection = null;
     }
 
-    closeQuietly(socket);
-    if (releasedConnection != null) {
-      eventListener.connectionReleased(call, releasedConnection);
+    /**
+     * Use this allocation to hold {@code connection}. Each call to this must be paired with a call to
+     * {@link #release} on the same connection.
+     */
+    public void acquire(RealConnection connection, boolean reportedAcquired) {
+        assert (Thread.holdsLock(connectionPool));
+        if (this.connection != null) throw new IllegalStateException();
+
+        this.connection = connection;
+        this.reportedAcquired = reportedAcquired;
+        connection.allocations.add(new StreamAllocationReference(this, callStackTrace));
     }
-  }
-
-  /**
-   * Use this allocation to hold {@code connection}. Each call to this must be paired with a call to
-   * {@link #release} on the same connection.
-   */
-  public void acquire(RealConnection connection, boolean reportedAcquired) {
-    assert (Thread.holdsLock(connectionPool));
-    if (this.connection != null) throw new IllegalStateException();
-
-    this.connection = connection;
-    this.reportedAcquired = reportedAcquired;
-    connection.allocations.add(new StreamAllocationReference(this, callStackTrace));
-  }
-
-  /** Remove this allocation from the connection's list of allocations. */
-  private void release(RealConnection connection) {
-    for (int i = 0, size = connection.allocations.size(); i < size; i++) {
-      Reference<StreamAllocation> reference = connection.allocations.get(i);
-      if (reference.get() == this) {
-        connection.allocations.remove(i);
-        return;
-      }
+
+    /**
+     * Remove this allocation from the connection's list of allocations.
+     */
+    private void release(RealConnection connection) {
+        for (int i = 0, size = connection.allocations.size(); i < size; i++) {
+            Reference<StreamAllocation> reference = connection.allocations.get(i);
+            if (reference.get() == this) {
+                connection.allocations.remove(i);
+                return;
+            }
+        }
+        throw new IllegalStateException();
     }
-    throw new IllegalStateException();
-  }
-
-  /**
-   * Release the connection held by this connection and acquire {@code newConnection} instead. It is
-   * only safe to call this if the held connection is newly connected but duplicated by {@code
-   * newConnection}. Typically this occurs when concurrently connecting to an HTTP/2 webserver.
-   *
-   * <p>Returns a closeable that the caller should pass to {@link Util#closeQuietly} upon completion
-   * of the synchronized block. (We don't do I/O while synchronized on the connection pool.)
-   */
-  public Socket releaseAndAcquire(RealConnection newConnection) {
-    assert (Thread.holdsLock(connectionPool));
-    if (codec != null || connection.allocations.size() != 1) throw new IllegalStateException();
-
-    // Release the old connection.
-    Reference<StreamAllocation> onlyAllocation = connection.allocations.get(0);
-    Socket socket = deallocate(true, false, false);
-
-    // Acquire the new connection.
-    this.connection = newConnection;
-    newConnection.allocations.add(onlyAllocation);
-
-    return socket;
-  }
-
-  public boolean hasMoreRoutes() {
-    return route != null
-        || (routeSelection != null && routeSelection.hasNext())
-        || routeSelector.hasNext();
-  }
-
-  @Override public String toString() {
-    RealConnection connection = connection();
-    return connection != null ? connection.toString() : address.toString();
-  }
-
-  public static final class StreamAllocationReference extends WeakReference<StreamAllocation> {
+
     /**
-     * Captures the stack trace at the time the Call is executed or enqueued. This is helpful for
-     * identifying the origin of connection leaks.
+     * Release the connection held by this connection and acquire {@code newConnection} instead. It is
+     * only safe to call this if the held connection is newly connected but duplicated by {@code
+     * newConnection}. Typically this occurs when concurrently connecting to an HTTP/2 webserver.
+     * <p>
+     * <p>Returns a closeable that the caller should pass to {@link Util#closeQuietly} upon completion
+     * of the synchronized block. (We don't do I/O while synchronized on the connection pool.)
      */
-    public final Object callStackTrace;
+    public Socket releaseAndAcquire(RealConnection newConnection) {
+        assert (Thread.holdsLock(connectionPool));
+        if (codec != null || connection.allocations.size() != 1) throw new IllegalStateException();
 
-    StreamAllocationReference(StreamAllocation referent, Object callStackTrace) {
-      super(referent);
-      this.callStackTrace = callStackTrace;
+        // Release the old connection.
+        Reference<StreamAllocation> onlyAllocation = connection.allocations.get(0);
+        Socket socket = deallocate(true, false, false);
+
+        // Acquire the new connection.
+        this.connection = newConnection;
+        newConnection.allocations.add(onlyAllocation);
+
+        return socket;
+    }
+
+    public boolean hasMoreRoutes() {
+        return route != null
+                || (routeSelection != null && routeSelection.hasNext())
+                || routeSelector.hasNext();
+    }
+
+    @Override
+    public String toString() {
+        RealConnection connection = connection();
+        return connection != null ? connection.toString() : address.toString();
+    }
+
+    public static final class StreamAllocationReference extends WeakReference<StreamAllocation> {
+        /**
+         * Captures the stack trace at the time the Call is executed or enqueued. This is helpful for
+         * identifying the origin of connection leaks.
+         */
+        public final Object callStackTrace;
+
+        StreamAllocationReference(StreamAllocation referent, Object callStackTrace) {
+            super(referent);
+            this.callStackTrace = callStackTrace;
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/http/CallServerInterceptor.java b/okhttp/src/main/java/okhttp3/internal/http/CallServerInterceptor.java
index b7aba87d6a..57f101eab6 100644
--- a/okhttp/src/main/java/okhttp3/internal/http/CallServerInterceptor.java
+++ b/okhttp/src/main/java/okhttp3/internal/http/CallServerInterceptor.java
@@ -17,6 +17,7 @@
 
 import java.io.IOException;
 import java.net.ProtocolException;
+
 import okhttp3.Interceptor;
 import okhttp3.Request;
 import okhttp3.Response;
@@ -29,110 +30,114 @@
 import okio.Okio;
 import okio.Sink;
 
-/** This is the last interceptor in the chain. It makes a network call to the server. */
+/**
+ * This is the last interceptor in the chain. It makes a network call to the server.
+ */
 public final class CallServerInterceptor implements Interceptor {
-  private final boolean forWebSocket;
-
-  public CallServerInterceptor(boolean forWebSocket) {
-    this.forWebSocket = forWebSocket;
-  }
-
-  @Override public Response intercept(Chain chain) throws IOException {
-    RealInterceptorChain realChain = (RealInterceptorChain) chain;
-    HttpCodec httpCodec = realChain.httpStream();
-    StreamAllocation streamAllocation = realChain.streamAllocation();
-    RealConnection connection = (RealConnection) realChain.connection();
-    Request request = realChain.request();
-
-    long sentRequestMillis = System.currentTimeMillis();
-
-    realChain.eventListener().requestHeadersStart(realChain.call());
-    httpCodec.writeRequestHeaders(request);
-    realChain.eventListener().requestHeadersEnd(realChain.call(), request);
-
-    Response.Builder responseBuilder = null;
-    if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {
-      // If there's a "Expect: 100-continue" header on the request, wait for a "HTTP/1.1 100
-      // Continue" response before transmitting the request body. If we don't get that, return
-      // what we did get (such as a 4xx response) without ever transmitting the request body.
-      if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
-        httpCodec.flushRequest();
-        realChain.eventListener().responseHeadersStart(realChain.call());
-        responseBuilder = httpCodec.readResponseHeaders(true);
-      }
-
-      if (responseBuilder == null) {
-        // Write the request body if the "Expect: 100-continue" expectation was met.
-        realChain.eventListener().requestBodyStart(realChain.call());
-        long contentLength = request.body().contentLength();
-        CountingSink requestBodyOut =
-            new CountingSink(httpCodec.createRequestBody(request, contentLength));
-        BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
-
-        request.body().writeTo(bufferedRequestBody);
-        bufferedRequestBody.close();
-        realChain.eventListener()
-            .requestBodyEnd(realChain.call(), requestBodyOut.successfulCount);
-      } else if (!connection.isMultiplexed()) {
-        // If the "Expect: 100-continue" expectation wasn't met, prevent the HTTP/1 connection
-        // from being reused. Otherwise we're still obligated to transmit the request body to
-        // leave the connection in a consistent state.
-        streamAllocation.noNewStreams();
-      }
-    }
-
-    httpCodec.finishRequest();
+    private final boolean forWebSocket;
 
-    if (responseBuilder == null) {
-      realChain.eventListener().responseHeadersStart(realChain.call());
-      responseBuilder = httpCodec.readResponseHeaders(false);
+    public CallServerInterceptor(boolean forWebSocket) {
+        this.forWebSocket = forWebSocket;
     }
 
-    Response response = responseBuilder
-        .request(request)
-        .handshake(streamAllocation.connection().handshake())
-        .sentRequestAtMillis(sentRequestMillis)
-        .receivedResponseAtMillis(System.currentTimeMillis())
-        .build();
-
-    realChain.eventListener()
-        .responseHeadersEnd(realChain.call(), response);
-
-    int code = response.code();
-    if (forWebSocket && code == 101) {
-      // Connection is upgrading, but we need to ensure interceptors see a non-null response body.
-      response = response.newBuilder()
-          .body(Util.EMPTY_RESPONSE)
-          .build();
-    } else {
-      response = response.newBuilder()
-          .body(httpCodec.openResponseBody(response))
-          .build();
-    }
+    @Override
+    public Response intercept(Chain chain) throws IOException {
+        RealInterceptorChain realChain = (RealInterceptorChain) chain;
+        HttpCodec httpCodec = realChain.httpStream();
+        StreamAllocation streamAllocation = realChain.streamAllocation();
+        RealConnection connection = (RealConnection) realChain.connection();
+        Request request = realChain.request();
+
+        long sentRequestMillis = System.currentTimeMillis();
+
+        realChain.eventListener().requestHeadersStart(realChain.call());
+        httpCodec.writeRequestHeaders(request);
+        realChain.eventListener().requestHeadersEnd(realChain.call(), request);
+
+        Response.Builder responseBuilder = null;
+        if (HttpMethod.permitsRequestBody(request.method()) && request.body() != null) {
+            // If there's a "Expect: 100-continue" header on the request, wait for a "HTTP/1.1 100
+            // Continue" response before transmitting the request body. If we don't get that, return
+            // what we did get (such as a 4xx response) without ever transmitting the request body.
+            if ("100-continue".equalsIgnoreCase(request.header("Expect"))) {
+                httpCodec.flushRequest();
+                realChain.eventListener().responseHeadersStart(realChain.call());
+                responseBuilder = httpCodec.readResponseHeaders(true);
+            }
+
+            if (responseBuilder == null) {
+                // Write the request body if the "Expect: 100-continue" expectation was met.
+                realChain.eventListener().requestBodyStart(realChain.call());
+                long contentLength = request.body().contentLength();
+                CountingSink requestBodyOut =
+                        new CountingSink(httpCodec.createRequestBody(request, contentLength));
+                BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut);
+
+                request.body().writeTo(bufferedRequestBody);
+                bufferedRequestBody.close();
+                realChain.eventListener()
+                        .requestBodyEnd(realChain.call(), requestBodyOut.successfulCount);
+            } else if (!connection.isMultiplexed()) {
+                // If the "Expect: 100-continue" expectation wasn't met, prevent the HTTP/1 connection
+                // from being reused. Otherwise we're still obligated to transmit the request body to
+                // leave the connection in a consistent state.
+                streamAllocation.noNewStreams();
+            }
+        }
+
+        httpCodec.finishRequest();
+
+        if (responseBuilder == null) {
+            realChain.eventListener().responseHeadersStart(realChain.call());
+            responseBuilder = httpCodec.readResponseHeaders(false);
+        }
+
+        Response response = responseBuilder
+                .request(request)
+                .handshake(streamAllocation.connection().handshake())
+                .sentRequestAtMillis(sentRequestMillis)
+                .receivedResponseAtMillis(System.currentTimeMillis())
+                .build();
 
-    if ("close".equalsIgnoreCase(response.request().header("Connection"))
-        || "close".equalsIgnoreCase(response.header("Connection"))) {
-      streamAllocation.noNewStreams();
-    }
-
-    if ((code == 204 || code == 205) && response.body().contentLength() > 0) {
-      throw new ProtocolException(
-          "HTTP " + code + " had non-zero Content-Length: " + response.body().contentLength());
+        realChain.eventListener()
+                .responseHeadersEnd(realChain.call(), response);
+
+        int code = response.code();
+        if (forWebSocket && code == 101) {
+            // Connection is upgrading, but we need to ensure interceptors see a non-null response body.
+            response = response.newBuilder()
+                    .body(Util.EMPTY_RESPONSE)
+                    .build();
+        } else {
+            response = response.newBuilder()
+                    .body(httpCodec.openResponseBody(response))
+                    .build();
+        }
+
+        if ("close".equalsIgnoreCase(response.request().header("Connection"))
+                || "close".equalsIgnoreCase(response.header("Connection"))) {
+            streamAllocation.noNewStreams();
+        }
+
+        if ((code == 204 || code == 205) && response.body().contentLength() > 0) {
+            throw new ProtocolException(
+                    "HTTP " + code + " had non-zero Content-Length: " + response.body().contentLength());
+        }
+
+        return response;
     }
 
-    return response;
-  }
+    static final class CountingSink extends ForwardingSink {
+        long successfulCount;
 
-  static final class CountingSink extends ForwardingSink {
-    long successfulCount;
-
-    CountingSink(Sink delegate) {
-      super(delegate);
-    }
+        CountingSink(Sink delegate) {
+            super(delegate);
+        }
 
-    @Override public void write(Buffer source, long byteCount) throws IOException {
-      super.write(source, byteCount);
-      successfulCount += byteCount;
+        @Override
+        public void write(Buffer source, long byteCount) throws IOException {
+            super.write(source, byteCount);
+            successfulCount += byteCount;
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/http/HttpCodec.java b/okhttp/src/main/java/okhttp3/internal/http/HttpCodec.java
index ad9759acce..b9a13daafd 100644
--- a/okhttp/src/main/java/okhttp3/internal/http/HttpCodec.java
+++ b/okhttp/src/main/java/okhttp3/internal/http/HttpCodec.java
@@ -16,46 +16,59 @@
 package okhttp3.internal.http;
 
 import java.io.IOException;
+
 import okhttp3.Request;
 import okhttp3.Response;
 import okhttp3.ResponseBody;
 import okio.Sink;
 
-/** Encodes HTTP requests and decodes HTTP responses. */
+/**
+ * Encodes HTTP requests and decodes HTTP responses.
+ */
 public interface HttpCodec {
-  /**
-   * The timeout to use while discarding a stream of input data. Since this is used for connection
-   * reuse, this timeout should be significantly less than the time it takes to establish a new
-   * connection.
-   */
-  int DISCARD_STREAM_TIMEOUT_MILLIS = 100;
-
-  /** Returns an output stream where the request body can be streamed. */
-  Sink createRequestBody(Request request, long contentLength);
-
-  /** This should update the HTTP engine's sentRequestMillis field. */
-  void writeRequestHeaders(Request request) throws IOException;
-
-  /** Flush the request to the underlying socket. */
-  void flushRequest() throws IOException;
-
-  /** Flush the request to the underlying socket and signal no more bytes will be transmitted. */
-  void finishRequest() throws IOException;
-
-  /**
-   * Parses bytes of a response header from an HTTP transport.
-   *
-   * @param expectContinue true to return null if this is an intermediate response with a "100"
-   *     response code. Otherwise this method never returns null.
-   */
-  Response.Builder readResponseHeaders(boolean expectContinue) throws IOException;
-
-  /** Returns a stream that reads the response body. */
-  ResponseBody openResponseBody(Response response) throws IOException;
-
-  /**
-   * Cancel this stream. Resources held by this stream will be cleaned up, though not synchronously.
-   * That may happen later by the connection pool thread.
-   */
-  void cancel();
+    /**
+     * The timeout to use while discarding a stream of input data. Since this is used for connection
+     * reuse, this timeout should be significantly less than the time it takes to establish a new
+     * connection.
+     */
+    int DISCARD_STREAM_TIMEOUT_MILLIS = 100;
+
+    /**
+     * Returns an output stream where the request body can be streamed.
+     */
+    Sink createRequestBody(Request request, long contentLength);
+
+    /**
+     * This should update the HTTP engine's sentRequestMillis field.
+     */
+    void writeRequestHeaders(Request request) throws IOException;
+
+    /**
+     * Flush the request to the underlying socket.
+     */
+    void flushRequest() throws IOException;
+
+    /**
+     * Flush the request to the underlying socket and signal no more bytes will be transmitted.
+     */
+    void finishRequest() throws IOException;
+
+    /**
+     * Parses bytes of a response header from an HTTP transport.
+     *
+     * @param expectContinue true to return null if this is an intermediate response with a "100"
+     *                       response code. Otherwise this method never returns null.
+     */
+    Response.Builder readResponseHeaders(boolean expectContinue) throws IOException;
+
+    /**
+     * Returns a stream that reads the response body.
+     */
+    ResponseBody openResponseBody(Response response) throws IOException;
+
+    /**
+     * Cancel this stream. Resources held by this stream will be cleaned up, though not synchronously.
+     * That may happen later by the connection pool thread.
+     */
+    void cancel();
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/http/RealInterceptorChain.java b/okhttp/src/main/java/okhttp3/internal/http/RealInterceptorChain.java
index 52f9880892..5dc996ec24 100644
--- a/okhttp/src/main/java/okhttp3/internal/http/RealInterceptorChain.java
+++ b/okhttp/src/main/java/okhttp3/internal/http/RealInterceptorChain.java
@@ -18,6 +18,7 @@
 import java.io.IOException;
 import java.util.List;
 import java.util.concurrent.TimeUnit;
+
 import okhttp3.Call;
 import okhttp3.Connection;
 import okhttp3.EventListener;
@@ -34,134 +35,159 @@
  * interceptors, the OkHttp core, all network interceptors, and finally the network caller.
  */
 public final class RealInterceptorChain implements Interceptor.Chain {
-  private final List<Interceptor> interceptors;
-  private final StreamAllocation streamAllocation;
-  private final HttpCodec httpCodec;
-  private final RealConnection connection;
-  private final int index;
-  private final Request request;
-  private final Call call;
-  private final EventListener eventListener;
-  private final int connectTimeout;
-  private final int readTimeout;
-  private final int writeTimeout;
-  private int calls;
-
-  public RealInterceptorChain(List<Interceptor> interceptors, StreamAllocation streamAllocation,
-      HttpCodec httpCodec, RealConnection connection, int index, Request request, Call call,
-      EventListener eventListener, int connectTimeout, int readTimeout, int writeTimeout) {
-    this.interceptors = interceptors;
-    this.connection = connection;
-    this.streamAllocation = streamAllocation;
-    this.httpCodec = httpCodec;
-    this.index = index;
-    this.request = request;
-    this.call = call;
-    this.eventListener = eventListener;
-    this.connectTimeout = connectTimeout;
-    this.readTimeout = readTimeout;
-    this.writeTimeout = writeTimeout;
-  }
-
-  @Override public Connection connection() {
-    return connection;
-  }
-
-  @Override public int connectTimeoutMillis() {
-    return connectTimeout;
-  }
-
-  @Override public Interceptor.Chain withConnectTimeout(int timeout, TimeUnit unit) {
-    int millis = checkDuration("timeout", timeout, unit);
-    return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
-        request, call, eventListener, millis, readTimeout, writeTimeout);
-  }
-
-  @Override public int readTimeoutMillis() {
-    return readTimeout;
-  }
-
-  @Override public Interceptor.Chain withReadTimeout(int timeout, TimeUnit unit) {
-    int millis = checkDuration("timeout", timeout, unit);
-    return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
-        request, call, eventListener, connectTimeout, millis, writeTimeout);
-  }
-
-  @Override public int writeTimeoutMillis() {
-    return writeTimeout;
-  }
-
-  @Override public Interceptor.Chain withWriteTimeout(int timeout, TimeUnit unit) {
-    int millis = checkDuration("timeout", timeout, unit);
-    return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
-        request, call, eventListener, connectTimeout, readTimeout, millis);
-  }
-
-  public StreamAllocation streamAllocation() {
-    return streamAllocation;
-  }
-
-  public HttpCodec httpStream() {
-    return httpCodec;
-  }
-
-  @Override public Call call() {
-    return call;
-  }
-
-  public EventListener eventListener() {
-    return eventListener;
-  }
-
-  @Override public Request request() {
-    return request;
-  }
-
-  @Override public Response proceed(Request request) throws IOException {
-    return proceed(request, streamAllocation, httpCodec, connection);
-  }
-
-  public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec,
-      RealConnection connection) throws IOException {
-    if (index >= interceptors.size()) throw new AssertionError();
-
-    calls++;
-
-    // If we already have a stream, confirm that the incoming request will use it.
-    if (this.httpCodec != null && !this.connection.supportsUrl(request.url())) {
-      throw new IllegalStateException("network interceptor " + interceptors.get(index - 1)
-          + " must retain the same host and port");
+    private final List<Interceptor> interceptors;
+    private final StreamAllocation streamAllocation;
+    private final HttpCodec httpCodec;
+    private final RealConnection connection;
+    private final int index;
+    private final Request request;
+    private final Call call;
+    private final EventListener eventListener;
+    private final int connectTimeout;
+    private final int readTimeout;
+    private final int writeTimeout;
+    private int calls;
+
+    public RealInterceptorChain(List<Interceptor> interceptors, StreamAllocation streamAllocation,
+                                HttpCodec httpCodec, RealConnection connection, int index, Request request, Call call,
+                                EventListener eventListener, int connectTimeout, int readTimeout, int writeTimeout) {
+        this.interceptors = interceptors;
+        this.connection = connection;
+        this.streamAllocation = streamAllocation;
+        this.httpCodec = httpCodec;
+        this.index = index;
+        this.request = request;
+        this.call = call;
+        this.eventListener = eventListener;
+        this.connectTimeout = connectTimeout;
+        this.readTimeout = readTimeout;
+        this.writeTimeout = writeTimeout;
+    }
+
+    @Override
+    public Connection connection() {
+        return connection;
+    }
+
+    @Override
+    public int connectTimeoutMillis() {
+        return connectTimeout;
+    }
+
+    @Override
+    public Interceptor.Chain withConnectTimeout(int timeout, TimeUnit unit) {
+        int millis = checkDuration("timeout", timeout, unit);
+        return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
+                request, call, eventListener, millis, readTimeout, writeTimeout);
+    }
+
+    @Override
+    public int readTimeoutMillis() {
+        return readTimeout;
+    }
+
+    @Override
+    public Interceptor.Chain withReadTimeout(int timeout, TimeUnit unit) {
+        int millis = checkDuration("timeout", timeout, unit);
+        return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
+                request, call, eventListener, connectTimeout, millis, writeTimeout);
+    }
+
+    @Override
+    public int writeTimeoutMillis() {
+        return writeTimeout;
+    }
+
+    @Override
+    public Interceptor.Chain withWriteTimeout(int timeout, TimeUnit unit) {
+        int millis = checkDuration("timeout", timeout, unit);
+        return new RealInterceptorChain(interceptors, streamAllocation, httpCodec, connection, index,
+                request, call, eventListener, connectTimeout, readTimeout, millis);
     }
 
-    // If we already have a stream, confirm that this is the only call to chain.proceed().
-    if (this.httpCodec != null && calls > 1) {
-      throw new IllegalStateException("network interceptor " + interceptors.get(index - 1)
-          + " must call proceed() exactly once");
+    public StreamAllocation streamAllocation() {
+        return streamAllocation;
     }
 
-    // Call the next interceptor in the chain.
-    RealInterceptorChain next = new RealInterceptorChain(interceptors, streamAllocation, httpCodec,
-        connection, index + 1, request, call, eventListener, connectTimeout, readTimeout,
-        writeTimeout);
-    Interceptor interceptor = interceptors.get(index);
-    Response response = interceptor.intercept(next);
-
-    // Confirm that the next interceptor made its required call to chain.proceed().
-    if (httpCodec != null && index + 1 < interceptors.size() && next.calls != 1) {
-      throw new IllegalStateException("network interceptor " + interceptor
-          + " must call proceed() exactly once");
+    public HttpCodec httpStream() {
+        return httpCodec;
     }
 
-    // Confirm that the intercepted response isn't null.
-    if (response == null) {
-      throw new NullPointerException("interceptor " + interceptor + " returned null");
+    @Override
+    public Call call() {
+        return call;
     }
 
-    if (response.body() == null) {
-      throw new IllegalStateException(
-          "interceptor " + interceptor + " returned a response with no body");
+    public EventListener eventListener() {
+        return eventListener;
     }
 
-    return response;
-  }
+    @Override
+    public Request request() {
+        return request;
+    }
+
+    @Override
+    public Response proceed(Request request) throws IOException {
+        return proceed(request, streamAllocation, httpCodec, connection);
+    }
+
+    /**
+     * 其实是个递归方法
+     *
+     * @param request
+     * @param streamAllocation
+     * @param httpCodec
+     * @param connection
+     * @return
+     * @throws IOException
+     */
+    public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec,
+                            RealConnection connection) throws IOException {
+        if (index >= interceptors.size()) throw new AssertionError();
+
+        calls++;
+
+        // If we already have a stream, confirm that the incoming request will use it.
+        if (this.httpCodec != null && !this.connection.supportsUrl(request.url())) {
+            throw new IllegalStateException("network interceptor " + interceptors.get(index - 1)
+                    + " must retain the same host and port");
+        }
+
+        // If we already have a stream, confirm that this is the only call to chain.proceed().
+        if (this.httpCodec != null && calls > 1) {
+            throw new IllegalStateException("network interceptor " + interceptors.get(index - 1)
+                    + " must call proceed() exactly once");
+        }
+
+        // Call the next interceptor in the chain.
+        // 创建下一个(index+1)拦截器的RealInterceptorChain
+        RealInterceptorChain next = new RealInterceptorChain(interceptors, streamAllocation, httpCodec,
+                connection, index + 1, request, call, eventListener, connectTimeout, readTimeout,
+                writeTimeout);
+        // 获取当前(index)的拦截器
+        Interceptor interceptor = interceptors.get(index);
+        // 执行当前拦截器的intercept方法，传入下一个(index+1)拦截器的RealInterceptorChain
+        // 除了CallServerInterceptor（链上的最后一个拦截器）
+        // 其他拦截器的intercept方法都会调用next的proceed方法
+        Response response = interceptor.intercept(next);
+
+        // Confirm that the next interceptor made its required call to chain.proceed().
+        if (httpCodec != null && index + 1 < interceptors.size() && next.calls != 1) {
+            throw new IllegalStateException("network interceptor " + interceptor
+                    + " must call proceed() exactly once");
+        }
+
+        // Confirm that the intercepted response isn't null.
+        if (response == null) {
+            throw new NullPointerException("interceptor " + interceptor + " returned null");
+        }
+
+        if (response.body() == null) {
+            throw new IllegalStateException(
+                    "interceptor " + interceptor + " returned a response with no body");
+        }
+
+        return response;
+    }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/http2/Http2Codec.java b/okhttp/src/main/java/okhttp3/internal/http2/Http2Codec.java
index 5268aa2c91..485ce0d9f5 100644
--- a/okhttp/src/main/java/okhttp3/internal/http2/Http2Codec.java
+++ b/okhttp/src/main/java/okhttp3/internal/http2/Http2Codec.java
@@ -21,6 +21,7 @@
 import java.util.List;
 import java.util.Locale;
 import java.util.concurrent.TimeUnit;
+
 import okhttp3.Headers;
 import okhttp3.Interceptor;
 import okhttp3.OkHttpClient;
@@ -50,183 +51,198 @@
 import static okhttp3.internal.http2.Header.TARGET_PATH;
 import static okhttp3.internal.http2.Header.TARGET_SCHEME;
 
-/** Encode requests and responses using HTTP/2 frames. */
+/**
+ * Encode requests and responses using HTTP/2 frames.
+ */
 public final class Http2Codec implements HttpCodec {
-  private static final ByteString CONNECTION = ByteString.encodeUtf8("connection");
-  private static final ByteString HOST = ByteString.encodeUtf8("host");
-  private static final ByteString KEEP_ALIVE = ByteString.encodeUtf8("keep-alive");
-  private static final ByteString PROXY_CONNECTION = ByteString.encodeUtf8("proxy-connection");
-  private static final ByteString TRANSFER_ENCODING = ByteString.encodeUtf8("transfer-encoding");
-  private static final ByteString TE = ByteString.encodeUtf8("te");
-  private static final ByteString ENCODING = ByteString.encodeUtf8("encoding");
-  private static final ByteString UPGRADE = ByteString.encodeUtf8("upgrade");
-
-  /** See http://tools.ietf.org/html/draft-ietf-httpbis-http2-09#section-8.1.3. */
-  private static final List<ByteString> HTTP_2_SKIPPED_REQUEST_HEADERS = Util.immutableList(
-      CONNECTION,
-      HOST,
-      KEEP_ALIVE,
-      PROXY_CONNECTION,
-      TE,
-      TRANSFER_ENCODING,
-      ENCODING,
-      UPGRADE,
-      TARGET_METHOD,
-      TARGET_PATH,
-      TARGET_SCHEME,
-      TARGET_AUTHORITY);
-  private static final List<ByteString> HTTP_2_SKIPPED_RESPONSE_HEADERS = Util.immutableList(
-      CONNECTION,
-      HOST,
-      KEEP_ALIVE,
-      PROXY_CONNECTION,
-      TE,
-      TRANSFER_ENCODING,
-      ENCODING,
-      UPGRADE);
-
-  private final OkHttpClient client;
-  private final Interceptor.Chain chain;
-  final StreamAllocation streamAllocation;
-  private final Http2Connection connection;
-  private Http2Stream stream;
-
-  public Http2Codec(OkHttpClient client, Interceptor.Chain chain, StreamAllocation streamAllocation,
-      Http2Connection connection) {
-    this.client = client;
-    this.chain = chain;
-    this.streamAllocation = streamAllocation;
-    this.connection = connection;
-  }
-
-  @Override public Sink createRequestBody(Request request, long contentLength) {
-    return stream.getSink();
-  }
-
-  @Override public void writeRequestHeaders(Request request) throws IOException {
-    if (stream != null) return;
-
-    boolean hasRequestBody = request.body() != null;
-    List<Header> requestHeaders = http2HeadersList(request);
-    stream = connection.newStream(requestHeaders, hasRequestBody);
-    stream.readTimeout().timeout(chain.readTimeoutMillis(), TimeUnit.MILLISECONDS);
-    stream.writeTimeout().timeout(chain.writeTimeoutMillis(), TimeUnit.MILLISECONDS);
-  }
-
-  @Override public void flushRequest() throws IOException {
-    connection.flush();
-  }
-
-  @Override public void finishRequest() throws IOException {
-    stream.getSink().close();
-  }
-
-  @Override public Response.Builder readResponseHeaders(boolean expectContinue) throws IOException {
-    List<Header> headers = stream.takeResponseHeaders();
-    Response.Builder responseBuilder = readHttp2HeadersList(headers);
-    if (expectContinue && Internal.instance.code(responseBuilder) == HTTP_CONTINUE) {
-      return null;
+    private static final ByteString CONNECTION = ByteString.encodeUtf8("connection");
+    private static final ByteString HOST = ByteString.encodeUtf8("host");
+    private static final ByteString KEEP_ALIVE = ByteString.encodeUtf8("keep-alive");
+    private static final ByteString PROXY_CONNECTION = ByteString.encodeUtf8("proxy-connection");
+    private static final ByteString TRANSFER_ENCODING = ByteString.encodeUtf8("transfer-encoding");
+    private static final ByteString TE = ByteString.encodeUtf8("te");
+    private static final ByteString ENCODING = ByteString.encodeUtf8("encoding");
+    private static final ByteString UPGRADE = ByteString.encodeUtf8("upgrade");
+
+    /**
+     * See http://tools.ietf.org/html/draft-ietf-httpbis-http2-09#section-8.1.3.
+     */
+    private static final List<ByteString> HTTP_2_SKIPPED_REQUEST_HEADERS = Util.immutableList(
+            CONNECTION,
+            HOST,
+            KEEP_ALIVE,
+            PROXY_CONNECTION,
+            TE,
+            TRANSFER_ENCODING,
+            ENCODING,
+            UPGRADE,
+            TARGET_METHOD,
+            TARGET_PATH,
+            TARGET_SCHEME,
+            TARGET_AUTHORITY);
+    private static final List<ByteString> HTTP_2_SKIPPED_RESPONSE_HEADERS = Util.immutableList(
+            CONNECTION,
+            HOST,
+            KEEP_ALIVE,
+            PROXY_CONNECTION,
+            TE,
+            TRANSFER_ENCODING,
+            ENCODING,
+            UPGRADE);
+
+    private final OkHttpClient client;
+    private final Interceptor.Chain chain;
+    final StreamAllocation streamAllocation;
+    private final Http2Connection connection;
+    private Http2Stream stream;
+
+    public Http2Codec(OkHttpClient client, Interceptor.Chain chain, StreamAllocation streamAllocation,
+                      Http2Connection connection) {
+        this.client = client;
+        this.chain = chain;
+        this.streamAllocation = streamAllocation;
+        this.connection = connection;
+    }
+
+    @Override
+    public Sink createRequestBody(Request request, long contentLength) {
+        return stream.getSink();
+    }
+
+    @Override
+    public void writeRequestHeaders(Request request) throws IOException {
+        if (stream != null) return;
+
+        boolean hasRequestBody = request.body() != null;
+        List<Header> requestHeaders = http2HeadersList(request);
+        stream = connection.newStream(requestHeaders, hasRequestBody);
+        stream.readTimeout().timeout(chain.readTimeoutMillis(), TimeUnit.MILLISECONDS);
+        stream.writeTimeout().timeout(chain.writeTimeoutMillis(), TimeUnit.MILLISECONDS);
     }
-    return responseBuilder;
-  }
-
-  public static List<Header> http2HeadersList(Request request) {
-    Headers headers = request.headers();
-    List<Header> result = new ArrayList<>(headers.size() + 4);
-    result.add(new Header(TARGET_METHOD, request.method()));
-    result.add(new Header(TARGET_PATH, RequestLine.requestPath(request.url())));
-    String host = request.header("Host");
-    if (host != null) {
-      result.add(new Header(TARGET_AUTHORITY, host)); // Optional.
+
+    @Override
+    public void flushRequest() throws IOException {
+        connection.flush();
     }
-    result.add(new Header(TARGET_SCHEME, request.url().scheme()));
-
-    for (int i = 0, size = headers.size(); i < size; i++) {
-      // header names must be lowercase.
-      ByteString name = ByteString.encodeUtf8(headers.name(i).toLowerCase(Locale.US));
-      if (!HTTP_2_SKIPPED_REQUEST_HEADERS.contains(name)) {
-        result.add(new Header(name, headers.value(i)));
-      }
+
+    @Override
+    public void finishRequest() throws IOException {
+        stream.getSink().close();
     }
-    return result;
-  }
-
-  /** Returns headers for a name value block containing an HTTP/2 response. */
-  public static Response.Builder readHttp2HeadersList(List<Header> headerBlock) throws IOException {
-    StatusLine statusLine = null;
-    Headers.Builder headersBuilder = new Headers.Builder();
-    for (int i = 0, size = headerBlock.size(); i < size; i++) {
-      Header header = headerBlock.get(i);
-
-      // If there were multiple header blocks they will be delimited by nulls. Discard existing
-      // header blocks if the existing header block is a '100 Continue' intermediate response.
-      if (header == null) {
-        if (statusLine != null && statusLine.code == HTTP_CONTINUE) {
-          statusLine = null;
-          headersBuilder = new Headers.Builder();
+
+    @Override
+    public Response.Builder readResponseHeaders(boolean expectContinue) throws IOException {
+        List<Header> headers = stream.takeResponseHeaders();
+        Response.Builder responseBuilder = readHttp2HeadersList(headers);
+        if (expectContinue && Internal.instance.code(responseBuilder) == HTTP_CONTINUE) {
+            return null;
         }
-        continue;
-      }
-
-      ByteString name = header.name;
-      String value = header.value.utf8();
-      if (name.equals(RESPONSE_STATUS)) {
-        statusLine = StatusLine.parse("HTTP/1.1 " + value);
-      } else if (!HTTP_2_SKIPPED_RESPONSE_HEADERS.contains(name)) {
-        Internal.instance.addLenient(headersBuilder, name.utf8(), value);
-      }
+        return responseBuilder;
     }
-    if (statusLine == null) throw new ProtocolException("Expected ':status' header not present");
-
-    return new Response.Builder()
-        .protocol(Protocol.HTTP_2)
-        .code(statusLine.code)
-        .message(statusLine.message)
-        .headers(headersBuilder.build());
-  }
-
-  @Override public ResponseBody openResponseBody(Response response) throws IOException {
-    streamAllocation.eventListener.responseBodyStart(streamAllocation.call);
-    String contentType = response.header("Content-Type");
-    long contentLength = HttpHeaders.contentLength(response);
-    Source source = new StreamFinishingSource(stream.getSource());
-    return new RealResponseBody(contentType, contentLength, Okio.buffer(source));
-  }
-
-  @Override public void cancel() {
-    if (stream != null) stream.closeLater(ErrorCode.CANCEL);
-  }
-
-  class StreamFinishingSource extends ForwardingSource {
-    boolean completed = false;
-    long bytesRead = 0;
-
-    StreamFinishingSource(Source delegate) {
-      super(delegate);
+
+    public static List<Header> http2HeadersList(Request request) {
+        Headers headers = request.headers();
+        List<Header> result = new ArrayList<>(headers.size() + 4);
+        result.add(new Header(TARGET_METHOD, request.method()));
+        result.add(new Header(TARGET_PATH, RequestLine.requestPath(request.url())));
+        String host = request.header("Host");
+        if (host != null) {
+            result.add(new Header(TARGET_AUTHORITY, host)); // Optional.
+        }
+        result.add(new Header(TARGET_SCHEME, request.url().scheme()));
+
+        for (int i = 0, size = headers.size(); i < size; i++) {
+            // header names must be lowercase.
+            ByteString name = ByteString.encodeUtf8(headers.name(i).toLowerCase(Locale.US));
+            if (!HTTP_2_SKIPPED_REQUEST_HEADERS.contains(name)) {
+                result.add(new Header(name, headers.value(i)));
+            }
+        }
+        return result;
     }
 
-    @Override public long read(Buffer sink, long byteCount) throws IOException {
-      try {
-        long read = delegate().read(sink, byteCount);
-        if (read > 0) {
-          bytesRead += read;
+    /**
+     * Returns headers for a name value block containing an HTTP/2 response.
+     */
+    public static Response.Builder readHttp2HeadersList(List<Header> headerBlock) throws IOException {
+        StatusLine statusLine = null;
+        Headers.Builder headersBuilder = new Headers.Builder();
+        for (int i = 0, size = headerBlock.size(); i < size; i++) {
+            Header header = headerBlock.get(i);
+
+            // If there were multiple header blocks they will be delimited by nulls. Discard existing
+            // header blocks if the existing header block is a '100 Continue' intermediate response.
+            if (header == null) {
+                if (statusLine != null && statusLine.code == HTTP_CONTINUE) {
+                    statusLine = null;
+                    headersBuilder = new Headers.Builder();
+                }
+                continue;
+            }
+
+            ByteString name = header.name;
+            String value = header.value.utf8();
+            if (name.equals(RESPONSE_STATUS)) {
+                statusLine = StatusLine.parse("HTTP/1.1 " + value);
+            } else if (!HTTP_2_SKIPPED_RESPONSE_HEADERS.contains(name)) {
+                Internal.instance.addLenient(headersBuilder, name.utf8(), value);
+            }
         }
-        return read;
-      } catch (IOException e) {
-        endOfInput(e);
-        throw e;
-      }
+        if (statusLine == null) throw new ProtocolException("Expected ':status' header not present");
+
+        return new Response.Builder()
+                .protocol(Protocol.HTTP_2)
+                .code(statusLine.code)
+                .message(statusLine.message)
+                .headers(headersBuilder.build());
+    }
+
+    @Override
+    public ResponseBody openResponseBody(Response response) throws IOException {
+        streamAllocation.eventListener.responseBodyStart(streamAllocation.call);
+        String contentType = response.header("Content-Type");
+        long contentLength = HttpHeaders.contentLength(response);
+        Source source = new StreamFinishingSource(stream.getSource());
+        return new RealResponseBody(contentType, contentLength, Okio.buffer(source));
     }
 
-    @Override public void close() throws IOException {
-      super.close();
-      endOfInput(null);
+    @Override
+    public void cancel() {
+        if (stream != null) stream.closeLater(ErrorCode.CANCEL);
     }
 
-    private void endOfInput(IOException e) {
-      if (completed) return;
-      completed = true;
-      streamAllocation.streamFinished(false, Http2Codec.this, bytesRead, e);
+    class StreamFinishingSource extends ForwardingSource {
+        boolean completed = false;
+        long bytesRead = 0;
+
+        StreamFinishingSource(Source delegate) {
+            super(delegate);
+        }
+
+        @Override
+        public long read(Buffer sink, long byteCount) throws IOException {
+            try {
+                long read = delegate().read(sink, byteCount);
+                if (read > 0) {
+                    bytesRead += read;
+                }
+                return read;
+            } catch (IOException e) {
+                endOfInput(e);
+                throw e;
+            }
+        }
+
+        @Override
+        public void close() throws IOException {
+            super.close();
+            endOfInput(null);
+        }
+
+        private void endOfInput(IOException e) {
+            if (completed) return;
+            completed = true;
+            streamAllocation.streamFinished(false, Http2Codec.this, bytesRead, e);
+        }
     }
-  }
 }
diff --git a/okhttp/src/main/java/okhttp3/internal/platform/Platform.java b/okhttp/src/main/java/okhttp3/internal/platform/Platform.java
index c4e12b4b38..8c1f3d5c8e 100644
--- a/okhttp/src/main/java/okhttp3/internal/platform/Platform.java
+++ b/okhttp/src/main/java/okhttp3/internal/platform/Platform.java
@@ -27,6 +27,7 @@
 import javax.net.ssl.SSLSocket;
 import javax.net.ssl.SSLSocketFactory;
 import javax.net.ssl.X509TrustManager;
+
 import okhttp3.OkHttpClient;
 import okhttp3.Protocol;
 import okhttp3.internal.tls.BasicCertificateChainCleaner;
@@ -37,211 +38,217 @@
 
 /**
  * Access to platform-specific features.
- *
+ * <p>
  * <h3>Server name indication (SNI)</h3>
- *
+ * <p>
  * <p>Supported on Android 2.3+.
- *
+ * <p>
  * Supported on OpenJDK 7+
- *
+ * <p>
  * <h3>Session Tickets</h3>
- *
+ * <p>
  * <p>Supported on Android 2.3+.
- *
+ * <p>
  * <h3>Android Traffic Stats (Socket Tagging)</h3>
- *
+ * <p>
  * <p>Supported on Android 4.0+.
- *
+ * <p>
  * <h3>ALPN (Application Layer Protocol Negotiation)</h3>
- *
+ * <p>
  * <p>Supported on Android 5.0+. The APIs were present in Android 4.4, but that implementation was
  * unstable.
- *
+ * <p>
  * Supported on OpenJDK 7 and 8 (via the JettyALPN-boot library).
- *
+ * <p>
  * Supported on OpenJDK 9 via SSLParameters and SSLSocket features.
- *
+ * <p>
  * <h3>Trust Manager Extraction</h3>
- *
+ * <p>
  * <p>Supported on Android 2.3+ and OpenJDK 7+. There are no public APIs to recover the trust
  * manager that was used to create an {@link SSLSocketFactory}.
- *
+ * <p>
  * <h3>Android Cleartext Permit Detection</h3>
- *
+ * <p>
  * <p>Supported on Android 6.0+ via {@code NetworkSecurityPolicy}.
  */
 public class Platform {
-  private static final Platform PLATFORM = findPlatform();
-  public static final int INFO = 4;
-  public static final int WARN = 5;
-  private static final Logger logger = Logger.getLogger(OkHttpClient.class.getName());
-
-  public static Platform get() {
-    return PLATFORM;
-  }
-
-  /** Prefix used on custom headers. */
-  public String getPrefix() {
-    return "OkHttp";
-  }
-
-  protected X509TrustManager trustManager(SSLSocketFactory sslSocketFactory) {
-    // Attempt to get the trust manager from an OpenJDK socket factory. We attempt this on all
-    // platforms in order to support Robolectric, which mixes classes from both Android and the
-    // Oracle JDK. Note that we don't support HTTP/2 or other nice features on Robolectric.
-    try {
-      Class<?> sslContextClass = Class.forName("sun.security.ssl.SSLContextImpl");
-      Object context = readFieldOrNull(sslSocketFactory, sslContextClass, "context");
-      if (context == null) return null;
-      return readFieldOrNull(context, X509TrustManager.class, "trustManager");
-    } catch (ClassNotFoundException e) {
-      return null;
-    }
-  }
-
-  /**
-   * Configure TLS extensions on {@code sslSocket} for {@code route}.
-   *
-   * @param hostname non-null for client-side handshakes; null for server-side handshakes.
-   */
-  public void configureTlsExtensions(SSLSocket sslSocket, String hostname,
-      List<Protocol> protocols) {
-  }
-
-  /**
-   * Called after the TLS handshake to release resources allocated by {@link
-   * #configureTlsExtensions}.
-   */
-  public void afterHandshake(SSLSocket sslSocket) {
-  }
-
-  /** Returns the negotiated protocol, or null if no protocol was negotiated. */
-  public String getSelectedProtocol(SSLSocket socket) {
-    return null;
-  }
-
-  public void connectSocket(Socket socket, InetSocketAddress address,
-      int connectTimeout) throws IOException {
-    socket.connect(address, connectTimeout);
-  }
-
-  public void log(int level, String message, Throwable t) {
-    Level logLevel = level == WARN ? Level.WARNING : Level.INFO;
-    logger.log(logLevel, message, t);
-  }
-
-  public boolean isCleartextTrafficPermitted(String hostname) {
-    return true;
-  }
-
-  /**
-   * Returns an object that holds a stack trace created at the moment this method is executed. This
-   * should be used specifically for {@link java.io.Closeable} objects and in conjunction with
-   * {@link #logCloseableLeak(String, Object)}.
-   */
-  public Object getStackTraceForCloseable(String closer) {
-    if (logger.isLoggable(Level.FINE)) {
-      return new Throwable(closer); // These are expensive to allocate.
-    }
-    return null;
-  }
-
-  public void logCloseableLeak(String message, Object stackTrace) {
-    if (stackTrace == null) {
-      message += " To see where this was allocated, set the OkHttpClient logger level to FINE: "
-          + "Logger.getLogger(OkHttpClient.class.getName()).setLevel(Level.FINE);";
-    }
-    log(WARN, message, (Throwable) stackTrace);
-  }
-
-  public static List<String> alpnProtocolNames(List<Protocol> protocols) {
-    List<String> names = new ArrayList<>(protocols.size());
-    for (int i = 0, size = protocols.size(); i < size; i++) {
-      Protocol protocol = protocols.get(i);
-      if (protocol == Protocol.HTTP_1_0) continue; // No HTTP/1.0 for ALPN.
-      names.add(protocol.toString());
-    }
-    return names;
-  }
-
-  public CertificateChainCleaner buildCertificateChainCleaner(X509TrustManager trustManager) {
-    return new BasicCertificateChainCleaner(buildTrustRootIndex(trustManager));
-  }
-
-  public CertificateChainCleaner buildCertificateChainCleaner(SSLSocketFactory sslSocketFactory) {
-    X509TrustManager trustManager = trustManager(sslSocketFactory);
-
-    if (trustManager == null) {
-      throw new IllegalStateException("Unable to extract the trust manager on " + Platform.get()
-          + ", sslSocketFactory is " + sslSocketFactory.getClass());
-    }
-
-    return buildCertificateChainCleaner(trustManager);
-  }
-
-  /** Attempt to match the host runtime to a capable Platform implementation. */
-  private static Platform findPlatform() {
-    Platform android = AndroidPlatform.buildIfSupported();
-
-    if (android != null) {
-      return android;
-    }
-
-    Platform jdk9 = Jdk9Platform.buildIfSupported();
-
-    if (jdk9 != null) {
-      return jdk9;
-    }
-
-    Platform jdkWithJettyBoot = JdkWithJettyBootPlatform.buildIfSupported();
+    private static final Platform PLATFORM = findPlatform();
+    public static final int INFO = 4;
+    public static final int WARN = 5;
+    private static final Logger logger = Logger.getLogger(OkHttpClient.class.getName());
+
+    public static Platform get() {
+        return PLATFORM;
+    }
+
+    /**
+     * Prefix used on custom headers.
+     */
+    public String getPrefix() {
+        return "OkHttp";
+    }
+
+    protected X509TrustManager trustManager(SSLSocketFactory sslSocketFactory) {
+        // Attempt to get the trust manager from an OpenJDK socket factory. We attempt this on all
+        // platforms in order to support Robolectric, which mixes classes from both Android and the
+        // Oracle JDK. Note that we don't support HTTP/2 or other nice features on Robolectric.
+        try {
+            Class<?> sslContextClass = Class.forName("sun.security.ssl.SSLContextImpl");
+            Object context = readFieldOrNull(sslSocketFactory, sslContextClass, "context");
+            if (context == null) return null;
+            return readFieldOrNull(context, X509TrustManager.class, "trustManager");
+        } catch (ClassNotFoundException e) {
+            return null;
+        }
+    }
 
-    if (jdkWithJettyBoot != null) {
-      return jdkWithJettyBoot;
-    }
+    /**
+     * Configure TLS extensions on {@code sslSocket} for {@code route}.
+     *
+     * @param hostname non-null for client-side handshakes; null for server-side handshakes.
+     */
+    public void configureTlsExtensions(SSLSocket sslSocket, String hostname,
+                                       List<Protocol> protocols) {
+    }
 
-    // Probably an Oracle JDK like OpenJDK.
-    return new Platform();
-  }
+    /**
+     * Called after the TLS handshake to release resources allocated by {@link
+     * #configureTlsExtensions}.
+     */
+    public void afterHandshake(SSLSocket sslSocket) {
+    }
 
-  /**
-   * Returns the concatenation of 8-bit, length prefixed protocol names.
-   * http://tools.ietf.org/html/draft-agl-tls-nextprotoneg-04#page-4
-   */
-  static byte[] concatLengthPrefixed(List<Protocol> protocols) {
-    Buffer result = new Buffer();
-    for (int i = 0, size = protocols.size(); i < size; i++) {
-      Protocol protocol = protocols.get(i);
-      if (protocol == Protocol.HTTP_1_0) continue; // No HTTP/1.0 for ALPN.
-      result.writeByte(protocol.toString().length());
-      result.writeUtf8(protocol.toString());
+    /**
+     * Returns the negotiated protocol, or null if no protocol was negotiated.
+     */
+    public String getSelectedProtocol(SSLSocket socket) {
+        return null;
     }
-    return result.readByteArray();
-  }
 
-  static <T> T readFieldOrNull(Object instance, Class<T> fieldType, String fieldName) {
-    for (Class<?> c = instance.getClass(); c != Object.class; c = c.getSuperclass()) {
-      try {
-        Field field = c.getDeclaredField(fieldName);
-        field.setAccessible(true);
-        Object value = field.get(instance);
-        if (value == null || !fieldType.isInstance(value)) return null;
-        return fieldType.cast(value);
-      } catch (NoSuchFieldException ignored) {
-      } catch (IllegalAccessException e) {
-        throw new AssertionError();
-      }
+    public void connectSocket(Socket socket, InetSocketAddress address,
+                              int connectTimeout) throws IOException {
+        socket.connect(address, connectTimeout);
     }
 
-    // Didn't find the field we wanted. As a last gasp attempt, try to find the value on a delegate.
-    if (!fieldName.equals("delegate")) {
-      Object delegate = readFieldOrNull(instance, Object.class, "delegate");
-      if (delegate != null) return readFieldOrNull(delegate, fieldType, fieldName);
+    public void log(int level, String message, Throwable t) {
+        Level logLevel = level == WARN ? Level.WARNING : Level.INFO;
+        logger.log(logLevel, message, t);
     }
 
-    return null;
-  }
+    public boolean isCleartextTrafficPermitted(String hostname) {
+        return true;
+    }
+
+    /**
+     * Returns an object that holds a stack trace created at the moment this method is executed. This
+     * should be used specifically for {@link java.io.Closeable} objects and in conjunction with
+     * {@link #logCloseableLeak(String, Object)}.
+     */
+    public Object getStackTraceForCloseable(String closer) {
+        if (logger.isLoggable(Level.FINE)) {
+            return new Throwable(closer); // These are expensive to allocate.
+        }
+        return null;
+    }
+
+    public void logCloseableLeak(String message, Object stackTrace) {
+        if (stackTrace == null) {
+            message += " To see where this was allocated, set the OkHttpClient logger level to FINE: "
+                    + "Logger.getLogger(OkHttpClient.class.getName()).setLevel(Level.FINE);";
+        }
+        log(WARN, message, (Throwable) stackTrace);
+    }
+
+    public static List<String> alpnProtocolNames(List<Protocol> protocols) {
+        List<String> names = new ArrayList<>(protocols.size());
+        for (int i = 0, size = protocols.size(); i < size; i++) {
+            Protocol protocol = protocols.get(i);
+            if (protocol == Protocol.HTTP_1_0) continue; // No HTTP/1.0 for ALPN.
+            names.add(protocol.toString());
+        }
+        return names;
+    }
+
+    public CertificateChainCleaner buildCertificateChainCleaner(X509TrustManager trustManager) {
+        return new BasicCertificateChainCleaner(buildTrustRootIndex(trustManager));
+    }
+
+    public CertificateChainCleaner buildCertificateChainCleaner(SSLSocketFactory sslSocketFactory) {
+        X509TrustManager trustManager = trustManager(sslSocketFactory);
+
+        if (trustManager == null) {
+            throw new IllegalStateException("Unable to extract the trust manager on " + Platform.get()
+                    + ", sslSocketFactory is " + sslSocketFactory.getClass());
+        }
+
+        return buildCertificateChainCleaner(trustManager);
+    }
+
+    /**
+     * Attempt to match the host runtime to a capable Platform implementation.
+     */
+    private static Platform findPlatform() {
+        Platform android = AndroidPlatform.buildIfSupported();
+
+        if (android != null) {
+            return android;
+        }
+
+        Platform jdk9 = Jdk9Platform.buildIfSupported();
+
+        if (jdk9 != null) {
+            return jdk9;
+        }
+
+        Platform jdkWithJettyBoot = JdkWithJettyBootPlatform.buildIfSupported();
+
+        if (jdkWithJettyBoot != null) {
+            return jdkWithJettyBoot;
+        }
+
+        // Probably an Oracle JDK like OpenJDK.
+        return new Platform();
+    }
+
+    /**
+     * Returns the concatenation of 8-bit, length prefixed protocol names.
+     * http://tools.ietf.org/html/draft-agl-tls-nextprotoneg-04#page-4
+     */
+    static byte[] concatLengthPrefixed(List<Protocol> protocols) {
+        Buffer result = new Buffer();
+        for (int i = 0, size = protocols.size(); i < size; i++) {
+            Protocol protocol = protocols.get(i);
+            if (protocol == Protocol.HTTP_1_0) continue; // No HTTP/1.0 for ALPN.
+            result.writeByte(protocol.toString().length());
+            result.writeUtf8(protocol.toString());
+        }
+        return result.readByteArray();
+    }
+
+    static <T> T readFieldOrNull(Object instance, Class<T> fieldType, String fieldName) {
+        for (Class<?> c = instance.getClass(); c != Object.class; c = c.getSuperclass()) {
+            try {
+                Field field = c.getDeclaredField(fieldName);
+                field.setAccessible(true);
+                Object value = field.get(instance);
+                if (value == null || !fieldType.isInstance(value)) return null;
+                return fieldType.cast(value);
+            } catch (NoSuchFieldException ignored) {
+            } catch (IllegalAccessException e) {
+                throw new AssertionError();
+            }
+        }
+
+        // Didn't find the field we wanted. As a last gasp attempt, try to find the value on a delegate.
+        if (!fieldName.equals("delegate")) {
+            Object delegate = readFieldOrNull(instance, Object.class, "delegate");
+            if (delegate != null) return readFieldOrNull(delegate, fieldType, fieldName);
+        }
+
+        return null;
+    }
 
     public TrustRootIndex buildTrustRootIndex(X509TrustManager trustManager) {
-      return new BasicTrustRootIndex(trustManager.getAcceptedIssuers());
+        return new BasicTrustRootIndex(trustManager.getAcceptedIssuers());
     }
 }
