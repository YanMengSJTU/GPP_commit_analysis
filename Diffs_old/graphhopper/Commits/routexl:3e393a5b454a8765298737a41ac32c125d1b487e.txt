diff --git a/.travis.yml b/.travis.yml
index 4d4ddff8eb..5554530cbe 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -12,8 +12,9 @@ env:
 matrix:
   include:
     - jdk: openjdk8
-    - env: JDK='OpenJDK 10'
-      install: . ./install-jdk.sh -F 10 -C
+    # spotbugs is not jdk 12 ready yet
+#    - env: JDK='OpenJDK 12'
+#      install: . ./install-jdk.sh -F 12 -C
     - env: JDK='OpenJDK 11'
       install: . ./install-jdk.sh -F 11 -C
     
@@ -41,13 +42,13 @@ script:
   - "mvn -Dkey=$API_KEY clean test verify checkstyle:check spotbugs:check forbiddenapis:check -B"
 
 after_success:
-  # deploy snapshot artifacts to sonatype and if tagged deploy then release to maven central
-  - if [ "$TRAVIS_JDK_VERSION" == "openjdk8" ] && [ "$TRAVIS_BRANCH" == "master" ] && [ "$TRAVIS_PULL_REQUEST" == "false" ]; then
-        mvn deploy --settings core/files/settings.xml -DskipTests=true -B;
-    elif [ "$TRAVIS_JDK_VERSION" == "openjdk8" ] && [ "$TRAVIS_TAG" != "" ]; then
+  # if tagged deploy then release to maven central or deploy snapshot artifacts to sonatype 
+  - if [ "$TRAVIS_JDK_VERSION" == "openjdk8" ] && [ "$TRAVIS_TAG" != "" ]; then
         echo "release to maven central";
         mvn versions:set -DnewVersion=$TRAVIS_TAG -DgenerateBackupPoms=false;
         mvn deploy -P release --settings core/files/settings.xml -DskipTests=true -B;
+    elif [ "$TRAVIS_JDK_VERSION" == "openjdk8" ] && [ "$TRAVIS_BRANCH" == "master" ] && [ "$TRAVIS_PULL_REQUEST" == "false" ]; then
+        mvn deploy --settings core/files/settings.xml -DskipTests=true -B;
     else
         echo "Not deploying artifacts for $TRAVIS_BRANCH";
     fi
diff --git a/NOTICE.md b/NOTICE.md
index b1033dbaf0..d834568aab 100644
--- a/NOTICE.md
+++ b/NOTICE.md
@@ -15,7 +15,7 @@ The core module includes the following software:
  * Apache Commons Collections - we copied parts of the BinaryHeap (Apache License)
  * java-string-similarity - we copied the implementation of JaroWinkler (MIT license)
  * com.fasterxml.jackson.core:jackson-annotations (Apache License)
- * com.vividsolutions:jts (LGPL), see #1039
+ * org.locationtech:jts (EDL), see #1039
 
 reader-osm:
 
@@ -25,7 +25,7 @@ reader-osm:
 
 reader-gtfs:
  
- * com.conveyal:gtfs-lib (BSD 2-clause license)
+ * some files from com.conveyal:gtfs-lib (BSD 2-clause license)
  * com.google.transit:gtfs-realtime-bindings (Apache license)
 
 reader-shp:
diff --git a/README.md b/README.md
index 23ebffc074..8f2c808077 100644
--- a/README.md
+++ b/README.md
@@ -98,7 +98,7 @@ but of course this is not necessary.
 OpenStreetMap is directly supported from GraphHopper. Without the amazing data from
 OpenStreetMap, GraphHopper wouldn't be possible at all.
 Other map data will need a custom import procedure, see e.g. <a href="https://github.com/graphhopper/graphhopper/issues/277">Ordnance Survey</a>,
-<a href="https://github.com/graphhopper/graphhopper/tree/master/reader-shp">Shapefile like ESRI</a> or <a href="https://github.com/knowname/morituri">Navteq</a>.
+<a href="https://github.com/graphhopper/graphhopper-reader-shp">Shapefile like ESRI</a> or <a href="https://github.com/knowname/morituri">Navteq</a>.
 
 ## Written in Java
 
diff --git a/android/app/build.gradle b/android/app/build.gradle
index 5a04ef81f7..25eedd70d8 100644
--- a/android/app/build.gradle
+++ b/android/app/build.gradle
@@ -48,9 +48,7 @@ dependencies {
     implementation 'org.mapsforge:vtm-android:0.9.2:natives-arm64-v8a'
     implementation 'org.mapsforge:vtm-android:0.9.2:natives-x86'
     implementation 'org.mapsforge:vtm-android:0.9.2:natives-x86_64'
-    implementation('org.mapsforge:vtm-jts:0.9.2') {
-      exclude group: 'com.vividsolutions', module: 'jts'
-    }
+    implementation 'org.mapsforge:vtm-jts:0.9.2'
     implementation 'org.mapsforge:vtm-themes:0.9.2'
     implementation 'com.caverock:androidsvg:1.2.2-beta-1'
 
diff --git a/android/app/pom.xml b/android/app/pom.xml
index c4c66c0ba2..c403712d79 100644
--- a/android/app/pom.xml
+++ b/android/app/pom.xml
@@ -92,7 +92,7 @@
             <version>${vtm.version}</version>
             <exclusions>
               <exclusion>
-                <groupId>com.vividsolutions</groupId>
+                <groupId>org.locationtech</groupId>
                 <artifactId>jts</artifactId>
               </exclusion>
             </exclusions>
@@ -105,7 +105,7 @@
         <dependency>
             <groupId>com.caverock</groupId>            
             <artifactId>androidsvg</artifactId>
-            <version>1.2.2-beta-1</version>
+            <version>1.3</version>
         </dependency> 
         
         <dependency>
diff --git a/api/pom.xml b/api/pom.xml
index 1d7c433ee7..a831ec3a4b 100644
--- a/api/pom.xml
+++ b/api/pom.xml
@@ -18,9 +18,9 @@
 
     <dependencies>
         <dependency>
-            <groupId>com.vividsolutions</groupId>
+            <groupId>org.locationtech.jts</groupId>
             <artifactId>jts-core</artifactId>
-            <version>1.14.0</version>
+            <version>1.16.0</version>
         </dependency>
         <dependency>
             <groupId>junit</groupId>
@@ -35,7 +35,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
                 <configuration>
                     <source>1.8</source>
                     <target>1.8</target>
diff --git a/api/src/main/java/com/graphhopper/Trip.java b/api/src/main/java/com/graphhopper/Trip.java
index 43805069b5..fdd6ef4d75 100644
--- a/api/src/main/java/com/graphhopper/Trip.java
+++ b/api/src/main/java/com/graphhopper/Trip.java
@@ -1,8 +1,8 @@
 package com.graphhopper;
 
 import com.graphhopper.util.InstructionList;
-import com.vividsolutions.jts.geom.Geometry;
-import com.vividsolutions.jts.geom.Point;
+import org.locationtech.jts.geom.Geometry;
+import org.locationtech.jts.geom.Point;
 
 import java.util.Date;
 import java.util.List;
diff --git a/api/src/main/java/com/graphhopper/json/geo/JsonFeature.java b/api/src/main/java/com/graphhopper/json/geo/JsonFeature.java
index 1cfd11916b..9ce4c4790b 100644
--- a/api/src/main/java/com/graphhopper/json/geo/JsonFeature.java
+++ b/api/src/main/java/com/graphhopper/json/geo/JsonFeature.java
@@ -18,7 +18,7 @@
 package com.graphhopper.json.geo;
 
 import com.graphhopper.util.shapes.BBox;
-import com.vividsolutions.jts.geom.Geometry;
+import org.locationtech.jts.geom.Geometry;
 
 import java.util.Map;
 
@@ -29,7 +29,7 @@
  */
 public class JsonFeature {
     private String id;
-    private String type;
+    private String type = "Feature";
     private BBox bbox;
     private Geometry geometry;
     private Map<String, Object> properties;
@@ -81,10 +81,6 @@ public void setId(String id) {
         this.id = id;
     }
 
-    public void setType(String type) {
-        this.type = type;
-    }
-
     public void setBbox(BBox bbox) {
         this.bbox = bbox;
     }
diff --git a/api/src/main/java/com/graphhopper/json/geo/JsonFeatureCollection.java b/api/src/main/java/com/graphhopper/json/geo/JsonFeatureCollection.java
index 39541f09b4..55d8a42187 100644
--- a/api/src/main/java/com/graphhopper/json/geo/JsonFeatureCollection.java
+++ b/api/src/main/java/com/graphhopper/json/geo/JsonFeatureCollection.java
@@ -17,14 +17,15 @@
  */
 package com.graphhopper.json.geo;
 
+import java.util.ArrayList;
 import java.util.List;
 
 /**
  * @author Peter Karich
  */
 public class JsonFeatureCollection {
-    String type;
-    List<JsonFeature> features;
+    String type = "FeatureCollection";
+    List<JsonFeature> features = new ArrayList<>();
 
     public String getType() {
         return type;
diff --git a/api/src/main/java/com/graphhopper/util/DistanceCalcEarth.java b/api/src/main/java/com/graphhopper/util/DistanceCalcEarth.java
index 6e0ebe8354..4c7bdbac5a 100644
--- a/api/src/main/java/com/graphhopper/util/DistanceCalcEarth.java
+++ b/api/src/main/java/com/graphhopper/util/DistanceCalcEarth.java
@@ -17,11 +17,11 @@
  */
 package com.graphhopper.util;
 
+import static java.lang.Math.*;
+
 import com.graphhopper.util.shapes.BBox;
 import com.graphhopper.util.shapes.GHPoint;
 
-import static java.lang.Math.*;
-
 /**
  * @author Peter Karich
  */
@@ -155,7 +155,7 @@ else if (factor < 0)
         return calcNormalizedDist(c_lat, c_lon / shrinkFactor, r_lat_deg, r_lon_deg);
     }
 
-    private double calcShrinkFactor(double a_lat_deg, double b_lat_deg) {
+    double calcShrinkFactor(double a_lat_deg, double b_lat_deg) {
         return cos(toRadians((a_lat_deg + b_lat_deg) / 2));
     }
 
diff --git a/api/src/main/java/com/graphhopper/util/PMap.java b/api/src/main/java/com/graphhopper/util/PMap.java
index 2590258393..c40ce658cb 100644
--- a/api/src/main/java/com/graphhopper/util/PMap.java
+++ b/api/src/main/java/com/graphhopper/util/PMap.java
@@ -34,7 +34,7 @@ public PMap() {
     }
 
     public PMap(int capacity) {
-        this(new HashMap<String, String>(capacity));
+        this(new HashMap<>(capacity));
     }
 
     public PMap(Map<String, String> map) {
@@ -128,6 +128,17 @@ public double getDouble(String key, double _default) {
         return _default;
     }
 
+    public float getFloat(String key, float _default) {
+        String str = get(key);
+        if (!Helper.isEmpty(str)) {
+            try {
+                return Float.parseFloat(str);
+            } catch (Exception ex) {
+            }
+        }
+        return _default;
+    }
+
     public String get(String key, String _default) {
         String str = get(key);
         if (Helper.isEmpty(str))
diff --git a/api/src/main/java/com/graphhopper/util/PointList.java b/api/src/main/java/com/graphhopper/util/PointList.java
index 2dca1d6f65..11ae6f155e 100644
--- a/api/src/main/java/com/graphhopper/util/PointList.java
+++ b/api/src/main/java/com/graphhopper/util/PointList.java
@@ -19,9 +19,9 @@
 
 import com.graphhopper.util.shapes.GHPoint;
 import com.graphhopper.util.shapes.GHPoint3D;
-import com.vividsolutions.jts.geom.Coordinate;
-import com.vividsolutions.jts.geom.GeometryFactory;
-import com.vividsolutions.jts.geom.LineString;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.GeometryFactory;
+import org.locationtech.jts.geom.LineString;
 
 import java.util.Arrays;
 import java.util.Iterator;
diff --git a/api/src/main/java/com/graphhopper/util/shapes/GHPoint.java b/api/src/main/java/com/graphhopper/util/shapes/GHPoint.java
index 38f435675d..37f85e1004 100644
--- a/api/src/main/java/com/graphhopper/util/shapes/GHPoint.java
+++ b/api/src/main/java/com/graphhopper/util/shapes/GHPoint.java
@@ -18,7 +18,7 @@
 package com.graphhopper.util.shapes;
 
 import com.graphhopper.util.NumHelper;
-import com.vividsolutions.jts.geom.Point;
+import org.locationtech.jts.geom.Point;
 
 /**
  * @author Peter Karich
diff --git a/api/src/main/java/com/graphhopper/util/shapes/Polygon.java b/api/src/main/java/com/graphhopper/util/shapes/Polygon.java
index e3c8e256bb..52d94115e0 100644
--- a/api/src/main/java/com/graphhopper/util/shapes/Polygon.java
+++ b/api/src/main/java/com/graphhopper/util/shapes/Polygon.java
@@ -82,7 +82,7 @@ public Polygon(double[] lat, double[] lon) {
     /**
      * Lossy conversion to a GraphHopper Polygon.
      */
-    public static Polygon create(com.vividsolutions.jts.geom.Polygon polygon) {
+    public static Polygon create(org.locationtech.jts.geom.Polygon polygon) {
         double[] lats = new double[polygon.getNumPoints()];
         double[] lons = new double[polygon.getNumPoints()];
         for (int i = 0; i < polygon.getNumPoints(); i++) {
diff --git a/client-hc/pom.xml b/client-hc/pom.xml
index 255d45cbfa..f0dc1a8816 100644
--- a/client-hc/pom.xml
+++ b/client-hc/pom.xml
@@ -74,7 +74,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.3</version>
                 <configuration>
                     <compilerArgument>-XDignore.symbol.file</compilerArgument>
                     <fork>true</fork>
@@ -83,19 +82,6 @@
                 </configuration>
             </plugin>
             
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-failsafe-plugin</artifactId>
-                <version>2.19.1</version>
-                <executions>
-                    <execution>
-                        <goals>
-                            <goal>integration-test</goal>
-                            <goal>verify</goal>
-                        </goals>
-                    </execution>
-                </executions>
-            </plugin>
         </plugins>        
     </build>
         
diff --git a/core/src/main/java/com/graphhopper/routing/ch/CHAlgoFactoryDecorator.java b/core/src/main/java/com/graphhopper/routing/ch/CHAlgoFactoryDecorator.java
index 3c714bcc0c..191841cca0 100644
--- a/core/src/main/java/com/graphhopper/routing/ch/CHAlgoFactoryDecorator.java
+++ b/core/src/main/java/com/graphhopper/routing/ch/CHAlgoFactoryDecorator.java
@@ -22,12 +22,10 @@
 import com.graphhopper.routing.util.HintsMap;
 import com.graphhopper.routing.util.TraversalMode;
 import com.graphhopper.routing.weighting.AbstractWeighting;
-import com.graphhopper.routing.weighting.BlockAreaWeighting;
-import com.graphhopper.routing.weighting.GenericWeighting;
 import com.graphhopper.routing.weighting.Weighting;
 import com.graphhopper.storage.*;
 import com.graphhopper.util.CmdArgs;
-import com.graphhopper.util.Helper;
+import com.graphhopper.util.PMap;
 import com.graphhopper.util.Parameters.CH;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -56,11 +54,7 @@
     private boolean enabled = true;
     private int preparationThreads;
     private ExecutorService threadPool;
-    private int preparationPeriodicUpdates = -1;
-    private int preparationLazyUpdates = -1;
-    private int preparationNeighborUpdates = -1;
-    private int preparationContractedNodes = -1;
-    private double preparationLogMessages = -1;
+    private PMap pMap = new PMap();
 
     public CHAlgoFactoryDecorator() {
         setPreparationThreads(1);
@@ -81,7 +75,7 @@ public void init(CmdArgs args) {
         String chWeightingsStr = args.get(CH.PREPARE + "weightings", "");
 
         if ("no".equals(chWeightingsStr) || "false".equals(chWeightingsStr)) {
-            // default is fastest and we need to clear this explicitely
+            // default is fastest and we need to clear this explicitly
             weightingsAsStrings.clear();
         } else if (!chWeightingsStr.isEmpty()) {
             List<String> tmpCHWeightingList = Arrays.asList(chWeightingsStr.split(","));
@@ -93,56 +87,7 @@ public void init(CmdArgs args) {
         if (enableThis)
             setDisablingAllowed(args.getBool(CH.INIT_DISABLING_ALLOWED, isDisablingAllowed()));
 
-        setPreparationPeriodicUpdates(args.getInt(CH.PREPARE + "updates.periodic", getPreparationPeriodicUpdates()));
-        setPreparationLazyUpdates(args.getInt(CH.PREPARE + "updates.lazy", getPreparationLazyUpdates()));
-        setPreparationNeighborUpdates(args.getInt(CH.PREPARE + "updates.neighbor", getPreparationNeighborUpdates()));
-        setPreparationContractedNodes(args.getInt(CH.PREPARE + "contracted_nodes", getPreparationContractedNodes()));
-        setPreparationLogMessages(args.getDouble(CH.PREPARE + "log_messages", getPreparationLogMessages()));
-    }
-
-    public int getPreparationPeriodicUpdates() {
-        return preparationPeriodicUpdates;
-    }
-
-    public CHAlgoFactoryDecorator setPreparationPeriodicUpdates(int preparePeriodicUpdates) {
-        this.preparationPeriodicUpdates = preparePeriodicUpdates;
-        return this;
-    }
-
-    public int getPreparationContractedNodes() {
-        return preparationContractedNodes;
-    }
-
-    public CHAlgoFactoryDecorator setPreparationContractedNodes(int prepareContractedNodes) {
-        this.preparationContractedNodes = prepareContractedNodes;
-        return this;
-    }
-
-    public int getPreparationLazyUpdates() {
-        return preparationLazyUpdates;
-    }
-
-    public CHAlgoFactoryDecorator setPreparationLazyUpdates(int prepareLazyUpdates) {
-        this.preparationLazyUpdates = prepareLazyUpdates;
-        return this;
-    }
-
-    public double getPreparationLogMessages() {
-        return preparationLogMessages;
-    }
-
-    public CHAlgoFactoryDecorator setPreparationLogMessages(double prepareLogMessages) {
-        this.preparationLogMessages = prepareLogMessages;
-        return this;
-    }
-
-    public int getPreparationNeighborUpdates() {
-        return preparationNeighborUpdates;
-    }
-
-    public CHAlgoFactoryDecorator setPreparationNeighborUpdates(int prepareNeighborUpdates) {
-        this.preparationNeighborUpdates = prepareNeighborUpdates;
-        return this;
+        pMap = args;
     }
 
     @Override
@@ -319,13 +264,8 @@ public void createPreparations(GraphHopperStorage ghStorage, TraversalMode trave
 
         for (Weighting weighting : getWeightings()) {
             PrepareContractionHierarchies tmpPrepareCH = new PrepareContractionHierarchies(
-                    new GHDirectory("", DAType.RAM_INT), ghStorage, ghStorage.getGraph(CHGraph.class, weighting),
-                    weighting, traversalMode);
-            tmpPrepareCH.setPeriodicUpdates(preparationPeriodicUpdates).
-                    setLazyUpdates(preparationLazyUpdates).
-                    setNeighborUpdates(preparationNeighborUpdates).
-                    setLogMessages(preparationLogMessages);
-
+                    new GHDirectory("", DAType.RAM_INT), ghStorage, ghStorage.getGraph(CHGraph.class, weighting), traversalMode);
+            tmpPrepareCH.setParams(pMap);
             addPreparation(tmpPrepareCH);
         }
     }
diff --git a/core/src/main/java/com/graphhopper/routing/ch/CHParameters.java b/core/src/main/java/com/graphhopper/routing/ch/CHParameters.java
new file mode 100644
index 0000000000..0d8ae21a6b
--- /dev/null
+++ b/core/src/main/java/com/graphhopper/routing/ch/CHParameters.java
@@ -0,0 +1,17 @@
+package com.graphhopper.routing.ch;
+
+import com.graphhopper.util.Parameters;
+
+public final class CHParameters {
+    static final String PERIODIC_UPDATES = Parameters.CH.PREPARE + "updates.periodic";
+    static final String LAST_LAZY_NODES_UPDATES = Parameters.CH.PREPARE + "updates.lazy";
+    static final String NEIGHBOR_UPDATES = Parameters.CH.PREPARE + "updates.neighbor";
+    static final String CONTRACTED_NODES = Parameters.CH.PREPARE + "contracted_nodes";
+    static final String LOG_MESSAGES = Parameters.CH.PREPARE + "log_messages";
+    static final String EDGE_DIFFERENCE_WEIGHT = Parameters.CH.PREPARE + "node.edge_difference_weight";
+    static final String ORIGINAL_EDGE_COUNT_WEIGHT = Parameters.CH.PREPARE + "node.original_edge_count_weight";
+    static final String CONTRACTED_NEIGHBORS_WEIGHT = Parameters.CH.PREPARE + "node.contracted_neighbors_weight";
+
+    private CHParameters() {
+    }
+}
diff --git a/core/src/main/java/com/graphhopper/routing/ch/NodeBasedNodeContractor.java b/core/src/main/java/com/graphhopper/routing/ch/NodeBasedNodeContractor.java
index 44c7a59d44..c37e144a02 100644
--- a/core/src/main/java/com/graphhopper/routing/ch/NodeBasedNodeContractor.java
+++ b/core/src/main/java/com/graphhopper/routing/ch/NodeBasedNodeContractor.java
@@ -28,6 +28,7 @@
 import java.util.Locale;
 import java.util.Map;
 
+import static com.graphhopper.routing.ch.CHParameters.*;
 import static com.graphhopper.util.Helper.nf;
 
 class NodeBasedNodeContractor extends AbstractNodeContractor {
@@ -35,6 +36,7 @@
     private final Map<Shortcut, Shortcut> shortcuts = new HashMap<>();
     private final AddShortcutHandler addScHandler = new AddShortcutHandler();
     private final CalcShortcutHandler calcScHandler = new CalcShortcutHandler();
+    private final Params params = new Params();
     private CHEdgeExplorer remainingEdgeExplorer;
     private IgnoreNodeFilter ignoreNodeFilter;
     private DijkstraOneToMany prepareAlgo;
@@ -45,9 +47,16 @@
     // each edge can exist in both directions
     private double meanDegree;
 
-    NodeBasedNodeContractor(Directory dir, GraphHopperStorage ghStorage, CHGraph prepareGraph, Weighting weighting) {
+    NodeBasedNodeContractor(Directory dir, GraphHopperStorage ghStorage, CHGraph prepareGraph, Weighting weighting, PMap pMap) {
         super(dir, ghStorage, prepareGraph, weighting);
         this.prepareWeighting = new PreparationWeighting(weighting);
+        extractParams(pMap);
+    }
+
+    private void extractParams(PMap pMap) {
+        params.edgeDifferenceWeight = pMap.getFloat(EDGE_DIFFERENCE_WEIGHT, params.edgeDifferenceWeight);
+        params.originalEdgesCountWeight = pMap.getFloat(ORIGINAL_EDGE_COUNT_WEIGHT, params.originalEdgesCountWeight);
+        params.contractedNeighborsWeight = pMap.getFloat(CONTRACTED_NEIGHBORS_WEIGHT, params.contractedNeighborsWeight);
     }
 
     @Override
@@ -120,8 +129,9 @@ public float calculatePriority(int node) {
         int edgeDifference = calcShortcutsResult.shortcutsCount - degree;
 
         // according to the paper do a simple linear combination of the properties to get the priority.
-        // this is the current optimum for unterfranken:
-        return 10 * edgeDifference + originalEdgesCount + contractedNeighbors;
+        return params.edgeDifferenceWeight * edgeDifference +
+                params.originalEdgesCountWeight * originalEdgesCount +
+                params.contractedNeighborsWeight * contractedNeighbors;
     }
 
     @Override
@@ -438,4 +448,11 @@ public void foundShortcut(int fromNode, int toNode,
         int shortcutsCount;
     }
 
+    public static class Params {
+        // default values were optimized for Unterfranken
+        private float edgeDifferenceWeight = 10;
+        private float originalEdgesCountWeight = 1;
+        private float contractedNeighborsWeight = 1;
+    }
+
 }
diff --git a/core/src/main/java/com/graphhopper/routing/ch/PrepareContractionHierarchies.java b/core/src/main/java/com/graphhopper/routing/ch/PrepareContractionHierarchies.java
index 31b993fc8c..29226da005 100644
--- a/core/src/main/java/com/graphhopper/routing/ch/PrepareContractionHierarchies.java
+++ b/core/src/main/java/com/graphhopper/routing/ch/PrepareContractionHierarchies.java
@@ -22,16 +22,14 @@
 import com.graphhopper.routing.util.*;
 import com.graphhopper.routing.weighting.Weighting;
 import com.graphhopper.storage.*;
-import com.graphhopper.util.CHEdgeExplorer;
-import com.graphhopper.util.CHEdgeIterator;
-import com.graphhopper.util.Helper;
-import com.graphhopper.util.StopWatch;
+import com.graphhopper.util.*;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.util.Locale;
 import java.util.Random;
 
+import static com.graphhopper.routing.ch.CHParameters.*;
 import static com.graphhopper.util.Helper.nf;
 import static com.graphhopper.util.Parameters.Algorithms.ASTAR_BI;
 import static com.graphhopper.util.Parameters.Algorithms.DIJKSTRA_BI;
@@ -63,6 +61,7 @@
     private final StopWatch lazyUpdateSW = new StopWatch();
     private final StopWatch neighborUpdateSW = new StopWatch();
     private final StopWatch contractionSW = new StopWatch();
+    private final Params params;
     private NodeContractor nodeContractor;
     private CHEdgeExplorer vehicleAllExplorer;
     private CHEdgeExplorer vehicleAllTmpExplorer;
@@ -70,93 +69,27 @@
     // nodes with highest priority come last
     private GHTreeMapComposed sortedNodes;
     private float oldPriorities[];
-    private int periodicUpdatesPercentage = 20;
-    private int lastNodesLazyUpdatePercentage = 10;
-    private int neighborUpdatePercentage = 20;
-    private double nodesContractedPercentage = 100;
-    private double logMessagesPercentage = 20;
+    private PMap pMap = new PMap();
     private int initSize;
     private int checkCounter;
 
-    public PrepareContractionHierarchies(Directory dir, GraphHopperStorage ghStorage, CHGraph chGraph,
-                                         Weighting weighting, TraversalMode traversalMode) {
+    public PrepareContractionHierarchies(Directory dir, GraphHopperStorage ghStorage, CHGraph chGraph, TraversalMode traversalMode) {
         this.dir = dir;
         this.ghStorage = ghStorage;
         this.prepareGraph = (CHGraphImpl) chGraph;
         this.traversalMode = traversalMode;
-        this.weighting = weighting;
+        this.weighting = ((CHGraphImpl) chGraph).getWeighting();
         prepareWeighting = new PreparationWeighting(weighting);
+        this.params = Params.forTraversalMode(traversalMode);
     }
 
-    /**
-     * The higher the values are the longer the preparation takes but the less shortcuts are
-     * produced.
-     * <p>
-     *
-     * @param periodicUpdates specifies how often periodic updates will happen. Use something less
-     *                        than 10.
-     */
-    public PrepareContractionHierarchies setPeriodicUpdates(int periodicUpdates) {
-        if (periodicUpdates < 0)
-            return this;
-        if (periodicUpdates > 100)
-            throw new IllegalArgumentException("periodicUpdates has to be in [0, 100], to disable it use 0");
-
-        this.periodicUpdatesPercentage = periodicUpdates;
-        return this;
-    }
-
-    /**
-     * @param lazyUpdates specifies when lazy updates will happen, measured relative to all existing
-     *                    nodes. 100 means always.
-     */
-    public PrepareContractionHierarchies setLazyUpdates(int lazyUpdates) {
-        if (lazyUpdates < 0)
-            return this;
-
-        if (lazyUpdates > 100)
-            throw new IllegalArgumentException("lazyUpdates has to be in [0, 100], to disable it use 0");
-
-        this.lastNodesLazyUpdatePercentage = lazyUpdates;
-        return this;
-    }
-
-    /**
-     * @param neighborUpdates specifies how often neighbor updates will happen. 100 means always.
-     */
-    public PrepareContractionHierarchies setNeighborUpdates(int neighborUpdates) {
-        if (neighborUpdates < 0)
-            return this;
-
-        if (neighborUpdates > 100)
-            throw new IllegalArgumentException("neighborUpdates has to be in [0, 100], to disable it use 0");
-
-        this.neighborUpdatePercentage = neighborUpdates;
-        return this;
-    }
-
-    /**
-     * Specifies how often a log message should be printed. Specify something around 20 (20% of the
-     * start nodes).
-     */
-    public PrepareContractionHierarchies setLogMessages(double logMessages) {
-        if (logMessages >= 0)
-            this.logMessagesPercentage = logMessages;
-        return this;
-    }
-
-    /**
-     * Define how many nodes (percentage) should be contracted. Less nodes means slower query but
-     * faster contraction duration.
-     */
-    public PrepareContractionHierarchies setContractedNodes(double nodesContracted) {
-        if (nodesContracted < 0)
-            return this;
-
-        if (nodesContracted > 100)
-            throw new IllegalArgumentException("setNodesContracted can be 100% maximum");
-
-        this.nodesContractedPercentage = nodesContracted;
+    public PrepareContractionHierarchies setParams(PMap pMap) {
+        this.pMap = pMap;
+        params.setPeriodicUpdatesPercentage(pMap.getInt(PERIODIC_UPDATES, params.getPeriodicUpdatesPercentage()));
+        params.setLastNodesLazyUpdatePercentage(pMap.getInt(LAST_LAZY_NODES_UPDATES, params.getLastNodesLazyUpdatePercentage()));
+        params.setNeighborUpdatePercentage(pMap.getInt(NEIGHBOR_UPDATES, params.getNeighborUpdatePercentage()));
+        params.setNodesContractedPercentage(pMap.getInt(CONTRACTED_NODES, params.getNodesContractedPercentage()));
+        params.setLogMessagesPercentage(pMap.getInt(LOG_MESSAGES, params.getLogMessagesPercentage()));
         return this;
     }
 
@@ -170,9 +103,9 @@ public void doSpecificWork() {
                 + ", new shortcuts: " + nf(nodeContractor.getAddedShortcutsCount())
                 + ", initSize:" + nf(initSize)
                 + ", " + prepareWeighting
-                + ", periodic:" + periodicUpdatesPercentage
-                + ", lazy:" + lastNodesLazyUpdatePercentage
-                + ", neighbor:" + neighborUpdatePercentage
+                + ", periodic:" + params.getPeriodicUpdatesPercentage()
+                + ", lazy:" + params.getLastNodesLazyUpdatePercentage()
+                + ", neighbor:" + params.getNeighborUpdatePercentage()
                 + ", " + getTimesAsString()
                 + ", lazy-overhead: " + (int) (100 * ((checkCounter / (double) initSize) - 1)) + "%"
                 + ", " + Helper.getMemInfo());
@@ -226,7 +159,7 @@ private void initFromGraph() {
         //   but we need the additional oldPriorities array to keep the old value which is necessary for the update method
         sortedNodes = new GHTreeMapComposed();
         oldPriorities = new float[prepareGraph.getNodes()];
-        nodeContractor = new NodeBasedNodeContractor(dir, ghStorage, prepareGraph, weighting);
+        nodeContractor = new NodeBasedNodeContractor(dir, ghStorage, prepareGraph, weighting, pMap);
         nodeContractor.initFromGraph();
     }
 
@@ -250,31 +183,31 @@ private void contractNodes() {
         initSize = sortedNodes.getSize();
         int level = 0;
         checkCounter = 0;
-        long logSize = Math.round(Math.max(10, initSize / 100d * logMessagesPercentage));
-        if (logMessagesPercentage == 0)
+        long logSize = Math.round(Math.max(10, initSize / 100d * params.getLogMessagesPercentage()));
+        if (params.getLogMessagesPercentage() == 0)
             logSize = Integer.MAX_VALUE;
 
         // preparation takes longer but queries are slightly faster with preparation
         // => enable it but call not so often
         boolean periodicUpdate = true;
         int updateCounter = 0;
-        long periodicUpdatesCount = Math.round(Math.max(10, sortedNodes.getSize() / 100d * periodicUpdatesPercentage));
-        if (periodicUpdatesPercentage == 0)
+        long periodicUpdatesCount = Math.round(Math.max(10, sortedNodes.getSize() / 100d * params.getPeriodicUpdatesPercentage()));
+        if (params.getPeriodicUpdatesPercentage() == 0)
             periodicUpdate = false;
 
         // disable lazy updates for last x percentage of nodes as preparation is then a lot slower
         // and query time does not really benefit
-        long lastNodesLazyUpdates = Math.round(sortedNodes.getSize() / 100d * lastNodesLazyUpdatePercentage);
+        long lastNodesLazyUpdates = Math.round(sortedNodes.getSize() / 100d * params.getLastNodesLazyUpdatePercentage());
 
         // according to paper "Polynomial-time Construction of Contraction Hierarchies for Multi-criteria Objectives" by Funke and Storandt
         // we don't need to wait for all nodes to be contracted
-        long nodesToAvoidContract = Math.round((100 - nodesContractedPercentage) / 100d * sortedNodes.getSize());
+        long nodesToAvoidContract = Math.round((100 - params.getNodesContractedPercentage()) / 100d * sortedNodes.getSize());
 
         // Recompute priority of uncontracted neighbors.
         // Without neighbor updates preparation is faster but we need them
         // to slightly improve query time. Also if not applied too often it decreases the shortcut number.
         boolean neighborUpdate = true;
-        if (neighborUpdatePercentage == 0)
+        if (params.getNeighborUpdatePercentage() == 0)
             neighborUpdate = false;
 
         while (!sortedNodes.isEmpty()) {
@@ -336,7 +269,7 @@ private void contractNodes() {
                 if (prepareGraph.getLevel(nn) != maxLevel)
                     continue;
 
-                if (neighborUpdate && rand.nextInt(100) < neighborUpdatePercentage) {
+                if (neighborUpdate && rand.nextInt(100) < params.getNeighborUpdatePercentage()) {
                     neighborUpdateSW.start();
                     float oldPrio = oldPriorities[nn];
                     float priority = oldPriorities[nn] = calculatePriority(nn);
@@ -421,4 +354,98 @@ private void logStats(int updateCounter) {
                 nodeContractor.getStatisticsString(),
                 Helper.getMemInfo()));
     }
+
+    private static class Params {
+        /**
+         * Specifies how often periodic updates will happen. The higher the value the longer the preparation takes
+         * but the less shortcuts are produced.
+         */
+        private int periodicUpdatesPercentage;
+        /**
+         * Specifies when lazy updates will happen, measured relative to all existing nodes. 100 means always.
+         */
+        private int lastNodesLazyUpdatePercentage;
+        /**
+         * Specifies how often neighbor updates will happen. 100 means always.
+         */
+        private int neighborUpdatePercentage;
+        /**
+         * Defines how many nodes (percentage) should be contracted. Less nodes means slower query but
+         * faster contraction.
+         */
+        private int nodesContractedPercentage;
+        /**
+         * Specifies how often a log message should be printed. Specify something around 20 (20% of the
+         * start nodes).
+         */
+        private int logMessagesPercentage;
+
+        static Params forTraversalMode(TraversalMode traversalMode) {
+            if (traversalMode.isEdgeBased()) {
+                throw new IllegalArgumentException("Contraction Hierarchies are not supported for edge-based traversal yet");
+            } else {
+                return new Params(20, 10, 20, 100, 20);
+            }
+        }
+
+        private Params(int periodicUpdatesPercentage, int lastNodesLazyUpdatePercentage, int neighborUpdatePercentage,
+                       int nodesContractedPercentage, int logMessagesPercentage) {
+            setPeriodicUpdatesPercentage(periodicUpdatesPercentage);
+            setLastNodesLazyUpdatePercentage(lastNodesLazyUpdatePercentage);
+            setNeighborUpdatePercentage(neighborUpdatePercentage);
+            setNodesContractedPercentage(nodesContractedPercentage);
+            setLogMessagesPercentage(logMessagesPercentage);
+        }
+
+        int getPeriodicUpdatesPercentage() {
+            return periodicUpdatesPercentage;
+        }
+
+        void setPeriodicUpdatesPercentage(int periodicUpdatesPercentage) {
+            checkPercentage(PERIODIC_UPDATES, periodicUpdatesPercentage);
+            this.periodicUpdatesPercentage = periodicUpdatesPercentage;
+        }
+
+        int getLastNodesLazyUpdatePercentage() {
+            return lastNodesLazyUpdatePercentage;
+        }
+
+        void setLastNodesLazyUpdatePercentage(int lastNodesLazyUpdatePercentage) {
+            checkPercentage(LAST_LAZY_NODES_UPDATES, lastNodesLazyUpdatePercentage);
+            this.lastNodesLazyUpdatePercentage = lastNodesLazyUpdatePercentage;
+        }
+
+        int getNeighborUpdatePercentage() {
+            return neighborUpdatePercentage;
+        }
+
+        void setNeighborUpdatePercentage(int neighborUpdatePercentage) {
+            checkPercentage(NEIGHBOR_UPDATES, neighborUpdatePercentage);
+            this.neighborUpdatePercentage = neighborUpdatePercentage;
+        }
+
+        int getNodesContractedPercentage() {
+            return nodesContractedPercentage;
+        }
+
+        void setNodesContractedPercentage(int nodesContractedPercentage) {
+            checkPercentage(CONTRACTED_NODES, nodesContractedPercentage);
+            this.nodesContractedPercentage = nodesContractedPercentage;
+        }
+
+        int getLogMessagesPercentage() {
+            return logMessagesPercentage;
+        }
+
+        void setLogMessagesPercentage(int logMessagesPercentage) {
+            checkPercentage(LOG_MESSAGES, logMessagesPercentage);
+            this.logMessagesPercentage = logMessagesPercentage;
+        }
+
+        private void checkPercentage(String name, int value) {
+            if (value < 0 || value > 100) {
+                throw new IllegalArgumentException(name + " has to be in [0, 100], to disable it use 0");
+            }
+        }
+    }
 }
diff --git a/core/src/main/java/com/graphhopper/routing/util/AbstractFlagEncoder.java b/core/src/main/java/com/graphhopper/routing/util/AbstractFlagEncoder.java
index 9d2d91462c..cdaac8d6b0 100644
--- a/core/src/main/java/com/graphhopper/routing/util/AbstractFlagEncoder.java
+++ b/core/src/main/java/com/graphhopper/routing/util/AbstractFlagEncoder.java
@@ -221,8 +221,10 @@ public int defineRelationBits(int index, int shift) {
 
     /**
      * Parse tags on nodes. Node tags can add to speed (like traffic_signals) where the value is
-     * strict negative or blocks access (like a barrier), then the value is strict positive.This
+     * strict negative or blocks access (like a barrier), then the value is strictly positive. This
      * method is called in the second parsing step.
+     *
+     * @return encoded values or 0 if not blocking or no value stored
      */
     public long handleNodeTags(ReaderNode node) {
         // absolute barriers always block
@@ -484,7 +486,7 @@ protected double getFerrySpeed(ReaderWay way) {
             }
 
         if (durationInHours == 0) {
-            if(estimatedLength != null && estimatedLength.doubleValue() <= 300)
+            if (estimatedLength != null && estimatedLength.doubleValue() <= 300)
                 return speedEncoder.factor / 2;
             // unknown speed -> put penalty on ferry transport
             return UNKNOWN_DURATION_FERRY_SPEED;
diff --git a/core/src/main/java/com/graphhopper/routing/util/BikeCommonFlagEncoder.java b/core/src/main/java/com/graphhopper/routing/util/BikeCommonFlagEncoder.java
index 9e57a52aed..639c3167f2 100644
--- a/core/src/main/java/com/graphhopper/routing/util/BikeCommonFlagEncoder.java
+++ b/core/src/main/java/com/graphhopper/routing/util/BikeCommonFlagEncoder.java
@@ -87,7 +87,9 @@ protected BikeCommonFlagEncoder(int speedBits, double speedFactor, int maxTurnCo
         potentialBarriers.add("gate");
         // potentialBarriers.add("lift_gate");
         potentialBarriers.add("swing_gate");
+        potentialBarriers.add("cattle_grid");
 
+        absoluteBarriers.add("fence");
         absoluteBarriers.add("stile");
         absoluteBarriers.add("turnstile");
 
diff --git a/core/src/main/java/com/graphhopper/routing/util/CarFlagEncoder.java b/core/src/main/java/com/graphhopper/routing/util/CarFlagEncoder.java
index afa6634888..33c41d4283 100644
--- a/core/src/main/java/com/graphhopper/routing/util/CarFlagEncoder.java
+++ b/core/src/main/java/com/graphhopper/routing/util/CarFlagEncoder.java
@@ -83,7 +83,9 @@ public CarFlagEncoder(int speedBits, double speedFactor, int maxTurnCosts) {
         potentialBarriers.add("lift_gate");
         potentialBarriers.add("kissing_gate");
         potentialBarriers.add("swing_gate");
+        potentialBarriers.add("cattle_grid");
 
+        absoluteBarriers.add("fence");
         absoluteBarriers.add("bollard");
         absoluteBarriers.add("stile");
         absoluteBarriers.add("turnstile");
diff --git a/core/src/main/java/com/graphhopper/routing/util/FootFlagEncoder.java b/core/src/main/java/com/graphhopper/routing/util/FootFlagEncoder.java
index a6162ea6c2..1ee6af1314 100644
--- a/core/src/main/java/com/graphhopper/routing/util/FootFlagEncoder.java
+++ b/core/src/main/java/com/graphhopper/routing/util/FootFlagEncoder.java
@@ -93,7 +93,9 @@ public FootFlagEncoder(int speedBits, double speedFactor) {
         sidewalkValues.add("right");
 
         setBlockByDefault(false);
+        absoluteBarriers.add("fence");
         potentialBarriers.add("gate");
+        potentialBarriers.add("cattle_grid");
 
         safeHighwayTags.add("footway");
         safeHighwayTags.add("path");
diff --git a/core/src/main/java/com/graphhopper/routing/util/spatialrules/SpatialRuleLookupBuilder.java b/core/src/main/java/com/graphhopper/routing/util/spatialrules/SpatialRuleLookupBuilder.java
index 3cd31c3e89..07dcbb99a0 100644
--- a/core/src/main/java/com/graphhopper/routing/util/spatialrules/SpatialRuleLookupBuilder.java
+++ b/core/src/main/java/com/graphhopper/routing/util/spatialrules/SpatialRuleLookupBuilder.java
@@ -4,7 +4,7 @@
 import com.graphhopper.json.geo.JsonFeatureCollection;
 import com.graphhopper.util.shapes.BBox;
 import com.graphhopper.util.shapes.Polygon;
-import com.vividsolutions.jts.geom.Geometry;
+import org.locationtech.jts.geom.Geometry;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -51,8 +51,8 @@ public static SpatialRuleLookup buildIndex(JsonFeatureCollection jsonFeatureColl
             List<Polygon> borders = new ArrayList<>();
             for (int i = 0; i < jsonFeature.getGeometry().getNumGeometries(); i++) {
                 Geometry poly = jsonFeature.getGeometry().getGeometryN(i);
-                if (poly instanceof com.vividsolutions.jts.geom.Polygon)
-                    borders.add(Polygon.create((com.vividsolutions.jts.geom.Polygon) poly));
+                if (poly instanceof org.locationtech.jts.geom.Polygon)
+                    borders.add(Polygon.create((org.locationtech.jts.geom.Polygon) poly));
                 else
                     throw new IllegalArgumentException("Geometry for " + id + " (" + i + ") not supported " + poly.getClass().getSimpleName());
             }
diff --git a/core/src/main/java/com/graphhopper/storage/GraphEdgeIdFinder.java b/core/src/main/java/com/graphhopper/storage/GraphEdgeIdFinder.java
index fea30d5225..c79a854572 100644
--- a/core/src/main/java/com/graphhopper/storage/GraphEdgeIdFinder.java
+++ b/core/src/main/java/com/graphhopper/storage/GraphEdgeIdFinder.java
@@ -29,7 +29,7 @@
 import com.graphhopper.util.shapes.Circle;
 import com.graphhopper.util.shapes.GHPoint;
 import com.graphhopper.util.shapes.Shape;
-import com.vividsolutions.jts.geom.*;
+import org.locationtech.jts.geom.*;
 
 import java.util.ArrayList;
 import java.util.List;
diff --git a/core/src/main/java/com/graphhopper/storage/GraphHopperStorage.java b/core/src/main/java/com/graphhopper/storage/GraphHopperStorage.java
index 78f6620161..c80ddf64c9 100644
--- a/core/src/main/java/com/graphhopper/storage/GraphHopperStorage.java
+++ b/core/src/main/java/com/graphhopper/storage/GraphHopperStorage.java
@@ -25,10 +25,7 @@
 import com.graphhopper.util.EdgeIteratorState;
 import com.graphhopper.util.shapes.BBox;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
+import java.util.*;
 
 /**
  * This class manages all storage related methods and delegates the calls to the associated graphs.
@@ -248,10 +245,7 @@ public boolean loadExisting() {
             String dim = properties.get("graph.dimension");
             baseGraph.loadExisting(dim);
 
-            String loadedCHWeightings = properties.get("graph.ch.weightings");
-            String configuredCHWeightings = getCHWeightings().toString();
-            if (!loadedCHWeightings.equals(configuredCHWeightings))
-                throw new IllegalStateException("Configured graph.ch.weightings: " + configuredCHWeightings + " is not equal to loaded " + loadedCHWeightings);
+            checkIfConfiguredAndLoadedWeightingsCompatible();
 
             for (CHGraphImpl cg : chGraphs) {
                 if (!cg.loadExisting())
@@ -263,6 +257,37 @@ public boolean loadExisting() {
         return false;
     }
 
+    private void checkIfConfiguredAndLoadedWeightingsCompatible() {
+        String loadedStr = properties.get("graph.ch.weightings");
+        List<String> loaded = parseList(loadedStr);
+        List<Weighting> configured = getCHWeightings();
+        if (configured.isEmpty() && !loaded.isEmpty()) {
+            throw new IllegalStateException("You loaded a CH graph, but you did not specify graph.ch.weightings");
+        }
+        for (Weighting w : configured) {
+            if (!loaded.contains(w.toString())) {
+                throw new IllegalStateException("Configured weighting: " + w.toString() + " is not contained in loaded weightings " + loadedStr + ".\n" +
+                        "You configured graph.ch.weightings: " + configured);
+            }
+        }
+    }
+
+    /**
+     * parses a string like [a,b,c]
+     */
+    private List<String> parseList(String listStr) {
+        String trimmed = listStr.trim();
+        String[] items = trimmed.substring(1, trimmed.length() - 1).split(",");
+        List<String> result = new ArrayList<>();
+        for (String item : items) {
+            String s = item.trim();
+            if (!s.isEmpty()) {
+                result.add(s);
+            }
+        }
+        return result;
+    }
+
     @Override
     public void flush() {
         for (CHGraphImpl cg : chGraphs) {
diff --git a/core/src/main/java/com/graphhopper/util/DistanceCalc2D.java b/core/src/main/java/com/graphhopper/util/DistanceCalc2D.java
index a8562aaf12..c34596ee5a 100644
--- a/core/src/main/java/com/graphhopper/util/DistanceCalc2D.java
+++ b/core/src/main/java/com/graphhopper/util/DistanceCalc2D.java
@@ -19,6 +19,9 @@
 
 import static java.lang.Math.sqrt;
 
+import com.graphhopper.util.shapes.BBox;
+import com.graphhopper.util.shapes.GHPoint;
+
 /**
  * Calculates the distance of two points or one point and an edge in euclidean space.
  * <p>
@@ -44,6 +47,10 @@ public double calcNormalizedDist(double dist) {
         return dist * dist;
     }
 
+    double calcShrinkFactor(double a_lat_deg, double b_lat_deg) {
+        return 1.;
+    }
+
     /**
      * Calculates in normalized meter
      */
@@ -58,4 +65,30 @@ public double calcNormalizedDist(double fromY, double fromX, double toY, double
     public String toString() {
         return "2D";
     }
+
+    @Override
+    public double calcCircumference(double lat) {
+        throw new UnsupportedOperationException("Not supported for the 2D Euclidean space");
+    }
+
+    @Override
+    public boolean isDateLineCrossOver(double lon1, double lon2) {
+        throw new UnsupportedOperationException("Not supported for the 2D Euclidean space");
+    }
+
+    @Override
+    public BBox createBBox(double lat, double lon, double radiusInMeter) {
+        throw new UnsupportedOperationException("Not supported for the 2D Euclidean space");
+    }
+
+    @Override
+    public GHPoint projectCoordinate(double latInDeg, double lonInDeg, double distanceInMeter,
+            double headingClockwiseFromNorth) {
+        throw new UnsupportedOperationException("Not supported for the 2D Euclidean space");
+    }
+
+    @Override
+    public boolean isCrossBoundary(double lon1, double lon2) {
+        throw new UnsupportedOperationException("Not supported for the 2D Euclidean space");
+    }
 }
diff --git a/core/src/main/resources/com/graphhopper/util/it.txt b/core/src/main/resources/com/graphhopper/util/it.txt
index b298978fc9..45593d315b 100644
--- a/core/src/main/resources/com/graphhopper/util/it.txt
+++ b/core/src/main/resources/com/graphhopper/util/it.txt
@@ -8,11 +8,11 @@ turn_slight_left=gira leggermente a sinistra
 turn_slight_right=gira leggermente a destra
 turn_sharp_left=gira nettamente a sinistra
 turn_sharp_right=gira nettamente a destra
-keep_left=
-keep_right=
+keep_left=tieni la sinistra
+keep_right=tieni la destra
 turn_onto=%1$s su %2$s
-u_turn=
-unknown=
+u_turn=fai una inversione a U
+unknown=sconosciuto %1$s
 web.search_button=Ricerca
 web.from_hint=Da
 web.via_hint=attraverso
@@ -20,8 +20,8 @@ web.to_hint=A
 web.more_button=altro
 web.gpx_export_button=Esporta GPX
 web.route_info=%1$s in %2$s
-web.pt_route_info=
-web.pt_route_info_walking=
+web.pt_route_info=arrivato alle %1$s con %2$s trasferimenti (%3$s)
+web.pt_route_info_walking=arrivato alle %1$s solocamminando (%2$s)
 web.locations_not_found=Percorso non calcolabile. Località non trovata(e) nell'area.
 web.bike=Bicicletta
 web.racingbike=Bici da corsa
@@ -56,10 +56,10 @@ roundabout_exit=Nella rotatoria, prendere l'uscita %1$s
 roundabout_exit_onto=Nella rotatoria, prendere l'uscita %1$s su %2$s
 total_ascend=%1$s di dislivello positivo
 total_descend=%1$s di dislivello negativo
-way_contains_ford=
-pt_start_trip=
-pt_end_trip=
-pt_transfer_to=
+way_contains_ford=c'é un guado sulla strada
+pt_start_trip=prendi %1$s
+pt_end_trip=lascia %1$s
+pt_transfer_to=cambia con %1$s
 web.start_label=Partenza
 web.intermediate_label=Punto intermedio
 web.end_label=Arrivo
diff --git a/core/src/main/resources/com/graphhopper/util/sk.txt b/core/src/main/resources/com/graphhopper/util/sk.txt
index a263e96c82..c1450f93b1 100644
--- a/core/src/main/resources/com/graphhopper/util/sk.txt
+++ b/core/src/main/resources/com/graphhopper/util/sk.txt
@@ -21,7 +21,7 @@ web.more_button=viac
 web.gpx_export_button=Export do GPX
 web.route_info=%1$s zaberie %2$s
 web.pt_route_info=
-web.pt_route_info_walking=
+web.pt_route_info_walking=príchod o %1$s iba chôdzou (%2$s)
 web.locations_not_found=Navigovanie nie je možné. Umiestnenie nebolo nájdené v oblasti.
 web.bike=Bicykel
 web.racingbike=Cestný bicykel
@@ -56,10 +56,10 @@ roundabout_exit=Na kruhovom objazde, ho opustite cez %1$s. výjazd
 roundabout_exit_onto=Na kruhovom objazde, ho opustite cez %1$s. výjazd na %2$s
 total_ascend=%1$s celkové stúpanie
 total_descend=%1$s celkové klesanie
-way_contains_ford=
-pt_start_trip=
-pt_end_trip=
-pt_transfer_to=
+way_contains_ford=popri ceste sa nachádza brod
+pt_start_trip=nastúpte na linku %1$s
+pt_end_trip=vystúpte z linky %1$s
+pt_transfer_to=prestúpte na linku %1$s
 web.start_label=Začiatok
 web.intermediate_label=Bod trasy
 web.end_label=Koniec
diff --git a/core/src/test/java/com/graphhopper/routing/DijkstraBidirectionCHTest.java b/core/src/test/java/com/graphhopper/routing/DijkstraBidirectionCHTest.java
index 3be22f30f0..d8bd400fee 100644
--- a/core/src/test/java/com/graphhopper/routing/DijkstraBidirectionCHTest.java
+++ b/core/src/test/java/com/graphhopper/routing/DijkstraBidirectionCHTest.java
@@ -58,8 +58,7 @@ protected GraphHopperStorage createGHStorage(EncodingManager em,
     @Override
     public RoutingAlgorithmFactory createFactory(GraphHopperStorage ghStorage, AlgorithmOptions opts) {
         PrepareContractionHierarchies ch = new PrepareContractionHierarchies(new GHDirectory("", DAType.RAM_INT),
-                ghStorage, getGraph(ghStorage, opts.getWeighting()),
-                opts.getWeighting(), TraversalMode.NODE_BASED);
+                ghStorage, getGraph(ghStorage, opts.getWeighting()), TraversalMode.NODE_BASED);
         ch.doWork();
         return ch;
     }
@@ -106,7 +105,7 @@ public void testPathRecursiveUnpacking() {
 
         AlgorithmOptions opts = new AlgorithmOptions(Parameters.Algorithms.DIJKSTRA_BI, weighting);
         Path p = new PrepareContractionHierarchies(new GHDirectory("", DAType.RAM_INT),
-                ghStorage, g2, weighting, TraversalMode.NODE_BASED).
+                ghStorage, g2, TraversalMode.NODE_BASED).
                 createAlgo(g2, opts).calcPath(0, 7);
 
         assertEquals(IntArrayList.from(0, 2, 5, 7), p.calcNodes());
@@ -262,7 +261,7 @@ private void runTestWithDirectionDependentEdgeSpeed(
 
     private RoutingAlgorithm createCHAlgo(GraphHopperStorage graph, CHGraph chGraph, boolean withSOD, AlgorithmOptions algorithmOptions) {
         PrepareContractionHierarchies ch = new PrepareContractionHierarchies(new GHDirectory("", DAType.RAM_INT),
-                graph, chGraph, algorithmOptions.getWeighting(), TraversalMode.NODE_BASED);
+                graph, chGraph, TraversalMode.NODE_BASED);
         if (!withSOD) {
             algorithmOptions.getHints().put("stall_on_demand", false);
         }
diff --git a/core/src/test/java/com/graphhopper/routing/ch/NodeBasedNodeContractorTest.java b/core/src/test/java/com/graphhopper/routing/ch/NodeBasedNodeContractorTest.java
index 2b56086672..6f67fbd5be 100644
--- a/core/src/test/java/com/graphhopper/routing/ch/NodeBasedNodeContractorTest.java
+++ b/core/src/test/java/com/graphhopper/routing/ch/NodeBasedNodeContractorTest.java
@@ -26,6 +26,7 @@
 import com.graphhopper.util.CHEdgeIteratorState;
 import com.graphhopper.util.EdgeIterator;
 import com.graphhopper.util.EdgeIteratorState;
+import com.graphhopper.util.PMap;
 import org.junit.Before;
 import org.junit.Test;
 
@@ -51,7 +52,7 @@ public void setUp() {
     }
 
     private NodeContractor createNodeContractor() {
-        NodeContractor nodeContractor = new NodeBasedNodeContractor(dir, graph, lg, weighting);
+        NodeContractor nodeContractor = new NodeBasedNodeContractor(dir, graph, lg, weighting, new PMap());
         nodeContractor.initFromGraph();
         nodeContractor.prepareContraction();
         return nodeContractor;
diff --git a/core/src/test/java/com/graphhopper/routing/ch/PrepareContractionHierarchiesTest.java b/core/src/test/java/com/graphhopper/routing/ch/PrepareContractionHierarchiesTest.java
index 104132d0bd..4fe487a03a 100644
--- a/core/src/test/java/com/graphhopper/routing/ch/PrepareContractionHierarchiesTest.java
+++ b/core/src/test/java/com/graphhopper/routing/ch/PrepareContractionHierarchiesTest.java
@@ -150,12 +150,20 @@ public void setUp() {
         dir = new GHDirectory("", DAType.RAM_INT);
     }
 
+    @Test
+    public void testReturnsCorrectWeighting() {
+        GraphHopperStorage g = createGHStorage();
+        CHGraph lg = g.getGraph(CHGraph.class);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
+        assertSame(weighting, prepare.getWeighting());
+    }
+    
     @Test
     public void testAddShortcuts() {
         GraphHopperStorage g = createExampleGraph();
         CHGraph lg = g.getGraph(CHGraph.class);
         int old = lg.getAllEdges().length();
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(old + 2, lg.getAllEdges().length());
     }
@@ -166,7 +174,7 @@ public void testMoreComplexGraph() {
         CHGraph lg = g.getGraph(CHGraph.class);
         initShortcutsGraph(lg);
         int oldCount = g.getAllEdges().length();
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(oldCount, g.getAllEdges().length());
         assertEquals(oldCount + 7, lg.getAllEdges().length());
@@ -185,14 +193,14 @@ public void testDirectedGraph() {
         g.freeze();
         int oldCount = GHUtility.count(lg.getAllEdges());
         assertEquals(6, oldCount);
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(2, prepare.getShortcuts());
         assertEquals(oldCount + 2, GHUtility.count(lg.getAllEdges()));
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, weighting, tMode));
         Path p = algo.calcPath(4, 2);
         assertEquals(3, p.getDistance(), 1e-6);
-        assertEquals(IntArrayList.from(new int[]{4, 3, 5, 2}), p.calcNodes());
+        assertEquals(IntArrayList.from(4, 3, 5, 2), p.calcNodes());
     }
 
     @Test
@@ -202,7 +210,7 @@ public void testDirectedGraph2() {
         initDirected2(g);
         int oldCount = GHUtility.count(g.getAllEdges());
         assertEquals(19, oldCount);
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         // PrepareTowerNodesShortcutsTest.printEdges(g);
         assertEquals(oldCount, g.getAllEdges().length());
@@ -215,7 +223,7 @@ public void testDirectedGraph2() {
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, weighting, tMode));
         Path p = algo.calcPath(0, 10);
         assertEquals(10, p.getDistance(), 1e-6);
-        assertEquals(IntArrayList.from(new int[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}), p.calcNodes());
+        assertEquals(IntArrayList.from(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), p.calcNodes());
     }
 
     void initRoundaboutGraph(Graph g) {
@@ -275,13 +283,13 @@ public void testRoundaboutUnpacking() {
         CHGraph lg = g.getGraph(CHGraph.class);
         initRoundaboutGraph(g);
         int oldCount = g.getAllEdges().length();
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(oldCount, g.getAllEdges().length());
         assertEquals(oldCount + 23, lg.getAllEdges().length());
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, weighting, tMode));
         Path p = algo.calcPath(4, 7);
-        assertEquals(IntArrayList.from(new int[]{4, 5, 6, 7}), p.calcNodes());
+        assertEquals(IntArrayList.from(4, 5, 6, 7), p.calcNodes());
     }
 
     void initUnpackingGraph(GraphHopperStorage ghStorage, CHGraph g, Weighting w) {
@@ -334,11 +342,11 @@ public void testUnpackingOrder() {
         GraphHopperStorage ghStorage = createGHStorage();
         CHGraph lg = ghStorage.getGraph(CHGraph.class);
         initUnpackingGraph(ghStorage, lg, weighting);
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, tMode);
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, weighting, tMode));
         Path p = algo.calcPath(10, 6);
         assertEquals(7, p.getDistance(), 1e-5);
-        assertEquals(IntArrayList.from(new int[]{10, 0, 1, 2, 3, 4, 5, 6}), p.calcNodes());
+        assertEquals(IntArrayList.from(10, 0, 1, 2, 3, 4, 5, 6), p.calcNodes());
     }
 
     @Test
@@ -348,11 +356,11 @@ public void testUnpackingOrder_Fastest() {
         Weighting w = new FastestWeighting(carEncoder);
         initUnpackingGraph(ghStorage, lg, w);
 
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, tMode);
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, weighting, tMode));
         Path p = algo.calcPath(10, 6);
         assertEquals(7, p.getDistance(), 1e-1);
-        assertEquals(IntArrayList.from(new int[]{10, 0, 1, 2, 3, 4, 5, 6}), p.calcNodes());
+        assertEquals(IntArrayList.from(10, 0, 1, 2, 3, 4, 5, 6), p.calcNodes());
     }
 
     @Test
@@ -366,7 +374,7 @@ public void testCircleBug() {
         g.edge(0, 1, 4, true);
         g.edge(0, 2, 10, true);
         g.edge(0, 3, 10, true);
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(0, prepare.getShortcuts());
     }
@@ -390,7 +398,7 @@ public void testBug178() {
         g.edge(3, 4, 1, true);
         g.edge(6, 3, 1, true);
 
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, weighting, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, g, lg, tMode);
         prepare.doWork();
         assertEquals(2, prepare.getShortcuts());
     }
@@ -452,7 +460,7 @@ public void testMultiplePreparationsIdenticalView() {
         ghStorage.freeze();
 
         for (Weighting w : chWeightings) {
-            checkPath(ghStorage, w, 7, 5, IntArrayList.from(new int[]{3, 9, 14, 16, 13, 12}));
+            checkPath(ghStorage, w, 7, 5, IntArrayList.from(3, 9, 14, 16, 13, 12));
         }
     }
 
@@ -473,14 +481,14 @@ public void testMultiplePreparationsDifferentView() {
 
         ghStorage.freeze();
 
-        checkPath(ghStorage, carWeighting, 7, 5, IntArrayList.from(new int[]{3, 9, 14, 16, 13, 12}));
+        checkPath(ghStorage, carWeighting, 7, 5, IntArrayList.from(3, 9, 14, 16, 13, 12));
         // detour around blocked 9,14
-        checkPath(ghStorage, bikeWeighting, 9, 5, IntArrayList.from(new int[]{3, 10, 14, 16, 13, 12}));
+        checkPath(ghStorage, bikeWeighting, 9, 5, IntArrayList.from(3, 10, 14, 16, 13, 12));
     }
 
     void checkPath(GraphHopperStorage ghStorage, Weighting w, int expShortcuts, double expDistance, IntIndexedContainer expNodes) {
         CHGraph lg = ghStorage.getGraph(CHGraph.class, w);
-        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, w, tMode);
+        PrepareContractionHierarchies prepare = new PrepareContractionHierarchies(dir, ghStorage, lg, tMode);
         prepare.doWork();
         assertEquals(w.toString(), expShortcuts, prepare.getShortcuts());
         RoutingAlgorithm algo = prepare.createAlgo(lg, new AlgorithmOptions(DIJKSTRA_BI, w, tMode));
diff --git a/core/src/test/java/com/graphhopper/routing/util/BikeFlagEncoderTest.java b/core/src/test/java/com/graphhopper/routing/util/BikeFlagEncoderTest.java
index 7d477f87cc..1d3de518f8 100644
--- a/core/src/test/java/com/graphhopper/routing/util/BikeFlagEncoderTest.java
+++ b/core/src/test/java/com/graphhopper/routing/util/BikeFlagEncoderTest.java
@@ -645,6 +645,11 @@ public void testBarrierAccess() {
         node.setTag("bicycle", "yes");
         // barrier!
         assertFalse(encoder.handleNodeTags(node) == 0);
+
+        // Test if cattle_grid is non blocking
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "cattle_grid");
+        assertTrue(encoder.handleNodeTags(node) == 0);
     }
 
     @Test
diff --git a/core/src/test/java/com/graphhopper/routing/util/CarFlagEncoderTest.java b/core/src/test/java/com/graphhopper/routing/util/CarFlagEncoderTest.java
index 3e18ee644b..29b4c2eec6 100644
--- a/core/src/test/java/com/graphhopper/routing/util/CarFlagEncoderTest.java
+++ b/core/src/test/java/com/graphhopper/routing/util/CarFlagEncoderTest.java
@@ -501,6 +501,13 @@ public void testBarrierAccess() {
         node.setTag("motorcar", "yes");
         // still barrier!
         assertTrue(encoder.handleNodeTags(node) > 0);
+
+        encoder.setBlockByDefault(false);
+
+        // Test if cattle_grid is not blocking
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "cattle_grid");
+        assertTrue(encoder.handleNodeTags(node) == 0);
     }
 
     @Test
diff --git a/core/src/test/java/com/graphhopper/routing/util/FootFlagEncoderTest.java b/core/src/test/java/com/graphhopper/routing/util/FootFlagEncoderTest.java
index 0dd1ec075a..fea5fd56bf 100644
--- a/core/src/test/java/com/graphhopper/routing/util/FootFlagEncoderTest.java
+++ b/core/src/test/java/com/graphhopper/routing/util/FootFlagEncoderTest.java
@@ -377,6 +377,7 @@ public void handleWayTagsCircularJunction() {
         assertTrue(footEncoder.isBool(flags, FlagEncoder.K_ROUNDABOUT));
     }
 
+    @Test
     public void testFord() {
         // by default deny access through fords!
         ReaderNode node = new ReaderNode(1, -1, -1);
@@ -402,4 +403,45 @@ public void testFord() {
         node.setTag("ford", "yes");
         assertTrue(footEncoder.handleNodeTags(node) == 0);
     }
+
+    @Test
+    public void testBlockByDefault() {
+        FootFlagEncoder tmpFootEncoder = new FootFlagEncoder();
+        new EncodingManager(tmpFootEncoder);
+
+        ReaderNode node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "gate");
+        // potential barriers are no barrier by default
+        assertTrue(tmpFootEncoder.handleNodeTags(node) == 0);
+        node.setTag("access", "no");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) > 0);
+
+        // absolute barriers always block
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "fence");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) > 0);
+        node.setTag("barrier", "fence");
+        node.setTag("access", "yes");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) > 0);
+
+        // Now let's block potential barriers per default (if no other access tag exists)
+        tmpFootEncoder.setBlockByDefault(true);
+
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "gate");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) > 0);
+        node.setTag("access", "yes");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) == 0);
+
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "fence");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) > 0);
+
+        // Let's stop block potential barriers to test if barrier:cattle_grid is non blocking
+        tmpFootEncoder.setBlockByDefault(false);
+
+        node = new ReaderNode(1, -1, -1);
+        node.setTag("barrier", "cattle_grid");
+        assertTrue(tmpFootEncoder.handleNodeTags(node) == 0);
+    }
 }
diff --git a/core/src/test/java/com/graphhopper/storage/GraphHopperStorageCHTest.java b/core/src/test/java/com/graphhopper/storage/GraphHopperStorageCHTest.java
index 6336dc4465..717673d7eb 100644
--- a/core/src/test/java/com/graphhopper/storage/GraphHopperStorageCHTest.java
+++ b/core/src/test/java/com/graphhopper/storage/GraphHopperStorageCHTest.java
@@ -21,6 +21,7 @@
 import com.graphhopper.routing.ch.PrepareEncoder;
 import com.graphhopper.routing.util.*;
 import com.graphhopper.routing.weighting.FastestWeighting;
+import com.graphhopper.routing.weighting.ShortestWeighting;
 import com.graphhopper.routing.weighting.Weighting;
 import com.graphhopper.storage.index.QueryResult;
 import com.graphhopper.util.*;
@@ -252,7 +253,7 @@ public void testQueryGraph() {
         EdgeExplorer explorer = baseGraph.createEdgeExplorer();
 
         assertTrue(chGraph.getNodes() < qGraph.getNodes());
-        assertTrue(baseGraph.getNodes() == qGraph.getNodes());
+        assertEquals(baseGraph.getNodes(), qGraph.getNodes());
 
         // traverse virtual edges and normal edges but no shortcuts!
         assertEquals(GHUtility.asSet(fromRes.getClosestNode()), GHUtility.getNeighbors(explorer.setBaseNode(0)));
@@ -414,7 +415,7 @@ public void testShortcutCreationAndAccessForManyVehicles() {
         // throw exception for wrong encoder
         try {
             assertFalse(carCHGraph.getEdgeIteratorState(carSC02.getEdge(), 2).isForward(tmpBike));
-            assertTrue(false);
+            fail();
         } catch (AssertionError ex) {
         }
 
@@ -425,8 +426,60 @@ public void testShortcutCreationAndAccessForManyVehicles() {
         // throw exception for wrong encoder
         try {
             assertFalse(bikeCHGraph.getEdgeIteratorState(bikeSC02.getEdge(), 2).isBackward(tmpCar));
-            assertTrue(false);
+            fail();
         } catch (AssertionError ex) {
         }
     }
+
+    @Test(expected = IllegalStateException.class)
+    public void testLoadingWithWrongWeighting_throws() {
+        // we start with one weighting
+        GraphHopperStorage ghStorage = newGHStorage(new GHDirectory(defaultGraphLoc, DAType.RAM_STORE), false);
+        ghStorage.create(defaultSize);
+        ghStorage.flush();
+
+        // but then configure another weighting and try to load the graph from disk -> error
+        GraphHopperStorage newGHStorage = createStorageWithWeightings(new ShortestWeighting(carEncoder));
+        newGHStorage.loadExisting();
+    }
+
+    @Test(expected = IllegalStateException.class)
+    public void testLoadingWithExtraWeighting_throws() {
+        // we start with one weighting
+        GraphHopperStorage ghStorage = newGHStorage(new GHDirectory(defaultGraphLoc, DAType.RAM_STORE), false);
+        ghStorage.create(defaultSize);
+        ghStorage.flush();
+
+        // but then add an additional weighting and try to load the graph from disk -> error
+        GraphHopperStorage newGHStorage = createStorageWithWeightings(
+                new FastestWeighting(carEncoder), new ShortestWeighting(carEncoder));
+        newGHStorage.loadExisting();
+    }
+
+    @Test
+    public void testLoadingWithLessWeightings_works() {
+        // we start with a gh storage with two ch weightings and flush it to disk
+        FastestWeighting weighting1 = new FastestWeighting(carEncoder);
+        ShortestWeighting weighting2 = new ShortestWeighting(carEncoder);
+        GraphHopperStorage originalStorage = createStorageWithWeightings(weighting1, weighting2);
+        originalStorage.create(defaultSize);
+        originalStorage.flush();
+
+        // now we create a new storage but only use one of the weightings, which should be ok
+        GraphHopperStorage smallStorage = createStorageWithWeightings(weighting1);
+        smallStorage.loadExisting();
+        assertEquals(1, smallStorage.getCHWeightings().size());
+        smallStorage.flush();
+
+        // now we create yet another storage that uses both weightings again, which still works
+        GraphHopperStorage fullStorage = createStorageWithWeightings(weighting1, weighting2);
+        fullStorage.loadExisting();
+        assertEquals(2, fullStorage.getCHWeightings().size());
+        fullStorage.flush();
+    }
+
+    private GraphHopperStorage createStorageWithWeightings(Weighting... weightings) {
+        return new GraphHopperStorage(Arrays.asList(weightings), new GHDirectory(defaultGraphLoc, DAType.RAM_STORE),
+                encodingManager, false, new GraphExtension.NoOpExtension());
+    }
 }
diff --git a/core/src/test/java/com/graphhopper/util/DistanceCalc2DTest.java b/core/src/test/java/com/graphhopper/util/DistanceCalc2DTest.java
new file mode 100644
index 0000000000..6ce67951cd
--- /dev/null
+++ b/core/src/test/java/com/graphhopper/util/DistanceCalc2DTest.java
@@ -0,0 +1,51 @@
+/*
+ *  Licensed to GraphHopper GmbH under one or more contributor
+ *  license agreements. See the NOTICE file distributed with this work for
+ *  additional information regarding copyright ownership.
+ *
+ *  GraphHopper GmbH licenses this file to you under the Apache License,
+ *  Version 2.0 (the "License"); you may not use this file except in
+ *  compliance with the License. You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an "AS IS" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package com.graphhopper.util;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import com.graphhopper.util.shapes.GHPoint;
+
+public class DistanceCalc2DTest {
+
+    @Test
+    public void testCrossingPointToEdge() {
+        DistanceCalc2D distanceCalc = new DistanceCalc2D();
+        GHPoint point = distanceCalc.calcCrossingPointToEdge(0, 10, 0, 0, 10, 10);
+        Assert.assertEquals(5, point.getLat(), 0);
+        Assert.assertEquals(5, point.getLon(), 0);
+    }
+
+    @Test
+    public void testCalcNormalizedEdgeDistance() {
+        DistanceCalc2D distanceCalc = new DistanceCalc2D();
+        double distance = distanceCalc.calcNormalizedEdgeDistance(0, 10, 0, 0, 10, 10);
+        Assert.assertEquals(50, distance, 0);
+    }
+
+    @Test
+    public void testValidEdgeDistance() {
+        DistanceCalc2D distanceCalc = new DistanceCalc2D();
+        boolean validEdgeDistance = distanceCalc.validEdgeDistance(5, 15, 0, 0, 10, 10);
+        Assert.assertEquals(false, validEdgeDistance);
+        validEdgeDistance = distanceCalc.validEdgeDistance(15, 5, 0, 0, 10, 10);
+        Assert.assertEquals(false, validEdgeDistance);
+    }
+}
diff --git a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/ContourBuilder.java b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/ContourBuilder.java
index 593c24a68a..ae612cba4b 100644
--- a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/ContourBuilder.java
+++ b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/ContourBuilder.java
@@ -13,10 +13,10 @@
 
 package com.graphhopper.isochrone.algorithm;
 
-import com.vividsolutions.jts.algorithm.CGAlgorithms;
-import com.vividsolutions.jts.geom.*;
-import com.vividsolutions.jts.triangulate.quadedge.QuadEdge;
-import com.vividsolutions.jts.triangulate.quadedge.QuadEdgeSubdivision;
+import org.locationtech.jts.algorithm.CGAlgorithms;
+import org.locationtech.jts.geom.*;
+import org.locationtech.jts.triangulate.quadedge.QuadEdge;
+import org.locationtech.jts.triangulate.quadedge.QuadEdgeSubdivision;
 
 import java.util.*;
 
@@ -40,7 +40,7 @@ public ContourBuilder(QuadEdgeSubdivision triangulation) {
         this.triangulation = triangulation;
     }
 
-    public Geometry computeIsoline(double z0) {
+    public MultiPolygon computeIsoline(double z0) {
         Set<QuadEdge> processed = new HashSet<>();
         List<LinearRing> rings = new ArrayList<>();
 
@@ -107,8 +107,8 @@ private Coordinate moveEpsilonTowards(Coordinate coordinate, Coordinate distantF
     }
 
     private int cut(double za, double zb, double z0) {
-        if (za < z0 && zb > z0) return 1;
-        if (za > z0 && zb < z0) return -1;
+        if (za <= z0 && zb > z0) return 1;
+        if (za > z0 && zb <= z0) return -1;
         return 0;
     }
 
diff --git a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilder.java b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilder.java
new file mode 100644
index 0000000000..75b66bcca4
--- /dev/null
+++ b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilder.java
@@ -0,0 +1,87 @@
+/*
+ *  Licensed to GraphHopper GmbH under one or more contributor
+ *  license agreements. See the NOTICE file distributed with this work for
+ *  additional information regarding copyright ownership.
+ *
+ *  GraphHopper GmbH licenses this file to you under the Apache License,
+ *  Version 2.0 (the "License"); you may not use this file except in
+ *  compliance with the License. You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an "AS IS" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+package com.graphhopper.isochrone.algorithm;
+
+import org.locationtech.jts.geom.*;
+import org.locationtech.jts.triangulate.ConformingDelaunayTriangulator;
+import org.locationtech.jts.triangulate.ConstraintVertex;
+import org.locationtech.jts.triangulate.quadedge.QuadEdgeSubdivision;
+import org.locationtech.jts.triangulate.quadedge.Vertex;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+/**
+ * @author Peter Karich
+ * @author Michael Zilske
+ */
+public class DelaunayTriangulationIsolineBuilder {
+
+    /**
+     * @return a list of polygons wrapping the specified points
+     */
+    @SuppressWarnings("unchecked")
+    public List<Coordinate[]> calcList(List<List<Coordinate>> pointLists, int maxIsolines) {
+
+        if (maxIsolines > pointLists.size()) {
+            throw new IllegalStateException("maxIsolines can only be smaller or equals to pointsList");
+        }
+
+        Collection<ConstraintVertex> sites = new ArrayList<>();
+        for (int i = 0; i < pointLists.size(); i++) {
+            List<Coordinate> level = pointLists.get(i);
+            for (Coordinate coord : level) {
+                ConstraintVertex site = new ConstraintVertex(coord);
+                site.setZ((double) i);
+                sites.add(site);
+            }
+        }
+        ConformingDelaunayTriangulator conformingDelaunayTriangulator = new ConformingDelaunayTriangulator(sites, 0.0);
+        conformingDelaunayTriangulator.setConstraints(new ArrayList(), new ArrayList());
+        conformingDelaunayTriangulator.formInitialDelaunay();
+        QuadEdgeSubdivision tin = conformingDelaunayTriangulator.getSubdivision();
+        for (Vertex vertex : (Collection<Vertex>) tin.getVertices(true)) {
+            if (tin.isFrameVertex(vertex)) {
+                vertex.setZ(Double.MAX_VALUE);
+            }
+        }
+        ArrayList<Coordinate[]> polygonShells = new ArrayList<>();
+        ContourBuilder contourBuilder = new ContourBuilder(tin);
+        // ignore the last isoline as it forms just the convex hull
+        for (int i = 0; i < maxIsolines; i++) {
+            MultiPolygon multiPolygon = contourBuilder.computeIsoline((double) i + 0.5);
+            int maxPoints = 0;
+            Polygon maxPolygon = null;
+            for (int j = 0; j < multiPolygon.getNumGeometries(); j++) {
+                Polygon polygon = (Polygon) multiPolygon.getGeometryN(j);
+                if (polygon.getNumPoints() > maxPoints) {
+                    maxPoints = polygon.getNumPoints();
+                    maxPolygon = polygon;
+                }
+            }
+            if (maxPolygon == null) {
+                throw new IllegalStateException("no maximum polygon was found?");
+            } else {
+                polygonShells.add(maxPolygon.getExteriorRing().getCoordinates());
+            }
+        }
+        return polygonShells;
+    }
+
+}
diff --git a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/Isochrone.java b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/Isochrone.java
index 771191ad39..abb378ba53 100644
--- a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/Isochrone.java
+++ b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/Isochrone.java
@@ -29,6 +29,7 @@
 import com.graphhopper.storage.SPTEntry;
 import com.graphhopper.util.EdgeExplorer;
 import com.graphhopper.util.EdgeIterator;
+import org.locationtech.jts.geom.Coordinate;
 
 import java.util.*;
 
@@ -102,14 +103,14 @@ public void setDistanceLimit(double limit) {
         this.finishLimit = limit + Math.max(limit * 0.14, 2_000);
     }
 
-    public List<List<Double[]>> searchGPS(int from, final int bucketCount) {
+    public List<List<Coordinate>> searchGPS(int from, final int bucketCount) {
         searchInternal(from);
 
         final double bucketSize = limit / bucketCount;
-        final List<List<Double[]>> buckets = new ArrayList<>(bucketCount);
+        final List<List<Coordinate>> buckets = new ArrayList<>(bucketCount);
 
         for (int i = 0; i < bucketCount + 1; i++) {
-            buckets.add(new ArrayList<Double[]>());
+            buckets.add(new ArrayList<Coordinate>());
         }
         final NodeAccess na = graph.getNodeAccess();
         fromMap.forEach(new IntObjectProcedure<IsoLabel>() {
@@ -125,14 +126,14 @@ public void apply(int nodeId, IsoLabel label) {
 
                 double lat = na.getLatitude(nodeId);
                 double lon = na.getLongitude(nodeId);
-                buckets.get(bucketIndex).add(new Double[]{lon, lat});
+                buckets.get(bucketIndex).add(new Coordinate(lon, lat));
 
                 // guess center of road to increase precision a bit for longer roads
                 if (label.parent != null) {
                     nodeId = label.parent.adjNode;
                     double lat2 = na.getLatitude(nodeId);
                     double lon2 = na.getLongitude(nodeId);
-                    buckets.get(bucketIndex).add(new Double[]{(lon + lon2) / 2, (lat + lat2) / 2});
+                    buckets.get(bucketIndex).add(new Coordinate((lon + lon2) / 2, (lat + lat2) / 2));
                 }
             }
         });
diff --git a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/RasterHullBuilder.java b/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/RasterHullBuilder.java
deleted file mode 100644
index c54f0b7670..0000000000
--- a/isochrone/src/main/java/com/graphhopper/isochrone/algorithm/RasterHullBuilder.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.isochrone.algorithm;
-
-import com.vividsolutions.jts.geom.Coordinate;
-import com.vividsolutions.jts.geom.Geometry;
-import com.vividsolutions.jts.geom.LineString;
-import com.vividsolutions.jts.geom.MultiPolygon;
-import com.vividsolutions.jts.geom.Point;
-import com.vividsolutions.jts.geom.Polygon;
-import com.vividsolutions.jts.triangulate.ConformingDelaunayTriangulator;
-import com.vividsolutions.jts.triangulate.ConstraintVertex;
-import com.vividsolutions.jts.triangulate.quadedge.QuadEdgeSubdivision;
-import com.vividsolutions.jts.triangulate.quadedge.Vertex;
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-
-/**
- * @author Peter Karich
- * @author Michael Zilske
- */
-public class RasterHullBuilder {
-
-    /**
-     * @return a list of polygons wrapping the specified points
-     */
-    @SuppressWarnings("unchecked")
-    public List<List<Double[]>> calcList(List<List<Double[]>> pointsList, int maxIsolines) {
-
-        if (maxIsolines > pointsList.size()) {
-            throw new IllegalStateException("maxIsolines can only be smaller or equals to pointsList");
-        }
-
-        Collection<ConstraintVertex> sites = new ArrayList<>();
-        for (int i = 0; i < pointsList.size(); i++) {
-            List<Double[]> level = pointsList.get(i);
-            for (Double[] xy : level) {
-                ConstraintVertex site = new ConstraintVertex(new Coordinate(xy[0], xy[1]));
-                site.setZ((double) i);
-                sites.add(site);
-            }
-        }
-        ConformingDelaunayTriangulator conformingDelaunayTriangulator = new ConformingDelaunayTriangulator(sites, 0.0);
-        conformingDelaunayTriangulator.setConstraints(new ArrayList(), new ArrayList());
-        conformingDelaunayTriangulator.formInitialDelaunay();
-        QuadEdgeSubdivision tin = conformingDelaunayTriangulator.getSubdivision();
-        for (Vertex vertex : (Collection<Vertex>) tin.getVertices(true)) {
-            if (tin.isFrameVertex(vertex)) {
-                vertex.setZ(Double.MAX_VALUE);
-            }
-        }
-        ArrayList<List<Double[]>> polygons = new ArrayList<>();
-        ContourBuilder contourBuilder = new ContourBuilder(tin);
-        // ignore the last polygon as it forms just the convex hull
-        for (int i = 0; i < maxIsolines; i++) {
-            Geometry geometry = contourBuilder.computeIsoline((double) i + 0.5);
-            List<Double[]> coords = new ArrayList<Double[]>();
-            if (geometry instanceof MultiPolygon) {
-                MultiPolygon mPoly = (MultiPolygon) geometry;
-                int maxPoints = 0;
-                Geometry maxGeo = null;
-                for (int j = 0; j < mPoly.getNumGeometries(); j++) {
-                    Geometry geo = mPoly.getGeometryN(j);
-                    if (geo.getNumPoints() > maxPoints) {
-                        maxPoints = geo.getNumPoints();
-                        maxGeo = geo;
-                    }
-                }
-
-                if (maxGeo == null) {
-                    throw new IllegalStateException("no maximum polygon was found?");
-                } else {
-                    fillExteriorRing(coords, maxGeo);
-                }
-            } else if (geometry instanceof Polygon) {
-                fillExteriorRing(coords, geometry);
-            } else {
-                throw new IllegalStateException("geometry no (multi)polygon");
-            }
-
-            polygons.add(coords);
-        }
-
-        return polygons;
-    }
-
-    private void fillExteriorRing(List<Double[]> coords, Geometry geo) {
-        if (geo instanceof Polygon) {
-            // normally this will be picked
-            Polygon poly = (Polygon) geo;
-            LineString ls = poly.getExteriorRing();
-            for (int j = 0; j < ls.getNumPoints(); j++) {
-                Point p = ls.getPointN(j);
-                coords.add(new Double[]{p.getX(), p.getY()});
-            }
-        } else {
-            int len = geo.getCoordinates().length;
-            Coordinate first = geo.getCoordinates()[0];
-            for (int j = 0; j < len; j++) {
-                Coordinate coord = geo.getCoordinates()[j];
-                // lon, lat
-                coords.add(new Double[]{coord.x, coord.y});
-
-                if (j > 10 && coord.x == first.x && coord.y == first.y) {
-                    break;
-                }
-            }
-        }
-    }
-
-}
diff --git a/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilderTest.java b/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilderTest.java
new file mode 100644
index 0000000000..a03241a981
--- /dev/null
+++ b/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/DelaunayTriangulationIsolineBuilderTest.java
@@ -0,0 +1,32 @@
+package com.graphhopper.isochrone.algorithm;
+
+import java.util.ArrayList;
+import java.util.List;
+import org.junit.Assert;
+import org.junit.Test;
+import org.locationtech.jts.geom.Coordinate;
+
+/**
+ *
+ * @author Peter Karich
+ */
+public class DelaunayTriangulationIsolineBuilderTest {
+
+    @Test
+    public void testCalc() {
+        DelaunayTriangulationIsolineBuilder instance = new DelaunayTriangulationIsolineBuilder();
+        List<List<Coordinate>> listOfList = new ArrayList<>();
+        List<Coordinate> list = new ArrayList<>();
+        listOfList.add(list);
+        // lon,lat!
+        list.add(new Coordinate(0.000, 0.000));
+        list.add(new Coordinate(0.001, 0.000));
+        list.add(new Coordinate(0.001, 0.001));
+        list.add(new Coordinate(0.001, 0.002));
+        list.add(new Coordinate(0.000, 0.002));
+
+        List<Coordinate[]> res = instance.calcList(listOfList, listOfList.size());
+        Coordinate[] geometry = res.get(0);
+        Assert.assertEquals(9, geometry.length);
+    }
+}
diff --git a/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/RasterHullBuilderTest.java b/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/RasterHullBuilderTest.java
deleted file mode 100644
index 98609c3b45..0000000000
--- a/isochrone/src/test/java/com/graphhopper/isochrone/algorithm/RasterHullBuilderTest.java
+++ /dev/null
@@ -1,31 +0,0 @@
-package com.graphhopper.isochrone.algorithm;
-
-import java.util.ArrayList;
-import java.util.List;
-import org.junit.Assert;
-import org.junit.Test;
-
-/**
- *
- * @author Peter Karich
- */
-public class RasterHullBuilderTest {
-
-    @Test
-    public void testCalc() {
-        RasterHullBuilder instance = new RasterHullBuilder();
-        List<List<Double[]>> listOfList = new ArrayList<List<Double[]>>();
-        List<Double[]> list = new ArrayList<Double[]>();
-        listOfList.add(list);
-        // lon,lat!
-        list.add(new Double[]{0.000, 0.000});
-        list.add(new Double[]{0.001, 0.000});
-        list.add(new Double[]{0.001, 0.001});
-        list.add(new Double[]{0.001, 0.002});
-        list.add(new Double[]{0.000, 0.002});
-
-        List<List<Double[]>> res = instance.calcList(listOfList, listOfList.size());
-        List<Double[]> geometry = res.get(0);
-        Assert.assertEquals(9, geometry.size());
-    }
-}
diff --git a/pom.xml b/pom.xml
index 4fde973f8b..518205dc56 100644
--- a/pom.xml
+++ b/pom.xml
@@ -90,7 +90,7 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
+                <version>3.8.0</version>
                 <configuration>
                     <!--
                     <compilerArgument>-Xlint:unchecked</compilerArgument>
@@ -109,7 +109,7 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-surefire-plugin</artifactId>
-                <version>2.19.1</version>
+                <version>2.22.1</version>
                 <configuration>
                     <argLine>-Xmx100m -Xms100m</argLine>
                 </configuration>
@@ -118,7 +118,7 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-failsafe-plugin</artifactId>
-                <version>2.19.1</version>
+                <version>2.22.1</version>
                 <executions>
                     <execution>
                         <goals>
@@ -137,7 +137,7 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-jar-plugin</artifactId>
-                <version>3.0.2</version>
+                <version>3.1.0</version>
             </plugin>
             <!-- example https://github.com/tananaev/traccar/blob/master/checkstyle.xml -->
             <plugin>
@@ -183,7 +183,7 @@
             <plugin>
                 <groupId>de.thetaphi</groupId>
                 <artifactId>forbiddenapis</artifactId>
-                <version>2.5</version>
+                <version>2.6</version>
                 <configuration>
                     <!--
                       if the used Java version is too new,
@@ -228,12 +228,6 @@
             <activation>
                 <activeByDefault>false</activeByDefault>
             </activation>
-            <!-- this exception is valid for jdk8 profile below too -->
-            <modules>
-                <!-- See https://github.com/graphhopper/graphhopper/pull/874#issuecomment-261231518
-                Currently works for jdk8 only -->
-                <module>reader-shp</module>
-            </modules>
             <build>
                 <plugins>
                     <plugin>
@@ -253,7 +247,7 @@
                     <plugin>
                         <groupId>org.sonatype.plugins</groupId>
                         <artifactId>nexus-staging-maven-plugin</artifactId>
-                        <version>1.6.7</version>
+                        <version>1.6.8</version>
                         <extensions>true</extensions>
                         <configuration>
                             <serverId>ossrh</serverId>
@@ -265,7 +259,7 @@
                     <plugin>
                         <groupId>org.apache.maven.plugins</groupId>
                         <artifactId>maven-javadoc-plugin</artifactId>
-                        <version>2.10.4</version>
+                        <version>3.0.1</version>
                         <configuration>
                           <quiet>true</quiet>
                         </configuration>
@@ -303,17 +297,6 @@
                 <module>android/app</module>
             </modules>
         </profile>
-	<profile>
-            <id>jdk10</id>
-            <activation>
-                <activeByDefault>false</activeByDefault>
-                <jdk>10</jdk>
-            </activation>
-            <properties>
-              <maven.compiler.source>10</maven.compiler.source>
-              <maven.compiler.target>10</maven.compiler.target>
-            </properties>
-        </profile>
 
     </profiles>
 
diff --git a/reader-gtfs/pom.xml b/reader-gtfs/pom.xml
index e9963bf3a1..c8be32a98e 100644
--- a/reader-gtfs/pom.xml
+++ b/reader-gtfs/pom.xml
@@ -27,23 +27,24 @@
             <version>${project.parent.version}</version>
         </dependency>
         <dependency>
-            <groupId>com.conveyal</groupId>
-            <artifactId>gtfs-lib</artifactId>
-            <version>2.1.0</version>
-            <exclusions>
-                <exclusion> 
-                    <groupId>org.slf4j</groupId>
-                    <artifactId>slf4j-simple</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>com.vividsolutions</groupId>
-                    <artifactId>jts</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>com.amazonaws</groupId>
-                    <artifactId>aws-java-sdk-s3</artifactId>
-                </exclusion>
-            </exclusions>
+            <groupId>com.google.guava</groupId>
+            <artifactId>guava</artifactId>
+            <version>24.0-jre</version>
+        </dependency>
+        <dependency>
+            <groupId>net.sourceforge.javacsv</groupId>
+            <artifactId>javacsv</artifactId>
+            <version>2.0</version>
+        </dependency>
+        <dependency>
+            <groupId>commons-io</groupId>
+            <artifactId>commons-io</artifactId>
+            <version>2.4</version>
+        </dependency>
+        <dependency>
+            <groupId>org.mapdb</groupId>
+            <artifactId>mapdb</artifactId>
+            <version>1.0.8</version>
         </dependency>
         <dependency>
             <groupId>org.slf4j</groupId>
@@ -96,7 +97,7 @@
         <dependency>
             <groupId>org.mockito</groupId>
             <artifactId>mockito-core</artifactId>
-            <version>1.10.19</version>
+            <version>2.23.0</version>
             <scope>test</scope>
         </dependency>
     </dependencies>
@@ -105,7 +106,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
                 <configuration>
                     <!--
                     <compilerArgument>-Xlint:unchecked</compilerArgument>
@@ -122,10 +122,9 @@
             <plugin>                
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-surefire-plugin</artifactId>
-                <version>2.19.1</version>
                 <!-- Currently we need a bit more memory than for other tests -->
                 <configuration>
-                    <argLine>-Xmx2000m -Xms2000m</argLine>
+                    <argLine>-Xmx1200m -Xms1200m</argLine>
                 </configuration>
             </plugin>
         </plugins>
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/GTFSFeed.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/GTFSFeed.java
new file mode 100644
index 0000000000..dd27df96d1
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/GTFSFeed.java
@@ -0,0 +1,475 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs;
+
+import com.conveyal.gtfs.error.GTFSError;
+import com.conveyal.gtfs.model.*;
+import com.conveyal.gtfs.model.Calendar;
+import com.google.common.collect.Iterables;
+import com.google.common.util.concurrent.ExecutionError;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.CoordinateList;
+import org.locationtech.jts.geom.GeometryFactory;
+import org.locationtech.jts.geom.LineString;
+import org.mapdb.BTreeMap;
+import org.mapdb.DB;
+import org.mapdb.DBMaker;
+import org.mapdb.Fun;
+import org.mapdb.Fun.Tuple2;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.Closeable;
+import java.io.File;
+import java.io.IOError;
+import java.io.IOException;
+import java.time.LocalDate;
+import java.time.format.DateTimeFormatter;
+import java.util.*;
+import java.util.concurrent.ConcurrentNavigableMap;
+import java.util.concurrent.ExecutionException;
+import java.util.stream.Collectors;
+import java.util.stream.StreamSupport;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipFile;
+
+/**
+ * All entities must be from a single feed namespace.
+ * Composed of several GTFSTables.
+ */
+public class GTFSFeed implements Cloneable, Closeable {
+
+    private static final Logger LOG = LoggerFactory.getLogger(GTFSFeed.class);
+
+    private DB db;
+
+    public String feedId = null;
+
+    public final Map<String, Agency> agency;
+    public final Map<String, FeedInfo> feedInfo;
+    // This is how you do a multimap in mapdb: https://github.com/jankotek/MapDB/blob/release-1.0/src/test/java/examples/MultiMap.java
+    public final NavigableSet<Tuple2<String, Frequency>> frequencies;
+    public final Map<String, Route> routes;
+    public final Map<String, Stop> stops;
+    public final Map<String, Transfer> transfers;
+    public final BTreeMap<String, Trip> trips;
+
+    /** CRC32 of the GTFS file this was loaded from */
+    public long checksum;
+
+    /* Map from 2-tuples of (shape_id, shape_pt_sequence) to shape points */
+    public final ConcurrentNavigableMap<Tuple2<String, Integer>, ShapePoint> shape_points;
+
+    /* Map from 2-tuples of (trip_id, stop_sequence) to stoptimes. */
+    public final BTreeMap<Tuple2, StopTime> stop_times;
+
+    /* A fare is a fare_attribute and all fare_rules that reference that fare_attribute. */
+    public final Map<String, Fare> fares;
+
+    /* A service is a calendar entry and all calendar_dates that modify that calendar entry. */
+    public final BTreeMap<String, Service> services;
+
+    /* A place to accumulate errors while the feed is loaded. Tolerate as many errors as possible and keep on loading. */
+    public final NavigableSet<GTFSError> errors;
+
+    /* Create geometry factory to produce LineString geometries. */
+    private GeometryFactory gf = new GeometryFactory();
+
+    private boolean loaded = false;
+
+    /**
+     * The order in which we load the tables is important for two reasons.
+     * 1. We must load feed_info first so we know the feed ID before loading any other entities. This could be relaxed
+     * by having entities point to the feed object rather than its ID String.
+     * 2. Referenced entities must be loaded before any entities that reference them. This is because we check
+     * referential integrity while the files are being loaded. This is done on the fly during loading because it allows
+     * us to associate a line number with errors in objects that don't have any other clear identifier.
+     *
+     * Interestingly, all references are resolvable when tables are loaded in alphabetical order.
+     */
+    public void loadFromFile(ZipFile zip, String fid) throws Exception {
+        if (this.loaded) throw new UnsupportedOperationException("Attempt to load GTFS into existing database");
+
+        // NB we don't have a single CRC for the file, so we combine all the CRCs of the component files. NB we are not
+        // simply summing the CRCs because CRCs are (I assume) uniformly randomly distributed throughout the width of a
+        // long, so summing them is a convolution which moves towards a Gaussian with mean 0 (i.e. more concentrated
+        // probability in the center), degrading the quality of the hash. Instead we XOR. Assuming each bit is independent,
+        // this will yield a nice uniformly distributed result, because when combining two bits there is an equal
+        // probability of any input, which means an equal probability of any output. At least I think that's all correct.
+        // Repeated XOR is not commutative but zip.stream returns files in the order they are in the central directory
+        // of the zip file, so that's not a problem.
+        checksum = zip.stream().mapToLong(ZipEntry::getCrc).reduce((l1, l2) -> l1 ^ l2).getAsLong();
+
+        db.getAtomicLong("checksum").set(checksum);
+
+        new FeedInfo.Loader(this).loadTable(zip);
+        // maybe we should just point to the feed object itself instead of its ID, and null out its stoptimes map after loading
+        if (fid != null) {
+            feedId = fid;
+            LOG.info("Feed ID is undefined, pester maintainers to include a feed ID. Using file name {}.", feedId); // TODO log an error, ideally feeds should include a feedID
+        }
+        else if (feedId == null || feedId.isEmpty()) {
+            feedId = new File(zip.getName()).getName().replaceAll("\\.zip$", "");
+            LOG.info("Feed ID is undefined, pester maintainers to include a feed ID. Using file name {}.", feedId); // TODO log an error, ideally feeds should include a feedID
+        }
+        else {
+            LOG.info("Feed ID is '{}'.", feedId);
+        }
+
+        db.getAtomicString("feed_id").set(feedId);
+
+        new Agency.Loader(this).loadTable(zip);
+
+        // calendars and calendar dates are joined into services. This means a lot of manipulating service objects as
+        // they are loaded; since mapdb keys/values are immutable, load them in memory then copy them to MapDB once
+        // we're done loading them
+        Map<String, Service> serviceTable = new HashMap<>();
+        new Calendar.Loader(this, serviceTable).loadTable(zip);
+        new CalendarDate.Loader(this, serviceTable).loadTable(zip);
+        this.services.putAll(serviceTable);
+        serviceTable = null; // free memory
+
+        // Same deal
+        Map<String, Fare> fares = new HashMap<>();
+        new FareAttribute.Loader(this, fares).loadTable(zip);
+        new FareRule.Loader(this, fares).loadTable(zip);
+        this.fares.putAll(fares);
+        fares = null; // free memory
+
+        new Route.Loader(this).loadTable(zip);
+        new ShapePoint.Loader(this).loadTable(zip);
+        new Stop.Loader(this).loadTable(zip);
+        new Transfer.Loader(this).loadTable(zip);
+        new Trip.Loader(this).loadTable(zip);
+        new Frequency.Loader(this).loadTable(zip);
+        new StopTime.Loader(this).loadTable(zip); // comment out this line for quick testing using NL feed
+        loaded = true;
+    }
+
+    public void loadFromFile(ZipFile zip) throws Exception {
+        loadFromFile(zip, null);
+    }
+
+    public boolean hasFeedInfo () {
+        return !this.feedInfo.isEmpty();
+    }
+
+    public FeedInfo getFeedInfo () {
+        return this.hasFeedInfo() ? this.feedInfo.values().iterator().next() : null;
+    }
+
+    /**
+     * For the given trip ID, fetch all the stop times in order of increasing stop_sequence.
+     * This is an efficient iteration over a tree map.
+     */
+    public Iterable<StopTime> getOrderedStopTimesForTrip (String trip_id) {
+        Map<Fun.Tuple2, StopTime> tripStopTimes =
+                stop_times.subMap(
+                        Fun.t2(trip_id, null),
+                        Fun.t2(trip_id, Fun.HI)
+                );
+        return tripStopTimes.values();
+    }
+
+    /** Get the shape for the given shape ID */
+    public Shape getShape (String shape_id) {
+        Shape shape = new Shape(this, shape_id);
+        return shape.shape_dist_traveled.length > 0 ? shape : null;
+    }
+
+    /**
+     * For the given trip ID, fetch all the stop times in order, and interpolate stop-to-stop travel times.
+     */
+    public Iterable<StopTime> getInterpolatedStopTimesForTrip (String trip_id) throws FirstAndLastStopsDoNotHaveTimes {
+        // clone stop times so as not to modify base GTFS structures
+        StopTime[] stopTimes = StreamSupport.stream(getOrderedStopTimesForTrip(trip_id).spliterator(), false)
+                .map(st -> st.clone())
+                .toArray(i -> new StopTime[i]);
+
+        // avoid having to make sure that the array has length below.
+        if (stopTimes.length == 0) return Collections.emptyList();
+
+        // first pass: set all partially filled stop times
+        for (StopTime st : stopTimes) {
+            if (st.arrival_time != Entity.INT_MISSING && st.departure_time == Entity.INT_MISSING) {
+                st.departure_time = st.arrival_time;
+            }
+
+            if (st.arrival_time == Entity.INT_MISSING && st.departure_time != Entity.INT_MISSING) {
+                st.arrival_time = st.departure_time;
+            }
+        }
+
+        // quick check: ensure that first and last stops have times.
+        // technically GTFS requires that both arrival_time and departure_time be filled at both the first and last stop,
+        // but we are slightly more lenient and only insist that one of them be filled at both the first and last stop.
+        // The meaning of the first stop's arrival time is unclear, and same for the last stop's departure time (except
+        // in the case of interlining).
+
+        // it's fine to just check departure time, as the above pass ensures that all stop times have either both
+        // arrival and departure times, or neither
+        if (stopTimes[0].departure_time == Entity.INT_MISSING || stopTimes[stopTimes.length - 1].departure_time == Entity.INT_MISSING) {
+            throw new FirstAndLastStopsDoNotHaveTimes();
+        }
+
+        // second pass: fill complete stop times
+        int startOfInterpolatedBlock = -1;
+        for (int stopTime = 0; stopTime < stopTimes.length; stopTime++) {
+
+            if (stopTimes[stopTime].departure_time == Entity.INT_MISSING && startOfInterpolatedBlock == -1) {
+                startOfInterpolatedBlock = stopTime;
+            }
+            else if (stopTimes[stopTime].departure_time != Entity.INT_MISSING && startOfInterpolatedBlock != -1) {
+                throw new RuntimeException("Missing stop times not supported.");
+            }
+        }
+
+        return Arrays.asList(stopTimes);
+    }
+
+    public Collection<Frequency> getFrequencies (String trip_id) {
+        // IntelliJ tells me all these casts are unnecessary, and that's also my feeling, but the code won't compile
+        // without them
+        return (List<Frequency>) frequencies.subSet(new Fun.Tuple2(trip_id, null), new Fun.Tuple2(trip_id, Fun.HI)).stream()
+                .map(t2 -> ((Tuple2<String, Frequency>) t2).b)
+                .collect(Collectors.toList());
+    }
+
+    public LineString getStraightLineForStops(String trip_id) {
+        CoordinateList coordinates = new CoordinateList();
+        LineString ls = null;
+        Trip trip = trips.get(trip_id);
+
+        Iterable<StopTime> stopTimes;
+        stopTimes = getOrderedStopTimesForTrip(trip.trip_id);
+        if (Iterables.size(stopTimes) > 1) {
+            for (StopTime stopTime : stopTimes) {
+                Stop stop = stops.get(stopTime.stop_id);
+                Double lat = stop.stop_lat;
+                Double lon = stop.stop_lon;
+                coordinates.add(new Coordinate(lon, lat));
+            }
+            ls = gf.createLineString(coordinates.toCoordinateArray());
+        }
+        // set ls equal to null if there is only one stopTime to avoid an exception when creating linestring
+        else{
+            ls = null;
+        }
+        return ls;
+    }
+
+    /**
+     * Returns a trip geometry object (LineString) for a given trip id.
+     * If the trip has a shape reference, this will be used for the geometry.
+     * Otherwise, the ordered stoptimes will be used.
+     *
+     * @param   trip_id   trip id of desired trip geometry
+     * @return          the LineString representing the trip geometry.
+     * @see             LineString
+     */
+    public LineString getTripGeometry(String trip_id){
+
+        CoordinateList coordinates = new CoordinateList();
+        LineString ls = null;
+        Trip trip = trips.get(trip_id);
+
+        // If trip has shape_id, use it to generate geometry.
+        if (trip.shape_id != null) {
+            Shape shape = getShape(trip.shape_id);
+            if (shape != null) ls = shape.geometry;
+        }
+
+        // Use the ordered stoptimes.
+        if (ls == null) {
+            ls = getStraightLineForStops(trip_id);
+        }
+
+        return ls;
+    }
+
+    /**
+     * Cloning can be useful when you want to make only a few modifications to an existing feed.
+     * Keep in mind that this is a shallow copy, so you'll have to create new maps in the clone for tables you want
+     * to modify.
+     */
+    @Override
+    public GTFSFeed clone() {
+        try {
+            return (GTFSFeed) super.clone();
+        } catch (CloneNotSupportedException e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    public void close () {
+        db.close();
+    }
+
+    /** Thrown when we cannot interpolate stop times because the first or last stops do not have times */
+    public class FirstAndLastStopsDoNotHaveTimes extends RuntimeException {
+        /** do nothing */
+    }
+
+    /** Create a GTFS feed in a temp file */
+    public GTFSFeed () {
+        // calls to this must be first operation in constructor - why, Java?
+        this(DBMaker.newTempFileDB()
+                .transactionDisable()
+                .mmapFileEnable()
+                .asyncWriteEnable()
+                .deleteFilesAfterClose()
+                .compressionEnable()
+                // .cacheSize(1024 * 1024) this bloats memory consumption
+                .make()); // TODO db.close();
+    }
+
+    /** Create a GTFS feed connected to a particular DB, which will be created if it does not exist. */
+    public GTFSFeed (String dbFile) throws IOException, ExecutionException {
+        this(constructDB(dbFile)); // TODO db.close();
+    }
+
+    private static DB constructDB(String dbFile) {
+        DB db;
+        try{
+            DBMaker dbMaker = DBMaker.newFileDB(new File(dbFile));
+            db = dbMaker
+                    .transactionDisable()
+                    .mmapFileEnable()
+                    .asyncWriteEnable()
+                    .compressionEnable()
+//                     .cacheSize(1024 * 1024) this bloats memory consumption
+                    .make();
+            return db;
+        } catch (ExecutionError | IOError | Exception e) {
+            LOG.error("Could not construct db from file.", e);
+            return null;
+        }
+    }
+
+    private GTFSFeed (DB db) {
+        this.db = db;
+
+        agency = db.getTreeMap("agency");
+        feedInfo = db.getTreeMap("feed_info");
+        routes = db.getTreeMap("routes");
+        trips = db.getTreeMap("trips");
+        stop_times = db.getTreeMap("stop_times");
+        frequencies = db.getTreeSet("frequencies");
+        transfers = db.getTreeMap("transfers");
+        stops = db.getTreeMap("stops");
+        fares = db.getTreeMap("fares");
+        services = db.getTreeMap("services");
+        shape_points = db.getTreeMap("shape_points");
+
+        feedId = db.getAtomicString("feed_id").get();
+        checksum = db.getAtomicLong("checksum").get();
+
+        errors = db.getTreeSet("errors");
+    }
+
+    public LocalDate getStartDate() {
+        LocalDate startDate = null;
+
+        if (hasFeedInfo()) startDate = getFeedInfo().feed_start_date;
+        if (startDate == null) startDate = getCalendarServiceRangeStart();
+        if (startDate == null) startDate = getCalendarDateStart();
+
+        return startDate;
+    }
+
+    public LocalDate getCalendarServiceRangeStart() {
+
+        int startDate = 0;
+        for (Service service : services.values()) {
+            if (service.calendar == null)
+                continue;
+            if (startDate == 0 || service.calendar.start_date < startDate) {
+                startDate = service.calendar.start_date;
+            }
+        }
+        if (startDate == 0)
+            return null;
+
+        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyyMMdd", Locale.getDefault());
+        return LocalDate.parse(String.valueOf(startDate), formatter);
+    }
+
+
+    public LocalDate getCalendarDateStart() {
+        LocalDate startDate = null;
+        for (Service service : services.values()) {
+            for (LocalDate date : service.calendar_dates.keySet()) {
+                if (startDate == null
+                        || date.isBefore(startDate))
+                    startDate = date;
+            }
+        }
+        return startDate;
+    }
+
+    public LocalDate getCalendarServiceRangeEnd() {
+
+        int endDate = 0;
+
+        for (Service service : services.values()) {
+            if (service.calendar == null)
+                continue;
+
+            if (endDate == 0 || service.calendar.end_date > endDate) {
+                endDate = service.calendar.end_date;
+            }
+        }
+        if (endDate == 0)
+            return null;
+
+        DateTimeFormatter formatter = DateTimeFormatter.ofPattern("yyyyMMdd", Locale.getDefault());
+        return LocalDate.parse(String.valueOf(endDate), formatter);
+    }
+
+    public LocalDate getEndDate() {
+        LocalDate endDate = null;
+
+        if (hasFeedInfo()) endDate = getFeedInfo().feed_end_date;
+        if (endDate == null) endDate = getCalendarServiceRangeEnd();
+        if (endDate == null) endDate = getCalendarDateEnd();
+
+        return endDate;
+    }
+
+    public LocalDate getCalendarDateEnd() {
+        LocalDate endDate = null;
+        for (Service service : services.values()) {
+            for (LocalDate date : service.calendar_dates.keySet()) {
+                if (endDate == null
+                        || date.isAfter(endDate))
+                    endDate = date;
+            }
+        }
+        return endDate;
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/TripPatternKey.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/TripPatternKey.java
new file mode 100644
index 0000000000..15ea8bec8d
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/TripPatternKey.java
@@ -0,0 +1,81 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs;
+
+import com.carrotsearch.hppc.IntArrayList;
+import com.conveyal.gtfs.model.StopTime;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * Used as a map key when grouping trips by stop pattern. Note that this includes the routeId, so the same sequence of
+ * stops on two different routes makes two different patterns.
+ * These objects are not intended for use outside the grouping process.
+ */
+public class TripPatternKey {
+
+    public String routeId;
+    public List<String> stops = new ArrayList<>();
+    public IntArrayList pickupTypes = new IntArrayList();
+    public IntArrayList dropoffTypes = new IntArrayList();
+
+    public TripPatternKey (String routeId) {
+        this.routeId = routeId;
+    }
+
+    public void addStopTime (StopTime st) {
+        stops.add(st.stop_id);
+        pickupTypes.add(st.pickup_type);
+        dropoffTypes.add(st.drop_off_type);
+    }
+
+    @Override
+    public boolean equals(Object o) {
+        if (this == o) return true;
+        if (o == null || getClass() != o.getClass()) return false;
+
+        TripPatternKey that = (TripPatternKey) o;
+
+        if (dropoffTypes != null ? !dropoffTypes.equals(that.dropoffTypes) : that.dropoffTypes != null) return false;
+        if (pickupTypes != null ? !pickupTypes.equals(that.pickupTypes) : that.pickupTypes != null) return false;
+        if (routeId != null ? !routeId.equals(that.routeId) : that.routeId != null) return false;
+        if (stops != null ? !stops.equals(that.stops) : that.stops != null) return false;
+
+        return true;
+    }
+
+    @Override
+    public int hashCode() {
+        int result = routeId != null ? routeId.hashCode() : 0;
+        result = 31 * result + (stops != null ? stops.hashCode() : 0);
+        result = 31 * result + (pickupTypes != null ? pickupTypes.hashCode() : 0);
+        result = 31 * result + (dropoffTypes != null ? dropoffTypes.hashCode() : 0);
+        return result;
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DateParseError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DateParseError.java
new file mode 100644
index 0000000000..ef2da04e0e
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DateParseError.java
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/** Represents a problem parsing a date field from a GTFS feed. */
+public class DateParseError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public DateParseError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return "Could not parse date (format should be YYYYMMDD).";
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DuplicateKeyError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DuplicateKeyError.java
new file mode 100644
index 0000000000..4d79e1a542
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/DuplicateKeyError.java
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/** Indicates that a GTFS entity was not added to a table because another object already exists with the same primary key. */
+public class DuplicateKeyError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public DuplicateKeyError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return "Duplicate primary key.";
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/EmptyFieldError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/EmptyFieldError.java
new file mode 100644
index 0000000000..24f56b9e06
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/EmptyFieldError.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Indicates that a field marked as required is not present in a GTFS feed on a particular line. */
+public class EmptyFieldError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public EmptyFieldError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "No value supplied for a required column.");
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GTFSError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GTFSError.java
new file mode 100644
index 0000000000..cc6fe4123a
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GTFSError.java
@@ -0,0 +1,97 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/**
+ * Represents an error encountered
+ */
+public abstract class GTFSError implements Comparable<GTFSError>, Serializable {
+
+    public final String file; // TODO GTFSTable enum? Or simply use class objects.
+    public final long   line;
+    public final String field;
+    public final String affectedEntityId;
+    public final String errorType;
+
+    public GTFSError(String file, long line, String field) {
+        this(file, line, field, null);
+    }
+
+    public GTFSError(String file, long line, String field, String affectedEntityId) {
+        this.file  = file;
+        this.line  = line;
+        this.field = field;
+        this.affectedEntityId = affectedEntityId;
+        this.errorType = this.getClass().getSimpleName();
+    }
+
+    public String getMessage() {
+        return "no message";
+    }
+
+    public String getMessageWithContext() {
+        StringBuilder sb = new StringBuilder();
+        sb.append(file);
+        sb.append(' ');
+        if (line >= 0) {
+            sb.append("line ");
+            sb.append(line);
+        } else {
+            sb.append("(no line)");
+        }
+        if (field != null) {
+            sb.append(", field '");
+            sb.append(field);
+            sb.append('\'');
+        }
+        sb.append(": ");
+        sb.append(getMessage());
+        return sb.toString();
+    }
+
+    /** must be comparable to put into mapdb */
+    public int compareTo (GTFSError o) {
+        if (this.file == null && o.file != null) return -1;
+        else if (this.file != null && o.file == null) return 1;
+
+        int file = this.file == null && o.file == null ? 0 : String.CASE_INSENSITIVE_ORDER.compare(this.file, o.file);
+        if (file != 0) return file;
+        int errorType = String.CASE_INSENSITIVE_ORDER.compare(this.errorType, o.errorType);
+        if (errorType != 0) return errorType;
+        int affectedEntityId = this.affectedEntityId == null && o.affectedEntityId == null ? 0 : String.CASE_INSENSITIVE_ORDER.compare(this.affectedEntityId, o.affectedEntityId);
+        if (affectedEntityId != 0) return affectedEntityId;
+        else return Long.compare(this.line, o.line);
+    }
+
+    @Override
+    public String toString() {
+        return "GTFSError: " + getMessageWithContext();
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GeneralError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GeneralError.java
new file mode 100644
index 0000000000..9ba99c09ed
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/GeneralError.java
@@ -0,0 +1,45 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/** Represents any GTFS loading problem that does not have its own class, with a free-text message. */
+public class GeneralError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    private String message;
+
+    public GeneralError(String file, long line, String field, String message) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return message;
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingColumnError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingColumnError.java
new file mode 100644
index 0000000000..ca580373c2
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingColumnError.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Indicates that a column marked as required is entirely missing from a GTFS feed. */
+public class MissingColumnError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public MissingColumnError(String file, String field) {
+        super(file, 1, field);
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "Missing required column.");
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingTableError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingTableError.java
new file mode 100644
index 0000000000..851ffb13f8
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/MissingTableError.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Indicates that a table marked as required is not present in a GTFS feed. */
+public class MissingTableError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public MissingTableError(String file) {
+        super(file, 0, null);
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "This table is required by the GTFS specification but is missing.");
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/NumberParseError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/NumberParseError.java
new file mode 100644
index 0000000000..d6d4e88e02
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/NumberParseError.java
@@ -0,0 +1,44 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Represents a problem parsing an integer field of GTFS feed. */
+public class NumberParseError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public NumberParseError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "Error parsing a number from a string.");
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/Priority.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/Priority.java
new file mode 100644
index 0000000000..9fdf2f49c6
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/Priority.java
@@ -0,0 +1,52 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+public enum Priority {
+    /** 
+     * Something that is likely to break routing results,
+     * e.g. stop times out of sequence or high-speed travel
+     */
+    HIGH,
+    
+    /** 
+     * Something that is likely to break display, but still give accurate routing results,
+     * e.g. broken shapes or route long name containing route short name.
+     */
+    MEDIUM,
+    
+    /**
+     * Something that will not affect user experience but should be corrected as time permits,
+     * e.g. unused stops.
+     */
+    LOW,
+    
+    /**
+     * An error for which we do not have a priority
+     */
+    UNKNOWN
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/RangeError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/RangeError.java
new file mode 100644
index 0000000000..fcc99c9087
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/RangeError.java
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Indicates that a number is out of the acceptable range. */
+public class RangeError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    final double min, max, actual;
+
+    public RangeError(String file, long line, String field, double min, double max, double actual) {
+        super(file, line, field);
+        this.min = min;
+        this.max = max;
+        this.actual = actual;
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "Number %s outside of acceptable range [%s,%s].", actual, min, max);
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/ReferentialIntegrityError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/ReferentialIntegrityError.java
new file mode 100644
index 0000000000..85c22decb1
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/ReferentialIntegrityError.java
@@ -0,0 +1,56 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/** Indicates that an entity referenced another entity that does not exist. */
+public class ReferentialIntegrityError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    // TODO: maybe also store the entity ID of the entity which contained the bad reference, in addition to the row number
+    public final String badReference;
+
+    public ReferentialIntegrityError(String tableName, long row, String field, String badReference) {
+        super(tableName, row, field);
+        this.badReference = badReference;
+    }
+
+    /** must be comparable to put into mapdb */
+    @Override
+    public int compareTo (GTFSError o) {
+        int compare = super.compareTo(o);
+        if (compare != 0) return compare;
+        return this.badReference.compareTo((((ReferentialIntegrityError) o).badReference));
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), badReference);
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TableInSubdirectoryError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TableInSubdirectoryError.java
new file mode 100644
index 0000000000..b225dbe7d9
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TableInSubdirectoryError.java
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+import java.util.Locale;
+
+/**
+ * Created by landon on 10/14/16.
+ */
+public class TableInSubdirectoryError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public final String directory;
+    public final Priority priority = Priority.HIGH;
+
+    public TableInSubdirectoryError(String file, String directory) {
+        super(file, 0, null);
+        this.directory = directory;
+    }
+
+    @Override public String getMessage() {
+        return String.format(Locale.getDefault(), "All GTFS files (including %s.txt) should be at root of zipfile, not nested in subdirectory (%s)", file, directory);
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TimeParseError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TimeParseError.java
new file mode 100644
index 0000000000..3c0d007a92
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/TimeParseError.java
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/** Represents a problem parsing a time of day field of GTFS feed. */
+public class TimeParseError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public TimeParseError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return "Could not parse time (format should be HH:MM:SS).";
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/error/URLParseError.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/URLParseError.java
new file mode 100644
index 0000000000..d5b4df0da5
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/error/URLParseError.java
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.error;
+
+import java.io.Serializable;
+
+/** Represents a problem parsing a URL field from a GTFS feed. */
+public class URLParseError extends GTFSError implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public URLParseError(String file, long line, String field) {
+        super(file, line, field);
+    }
+
+    @Override public String getMessage() {
+        return "Could not parse URL (format should be <scheme>://<authority><path>?<query>#<fragment>).";
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Agency.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Agency.java
new file mode 100644
index 0000000000..926cf3a643
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Agency.java
@@ -0,0 +1,112 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+
+import java.io.IOException;
+import java.net.URL;
+import java.util.Iterator;
+
+public class Agency extends Entity {
+
+    private static final long serialVersionUID = -2825890165823575940L;
+    public String agency_id;
+    public String agency_name;
+    public URL    agency_url;
+    public String agency_timezone;
+    public String agency_lang;
+    public String agency_phone;
+    public URL    agency_fare_url;
+    public URL    agency_branding_url;
+    public String feed_id;
+
+    public static class Loader extends Entity.Loader<Agency> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "agency");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Agency a = new Agency();
+            a.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            a.agency_id    = getStringField("agency_id", false); // can only be absent if there is a single agency -- requires a special validator.
+            a.agency_name  = getStringField("agency_name", true);
+            a.agency_url   = getUrlField("agency_url", true);
+            a.agency_lang  = getStringField("agency_lang", false);
+            a.agency_phone = getStringField("agency_phone", false);
+            a.agency_timezone = getStringField("agency_timezone", true);
+            a.agency_fare_url = getUrlField("agency_fare_url", false);
+            a.agency_branding_url = getUrlField("agency_branding_url", false);
+            a.feed = feed;
+            a.feed_id = feed.feedId;
+
+            // TODO clooge due to not being able to have null keys in mapdb
+            if (a.agency_id == null) a.agency_id = "NONE";
+
+            feed.agency.put(a.agency_id, a);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<Agency> {
+        public Writer(GTFSFeed feed) {
+            super(feed, "agency");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"agency_id", "agency_name", "agency_url", "agency_lang",
+                    "agency_phone", "agency_timezone", "agency_fare_url", "agency_branding_url"});
+        }
+
+        @Override
+        public void writeOneRow(Agency a) throws IOException {
+            writeStringField(a.agency_id);
+            writeStringField(a.agency_name);
+            writeUrlField(a.agency_url);
+            writeStringField(a.agency_lang);
+            writeStringField(a.agency_phone);
+            writeStringField(a.agency_timezone);
+            writeUrlField(a.agency_fare_url);
+            writeUrlField(a.agency_branding_url);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<Agency> iterator() {
+            return this.feed.agency.values().iterator();
+        }
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Calendar.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Calendar.java
new file mode 100644
index 0000000000..595a1c3d81
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Calendar.java
@@ -0,0 +1,149 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.DuplicateKeyError;
+import com.google.common.base.Function;
+import com.google.common.base.Predicate;
+import com.google.common.collect.Iterators;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.Iterator;
+import java.util.Map;
+
+public class Calendar extends Entity implements Serializable {
+
+    private static final long serialVersionUID = 6634236680822635875L;
+    public int monday;
+    public int tuesday;
+    public int wednesday;
+    public int thursday;
+    public int friday;
+    public int saturday;
+    public int sunday;
+    public int start_date;
+    public int end_date;
+    public String feed_id;
+    public String service_id;
+
+    public static class Loader extends Entity.Loader<Calendar> {
+
+        private final Map<String, Service> services;
+
+        /**
+         * Create a loader. The map parameter should be an in-memory map that will be modified. We can't write directly
+         * to MapDB because we modify services as we load calendar dates, and this creates concurrentmodificationexceptions.
+         */
+        public Loader(GTFSFeed feed, Map<String, Service> services) {
+            super(feed, "calendar");
+            this.services = services;
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+
+            /* Calendars and Fares are special: they are stored as joined tables rather than simple maps. */
+            String service_id = getStringField("service_id", true); // TODO service_id can reference either calendar or calendar_dates.
+            Service service = services.computeIfAbsent(service_id, Service::new);
+            if (service.calendar != null) {
+                feed.errors.add(new DuplicateKeyError(tableName, row, "service_id"));
+            } else {
+                Calendar c = new Calendar();
+                c.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+                c.service_id = service.service_id;
+                c.monday = getIntField("monday", true, 0, 1);
+                c.tuesday = getIntField("tuesday", true, 0, 1);
+                c.wednesday = getIntField("wednesday", true, 0, 1);
+                c.thursday = getIntField("thursday", true, 0, 1);
+                c.friday = getIntField("friday", true, 0, 1);
+                c.saturday = getIntField("saturday", true, 0, 1);
+                c.sunday = getIntField("sunday", true, 0, 1);
+                // TODO check valid dates
+                c.start_date = getIntField("start_date", true, 18500101, 22001231);
+                c.end_date = getIntField("end_date", true, 18500101, 22001231);
+                c.feed = feed;
+                c.feed_id = feed.feedId;
+                service.calendar = c;
+            }
+
+        }    
+    }
+
+    public static class Writer extends Entity.Writer<Calendar> {
+        public Writer(GTFSFeed feed) {
+            super(feed, "calendar");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"service_id", "monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday", "start_date", "end_date"});
+        }
+
+        @Override
+        protected void writeOneRow(Calendar c) throws IOException {
+            writeStringField(c.service_id);
+            writeIntField(c.monday);
+            writeIntField(c.tuesday);
+            writeIntField(c.wednesday);
+            writeIntField(c.thursday);
+            writeIntField(c.friday);
+            writeIntField(c.saturday);
+            writeIntField(c.sunday);
+            writeIntField(c.start_date);
+            writeIntField(c.end_date);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<Calendar> iterator() {
+            // wrap an iterator over services
+            Iterator<Calendar> calIt = Iterators.transform(feed.services.values().iterator(), new Function<Service, Calendar> () {
+                @Override
+                public Calendar apply (Service s) {
+                    return s.calendar;
+                }
+            });
+            
+            // not every service has a calendar (e.g. TriMet has no calendars, just calendar dates).
+            // This is legal GTFS, so skip services with no calendar
+            return Iterators.filter(calIt, new Predicate<Calendar> () {
+                @Override
+                public boolean apply(Calendar c) {
+                    return c != null;
+                }
+            });
+            
+        }
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/CalendarDate.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/CalendarDate.java
new file mode 100644
index 0000000000..af6acfcd82
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/CalendarDate.java
@@ -0,0 +1,122 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.DuplicateKeyError;
+import com.google.common.base.Function;
+import com.google.common.collect.Iterators;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.time.LocalDate;
+import java.util.Iterator;
+import java.util.Map;
+
+public class CalendarDate extends Entity implements Cloneable, Serializable {
+
+    private static final long serialVersionUID = 6936614582249119431L;
+    public String    service_id;
+    public LocalDate date;
+    public int       exception_type;
+
+    public CalendarDate clone () {
+        try {
+            return (CalendarDate) super.clone();
+        } catch (CloneNotSupportedException e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    public static class Loader extends Entity.Loader<CalendarDate> {
+
+        private final Map<String, Service> services;
+
+        /**
+         * Create a loader. The map parameter should be an in-memory map that will be modified. We can't write directly
+         * to MapDB because we modify services as we load calendar dates, and this creates concurrentmodificationexceptions.
+         */
+        public Loader(GTFSFeed feed, Map<String, Service> services) {
+            super(feed, "calendar_dates");
+            this.services = services;
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            /* Calendars and Fares are special: they are stored as joined tables rather than simple maps. */
+            String service_id = getStringField("service_id", true);
+            Service service = services.computeIfAbsent(service_id, Service::new);
+            LocalDate date = getDateField("date", true);
+            if (service.calendar_dates.containsKey(date)) {
+                feed.errors.add(new DuplicateKeyError(tableName, row, "(service_id, date)"));
+            } else {
+                CalendarDate cd = new CalendarDate();
+                cd.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+                cd.service_id = service_id;
+                cd.date = date;
+                cd.exception_type = getIntField("exception_type", true, 1, 2);
+                cd.feed = feed;
+                service.calendar_dates.put(date, cd);
+            }
+        }
+    }
+
+    public static class Writer extends Entity.Writer<CalendarDate> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "calendar_dates");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"service_id", "date", "exception_type"});
+        }
+
+        @Override
+        protected void writeOneRow(CalendarDate d) throws IOException {
+            writeStringField(d.service_id);
+            writeDateField(d.date);
+            writeIntField(d.exception_type);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<CalendarDate> iterator() {
+            Iterator<Service> serviceIterator = feed.services.values().iterator();
+            return Iterators.concat(Iterators.transform(serviceIterator, new Function<Service, Iterator<CalendarDate>> () {
+                @Override
+                public Iterator<CalendarDate> apply(Service service) {
+                    return service.calendar_dates.values().iterator();
+                }
+            }));
+        }
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Entity.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Entity.java
new file mode 100644
index 0000000000..91552eb164
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Entity.java
@@ -0,0 +1,448 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.*;
+import com.csvreader.CsvReader;
+import com.csvreader.CsvWriter;
+import org.apache.commons.io.input.BOMInputStream;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.*;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.nio.charset.Charset;
+import java.time.LocalDate;
+import java.time.format.DateTimeFormatter;
+import java.util.*;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipFile;
+import java.util.zip.ZipOutputStream;
+
+/**
+ * An abstract base class that represents a row in a GTFS table, e.g. a Stop, Trip, or Agency.
+ * One concrete subclass is defined for each table in a GTFS feed.
+ */
+// TODO K is the key type for this table
+public abstract class Entity implements Serializable {
+
+    private static final long serialVersionUID = -3576441868127607448L;
+    public static final int INT_MISSING = Integer.MIN_VALUE;
+    public long sourceFileLine;
+
+    /* The feed from which this entity was loaded. */
+    transient GTFSFeed feed;
+
+    /* A class that can produce Entities from CSV, and record errors that occur in the process. */
+    // This is almost a GTFSTable... rename?
+    public static abstract class Loader<E extends Entity> {
+
+        private static final Logger LOG = LoggerFactory.getLogger(Loader.class);
+
+        protected final GTFSFeed feed;    // the feed into which we are loading the entities
+        protected final String tableName; // name of corresponding table without .txt
+        protected final Set<String> missingRequiredColumns = new HashSet<>();
+
+        protected CsvReader reader;
+        protected long      row;
+        // TODO "String column" that is set before any calls to avoid passing around the column name
+
+        public Loader(GTFSFeed feed, String tableName) {
+            this.feed = feed;
+            this.tableName = tableName;
+        }
+
+        /** @return whether the number actual is in the range [min, max] */
+        protected boolean checkRangeInclusive(double min, double max, double actual) {
+            if (actual < min || actual > max) {
+                feed.errors.add(new RangeError(tableName, row, null, min, max, actual)); // TODO set column name in loader so it's available in methods
+                return false;
+            }
+            return true;
+        }
+
+        /**
+         * Fetch the value from the given column of the current row. Record an error the first time a column is
+         * seen to be missing, and whenever empty values are encountered.
+         * I was originally just calling getStringField from the other getXField functions as a first step to get
+         * the missing-field check. But we don't want deduplication performed on strings that aren't being retained.
+         * Therefore the missing-field behavior is this separate function.
+         * @return null if column was missing or field is empty
+         */
+        private String getFieldCheckRequired(String column, boolean required) throws IOException {
+            String str = reader.get(column);
+            if (str == null) {
+                if (!missingRequiredColumns.contains(column)) {
+                    feed.errors.add(new MissingColumnError(tableName, column));
+                    missingRequiredColumns.add(column);
+                }
+            } else if (str.isEmpty()) {
+                if (required) {
+                    feed.errors.add(new EmptyFieldError(tableName, row, column));
+                }
+                str = null;
+            }
+            return str;
+        }
+
+        /** @return the given column from the current row as a deduplicated String. */
+        protected String getStringField(String column, boolean required) throws IOException {
+            return getFieldCheckRequired(column, required);
+        }
+
+        protected int getIntField(String column, boolean required, int min, int max) throws IOException {
+            return getIntField(column, required, min, max, 0);
+        }
+
+        protected int getIntField(String column, boolean required, int min, int max, int defaultValue) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            int val = INT_MISSING;
+            if (str == null) {
+                val = defaultValue; // defaults to 0 per overloaded function, unless provided.
+            } else try {
+                val = Integer.parseInt(str);
+                checkRangeInclusive(min, max, val);
+            } catch (NumberFormatException nfe) {
+                feed.errors.add(new NumberParseError(tableName, row, column));
+            }
+            return val;
+        }
+
+        /**
+         * Fetch the given column of the current row, and interpret it as a time in the format HH:MM:SS.
+         * @return the time value in seconds since midnight
+         */
+        protected int getTimeField(String column, boolean required) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            int val = INT_MISSING;
+            
+            if (str != null) {
+                String[] fields = str.split(":");
+                if (fields.length != 3) {
+                    feed.errors.add(new TimeParseError(tableName, row, column));
+                } else {
+                    try {
+                        int hours = Integer.parseInt(fields[0]);
+                        int minutes = Integer.parseInt(fields[1]);
+                        int seconds = Integer.parseInt(fields[2]);
+                        checkRangeInclusive(0, 72, hours); // GTFS hours can go past midnight. Some trains run for 3 days.
+                        checkRangeInclusive(0, 59, minutes);
+                        checkRangeInclusive(0, 59, seconds);
+                        val = (hours * 60 * 60) + minutes * 60 + seconds;
+                    } catch (NumberFormatException nfe) {
+                        feed.errors.add(new TimeParseError(tableName, row, column));
+                    }
+                }
+            }
+            
+            return val;
+        }
+
+        /**
+         * Fetch the given column of the current row, and interpret it as a date in the format YYYYMMDD.
+         * @return the date value as Java LocalDate, or null if it could not be parsed.
+         */
+        protected LocalDate getDateField(String column, boolean required) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            LocalDate dateTime = null;
+            if (str != null) try {
+                dateTime = LocalDate.parse(str, DateTimeFormatter.BASIC_ISO_DATE);
+                checkRangeInclusive(2000, 2100, dateTime.getYear());
+            } catch (IllegalArgumentException iae) {
+                feed.errors.add(new DateParseError(tableName, row, column));
+            }
+            return dateTime;
+        }
+
+        /**
+         * Fetch the given column of the current row, and interpret it as a URL.
+         * @return the URL, or null if the field was missing or empty.
+         */
+        protected URL getUrlField(String column, boolean required) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            URL url = null;
+            if (str != null) try {
+                url = new URL(str);
+            } catch (MalformedURLException mue) {
+                feed.errors.add(new URLParseError(tableName, row, column));
+            }
+            return url;
+        }
+
+        protected double getDoubleField(String column, boolean required, double min, double max) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            double val = Double.NaN;
+            if (str != null) try {
+                val = Double.parseDouble(str);
+                checkRangeInclusive(min, max, val);
+            } catch (NumberFormatException nfe) {
+                feed.errors.add(new NumberParseError(tableName, row, column));
+            }
+            return val;
+        }
+
+        /**
+         * Used to check referential integrity.
+         * Return value is not used, but could allow entities to point to each other directly rather than
+         * using indirection through string-keyed maps.
+         */
+        protected <K, V> V getRefField(String column, boolean required, Map<K, V> target) throws IOException {
+            String str = getFieldCheckRequired(column, required);
+            V val = null;
+            if (str != null) {
+                val = target.get(str);
+            }
+            return val;
+        }
+
+        protected abstract boolean isRequired();
+
+        /** Implemented by subclasses to read one row, produce one GTFS entity, and store that entity in a map. */
+        protected abstract void loadOneRow() throws IOException;
+
+        /**
+         * The main entry point into an Entity.Loader. Interprets each row of a CSV file within a zip file as a sinle
+         * GTFS entity, and loads them into a table.
+         *
+         * @param zip the zip file from which to read a table
+         */
+        public void loadTable(ZipFile zip) throws IOException {
+            ZipEntry entry = zip.getEntry(tableName + ".txt");
+            if (entry == null) {
+                Enumeration<? extends ZipEntry> entries = zip.entries();
+                // check if table is contained within sub-directory
+                while (entries.hasMoreElements()) {
+                    ZipEntry e = entries.nextElement();
+                    if (e.getName().endsWith(tableName + ".txt")) {
+                        entry = e;
+                        feed.errors.add(new TableInSubdirectoryError(tableName, entry.getName().replace(tableName + ".txt", "")));
+                    }
+                }
+                /* This GTFS table did not exist in the zip. */
+                if (this.isRequired()) {
+                    feed.errors.add(new MissingTableError(tableName));
+                } else {
+                    LOG.info("Table {} was missing but it is not required.", tableName);
+                }
+
+                if (entry == null) return;
+            }
+            LOG.info("Loading GTFS table {} from {}", tableName, entry);
+            InputStream zis = zip.getInputStream(entry);
+            // skip any byte order mark that may be present. Files must be UTF-8,
+            // but the GTFS spec says that "files that include the UTF byte order mark are acceptable"
+            InputStream bis = new BOMInputStream(zis);
+            CsvReader reader = new CsvReader(bis, ',', Charset.forName("UTF8"));
+            this.reader = reader;
+            reader.readHeaders();
+            while (reader.readRecord()) {
+                // reader.getCurrentRecord() is zero-based and does not include the header line, keep our own row count
+                if (++row % 500000 == 0) {
+                    LOG.info("Record number {}", human(row));
+                }
+                loadOneRow(); // Call subclass method to produce an entity from the current row.
+            }
+        }
+
+    }
+
+    /**
+     * An output stream that cannot be closed. CSVWriters try to close their output streams when they are garbage-collected,
+     * which breaks if another CSV writer is still writing to the ZIP file.
+     *
+     * Apache Commons has something similar but it seemed silly to import another large dependency. Eventually Guava will have this,
+     * see Guava issue 1367. At that point we should switch to using Guava.
+     */
+    private static class UncloseableOutputStream extends FilterOutputStream {
+        public UncloseableOutputStream(OutputStream out) {
+            super(out);
+        }
+
+        @Override
+        public void close () {
+            // no-op
+            return;
+        }
+    }
+
+    /**
+     * Write this entity to a CSV file. This should be subclassed in subclasses of Entity.
+     * The following (abstract) methods should be overridden in a subclass:
+     * 
+     * writeHeaders(): write the headers to the CsvWriter writer.
+     * writeRow(E): write the passed-in object to the CsvWriter writer, potentially using the write*Field methods.
+     * iterator(): return an iterator over objects of this class (note that the feed is available at this.feed
+     * public Writer (GTFSFeed feed): this should super to Writer(GTFSFeed feed, String tableName), with the table name
+     * defined. 
+     * 
+     * @author mattwigway
+     */
+    public static abstract class Writer<E extends Entity> {
+        private static final Logger LOG = LoggerFactory.getLogger(Writer.class);
+
+        protected final GTFSFeed feed;    // the feed into which we are loading the entities
+        protected final String tableName; // name of corresponding table without .txt
+
+        protected CsvWriter writer;
+
+        /**
+         * one-based to match reader.
+         */
+        protected long row;
+
+        protected Writer(GTFSFeed feed, String tableName) {
+            this.feed = feed;
+            this.tableName = tableName;
+        }
+
+        /**
+         * Write the CSV header.
+         */
+        protected abstract void writeHeaders() throws IOException;
+
+        /**
+         * Write one row of the CSV from the passed-in object.
+         */
+        protected abstract void writeOneRow(E obj) throws IOException;
+
+        /**
+         * Get an iterator over objects of this type.
+         */
+        protected abstract Iterator<E> iterator();
+
+        public void writeTable (ZipOutputStream zip) throws IOException {
+            LOG.info("Writing GTFS table {}", tableName);
+
+            ZipEntry zipEntry = new ZipEntry(tableName + ".txt");
+            zip.putNextEntry(zipEntry);
+
+            // don't let CSVWriter close the stream when it is garbage-collected
+            OutputStream protectedOut = new UncloseableOutputStream(zip);
+            this.writer = new CsvWriter(protectedOut, ',', Charset.forName("UTF8"));
+
+            this.writeHeaders();
+
+            // write rows until there are none left.
+            row = 0;        	
+            Iterator<E> iter = this.iterator();
+            while (iter.hasNext()) {
+                if (++row % 500000 == 0) {
+                    LOG.info("Record number {}", human(row));
+                }
+
+                writeOneRow(iter.next());
+            }
+
+            // closing the writer closes the underlying output stream, so we don't do that.
+            writer.flush();
+            zip.closeEntry();
+
+            LOG.info("Wrote {} rows", human(row));
+        }
+
+        protected void writeStringField(String str) throws IOException {
+            writer.write(str);
+        }
+
+        protected void writeUrlField(URL obj) throws IOException {
+            writeStringField(obj != null ? obj.toString() : "");
+        }
+
+        /**
+         * Writes date as YYYYMMDD
+         */
+        protected void writeDateField (LocalDate d) throws IOException {
+            writeStringField(d.format(DateTimeFormatter.BASIC_ISO_DATE));
+        }
+
+        /**
+         * Take a time expressed in seconds since noon - 12h (midnight, usually) and write it in HH:MM:SS format.
+         */
+        protected void writeTimeField (int secsSinceMidnight) throws IOException {
+            if (secsSinceMidnight == INT_MISSING) {
+                writeStringField("");
+                return;
+            }
+            
+            writeStringField(convertToGtfsTime(secsSinceMidnight));
+        }
+
+        public static String convertToGtfsTime (int secsSinceMidnight) {
+            int seconds = secsSinceMidnight % 60;
+            secsSinceMidnight -= seconds;
+            // note that the minute and hour values are still expressed in seconds until we write it out, to avoid unnecessary division.
+            int minutes = (secsSinceMidnight % 3600);
+            // secsSinceMidnight now represents hours
+            secsSinceMidnight -= minutes;
+
+            // integer divide is fine as we've subtracted off remainders
+            return String.format(Locale.getDefault(), "%02d:%02d:%02d", secsSinceMidnight / 3600, minutes / 60, seconds);
+        }
+
+        protected void writeIntField (Integer val) throws IOException {
+            if (val.equals(INT_MISSING))
+                writeStringField("");
+            else
+                writeStringField(val.toString());
+        }
+
+        /**
+         * Write a double value, with precision 10^-7. NaN is written as "".
+         */
+        protected void writeDoubleField (double val) throws IOException {
+            // NaN's represent missing values
+            if (Double.isNaN(val))
+                writeStringField("");
+            
+            // control file size: don't use unnecessary precision
+            // This is usually used for coordinates; one ten-millionth of a degree at the equator is 1.1cm,
+            // and smaller elsewhere on earth, plenty precise enough.
+            // On Jupiter, however, it's a different story.
+            // Use the US locale so that . is used as the decimal separator
+            else
+                writeStringField(String.format(Locale.US, "%.7f", val));
+        }
+
+        /**
+         * End a row.
+         * This is just a proxy to the writer, but could be used for hooks in the future.
+         */
+        public void endRecord () throws IOException {
+            writer.endRecord();
+        }
+    }
+
+
+    // shared code between reading and writing
+    private static final String human (long n) {
+        if (n >= 1000000) return String.format(Locale.getDefault(), "%.1fM", n/1000000.0);
+        if (n >= 1000) return String.format(Locale.getDefault(), "%.1fk", n/1000.0);
+        else return String.format(Locale.getDefault(), "%d", n);
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Fare.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Fare.java
new file mode 100644
index 0000000000..3e76b70bbe
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Fare.java
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.google.common.collect.Lists;
+
+import java.io.Serializable;
+import java.util.List;
+
+/**
+ * This table does not exist in GTFS. It is a join of fare_attributes and fare_rules on fare_id.
+ * There should only be one fare_attribute per fare_id, but there can be many fare_rules per fare_id.
+ */
+public class Fare implements Serializable {
+    public static final long serialVersionUID = 1L;
+
+    public String         fare_id;
+    public FareAttribute  fare_attribute;
+    public List<FareRule> fare_rules = Lists.newArrayList();
+
+    public Fare(String fare_id) {
+        this.fare_id = fare_id;
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareAttribute.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareAttribute.java
new file mode 100644
index 0000000000..f033101548
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareAttribute.java
@@ -0,0 +1,116 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.DuplicateKeyError;
+
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.Map;
+
+public class FareAttribute extends Entity {
+
+    private static final long serialVersionUID = 2157859372072056891L;
+    public String fare_id;
+    public double price;
+    public String currency_type;
+    public int payment_method;
+    public int transfers;
+    public int transfer_duration;
+    public String feed_id;
+
+    public static class Loader extends Entity.Loader<FareAttribute> {
+        private final Map<String, Fare> fares;
+
+        public Loader(GTFSFeed feed, Map<String, Fare> fares) {
+            super(feed, "fare_attributes");
+            this.fares = fares;
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+
+            /* Calendars and Fares are special: they are stored as joined tables rather than simple maps. */
+            String fareId = getStringField("fare_id", true);
+            Fare fare = fares.computeIfAbsent(fareId, Fare::new);
+            if (fare.fare_attribute != null) {
+                feed.errors.add(new DuplicateKeyError(tableName, row, "fare_id"));
+            } else {
+                FareAttribute fa = new FareAttribute();
+                fa.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+                fa.fare_id = fareId;
+                fa.price = getDoubleField("price", true, 0, Integer.MAX_VALUE);
+                fa.currency_type = getStringField("currency_type", true);
+                fa.payment_method = getIntField("payment_method", true, 0, 1);
+                fa.transfers = getIntField("transfers", false, 0, 10); // TODO missing means "unlimited" in this case (rather than 0), supply default value or just use the NULL to mean unlimited
+                fa.transfer_duration = getIntField("transfer_duration", false, 0, 24 * 60 * 60);
+                fa.feed = feed;
+                fa.feed_id = feed.feedId;
+                fare.fare_attribute = fa;
+            }
+
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<FareAttribute> {
+        public Writer(GTFSFeed feed) {
+            super(feed, "fare_attributes");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"fare_id", "price", "currency_type", "payment_method",
+                    "transfers", "transfer_duration"});
+        }
+
+        @Override
+        public void writeOneRow(FareAttribute fa) throws IOException {
+            writeStringField(fa.fare_id);
+            writeDoubleField(fa.price);
+            writeStringField(fa.currency_type);
+            writeIntField(fa.payment_method);
+            writeIntField(fa.transfers);
+            writeIntField(fa.transfer_duration);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<FareAttribute> iterator() {
+            return feed.fares.values().stream()
+                    .map(f -> f.fare_attribute)
+                    .iterator();
+        }
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareRule.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareRule.java
new file mode 100644
index 0000000000..616fe295ec
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FareRule.java
@@ -0,0 +1,115 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.ReferentialIntegrityError;
+
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.Map;
+
+public class FareRule extends Entity {
+
+    private static final long serialVersionUID = 3209660216692732272L;
+    public String fare_id;
+    public String route_id;
+    public String origin_id;
+    public String destination_id;
+    public String contains_id;
+
+    public static class Loader extends Entity.Loader<FareRule> {
+
+        private final Map<String, Fare> fares;
+
+        public Loader(GTFSFeed feed, Map<String, Fare> fares) {
+            super(feed, "fare_rules");
+            this.fares = fares;
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+
+            /* Calendars and Fares are special: they are stored as joined tables rather than simple maps. */
+            String fareId = getStringField("fare_id", true);
+
+            /* Referential integrity check for fare id */
+            if (!fares.containsKey(fareId)) {
+                this.feed.errors.add(new ReferentialIntegrityError(tableName, row, "fare_id", fareId));
+            }
+
+            Fare fare = fares.computeIfAbsent(fareId, Fare::new);
+            FareRule fr = new FareRule();
+            fr.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            fr.fare_id = fare.fare_id;
+            fr.route_id = getStringField("route_id", false);
+            fr.origin_id = getStringField("origin_id", false);
+            fr.destination_id = getStringField("destination_id", false);
+            fr.contains_id = getStringField("contains_id", false);
+            fr.feed = feed;
+            fare.fare_rules.add(fr);
+
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<FareRule> {
+        public Writer(GTFSFeed feed) {
+            super(feed, "fare_rules");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"fare_id", "route_id", "origin_id", "destination_id",
+                    "contains_id"});
+        }
+
+        @Override
+        public void writeOneRow(FareRule fr) throws IOException {
+            writeStringField(fr.fare_id);
+            writeStringField(fr.route_id);
+            writeStringField(fr.origin_id);
+            writeStringField(fr.destination_id);
+            writeStringField(fr.contains_id);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<FareRule> iterator() {
+            return feed.fares.values().stream()
+                    .map(f -> f.fare_rules)
+                    .flatMap(fr -> fr.stream())
+                    .iterator();
+        }
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FeedInfo.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FeedInfo.java
new file mode 100644
index 0000000000..18632e5054
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/FeedInfo.java
@@ -0,0 +1,122 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import com.conveyal.gtfs.error.GeneralError;
+
+import java.io.IOException;
+import java.net.URL;
+import java.time.LocalDate;
+import java.util.Iterator;
+
+public class FeedInfo extends Entity implements Cloneable {
+
+    private static final long serialVersionUID = 8718856987299076452L;
+    public String    feed_id = "NONE";
+    public String    feed_publisher_name;
+    public URL       feed_publisher_url;
+    public String    feed_lang;
+    public LocalDate feed_start_date;
+    public LocalDate feed_end_date;
+    public String    feed_version;
+
+    public FeedInfo clone () {
+        try {
+            return (FeedInfo) super.clone();
+        } catch (CloneNotSupportedException e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    public static class Loader extends Entity.Loader<FeedInfo> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "feed_info");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            FeedInfo fi = new FeedInfo();
+            fi.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            fi.feed_id = getStringField("feed_id", false);
+            fi.feed_publisher_name = getStringField("feed_publisher_name", true);
+            fi.feed_publisher_url = getUrlField("feed_publisher_url", true);
+            fi.feed_lang = getStringField("feed_lang", true);
+            fi.feed_start_date = getDateField("feed_start_date", false);
+            fi.feed_end_date = getDateField("feed_end_date", false);
+            fi.feed_version = getStringField("feed_version", false);
+            fi.feed = feed;
+            if (feed.feedInfo.isEmpty()) {
+                feed.feedInfo.put("NONE", fi);
+                feed.feedId = fi.feed_id;
+            } else {
+                feed.errors.add(new GeneralError(tableName, row, null, "FeedInfo contains more than one record."));
+            }
+        }
+    }
+
+    public static class Writer extends Entity.Writer<FeedInfo> {
+
+        public Writer(GTFSFeed feed) {
+            super(feed, "feed_info");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"feed_id", "feed_publisher_name", "feed_publisher_url", "feed_lang",
+                    "feed_start_date", "feed_end_date", "feed_version"});
+        }
+
+        @Override
+        public void writeOneRow(FeedInfo i) throws IOException {
+            writeStringField(i.feed_id != null && i.feed_id.equals("NONE") ? "" : i.feed_id);
+            writeStringField(i.feed_publisher_name);
+            writeUrlField(i.feed_publisher_url);
+            writeStringField(i.feed_lang);
+
+            if (i.feed_start_date != null) writeDateField(i.feed_start_date);
+            else writeStringField("");
+
+            if (i.feed_end_date != null) writeDateField(i.feed_end_date);
+            else writeStringField("");
+
+            writeStringField(i.feed_version);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<FeedInfo> iterator() {
+            return feed.feedInfo.values().iterator();
+        }
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Frequency.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Frequency.java
new file mode 100644
index 0000000000..8d7bfd14c1
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Frequency.java
@@ -0,0 +1,128 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import org.mapdb.Fun;
+
+import java.io.IOException;
+import java.util.Iterator;
+import java.util.Locale;
+
+import static com.conveyal.gtfs.model.Entity.Writer.convertToGtfsTime;
+
+public class Frequency extends Entity implements Comparable<Frequency> {
+    /**
+     * Frequency entries have no ID in GTFS so we define one based on the fields in the frequency entry.
+     *
+     * It is possible to have two identical frequency entries in the GTFS, which under our understanding of the situation
+     * would mean that two sets of vehicles were randomly running the same trip at the same headway, but uncorrelated
+     * with each other, which is almost certain to be an error.
+     */
+     public String getId() {
+        StringBuilder sb = new StringBuilder();
+         sb.append(trip_id);
+         sb.append('_');
+         sb.append(convertToGtfsTime(start_time));
+         sb.append("_to_");
+         sb.append(convertToGtfsTime(end_time));
+         sb.append("_every_");
+         sb.append(String.format(Locale.getDefault(), "%dm%02ds", headway_secs / 60, headway_secs % 60));
+         if (exact_times == 1) sb.append("_exact");
+         return sb.toString();
+     }
+
+    private static final long serialVersionUID = -7182161664471704133L;
+    public String trip_id;
+    public int start_time;
+    public int end_time;
+    public int headway_secs;
+    public int exact_times;
+
+    /** must have a comparator since they go in a navigable set that is serialized */
+    @Override
+    public int compareTo(Frequency o) {
+        return this.start_time - o.start_time;
+    }
+
+    public static class Loader extends Entity.Loader<Frequency> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "frequencies");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Frequency f = new Frequency();
+            Trip trip = getRefField("trip_id", true, feed.trips);
+            f.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            f.trip_id = trip.trip_id;
+            f.start_time = getTimeField("start_time", true);
+            f.end_time = getTimeField("end_time", true);
+            f.headway_secs = getIntField("headway_secs", true, 1, 24 * 60 * 60);
+            f.exact_times = getIntField("exact_times", false, 0, 1);
+            f.feed = feed;
+            feed.frequencies.add(Fun.t2(f.trip_id, f));
+        }
+    }
+
+    public static class Writer extends Entity.Writer<Frequency> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "frequencies");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"trip_id", "start_time", "end_time", "headway_secs", "exact_times"});
+        }
+
+        @Override
+        public void writeOneRow(Frequency f) throws IOException {
+            writeStringField(f.trip_id);
+            writeTimeField(f.start_time);
+            writeTimeField(f.end_time);
+            writeIntField(f.headway_secs);
+            writeIntField(f.exact_times);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<Frequency> iterator() {
+            return feed.frequencies.stream()
+                    .map(t2 -> t2.b)
+                    .iterator();
+        }
+
+
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Route.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Route.java
new file mode 100644
index 0000000000..0ad6505cc2
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Route.java
@@ -0,0 +1,140 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+
+import java.io.IOException;
+import java.net.URL;
+import java.util.Iterator;
+
+public class Route extends Entity { // implements Entity.Factory<Route>
+
+    private static final long serialVersionUID = -819444896818029068L;
+
+    public static final int TRAM = 0;
+    public static final int SUBWAY = 1;
+    public static final int RAIL = 2;
+    public static final int BUS = 3;
+    public static final int FERRY = 4;
+    public static final int CABLE_CAR = 4;
+    public static final int GONDOLA = 4;
+    public static final int FUNICULAR = 5;
+
+    public String route_id;
+    public String agency_id;
+    public String route_short_name;
+    public String route_long_name;
+    public String route_desc;
+    public int    route_type;
+    public URL    route_url;
+    public String route_color;
+    public String route_text_color;
+    public URL route_branding_url;
+    public String feed_id;
+
+    public static class Loader extends Entity.Loader<Route> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "routes");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Route r = new Route();
+            r.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            r.route_id = getStringField("route_id", true);
+            Agency agency = getRefField("agency_id", false, feed.agency);
+
+            // if there is only one agency, associate with it automatically
+            // TODO: what will this do if the agency and the route have agency_ids but they do not match?
+            if (agency == null && feed.agency.size() == 1)
+                agency = feed.agency.values().iterator().next();
+
+            r.agency_id = agency.agency_id;
+
+            r.route_short_name = getStringField("route_short_name", false); // one or the other required, needs a special validator
+            r.route_long_name = getStringField("route_long_name", false);
+            r.route_desc = getStringField("route_desc", false);
+            r.route_type = getIntField("route_type", true, 0, 7);
+            r.route_url = getUrlField("route_url", false);
+            r.route_color = getStringField("route_color", false);
+            r.route_text_color = getStringField("route_text_color", false);
+            r.route_branding_url = getUrlField("route_branding_url", false);
+            r.feed = feed;
+            r.feed_id = feed.feedId;
+            feed.routes.put(r.route_id, r);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<Route> {    	
+        public Writer (GTFSFeed feed) {
+            super(feed, "routes");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writeStringField("agency_id");
+            writeStringField("route_id");
+            writeStringField("route_short_name");
+            writeStringField("route_long_name");
+            writeStringField("route_desc");
+            writeStringField("route_type");
+            writeStringField("route_url");
+            writeStringField("route_color");
+            writeStringField("route_text_color");
+            writeStringField("route_branding_url");
+            endRecord();
+        }
+
+        @Override
+        public void writeOneRow(Route r) throws IOException {
+            writeStringField(r.agency_id);
+            writeStringField(r.route_id);
+            writeStringField(r.route_short_name);
+            writeStringField(r.route_long_name);
+            writeStringField(r.route_desc);
+            writeIntField(r.route_type);
+            writeUrlField(r.route_url);
+            writeStringField(r.route_color);
+            writeStringField(r.route_text_color);
+            writeUrlField(r.route_branding_url);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<Route> iterator() {
+            return feed.routes.values().iterator();
+        }   	
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Service.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Service.java
new file mode 100644
index 0000000000..16039075a1
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Service.java
@@ -0,0 +1,171 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.google.common.collect.Maps;
+
+import java.io.Serializable;
+import java.time.DayOfWeek;
+import java.time.LocalDate;
+import java.util.EnumSet;
+import java.util.Map;
+
+import static java.time.DayOfWeek.*;
+
+/**
+ * This table does not exist in GTFS. It is a join of calendars and calendar_dates on service_id.
+ * There should only be one Calendar per service_id. There should only be one calendar_date per tuple of
+ * (service_id, date), which means there can be many calendar_dates per service_id.
+ */
+public class Service implements Serializable {
+
+    private static final long serialVersionUID = 7966238549509747091L;
+    public String   service_id;
+    public Calendar calendar;
+    public Map<LocalDate, CalendarDate> calendar_dates = Maps.newHashMap();
+
+    public Service(String service_id) {
+        this.service_id = service_id;
+    }
+
+    /**
+     * @param service_id the service_id to assign to the newly created copy.
+     * @param daysToRemove the days of the week on which to deactivate service in the copy.
+     * @return a copy of this Service with any service on the specified days of the week deactivated.
+     */
+    public Service removeDays(String service_id, EnumSet<DayOfWeek> daysToRemove) {
+        Service service = new Service(service_id);
+        // First, duplicate any Calendar in this Service, minus the specified days of the week.
+        if (this.calendar != null) {
+            Calendar calendar = new Calendar();
+            //  TODO calendar.getDaysOfWeek/setDaysOfWeek which allow simplifying this section and activeOn below.
+            calendar.monday    = daysToRemove.contains(MONDAY)    ? 0 : this.calendar.monday;
+            calendar.tuesday   = daysToRemove.contains(TUESDAY)   ? 0 : this.calendar.tuesday;
+            calendar.wednesday = daysToRemove.contains(WEDNESDAY) ? 0 : this.calendar.wednesday;
+            calendar.thursday  = daysToRemove.contains(THURSDAY)  ? 0 : this.calendar.thursday;
+            calendar.friday    = daysToRemove.contains(FRIDAY)    ? 0 : this.calendar.friday;
+            calendar.saturday  = daysToRemove.contains(SATURDAY)  ? 0 : this.calendar.saturday;
+            calendar.sunday    = daysToRemove.contains(SUNDAY)    ? 0 : this.calendar.sunday;
+            // The new calendar should cover exactly the same time range as the existing one.
+            calendar.start_date = this.calendar.start_date;
+            calendar.end_date   = this.calendar.end_date;
+            // Create the bidirectional reference between Calendar and Service.
+            service.calendar = calendar;
+        }
+        // Copy over all exceptions whose dates fall on days of the week that are retained.
+        this.calendar_dates.forEach((date, exception) -> {
+            DayOfWeek dow = date.getDayOfWeek();
+            if (!daysToRemove.contains(dow)) {
+                CalendarDate newException = exception.clone();
+                service.calendar_dates.put(date, newException);
+            }
+        });
+        return service;
+    }
+
+    /**
+     * @return whether this Service is ever active at all, either from calendar or calendar_dates.
+     */
+    public boolean hasAnyService() {
+
+        // Look for any service defined in calendar (on days of the week).
+        boolean hasAnyService = calendar != null && (
+                calendar.monday == 1 ||
+                calendar.tuesday == 1 ||
+                calendar.wednesday == 1 ||
+                calendar.thursday == 1 ||
+                calendar.friday == 1 ||
+                calendar.saturday == 1 ||
+                calendar.sunday == 1 );
+
+        // Also look for any exceptions of type 1 (added service).
+        hasAnyService |= calendar_dates.values().stream().anyMatch(cd -> cd.exception_type == 1);
+
+        return hasAnyService;
+    }
+
+    /**
+     * Is this service active on the specified date?
+     */
+    public boolean activeOn (LocalDate date) {
+        // first check for exceptions
+        CalendarDate exception = calendar_dates.get(date);
+
+        if (exception != null)
+            return exception.exception_type == 1;
+
+        else if (calendar == null)
+            return false;
+
+        else {
+            int gtfsDate = date.getYear() * 10000 + date.getMonthValue() * 100 + date.getDayOfMonth();
+            boolean withinValidityRange = calendar.end_date >= gtfsDate && calendar.start_date <= gtfsDate;
+
+            if (!withinValidityRange) return false;
+
+            switch (date.getDayOfWeek()) {
+                case MONDAY:
+                    return calendar.monday == 1;
+                case TUESDAY:
+                    return calendar.tuesday == 1;
+                case WEDNESDAY:
+                    return calendar.wednesday == 1;
+                case THURSDAY:
+                    return calendar.thursday == 1;
+                case FRIDAY:
+                    return calendar.friday == 1;
+                case SATURDAY:
+                    return calendar.saturday == 1;
+                case SUNDAY:
+                    return calendar.sunday == 1;
+                default:
+                    throw new IllegalArgumentException("unknown day of week constant!");
+            }
+        }
+    }
+
+    /**
+     * Checks for overlapping days of week between two service calendars
+     * @param s1
+     * @param s2
+     * @return true if both calendars simultaneously operate on at least one day of the week
+     */
+    public static boolean checkOverlap (Service s1, Service s2) {
+        if (s1.calendar == null || s2.calendar == null) {
+            return false;
+        }
+        // overlap exists if at least one day of week is shared by two calendars
+        boolean overlappingDays = s1.calendar.monday == 1 && s2.calendar.monday == 1 ||
+                s1.calendar.tuesday == 1 && s2.calendar.tuesday == 1 ||
+                s1.calendar.wednesday == 1 && s2.calendar.wednesday == 1 ||
+                s1.calendar.thursday == 1 && s2.calendar.thursday == 1 ||
+                s1.calendar.friday == 1 && s2.calendar.friday == 1 ||
+                s1.calendar.saturday == 1 && s2.calendar.saturday == 1 ||
+                s1.calendar.sunday == 1 && s2.calendar.sunday == 1;
+        return overlappingDays;
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Shape.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Shape.java
new file mode 100644
index 0000000000..44723c6bce
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Shape.java
@@ -0,0 +1,58 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.GeometryFactory;
+import org.locationtech.jts.geom.LineString;
+import org.mapdb.Fun;
+
+import java.util.Map;
+
+/**
+ * Represents a collection of GTFS shape points. Never saved in MapDB but constructed on the fly.
+ */
+public class Shape {
+    public static GeometryFactory geometryFactory = new GeometryFactory();
+    /** The shape itself */
+    public LineString geometry;
+
+    /** shape_dist_traveled for each point in the geometry. TODO how to handle shape dist traveled not specified, or not specified on all stops? */
+    public double[] shape_dist_traveled;
+
+    public Shape (GTFSFeed feed, String shape_id) {
+        Map<Fun.Tuple2<String, Integer>, ShapePoint> points =
+                feed.shape_points.subMap(new Fun.Tuple2(shape_id, null), new Fun.Tuple2(shape_id, Fun.HI));
+
+        Coordinate[] coords = points.values().stream()
+                .map(point -> new Coordinate(point.shape_pt_lon, point.shape_pt_lat))
+                .toArray(i -> new Coordinate[i]);
+        geometry = geometryFactory.createLineString(coords);
+        shape_dist_traveled = points.values().stream().mapToDouble(point -> point.shape_dist_traveled).toArray();
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/ShapePoint.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/ShapePoint.java
new file mode 100644
index 0000000000..2691a2783f
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/ShapePoint.java
@@ -0,0 +1,104 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import org.mapdb.Fun.Tuple2;
+
+import java.io.IOException;
+import java.util.Iterator;
+
+public class ShapePoint extends Entity {
+
+    private static final long serialVersionUID = 6751814959971086070L;
+    public final String shape_id;
+    public final double shape_pt_lat;
+    public final double shape_pt_lon;
+    public final int    shape_pt_sequence;
+    public final double shape_dist_traveled;
+
+    // Similar to stoptime, we have to have a constructor, because fields are final so as to be immutable for storage in MapDB.
+    public ShapePoint(String shape_id, double shape_pt_lat, double shape_pt_lon, int shape_pt_sequence, double shape_dist_traveled) {
+        this.shape_id = shape_id;
+        this.shape_pt_lat = shape_pt_lat;
+        this.shape_pt_lon = shape_pt_lon;
+        this.shape_pt_sequence = shape_pt_sequence;
+        this.shape_dist_traveled = shape_dist_traveled;
+    }
+
+    public static class Loader extends Entity.Loader<ShapePoint> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "shapes");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            String shape_id = getStringField("shape_id", true);
+            double shape_pt_lat = getDoubleField("shape_pt_lat", true, -90D, 90D);
+            double shape_pt_lon = getDoubleField("shape_pt_lon", true, -180D, 180D);
+            int shape_pt_sequence = getIntField("shape_pt_sequence", true, 0, Integer.MAX_VALUE);
+            double shape_dist_traveled = getDoubleField("shape_dist_traveled", false, 0D, Double.MAX_VALUE);
+
+            ShapePoint s = new ShapePoint(shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence, shape_dist_traveled);
+            s.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            s.feed = null; // since we're putting this into MapDB, we don't want circular serialization
+            feed.shape_points.put(new Tuple2<String, Integer>(s.shape_id, s.shape_pt_sequence), s);
+        }
+    }
+
+    public static class Writer extends Entity.Writer<ShapePoint> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "shapes");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"shape_id", "shape_pt_lat", "shape_pt_lon", "shape_pt_sequence", "shape_dist_traveled"});
+        }
+
+        @Override
+        protected void writeOneRow(ShapePoint s) throws IOException {
+            writeStringField(s.shape_id);
+            writeDoubleField(s.shape_pt_lat);
+            writeDoubleField(s.shape_pt_lon);
+            writeIntField(s.shape_pt_sequence);
+            writeDoubleField(s.shape_dist_traveled);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<ShapePoint> iterator() {
+            return feed.shape_points.values().iterator();
+        }
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Stop.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Stop.java
new file mode 100644
index 0000000000..f35303ee15
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Stop.java
@@ -0,0 +1,122 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+
+import java.io.IOException;
+import java.net.URL;
+import java.util.Iterator;
+
+public class Stop extends Entity {
+
+    private static final long serialVersionUID = 464065335273514677L;
+    public String stop_id;
+    public String stop_code;
+    public String stop_name;
+    public String stop_desc;
+    public double stop_lat;
+    public double stop_lon;
+    public String zone_id;
+    public URL    stop_url;
+    public int    location_type;
+    public String parent_station;
+    public String stop_timezone;
+    // TODO should be int
+    public String wheelchair_boarding;
+    public String feed_id;
+
+    public static class Loader extends Entity.Loader<Stop> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "stops");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Stop s = new Stop();
+            s.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            s.stop_id   = getStringField("stop_id", true);
+            s.stop_code = getStringField("stop_code", false);
+            s.stop_name = getStringField("stop_name", true);
+            s.stop_desc = getStringField("stop_desc", false);
+            s.stop_lat  = getDoubleField("stop_lat", true, -90D, 90D);
+            s.stop_lon  = getDoubleField("stop_lon", true, -180D, 180D);
+            s.zone_id   = getStringField("zone_id", false);
+            s.stop_url  = getUrlField("stop_url", false);
+            s.location_type  = getIntField("location_type", false, 0, 1);
+            s.parent_station = getStringField("parent_station", false);
+            s.stop_timezone  = getStringField("stop_timezone", false);
+            s.wheelchair_boarding = getStringField("wheelchair_boarding", false);
+            s.feed = feed;
+            s.feed_id = feed.feedId;
+            /* TODO check ref integrity later, this table self-references via parent_station */
+
+            feed.stops.put(s.stop_id, s);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<Stop> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "stops");
+        }
+
+        @Override
+        public void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"stop_id", "stop_code", "stop_name", "stop_desc", "stop_lat", "stop_lon", "zone_id",					
+                    "stop_url", "location_type", "parent_station", "stop_timezone", "wheelchair_boarding"});
+        }
+
+        @Override
+        public void writeOneRow(Stop s) throws IOException {
+            writeStringField(s.stop_id);
+            writeStringField(s.stop_code);
+            writeStringField(s.stop_name);
+            writeStringField(s.stop_desc);
+            writeDoubleField(s.stop_lat);
+            writeDoubleField(s.stop_lon);
+            writeStringField(s.zone_id);
+            writeUrlField(s.stop_url);
+            writeIntField(s.location_type);
+            writeStringField(s.parent_station);
+            writeStringField(s.stop_timezone);
+            writeStringField(s.wheelchair_boarding);
+            endRecord();
+        }
+
+        @Override
+        public Iterator<Stop> iterator() {
+            return feed.stops.values().iterator();
+        }   	
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/StopTime.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/StopTime.java
new file mode 100644
index 0000000000..943a50641e
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/StopTime.java
@@ -0,0 +1,137 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+import org.mapdb.Fun;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.Iterator;
+
+/**
+ * Represents a GTFS StopTime. Note that once created and saved in a feed, stop times are by convention immutable
+ * because they are in a MapDB.
+ */
+public class StopTime extends Entity implements Cloneable, Serializable {
+
+    private static final long serialVersionUID = -8883780047901081832L;
+    /* StopTime cannot directly reference Trips or Stops because they would be serialized into the MapDB. */
+    public String trip_id;
+    public int    arrival_time = INT_MISSING;
+    public int    departure_time = INT_MISSING;
+    public String stop_id;
+    public int    stop_sequence;
+    public String stop_headsign;
+    public int    pickup_type;
+    public int    drop_off_type;
+    public double shape_dist_traveled;
+    public int    timepoint = INT_MISSING;
+
+    public static class Loader extends Entity.Loader<StopTime> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "stop_times");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            StopTime st = new StopTime();
+            st.sourceFileLine = row + 1; // offset line number by 1 to account for 0-based row index
+            st.trip_id        = getStringField("trip_id", true);
+            // TODO: arrival_time and departure time are not required, but if one is present the other should be
+            // also, if this is the first or last stop, they are both required
+            st.arrival_time   = getTimeField("arrival_time", false);
+            st.departure_time = getTimeField("departure_time", false);
+            st.stop_id        = getStringField("stop_id", true);
+            st.stop_sequence  = getIntField("stop_sequence", true, 0, Integer.MAX_VALUE);
+            st.stop_headsign  = getStringField("stop_headsign", false);
+            st.pickup_type    = getIntField("pickup_type", false, 0, 3); // TODO add ranges as parameters
+            st.drop_off_type  = getIntField("drop_off_type", false, 0, 3);
+            st.shape_dist_traveled = getDoubleField("shape_dist_traveled", false, 0D, Double.MAX_VALUE); // FIXME using both 0 and NaN for "missing", define DOUBLE_MISSING
+            st.timepoint      = getIntField("timepoint", false, 0, 1, INT_MISSING);
+            st.feed           = null; // this could circular-serialize the whole feed
+            feed.stop_times.put(new Fun.Tuple2(st.trip_id, st.stop_sequence), st);
+
+            /*
+              Check referential integrity without storing references. StopTime cannot directly reference Trips or
+              Stops because they would be serialized into the MapDB.
+             */
+            getRefField("trip_id", true, feed.trips);
+            getRefField("stop_id", true, feed.stops);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<StopTime> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "stop_times");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"trip_id", "arrival_time", "departure_time", "stop_id", "stop_sequence", "stop_headsign",
+                    "pickup_type", "drop_off_type", "shape_dist_traveled", "timepoint"});
+        }
+
+        @Override
+        protected void writeOneRow(StopTime st) throws IOException {
+            writeStringField(st.trip_id);
+            writeTimeField(st.arrival_time);
+            writeTimeField(st.departure_time);
+            writeStringField(st.stop_id);
+            writeIntField(st.stop_sequence);
+            writeStringField(st.stop_headsign);
+            writeIntField(st.pickup_type);
+            writeIntField(st.drop_off_type);
+            writeDoubleField(st.shape_dist_traveled);
+            writeIntField(st.timepoint);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<StopTime> iterator() {
+            return feed.stop_times.values().iterator();
+        }
+
+
+    }
+
+    @Override
+    public StopTime clone () {
+        try {
+            return (StopTime) super.clone();
+        } catch (CloneNotSupportedException e) {
+            throw new RuntimeException(e);
+        }
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Transfer.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Transfer.java
new file mode 100644
index 0000000000..4fe43fb881
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Transfer.java
@@ -0,0 +1,109 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+
+import java.io.IOException;
+import java.util.Iterator;
+
+public class Transfer extends Entity {
+
+    private static final long serialVersionUID = -4944512120812641063L;
+    public String from_stop_id;
+    public String to_stop_id;
+    public int  transfer_type;
+    public int  min_transfer_time;
+    public String from_route_id;
+    public String to_route_id;
+    public String from_trip_id;
+    public String to_trip_id;
+
+    public static class Loader extends Entity.Loader<Transfer> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "transfers");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return false;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Transfer tr = new Transfer();
+            tr.sourceFileLine    = row + 1; // offset line number by 1 to account for 0-based row index
+            tr.from_stop_id      = getStringField("from_stop_id", true);
+            tr.to_stop_id        = getStringField("to_stop_id", true);
+            tr.transfer_type     = getIntField("transfer_type", true, 0, 3);
+            tr.min_transfer_time = getIntField("min_transfer_time", false, 0, Integer.MAX_VALUE);
+            tr.from_route_id     = getStringField("from_route_id", false);
+            tr.to_route_id       = getStringField("to_route_id", false);
+            tr.from_trip_id      = getStringField("from_trip_id", false);
+            tr.to_trip_id        = getStringField("to_trip_id", false);
+
+            getRefField("from_stop_id", true, feed.stops);
+            getRefField("to_stop_id", true, feed.stops);
+            getRefField("from_route_id", false, feed.routes);
+            getRefField("to_route_id", false, feed.routes);
+            getRefField("from_trip_id", false, feed.trips);
+            getRefField("to_trip_id", false, feed.trips);
+
+            tr.feed = feed;
+            feed.transfers.put(Long.toString(row), tr);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<Transfer> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "transfers");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            writer.writeRecord(new String[] {"from_stop_id", "to_stop_id", "transfer_type", "min_transfer_time"});
+        }
+
+        @Override
+        protected void writeOneRow(Transfer t) throws IOException {
+            writeStringField(t.from_stop_id);
+            writeStringField(t.to_stop_id);
+            writeIntField(t.transfer_type);
+            writeIntField(t.min_transfer_time);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<Transfer> iterator() {
+            return feed.transfers.values().iterator();
+        }
+
+
+    }
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Trip.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Trip.java
new file mode 100644
index 0000000000..b7c4b06e87
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/model/Trip.java
@@ -0,0 +1,125 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.model;
+
+import com.conveyal.gtfs.GTFSFeed;
+
+import java.io.IOException;
+import java.util.Iterator;
+
+public class Trip extends Entity {
+
+    private static final long serialVersionUID = -4869384750974542712L;
+    public String route_id;
+    public String service_id;
+    public String trip_id;
+    public String trip_headsign;
+    public String trip_short_name;
+    public int    direction_id;
+    public String block_id;
+    public String shape_id;
+    public int    bikes_allowed;
+    public int    wheelchair_accessible;
+    public String feed_id;
+
+    public static class Loader extends Entity.Loader<Trip> {
+
+        public Loader(GTFSFeed feed) {
+            super(feed, "trips");
+        }
+
+        @Override
+        protected boolean isRequired() {
+            return true;
+        }
+
+        @Override
+        public void loadOneRow() throws IOException {
+            Trip t = new Trip();
+
+            t.sourceFileLine  = row + 1; // offset line number by 1 to account for 0-based row index
+            t.route_id        = getStringField("route_id", true);
+            t.service_id      = getStringField("service_id", true);
+            t.trip_id         = getStringField("trip_id", true);
+            t.trip_headsign   = getStringField("trip_headsign", false);
+            t.trip_short_name = getStringField("trip_short_name", false);
+            t.direction_id    = getIntField("direction_id", false, 0, 1);
+            t.block_id        = getStringField("block_id", false); // make a blocks multimap
+            t.shape_id        = getStringField("shape_id", false);
+            t.bikes_allowed   = getIntField("bikes_allowed", false, 0, 2);
+            t.wheelchair_accessible = getIntField("wheelchair_accessible", false, 0, 2);
+            t.feed = feed;
+            t.feed_id = feed.feedId;
+            feed.trips.put(t.trip_id, t);
+
+            /*
+              Check referential integrity without storing references. Trip cannot directly reference Services or
+              Routes because they would be serialized into the MapDB.
+             */
+            // TODO confirm existence of shape ID
+            getRefField("service_id", true, feed.services);
+            getRefField("route_id", true, feed.routes);
+        }
+
+    }
+
+    public static class Writer extends Entity.Writer<Trip> {
+        public Writer (GTFSFeed feed) {
+            super(feed, "trips");
+        }
+
+        @Override
+        protected void writeHeaders() throws IOException {
+            // TODO: export shapes
+            writer.writeRecord(new String[] {"route_id", "trip_id", "trip_headsign", "trip_short_name", "direction_id", "block_id",
+                    "shape_id", "bikes_allowed", "wheelchair_accessible", "service_id"});
+        }
+
+        @Override
+        protected void writeOneRow(Trip t) throws IOException {
+            writeStringField(t.route_id);
+            writeStringField(t.trip_id);
+            writeStringField(t.trip_headsign);
+            writeStringField(t.trip_short_name);
+            writeIntField(t.direction_id);
+            writeStringField(t.block_id);
+            writeStringField(t.shape_id);
+            writeIntField(t.bikes_allowed);
+            writeIntField(t.wheelchair_accessible);
+            writeStringField(t.service_id);
+            endRecord();
+        }
+
+        @Override
+        protected Iterator<Trip> iterator() {
+            return feed.trips.values().iterator();
+        }
+
+
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/conveyal/gtfs/util/Deduplicator.java b/reader-gtfs/src/main/java/com/conveyal/gtfs/util/Deduplicator.java
new file mode 100644
index 0000000000..54defdb1a3
--- /dev/null
+++ b/reader-gtfs/src/main/java/com/conveyal/gtfs/util/Deduplicator.java
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2015, Conveyal
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ *  Redistributions of source code must retain the above copyright notice, this
+ *   list of conditions and the following disclaimer.
+ *
+ *  Redistributions in binary form must reproduce the above copyright notice,
+ *   this list of conditions and the following disclaimer in the documentation
+ *   and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+ * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
+ * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+package com.conveyal.gtfs.util;
+
+import com.google.common.collect.Maps;
+
+import java.io.Serializable;
+import java.util.Map;
+
+/**
+ * Does the same thing as String.intern, but for several different types.
+ * Java's String.intern uses perm gen space and is broken anyway.
+ */
+public class Deduplicator implements Serializable {
+    private static final long serialVersionUID = 20140524L;
+
+    private final Map<String, String> canonicalStrings = Maps.newHashMap();
+
+    /** Free up any memory used by the deduplicator. */
+    public void reset() {
+        canonicalStrings.clear();
+    }
+
+}
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphExplorer.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphExplorer.java
index 56023505cd..4da8ccbd00 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphExplorer.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphExplorer.java
@@ -32,15 +32,13 @@
 import java.time.Instant;
 import java.time.ZoneId;
 import java.time.temporal.ChronoUnit;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Spliterators;
+import java.util.*;
 import java.util.function.Consumer;
 import java.util.function.Predicate;
 import java.util.stream.Stream;
 import java.util.stream.StreamSupport;
 
-final class GraphExplorer {
+public final class GraphExplorer {
 
     private final EdgeExplorer edgeExplorer;
     private final PtFlagEncoder flagEncoder;
@@ -56,7 +54,7 @@
     private double walkSpeedKmH;
 
 
-    GraphExplorer(Graph graph, Weighting accessEgressWeighting, PtFlagEncoder flagEncoder, GtfsStorage gtfsStorage, RealtimeFeed realtimeFeed, boolean reverse, List<VirtualEdgeIteratorState> extraEdges, boolean walkOnly, double walkSpeedKmh) {
+    public GraphExplorer(Graph graph, Weighting accessEgressWeighting, PtFlagEncoder flagEncoder, GtfsStorage gtfsStorage, RealtimeFeed realtimeFeed, boolean reverse, List<VirtualEdgeIteratorState> extraEdges, boolean walkOnly, double walkSpeedKmh) {
         this.graph = graph;
         this.accessEgressWeighting = accessEgressWeighting;
         DefaultEdgeFilter accessEgressIn = DefaultEdgeFilter.inEdges(accessEgressWeighting.getFlagEncoder());
@@ -96,12 +94,33 @@
             @Override
             public boolean tryAdvance(Consumer<? super EdgeIteratorState> action) {
                 if (edgeIterator.next()) {
+                    GtfsStorage.EdgeType edgeType = flagEncoder.getEdgeType(edgeIterator.getFlags());
+
+                    // Optimization (around 20% in Swiss network):
+                    // Only use the (single) least-wait-time edge to enter the
+                    // time expanded network. Later departures are reached via
+                    // WAIT edges. Algorithmically not necessary, and does not
+                    // reduce total number of relaxed nodes, but takes stress
+                    // off the priority queue.
+                    if (edgeType == GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK) {
+                        action.accept(findEnterEdge()); // fully consumes edgeIterator
+                        return true;
+                    }
+
                     action.accept(edgeIterator);
                     return true;
                 }
                 return false;
             }
 
+            private EdgeIteratorState findEnterEdge() {
+                ArrayList<EdgeIteratorState> allEnterEdges = new ArrayList<>();
+                allEnterEdges.add(edgeIterator.detach(false));
+                while (edgeIterator.next()) {
+                    allEnterEdges.add(edgeIterator.detach(false));
+                }
+                return allEnterEdges.stream().min(Comparator.comparingLong(e -> calcTravelTimeMillis(e, label.currentTime))).get();
+            }
 
         }, false);
     }
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphHopperGtfs.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphHopperGtfs.java
index 8dbcccbfd9..2a2c2bf448 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphHopperGtfs.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GraphHopperGtfs.java
@@ -366,7 +366,7 @@ public static GraphHopperStorage createOrLoad(GHDirectory directory, EncodingMan
                             t.transfer.min_transfer_time = (int) (t.time / 1000L);
                             gtfsFeed.transfers.put(t.id, t.transfer);
                         });
-                gtfsReader.readGraph();
+                gtfsReader.buildPtNetwork();
             }
             graphHopperStorage.flush();
             return graphHopperStorage;
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsReader.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsReader.java
index bf0290d28e..8dc039f17b 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsReader.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsReader.java
@@ -20,15 +20,8 @@
 
 import com.carrotsearch.hppc.IntArrayList;
 import com.conveyal.gtfs.GTFSFeed;
-import com.conveyal.gtfs.model.Frequency;
-import com.conveyal.gtfs.model.Route;
-import com.conveyal.gtfs.model.Service;
-import com.conveyal.gtfs.model.Stop;
-import com.conveyal.gtfs.model.StopTime;
-import com.conveyal.gtfs.model.Transfer;
-import com.conveyal.gtfs.model.Trip;
+import com.conveyal.gtfs.model.*;
 import com.google.common.collect.HashMultimap;
-import com.google.common.collect.SetMultimap;
 import com.google.transit.realtime.GtfsRealtime;
 import com.graphhopper.routing.util.DefaultEdgeFilter;
 import com.graphhopper.routing.util.EdgeFilter;
@@ -42,32 +35,14 @@
 import com.graphhopper.util.EdgeIterator;
 import com.graphhopper.util.EdgeIteratorState;
 import com.graphhopper.util.Helper;
-import gnu.trove.map.hash.TIntIntHashMap;
 import org.mapdb.Fun;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.time.LocalDate;
 import java.time.ZoneId;
-import java.util.ArrayList;
-import java.util.BitSet;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.Iterator;
-import java.util.List;
-import java.util.ListIterator;
-import java.util.Map;
-import java.util.NavigableSet;
-import java.util.Optional;
-import java.util.Set;
-import java.util.SortedSet;
-import java.util.Spliterators;
-import java.util.TreeSet;
-import java.util.function.Consumer;
+import java.util.*;
 import java.util.stream.Collectors;
-import java.util.stream.Stream;
-import java.util.stream.StreamSupport;
 
 import static com.conveyal.gtfs.model.Entity.Writer.convertToGtfsTime;
 import static java.time.temporal.ChronoUnit.DAYS;
@@ -78,7 +53,7 @@
     private LocalDate endDate;
 
     static class TripWithStopTimes {
-        public TripWithStopTimes(Trip trip, List<StopTime> stopTimes, BitSet validOnDay, Set<Integer> cancelledArrivals, Set<Integer> cancelledDepartures) {
+        TripWithStopTimes(Trip trip, List<StopTime> stopTimes, BitSet validOnDay, Set<Integer> cancelledArrivals, Set<Integer> cancelledDepartures) {
             this.trip = trip;
             this.stopTimes = stopTimes;
             this.validOnDay = validOnDay;
@@ -93,18 +68,6 @@ public TripWithStopTimes(Trip trip, List<StopTime> stopTimes, BitSet validOnDay,
         Set<Integer> cancelledDeparture;
     }
 
-    private static class TimelineNodeIdWithTripId {
-        final String tripId;
-        final String routeId;
-        final int timelineNodeId;
-
-        private TimelineNodeIdWithTripId(int timelineNodeId, String tripId, String routeId) {
-            this.tripId = tripId;
-            this.routeId = routeId;
-            this.timelineNodeId = timelineNodeId;
-        }
-    }
-
     private static final Logger LOGGER = LoggerFactory.getLogger(GtfsReader.class);
 
     private final Graph graph;
@@ -117,9 +80,8 @@ private TimelineNodeIdWithTripId(int timelineNodeId, String tripId, String route
     private final String id;
     private int i;
     private GTFSFeed feed;
-    private final TIntIntHashMap times = new TIntIntHashMap();
-    private final SetMultimap<String, TimelineNodeIdWithTripId> departureTimelineNodes = HashMultimap.create();
-    private final SetMultimap<String, TimelineNodeIdWithTripId> arrivalTimelineNodes = HashMultimap.create();
+    private final Map<String, Map<GtfsStorageI.PlatformDescriptor, NavigableMap<Integer, Integer>>> departureTimelinesByStop = new HashMap<>();
+    private final Map<String, Map<GtfsStorageI.PlatformDescriptor, NavigableMap<Integer, Integer>>> arrivalTimelinesByStop = new HashMap<>();
     private final PtFlagEncoder encoder;
 
     GtfsReader(String id, Graph graph, GtfsStorageI gtfsStorage, PtFlagEncoder encoder, LocationIndex walkNetworkIndex) {
@@ -132,38 +94,42 @@ private TimelineNodeIdWithTripId(int timelineNodeId, String tripId, String route
         this.feed = this.gtfsStorage.getGtfsFeeds().get(id);
         this.transfers = this.gtfsStorage.getTransfers().get(id);
         this.i = graph.getNodes();
-        this.startDate = feed.calculateStats().getStartDate();
-        this.endDate = feed.calculateStats().getEndDate();
-    }
-
-    void readGraph() {
-        gtfsStorage.getFares().putAll(feed.fares);
-        transfers = new Transfers(feed);
-        gtfsStorage.getTransfers().put(id, transfers);
-        buildPtNetwork();
+        this.startDate = feed.getStartDate();
+        this.endDate = feed.getEndDate();
     }
 
     void connectStopsToStreetNetwork() {
         FlagEncoder footEncoder = ((GraphHopperStorage) graph).getEncodingManager().getEncoder("foot");
         final EdgeFilter filter = DefaultEdgeFilter.allEdges(footEncoder);
         for (Stop stop : feed.stops.values()) {
-            QueryResult locationQueryResult = walkNetworkIndex.findClosest(stop.stop_lat, stop.stop_lon, filter);
-            int streetNode;
-            if (!locationQueryResult.isValid()) {
-                streetNode = i++;
-                nodeAccess.setNode(streetNode, stop.stop_lat, stop.stop_lon);
-                EdgeIteratorState edge = graph.edge(streetNode, streetNode);
-                edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                edge.setFlags(footEncoder.setAccess(edge.getFlags(), true, false));
-                edge.setFlags(footEncoder.setSpeed(edge.getFlags(), 5.0));
-            } else {
-                streetNode = locationQueryResult.getClosestNode();
+            if (stop.location_type == 0) { // Only stops. Not interested in parent stations for now.
+                QueryResult locationQueryResult = walkNetworkIndex.findClosest(stop.stop_lat, stop.stop_lon, filter);
+                int streetNode;
+                if (!locationQueryResult.isValid()) {
+                    streetNode = i++;
+                    nodeAccess.setNode(streetNode, stop.stop_lat, stop.stop_lon);
+                    EdgeIteratorState edge = graph.edge(streetNode, streetNode);
+                    edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+                    edge.setFlags(footEncoder.setAccess(edge.getFlags(), true, false));
+                    edge.setFlags(footEncoder.setSpeed(edge.getFlags(), 5.0));
+                } else {
+                    streetNode = locationQueryResult.getClosestNode();
+                }
+                gtfsStorage.getStationNodes().put(stop.stop_id, streetNode);
             }
-            gtfsStorage.getStationNodes().put(stop.stop_id, streetNode);
         }
     }
 
-    private void buildPtNetwork() {
+    void buildPtNetwork() {
+        gtfsStorage.getFares().putAll(feed.fares);
+        transfers = new Transfers(feed);
+        gtfsStorage.getTransfers().put(id, transfers);
+        createTrips();
+        wireUpStops();
+        insertTransfers();
+    }
+
+    private void createTrips() {
         HashMultimap<String, Trip> blockTrips = HashMultimap.create();
         for (Trip trip : feed.trips.values()) {
             if (trip.block_id != null) {
@@ -183,7 +149,7 @@ private void buildPtNetwork() {
                             }
                         }
                         ArrayList<StopTime> stopTimes = new ArrayList<>();
-                        getInterpolatedStopTimesForTrip(trip.trip_id).forEach(stopTimes::add);
+                        feed.getInterpolatedStopTimesForTrip(trip.trip_id).forEach(stopTimes::add);
                         return new TripWithStopTimes(trip, stopTimes, validOnDay, Collections.emptySet(), Collections.emptySet());
                     })
                     .sorted(Comparator.comparingInt(trip -> trip.stopTimes.iterator().next().departure_time))
@@ -203,219 +169,51 @@ private void buildPtNetwork() {
                 }
             }
         });
-
-        wireUpStops();
     }
 
-    void wireUpStops() {
-        for (Stop stop : feed.stops.values()) {
-            if (stop.location_type == 0) { // Only stops. Not interested in parent stations for now.
-                int streetNode = gtfsStorage.getStationNodes().get(stop.stop_id);
-
-                if (arrivalTimelineNodes.containsKey(stop.stop_id)) {
-                    final Map<String, List<TimelineNodeIdWithTripId>> arrivalTimelineNodesByRoute = arrivalTimelineNodes.get(stop.stop_id).stream().collect(Collectors.groupingBy(t -> t.routeId));
-
-                    arrivalTimelineNodesByRoute.forEach((routeId, timelineNodesWithTripId) -> {
-                        Route route = feed.routes.get(routeId);
-                        nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
-                        int stopExitNode = i-1;
-                        nodeAccess.setAdditionalNodeField(stopExitNode, NodeType.STOP_EXIT_NODE.ordinal());
-
-                        EdgeIteratorState exitEdge = graph.edge(stopExitNode, streetNode);
-                        exitEdge.setFlags(encoder.setAccess(exitEdge.getFlags(), true, false));
-                        setEdgeTypeAndClearDistance(exitEdge, GtfsStorage.EdgeType.EXIT_PT);
-                        exitEdge.setFlags(encoder.setValidityId(exitEdge.getFlags(), route.route_type));
-                        exitEdge.setName(stop.stop_name);
-                        gtfsStorage.getRoutes().put(exitEdge.getEdge(), routeId);
-
-                        NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesWithTripId);
-                        wireUpAndAndConnectArrivalTimeline(stop, routeId,stopExitNode, timeNodes);
-                    });
-
-                }
-
-                if (departureTimelineNodes.containsKey(stop.stop_id)) {
-                    final Map<String, List<TimelineNodeIdWithTripId>> departureTimelineNodesByRoute = departureTimelineNodes.get(stop.stop_id).stream().collect(Collectors.groupingBy(t -> t.routeId));
-
-                    departureTimelineNodesByRoute.forEach((routeId, timelineNodesWithTripId) -> {
-                        Route route = feed.routes.get(routeId);
-                        nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
-                        int stopEnterNode = i-1;
-                        nodeAccess.setAdditionalNodeField(stopEnterNode, NodeType.STOP_ENTER_NODE.ordinal());
-
-                        EdgeIteratorState entryEdge = graph.edge(streetNode, stopEnterNode);
-                        entryEdge.setFlags(encoder.setAccess(entryEdge.getFlags(), true, false));
-                        setEdgeTypeAndClearDistance(entryEdge, GtfsStorage.EdgeType.ENTER_PT);
-                        entryEdge.setFlags(encoder.setValidityId(entryEdge.getFlags(), route.route_type));
-                        entryEdge.setName(stop.stop_name);
-                        gtfsStorage.getRoutes().put(entryEdge.getEdge(), routeId);
-
-                        NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesWithTripId);
-                        wireUpAndAndConnectDepartureTimeline(stop, routeId,stopEnterNode, timeNodes);
-                    });
-                }
-            }
-        }
-        insertTransfers();
-    }
-
-    void wireUpAdditionalDepartures(ZoneId zoneId) {
-        for (Stop stop : feed.stops.values()) {
-            int stationNode = gtfsStorage.getStationNodes().get(stop.stop_id);
-            final Map<String, List<TimelineNodeIdWithTripId>> departureTimelineNodesByRoute = departureTimelineNodes.get(stop.stop_id).stream().collect(Collectors.groupingBy(t -> t.routeId));
-            departureTimelineNodesByRoute.forEach((routeId, timelineNodesWithTripId) -> {
-                int platformNode = findPlatformEnterNode(stationNode, routeId);
-                if (platformNode != -1) {
-                    NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesWithTripId);
-                    Iterator<Fun.Tuple2<Integer, Integer>> realtimeTimelineIterator = timeNodes.iterator();
-                    NavigableSet<Fun.Tuple2<Integer, Integer>> staticTimelineNodesForRoute = findDepartureTimelineNodesForRoute(stationNode, routeId).collect(Collectors.toCollection(TreeSet::new));
-                    realtimeTimelineIterator.forEachRemaining(timelineNode -> {
-                        SortedSet<Fun.Tuple2<Integer, Integer>> headSet = staticTimelineNodesForRoute.headSet(timelineNode);
-                        if(!headSet.isEmpty()) {
-                            Fun.Tuple2<Integer, Integer> before = headSet.last();
-                            EdgeIteratorState edge = graph.edge(before.b, timelineNode.b);
-                            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT);
-                            edge.setFlags(encoder.setTime(edge.getFlags(), timelineNode.a-before.a));
-                        }
-                        SortedSet<Fun.Tuple2<Integer, Integer>> tailSet = staticTimelineNodesForRoute.tailSet(timelineNode);
-                        if (!tailSet.isEmpty()) {
-                            Fun.Tuple2<Integer, Integer> after = tailSet.first();
-                            EdgeIteratorState edge = graph.edge(timelineNode.b, after.b);
-                            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT);
-                            edge.setFlags(encoder.setTime(edge.getFlags(), after.a-timelineNode.a));
-
-//                            System.out.println(" "+ after);
-//                            EdgeIterator ei = graph.getBaseGraph().createEdgeExplorer(DefaultEdgeFilter.inEdges(encoder)).setBaseNode(after.b);
-//                            while(ei.next()) {
-//                                if (encoder.getEdgeType(ei.getFlags()) == GtfsStorage.EdgeType.TRANSFER) {
-//                                    System.out.println("   "+ei+"   @"+Long.toString(after.a-encoder.getTime(ei.getFlags())));
-//                                }
-//                            }
-
-                        }
-
-                        EdgeIteratorState edge = graph.edge(platformNode, timelineNode.b);
-                        edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                        setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK);
-                        edge.setFlags(encoder.setTime(edge.getFlags(), timelineNode.a));
-                        setFeedIdWithTimezone(edge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
-                    });
-                } else {
-                    nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
-                    int stopEnterNode = i-1;
-                    nodeAccess.setAdditionalNodeField(stopEnterNode, NodeType.STOP_ENTER_NODE.ordinal());
-                    EdgeIteratorState entryEdge = graph.edge(stationNode, stopEnterNode);
-                    entryEdge.setFlags(encoder.setAccess(entryEdge.getFlags(), true, false));
-                    setEdgeTypeAndClearDistance(entryEdge, GtfsStorage.EdgeType.ENTER_PT);
-                    entryEdge.setName(stop.stop_name);
-                    NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesWithTripId);
-                    wireUpAndAndConnectDepartureTimeline(stop, routeId,stopEnterNode, timeNodes);
-                }
-            });
-            final Map<String, List<TimelineNodeIdWithTripId>> arrivalTimelineNodesByRoute = arrivalTimelineNodes.get(stop.stop_id).stream().collect(Collectors.groupingBy(t -> t.routeId));
-            arrivalTimelineNodesByRoute.forEach((routeId, timelineNodesWithTripId) -> {
-                int platformNode = findPlatformExitNode(stationNode, routeId);
-                NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesWithTripId);
-
-                if (platformNode != -1) {
-                    Iterator<Fun.Tuple2<Integer, Integer>> realtimeTimelineIterator = timeNodes.iterator();
-                    realtimeTimelineIterator.forEachRemaining(timelineNode -> {
-                        EdgeIteratorState edge = graph.edge(timelineNode.b, platformNode);
-                        edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                        setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK);
-                        edge.setFlags(encoder.setTime(edge.getFlags(), timelineNode.a));
-                        setFeedIdWithTimezone(edge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
-                    });
-                } else {
-                    nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
-                    int stopExitNode = i-1;
-                    nodeAccess.setAdditionalNodeField(stopExitNode, NodeType.STOP_EXIT_NODE.ordinal());
-                    EdgeIteratorState exitEdge = graph.edge(stopExitNode, stationNode);
-                    exitEdge.setFlags(encoder.setAccess(exitEdge.getFlags(), true, false));
-                    setEdgeTypeAndClearDistance(exitEdge, GtfsStorage.EdgeType.EXIT_PT);
-                    exitEdge.setName(stop.stop_name);
-                    wireUpAndAndConnectArrivalTimeline(stop, routeId,stopExitNode, timeNodes);
-                }
-                final Optional<Transfer> withinStationTransfer = transfers.getTransfersFromStop(stop.stop_id, routeId).stream().filter(t -> t.from_stop_id.equals(stop.stop_id)).findAny();
-                if (!withinStationTransfer.isPresent()) {
-                    insertOutboundTransfers(stop.stop_id, null, 0, timeNodes);
-                }
-                transfers.getTransfersFromStop(stop.stop_id, routeId).forEach(transfer -> {
-                    insertOutboundTransfers(transfer.from_stop_id, transfer.from_route_id, transfer.min_transfer_time, timeNodes);
-                });
-            });
-        }
+    private void wireUpStops() {
+        arrivalTimelinesByStop.forEach((stopId, arrivalTimelines) -> {
+            int streetNode = gtfsStorage.getStationNodes().get(stopId);
+            Stop stop = feed.stops.get(stopId);
+            arrivalTimelines.forEach(((platformDescriptor, arrivalTimeline) ->
+                    wireUpArrivalTimeline(streetNode, stop, arrivalTimeline, routeType(platformDescriptor), platformDescriptor)));
+        });
+        departureTimelinesByStop.forEach((stopId, departureTimelines) -> {
+            int streetNode = gtfsStorage.getStationNodes().get(stopId);
+            Stop stop = feed.stops.get(stopId);
+            departureTimelines.forEach(((platformDescriptor, departureTimeline) ->
+                    wireUpDepartureTimeline(streetNode, stop, departureTimeline, routeType(platformDescriptor), platformDescriptor)));
+        });
     }
 
-    private Stream<Fun.Tuple2<Integer, Integer>> findDepartureTimelineNodesForRoute(int stationNode, String routeId) {
-        int node = findPlatformEnterNode(stationNode, routeId);
-        if (node == -1) {
-            return Stream.empty();
-        }
-        return StreamSupport.stream(new Spliterators.AbstractSpliterator<EdgeIteratorState>(0, 0) {
-            EdgeIterator edgeIterator = graph.getBaseGraph().createEdgeExplorer(DefaultEdgeFilter.outEdges(encoder)).setBaseNode(node);
-            @Override
-            public boolean tryAdvance(Consumer<? super EdgeIteratorState> action) {
-                if (edgeIterator.next()) {
-                    action.accept(edgeIterator);
-                    return true;
-                } else {
-                    return false;
-                }
-            }
-        }, false)
-                .filter(edge -> encoder.getEdgeType(edge.getFlags()) == GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK)
-                .map(edge -> new Fun.Tuple2<>((int) encoder.getTime(edge.getFlags()), edge.getAdjNode()));
+    private void insertTransfers() {
+        departureTimelinesByStop.forEach((toStopId, departureTimelines) ->
+                departureTimelines.forEach(((platformDescriptor, departureTimeline) ->
+                        insertTransfers(toStopId, routeIdOrNull(platformDescriptor), departureTimeline))));
     }
 
-    private int findPlatformEnterNode(int stationNode, String routeId) {
-        EdgeIterator i = graph.getBaseGraph().createEdgeExplorer(DefaultEdgeFilter.outEdges(encoder)).setBaseNode(stationNode);
-        while (i.next()) {
-            GtfsStorage.EdgeType edgeType = encoder.getEdgeType(i.getFlags());
-            if (edgeType == GtfsStorage.EdgeType.ENTER_PT) {
-                if (routeId.equals(gtfsStorage.getRoutes().get(i.getEdge()))) {
-                    return i.getAdjNode();
-                }
-            }
-        }
-        return -1;
-    }
 
-    private int findPlatformExitNode(int stationNode, String routeId) {
-        EdgeIterator i = graph.getBaseGraph().createEdgeExplorer(DefaultEdgeFilter.inEdges(encoder)).setBaseNode(stationNode);
-        while (i.next()) {
-            GtfsStorage.EdgeType edgeType = encoder.getEdgeType(i.getFlags());
-            if (edgeType == GtfsStorage.EdgeType.EXIT_PT) {
-                if (routeId.equals(gtfsStorage.getRoutes().get(i.getEdge()))) {
-                    return i.getAdjNode();
-                }
-            }
+    private void insertTransfers(String toStopId, String toRouteId, NavigableMap<Integer, Integer> departureTimeline) {
+        final Optional<Transfer> withinStationTransfer = transfers.getTransfersToStop(toStopId, toRouteId).stream().filter(t -> t.from_stop_id.equals(toStopId)).findAny();
+        if (!withinStationTransfer.isPresent()) {
+            insertInboundTransfers(toStopId, null, 0, departureTimeline);
         }
-        return -1;
+        transfers.getTransfersToStop(toStopId, toRouteId).forEach(transfer ->
+                insertInboundTransfers(transfer.from_stop_id, transfer.from_route_id, transfer.min_transfer_time, departureTimeline));
     }
 
-    private NavigableSet<Fun.Tuple2<Integer, Integer>> sorted(List<TimelineNodeIdWithTripId> timelineNodesWithTripId) {
-        NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = new TreeSet<>();
-        timelineNodesWithTripId.stream().map(t -> t.timelineNodeId)
-                .forEach(nodeId -> timeNodes.add(new Fun.Tuple2<>(times.get(nodeId) % (24*60*60), nodeId)));
-        return timeNodes;
-    }
-
-    void insertTransfers() {
-        departureTimelineNodes.asMap().forEach((toStopId, timelineNodesWithTripId) -> {
-            final Map<String, List<TimelineNodeIdWithTripId>> departureTimelineNodesByRoute = departureTimelineNodes.get(toStopId).stream().collect(Collectors.groupingBy(t -> t.routeId));
-            departureTimelineNodesByRoute.forEach((toRouteId, timelineNodesByRoute) -> {
-                NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes = sorted(timelineNodesByRoute);
-                final Optional<Transfer> withinStationTransfer = transfers.getTransfersToStop(toStopId, toRouteId).stream().filter(t -> t.from_stop_id.equals(toStopId)).findAny();
-                if (!withinStationTransfer.isPresent()) {
-                    insertInboundTransfers(toStopId, null, 0, timeNodes);
-                }
-                transfers.getTransfersToStop(toStopId, toRouteId).forEach(transfer -> {
-                    insertInboundTransfers(transfer.from_stop_id, transfer.from_route_id, transfer.min_transfer_time, timeNodes);
-                });
-            });
+    void wireUpAdditionalDeparturesAndArrivals(ZoneId zoneId) {
+        departureTimelinesByStop.forEach((stopId, departureTimelines) -> {
+            int stationNode = gtfsStorage.getStationNodes().get(stopId);
+            Stop stop = feed.stops.get(stopId);
+            departureTimelines.forEach(((platformDescriptor, timeline) ->
+                    wireUpOrPatchDepartureTimeline(zoneId, stationNode, stop, timeline, platformDescriptor)));
+        });
+        arrivalTimelinesByStop.forEach((stopId, arrivalTimelines) -> {
+            int stationNode = gtfsStorage.getStationNodes().get(stopId);
+            Stop stop = feed.stops.get(stopId);
+            arrivalTimelines.forEach(((platformDescriptor, timeline) ->
+                    wireUpOrPatchArrivalTimeline(zoneId, stationNode, stop, routeIdOrNull(platformDescriptor), timeline, platformDescriptor)));
         });
     }
 
@@ -435,6 +233,7 @@ private void addTrips(ZoneId zoneId, List<TripWithStopTimes> trips, int time, bo
     private static class TripWithStopTimeAndArrivalNode {
         TripWithStopTimes tripWithStopTimes;
         int arrivalNode;
+        int arrivalTime;
     }
 
     void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arrivalNodes, TripWithStopTimes trip, GtfsRealtime.TripDescriptor tripDescriptor, boolean frequencyBased) {
@@ -442,13 +241,14 @@ void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arriv
         IntArrayList alightEdges = new IntArrayList();
         StopTime prev = null;
         int arrivalNode = -1;
+        int arrivalTime = -1;
         int departureNode = -1;
         for (StopTime stopTime : trip.stopTimes) {
             Stop stop = feed.stops.get(stopTime.stop_id);
             arrivalNode = i++;
             nodeAccess.setNode(arrivalNode, stop.stop_lat, stop.stop_lon);
             nodeAccess.setAdditionalNodeField(arrivalNode, NodeType.INTERNAL_PT.ordinal());
-            times.put(arrivalNode, stopTime.arrival_time + time);
+            arrivalTime = stopTime.arrival_time + time;
             if (prev != null) {
                 Stop fromStop = feed.stops.get(prev.stop_id);
                 double distance = distCalc.calcDist(
@@ -464,20 +264,37 @@ void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arriv
                 edge.setFlags(encoder.setTime(edge.getFlags(), stopTime.arrival_time - prev.departure_time));
                 gtfsStorage.getStopSequences().put(edge.getEdge(), stopTime.stop_sequence);
             }
-            final int departureTimelineNode = i++;
-            nodeAccess.setNode(departureTimelineNode, stop.stop_lat, stop.stop_lon);
-            nodeAccess.setAdditionalNodeField(departureTimelineNode, NodeType.INTERNAL_PT.ordinal());
-            times.put(departureTimelineNode, stopTime.departure_time + time);
-            departureTimelineNodes.put(stopTime.stop_id, new TimelineNodeIdWithTripId(departureTimelineNode, trip.trip.trip_id, trip.trip.route_id));
-            final int arrivalTimelineNode = i++;
-            nodeAccess.setNode(arrivalTimelineNode, stop.stop_lat, stop.stop_lon);
-            nodeAccess.setAdditionalNodeField(arrivalTimelineNode, NodeType.INTERNAL_PT.ordinal());
-            times.put(arrivalTimelineNode, stopTime.arrival_time + time);
-            arrivalTimelineNodes.put(stopTime.stop_id, new TimelineNodeIdWithTripId(arrivalTimelineNode, trip.trip.trip_id, trip.trip.route_id));
+            Route route = feed.routes.get(trip.trip.route_id);
+            Map<GtfsStorageI.PlatformDescriptor, NavigableMap<Integer, Integer>> departureTimelines = departureTimelinesByStop.computeIfAbsent(stopTime.stop_id, s -> new HashMap<>());
+            NavigableMap<Integer, Integer> departureTimeline;
+            if (transfers.hasNoRouteSpecificDepartureTransferRules(stopTime.stop_id)) {
+                departureTimeline = departureTimelines.computeIfAbsent(GtfsStorageI.PlatformDescriptor.routeType(route.route_type), s -> new TreeMap<>());
+            } else {
+                departureTimeline = departureTimelines.computeIfAbsent(GtfsStorageI.PlatformDescriptor.route(route.route_id), s -> new TreeMap<>());
+            }
+            int departureTimelineNode = departureTimeline.computeIfAbsent((stopTime.departure_time + time) % (24 * 60 * 60), t -> {
+                final int _departureTimelineNode = i++;
+                nodeAccess.setNode(_departureTimelineNode, stop.stop_lat, stop.stop_lon);
+                nodeAccess.setAdditionalNodeField(_departureTimelineNode, NodeType.INTERNAL_PT.ordinal());
+                return _departureTimelineNode;
+            });
+
+            Map<GtfsStorageI.PlatformDescriptor, NavigableMap<Integer, Integer>>  arrivalTimelines = arrivalTimelinesByStop.computeIfAbsent(stopTime.stop_id, s -> new HashMap<>());
+            NavigableMap<Integer, Integer> arrivalTimeline;
+            if (transfers.hasNoRouteSpecificArrivalTransferRules(stopTime.stop_id)) {
+                arrivalTimeline = arrivalTimelines.computeIfAbsent(GtfsStorageI.PlatformDescriptor.routeType(route.route_type), s -> new TreeMap<>());
+            } else {
+                arrivalTimeline = arrivalTimelines.computeIfAbsent(GtfsStorageI.PlatformDescriptor.route(route.route_id), s -> new TreeMap<>());
+            }
+            int arrivalTimelineNode = arrivalTimeline.computeIfAbsent((stopTime.arrival_time + time) % (24 * 60 * 60), t -> {
+                final int _arrivalTimelineNode = i++;
+                nodeAccess.setNode(_arrivalTimelineNode, stop.stop_lat, stop.stop_lon);
+                nodeAccess.setAdditionalNodeField(_arrivalTimelineNode, NodeType.INTERNAL_PT.ordinal());
+                return _arrivalTimelineNode;
+            });
             departureNode = i++;
             nodeAccess.setNode(departureNode, stop.stop_lat, stop.stop_lon);
             nodeAccess.setAdditionalNodeField(departureNode, NodeType.INTERNAL_PT.ordinal());
-            times.put(departureNode, stopTime.departure_time + time);
             int dayShift = stopTime.departure_time / (24 * 60 * 60);
             GtfsStorage.Validity validOn = new GtfsStorage.Validity(getValidOn(trip.validOnDay, dayShift), zoneId, startDate);
             int validityId;
@@ -512,8 +329,6 @@ void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arriv
             gtfsStorage.getStopSequences().put(alightEdge.getEdge(), stopTime.stop_sequence);
             gtfsStorage.getTripDescriptors().put(alightEdge.getEdge(), tripDescriptor.toByteArray());
             alightEdge.setFlags(encoder.setValidityId(alightEdge.getFlags(), validityId));
-//                            alightEdge.setFlags(encoder.setTransfers(alightEdge.getFlags(), 1));
-
 
             EdgeIteratorState dwellEdge = graph.edge(arrivalNode, departureNode);
             dwellEdge.setFlags(encoder.setAccess(dwellEdge.getFlags(), true, false));
@@ -521,7 +336,7 @@ void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arriv
             setEdgeTypeAndClearDistance(dwellEdge, GtfsStorage.EdgeType.DWELL);
             dwellEdge.setFlags(encoder.setTime(dwellEdge.getFlags(), stopTime.departure_time - stopTime.arrival_time));
             if (prev == null) {
-                insertInboundBlockTransfers(arrivalNodes, tripDescriptor, departureNode, stopTime, stop, validOn, zoneId);
+                insertInboundBlockTransfers(arrivalNodes, tripDescriptor, departureNode, stopTime.departure_time + time, stopTime, stop, validOn, zoneId);
             }
             prev = stopTime;
         }
@@ -530,18 +345,146 @@ void addTrip(ZoneId zoneId, int time, List<TripWithStopTimeAndArrivalNode> arriv
         TripWithStopTimeAndArrivalNode tripWithStopTimeAndArrivalNode = new TripWithStopTimeAndArrivalNode();
         tripWithStopTimeAndArrivalNode.tripWithStopTimes = trip;
         tripWithStopTimeAndArrivalNode.arrivalNode = arrivalNode;
+        tripWithStopTimeAndArrivalNode.arrivalTime = arrivalTime;
         arrivalNodes.add(tripWithStopTimeAndArrivalNode);
     }
 
+    private void wireUpDepartureTimeline(int streetNode, Stop stop, NavigableMap<Integer, Integer> departureTimeline, int route_type, GtfsStorageI.PlatformDescriptor platformDescriptorIfStatic) {
+        nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
+        int stopEnterNode = i - 1;
+        nodeAccess.setAdditionalNodeField(stopEnterNode, NodeType.STOP_ENTER_NODE.ordinal());
+        EdgeIteratorState entryEdge = graph.edge(streetNode, stopEnterNode);
+        entryEdge.setFlags(encoder.setAccess(entryEdge.getFlags(), true, false));
+        setEdgeTypeAndClearDistance(entryEdge, GtfsStorage.EdgeType.ENTER_PT);
+        entryEdge.setFlags(encoder.setValidityId(entryEdge.getFlags(), route_type));
+        entryEdge.setName(stop.stop_name);
+        if (platformDescriptorIfStatic != null) {
+            gtfsStorage.getRoutes().put(entryEdge.getEdge(), platformDescriptorIfStatic);
+        }
+        wireUpAndConnectTimeline(stop, stopEnterNode, departureTimeline, GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK, GtfsStorage.EdgeType.WAIT);
+    }
+
+    private void wireUpArrivalTimeline(int streetNode, Stop stop, NavigableMap<Integer, Integer> arrivalTimeline, int route_type, GtfsStorageI.PlatformDescriptor platformDescriptorIfStatic) {
+        nodeAccess.setNode(i++, stop.stop_lat, stop.stop_lon);
+        int stopExitNode = i - 1;
+        nodeAccess.setAdditionalNodeField(stopExitNode, NodeType.STOP_EXIT_NODE.ordinal());
+        EdgeIteratorState exitEdge = graph.edge(stopExitNode, streetNode);
+        exitEdge.setFlags(encoder.setAccess(exitEdge.getFlags(), true, false));
+        setEdgeTypeAndClearDistance(exitEdge, GtfsStorage.EdgeType.EXIT_PT);
+        exitEdge.setFlags(encoder.setValidityId(exitEdge.getFlags(), route_type));
+        exitEdge.setName(stop.stop_name);
+        if (platformDescriptorIfStatic != null) {
+            gtfsStorage.getRoutes().put(exitEdge.getEdge(), platformDescriptorIfStatic);
+        }
+        wireUpAndConnectTimeline(stop, stopExitNode, arrivalTimeline, GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK, GtfsStorage.EdgeType.WAIT_ARRIVAL);
+    }
+
+    private void wireUpOrPatchDepartureTimeline(ZoneId zoneId, int stationNode, Stop stop, NavigableMap<Integer, Integer> timeline, GtfsStorageI.PlatformDescriptor route) {
+        int platformEnterNode = findPlatformNode(stationNode, route, GtfsStorage.EdgeType.ENTER_PT);
+        if (platformEnterNode != -1) {
+            patchDepartureTimeline(zoneId, timeline, platformEnterNode);
+        } else {
+            wireUpDepartureTimeline(stationNode, stop, timeline, 0, null);
+        }
+    }
+
+    private void wireUpOrPatchArrivalTimeline(ZoneId zoneId, int stationNode, Stop stop, String routeId, NavigableMap<Integer, Integer> timeline, GtfsStorageI.PlatformDescriptor route) {
+        int platformExitNode = findPlatformNode(stationNode, route, GtfsStorage.EdgeType.EXIT_PT);
+        if (platformExitNode != -1) {
+            patchArrivalTimeline(zoneId, timeline, platformExitNode);
+        } else {
+            wireUpArrivalTimeline(stationNode, stop, timeline, 0, null);
+        }
+        final Optional<Transfer> withinStationTransfer = transfers.getTransfersFromStop(stop.stop_id, routeId).stream().filter(t -> t.from_stop_id.equals(stop.stop_id)).findAny();
+        if (!withinStationTransfer.isPresent()) {
+            insertOutboundTransfers(stop.stop_id, null, 0, timeline);
+        }
+        transfers.getTransfersFromStop(stop.stop_id, routeId).forEach(transfer ->
+                insertOutboundTransfers(transfer.from_stop_id, transfer.from_route_id, transfer.min_transfer_time, timeline));
+    }
+
+    private void patchDepartureTimeline(ZoneId zoneId, NavigableMap<Integer, Integer> timeline, int platformNode) {
+        NavigableMap<Integer, Integer> staticDepartureTimelineForRoute = findDepartureTimelineForPlatform(platformNode);
+        timeline.forEach((time, node) -> {
+            SortedMap<Integer, Integer> headMap = staticDepartureTimelineForRoute.headMap(time);
+            if (!headMap.isEmpty()) {
+                EdgeIteratorState edge = graph.edge(headMap.get(headMap.lastKey()), node);
+                edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+                setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT);
+                edge.setFlags(encoder.setTime(edge.getFlags(), time - headMap.lastKey()));
+            }
+            SortedMap<Integer, Integer> tailMap = staticDepartureTimelineForRoute.tailMap(time);
+            if (!tailMap.isEmpty()) {
+                EdgeIteratorState edge = graph.edge(node, tailMap.get(tailMap.firstKey()));
+                edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+                setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT);
+                edge.setFlags(encoder.setTime(edge.getFlags(), tailMap.firstKey() - time));
+            }
+
+            EdgeIteratorState edge = graph.edge(platformNode, node);
+            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK);
+            edge.setFlags(encoder.setTime(edge.getFlags(), time));
+            setFeedIdWithTimezone(edge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
+        });
+    }
+
+    private void patchArrivalTimeline(ZoneId zoneId, NavigableMap<Integer, Integer> timeline, int platformExitNode) {
+        timeline.forEach((time, node) -> {
+            EdgeIteratorState edge = graph.edge(node, platformExitNode);
+            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK);
+            edge.setFlags(encoder.setTime(edge.getFlags(), time));
+            setFeedIdWithTimezone(edge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
+        });
+    }
+
+    private NavigableMap<Integer, Integer> findDepartureTimelineForPlatform(int platformEnterNode) {
+        TreeMap<Integer, Integer> result = new TreeMap<>();
+        if (platformEnterNode == -1) {
+            return result;
+        }
+        EdgeIterator edge = graph.getBaseGraph().createEdgeExplorer(DefaultEdgeFilter.outEdges(encoder)).setBaseNode(platformEnterNode);
+        while (edge.next()) {
+            if (encoder.getEdgeType(edge.getFlags()) == GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK) {
+                result.put((int) encoder.getTime(edge.getFlags()), edge.getAdjNode());
+            }
+        }
+        return result;
+    }
+
+    private int findPlatformNode(int stationNode, GtfsStorageI.PlatformDescriptor platformDescriptor, GtfsStorage.EdgeType edgeType) {
+        DefaultEdgeFilter filter;
+        if (edgeType == GtfsStorage.EdgeType.ENTER_PT) {
+            filter = DefaultEdgeFilter.outEdges(encoder);
+        } else if (edgeType == GtfsStorage.EdgeType.EXIT_PT) {
+            filter = DefaultEdgeFilter.inEdges(encoder);
+        } else {
+            throw new RuntimeException();
+        }
+        EdgeIterator i = graph.getBaseGraph().createEdgeExplorer(filter).setBaseNode(stationNode);
+        while (i.next()) {
+            if (encoder.getEdgeType(i.getFlags()) == edgeType) {
+                if (platformDescriptor.equals(gtfsStorage.getRoutes().get(i.getEdge()))) {
+                    return i.getAdjNode();
+                }
+            }
+        }
+        return -1;
+    }
+
     int addDelayedBoardEdge(ZoneId zoneId, GtfsRealtime.TripDescriptor tripDescriptor, int stopSequence, int departureTime, int departureNode, BitSet validOnDay) {
         Trip trip = feed.trips.get(tripDescriptor.getTripId());
-        final int departureTimelineNode = i++;
         StopTime stopTime = feed.stop_times.get(new Fun.Tuple2(tripDescriptor.getTripId(), stopSequence));
         Stop stop = feed.stops.get(stopTime.stop_id);
-        nodeAccess.setNode(departureTimelineNode, stop.stop_lat, stop.stop_lon);
-        nodeAccess.setAdditionalNodeField(departureTimelineNode, NodeType.INTERNAL_PT.ordinal());
-        times.put(departureTimelineNode, departureTime);
-        departureTimelineNodes.put(stopTime.stop_id, new TimelineNodeIdWithTripId(departureTimelineNode, tripDescriptor.getTripId(), trip.route_id));
+        Map<GtfsStorageI.PlatformDescriptor, NavigableMap<Integer, Integer>> departureTimelineNodesByRoute = departureTimelinesByStop.computeIfAbsent(stopTime.stop_id, s -> new HashMap<>());
+        NavigableMap<Integer, Integer> departureTimelineNodes = departureTimelineNodesByRoute.computeIfAbsent(GtfsStorageI.PlatformDescriptor.route(trip.route_id), s -> new TreeMap<>());
+        int departureTimelineNode = departureTimelineNodes.computeIfAbsent(departureTime % (24 * 60 * 60), t -> {
+            final int _departureTimelineNode = i++;
+            nodeAccess.setNode(_departureTimelineNode, stop.stop_lat, stop.stop_lon);
+            nodeAccess.setAdditionalNodeField(_departureTimelineNode, NodeType.INTERNAL_PT.ordinal());
+            return _departureTimelineNode;
+        });
 
         int dayShift = departureTime / (24 * 60 * 60);
         GtfsStorage.Validity validOn = new GtfsStorage.Validity(getValidOn(validOnDay, dayShift), zoneId, startDate);
@@ -564,26 +507,41 @@ int addDelayedBoardEdge(ZoneId zoneId, GtfsRealtime.TripDescriptor tripDescripto
         return boardEdge.getEdge();
     }
 
-    private void wireUpAndAndConnectArrivalTimeline(Stop toStop, String routeId, int stopExitNode, NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes) {
-        ZoneId zoneId = ZoneId.of(feed.agency.get(feed.routes.get(routeId).agency_id).agency_timezone);
+    private void wireUpAndConnectTimeline(Stop toStop, int platformNode, NavigableMap<Integer, Integer> timeNodes, GtfsStorage.EdgeType timeExpandedNetworkEdgeType, GtfsStorage.EdgeType waitEdgeType) {
+        ZoneId zoneId = ZoneId.of(feed.agency.values().iterator().next().agency_timezone);
         int time = 0;
         int prev = -1;
-        for (Fun.Tuple2<Integer, Integer> e : timeNodes.descendingSet()) {
-            EdgeIteratorState leaveTimeExpandedNetworkEdge = graph.edge(e.b, stopExitNode);
-            leaveTimeExpandedNetworkEdge.setFlags(encoder.setAccess(leaveTimeExpandedNetworkEdge.getFlags(), true, false));
-            setEdgeTypeAndClearDistance(leaveTimeExpandedNetworkEdge, GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK);
-            int arrivalTime = e.a;
-            leaveTimeExpandedNetworkEdge.setFlags(encoder.setTime(leaveTimeExpandedNetworkEdge.getFlags(), arrivalTime));
-            setFeedIdWithTimezone(leaveTimeExpandedNetworkEdge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
+        for (Map.Entry<Integer, Integer> e : timeNodes.descendingMap().entrySet()) {
+            EdgeIteratorState timeExpandedNetworkEdge;
+            if (timeExpandedNetworkEdgeType == GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK) {
+                timeExpandedNetworkEdge = graph.edge(e.getValue(), platformNode);
+            } else if (timeExpandedNetworkEdgeType == GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK) {
+                timeExpandedNetworkEdge = graph.edge(platformNode, e.getValue());
+            } else {
+                throw new RuntimeException();
+            }
+            timeExpandedNetworkEdge.setFlags(encoder.setAccess(timeExpandedNetworkEdge.getFlags(), true, false));
+            timeExpandedNetworkEdge.setName(toStop.stop_name);
+            setEdgeTypeAndClearDistance(timeExpandedNetworkEdge, timeExpandedNetworkEdgeType);
+            timeExpandedNetworkEdge.setFlags(encoder.setTime(timeExpandedNetworkEdge.getFlags(), e.getKey()));
+            setFeedIdWithTimezone(timeExpandedNetworkEdge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
             if (prev != -1) {
-                EdgeIteratorState edge = graph.edge(e.b, prev);
-                edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT_ARRIVAL);
-                edge.setName(toStop.stop_name);
-                edge.setFlags(encoder.setTime(edge.getFlags(), time-e.a));
+                EdgeIteratorState waitEdge = graph.edge(e.getValue(), prev);
+                waitEdge.setFlags(encoder.setAccess(waitEdge.getFlags(), true, false));
+                setEdgeTypeAndClearDistance(waitEdge, waitEdgeType);
+                waitEdge.setName(toStop.stop_name);
+                waitEdge.setFlags(encoder.setTime(waitEdge.getFlags(), time-e.getKey()));
             }
-            time = e.a;
-            prev = e.b;
+            time = e.getKey();
+            prev = e.getValue();
+        }
+        if (!timeNodes.isEmpty()) {
+            EdgeIteratorState edge = graph.edge(timeNodes.get(timeNodes.lastKey()), timeNodes.get(timeNodes.firstKey()));
+            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
+            int rolloverTime = 24 * 60 * 60 - timeNodes.lastKey() + timeNodes.firstKey();
+            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.OVERNIGHT);
+            edge.setName(toStop.stop_name);
+            edge.setFlags(encoder.setTime(edge.getFlags(), rolloverTime));
         }
     }
 
@@ -598,44 +556,13 @@ private void setFeedIdWithTimezone(EdgeIteratorState leaveTimeExpandedNetworkEdg
         leaveTimeExpandedNetworkEdge.setFlags(encoder.setValidityId(leaveTimeExpandedNetworkEdge.getFlags(), validityId));
     }
 
-    private void wireUpAndAndConnectDepartureTimeline(Stop toStop, String toRouteId, int stopEnterNode, NavigableSet<Fun.Tuple2<Integer, Integer>> timeNodes) {
-        ZoneId zoneId = ZoneId.of(feed.agency.get(feed.routes.get(toRouteId).agency_id).agency_timezone);
-        int time = 0;
-        int prev = -1;
-        for (Fun.Tuple2<Integer, Integer> e : timeNodes.descendingSet()) {
-            EdgeIteratorState enterTimeExpandedNetworkEdge = graph.edge(stopEnterNode, e.b);
-            enterTimeExpandedNetworkEdge.setFlags(encoder.setAccess(enterTimeExpandedNetworkEdge.getFlags(), true, false));
-            enterTimeExpandedNetworkEdge.setName(toStop.stop_name);
-            setEdgeTypeAndClearDistance(enterTimeExpandedNetworkEdge, GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK);
-            enterTimeExpandedNetworkEdge.setFlags(encoder.setTime(enterTimeExpandedNetworkEdge.getFlags(), e.a));
-            setFeedIdWithTimezone(enterTimeExpandedNetworkEdge, new GtfsStorage.FeedIdWithTimezone(id, zoneId));
-            if (prev != -1) {
-                EdgeIteratorState edge = graph.edge(e.b, prev);
-                edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-                setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.WAIT);
-                edge.setName(toStop.stop_name);
-                edge.setFlags(encoder.setTime(edge.getFlags(), time-e.a));
-            }
-            time = e.a;
-            prev = e.b;
-        }
-        if (!timeNodes.isEmpty()) {
-            EdgeIteratorState edge = graph.edge(timeNodes.last().b, timeNodes.first().b);
-            edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
-            int rolloverTime = 24 * 60 * 60 - timeNodes.last().a + timeNodes.first().a;
-            setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.OVERNIGHT);
-            edge.setName(toStop.stop_name);
-            edge.setFlags(encoder.setTime(edge.getFlags(), rolloverTime));
-        }
-    }
-
-    private void insertInboundBlockTransfers(List<TripWithStopTimeAndArrivalNode> arrivalNodes, GtfsRealtime.TripDescriptor tripDescriptor, int departureNode, StopTime stopTime, Stop stop, GtfsStorage.Validity validOn, ZoneId zoneId) {
+    private void insertInboundBlockTransfers(List<TripWithStopTimeAndArrivalNode> arrivalNodes, GtfsRealtime.TripDescriptor tripDescriptor, int departureNode, int departureTime, StopTime stopTime, Stop stop, GtfsStorage.Validity validOn, ZoneId zoneId) {
         BitSet accumulatorValidity = new BitSet(validOn.validity.size());
         accumulatorValidity.or(validOn.validity);
         ListIterator<TripWithStopTimeAndArrivalNode> li = arrivalNodes.listIterator(arrivalNodes.size());
         while(li.hasPrevious() && accumulatorValidity.cardinality() > 0) {
             TripWithStopTimeAndArrivalNode lastTrip = li.previous();
-            int dwellTime = times.get(departureNode) - times.get(lastTrip.arrivalNode);
+            int dwellTime = departureTime - lastTrip.arrivalTime;
             if (dwellTime >= 0 && accumulatorValidity.intersects(lastTrip.tripWithStopTimes.validOnDay)) {
                 BitSet blockTransferValidity = new BitSet(validOn.validity.size());
                 blockTransferValidity.or(validOn.validity);
@@ -665,34 +592,23 @@ private void insertInboundBlockTransfers(List<TripWithStopTimeAndArrivalNode> ar
         }
     }
 
-    private Iterable<StopTime> getInterpolatedStopTimesForTrip(String trip_id) {
-        try {
-            return feed.getInterpolatedStopTimesForTrip(trip_id);
-        } catch (GTFSFeed.FirstAndLastStopsDoNotHaveTimes e) {
-            throw new RuntimeException(e);
-        }
-    }
-
-    private void insertInboundTransfers(String fromStopId, String from_route_id, int minimumTransferTime, SortedSet<Fun.Tuple2<Integer, Integer>> toStopTimelineNode) {
+    private void insertInboundTransfers(String fromStopId, String from_route_id, int minimumTransferTime, NavigableMap<Integer, Integer> toStopTimelineNode) {
         int stationNode = gtfsStorage.getStationNodes().get(fromStopId);
         EdgeIterator i = graph.createEdgeExplorer().setBaseNode(stationNode);
         while (i.next()) {
-            GtfsStorage.EdgeType edgeType = encoder.getEdgeType(i.getFlags());
-            if (edgeType == GtfsStorage.EdgeType.EXIT_PT) {
-                String routeId = gtfsStorage.getRoutes().get(i.getEdge());
-                if (from_route_id == null || from_route_id.equals(routeId)) {
+            if (encoder.getEdgeType(i.getFlags()) == GtfsStorage.EdgeType.EXIT_PT) {
+                GtfsStorageI.PlatformDescriptor routeId = gtfsStorage.getRoutes().get(i.getEdge());
+                if (from_route_id == null || GtfsStorageI.PlatformDescriptor.route(from_route_id).equals(routeId)) {
                     EdgeIterator j = graph.createEdgeExplorer().setBaseNode(i.getAdjNode());
                     while (j.next()) {
-                        GtfsStorage.EdgeType edgeType2 = encoder.getEdgeType(j.getFlags());
-                        if (edgeType2 == GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK) {
+                        if (encoder.getEdgeType(j.getFlags()) == GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK) {
                             int arrivalTime = (int) encoder.getTime(j.getFlags());
-                            SortedSet<Fun.Tuple2<Integer, Integer>> tailSet = toStopTimelineNode.tailSet(new Fun.Tuple2<>(arrivalTime + minimumTransferTime, -1));
+                            SortedMap<Integer, Integer> tailSet = toStopTimelineNode.tailMap(arrivalTime + minimumTransferTime);
                             if (!tailSet.isEmpty()) {
-                                Fun.Tuple2<Integer, Integer> e = tailSet.first();
-                                EdgeIteratorState edge = graph.edge(j.getAdjNode(), e.b);
+                                EdgeIteratorState edge = graph.edge(j.getAdjNode(), tailSet.get(tailSet.firstKey()));
                                 edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
                                 setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.TRANSFER);
-                                edge.setFlags(encoder.setTime(edge.getFlags(), e.a - arrivalTime));
+                                edge.setFlags(encoder.setTime(edge.getFlags(), tailSet.firstKey() - arrivalTime));
                             }
                         }
                     }
@@ -701,27 +617,27 @@ private void insertInboundTransfers(String fromStopId, String from_route_id, int
         }
     }
 
-    private void insertOutboundTransfers(String toStopId, String toRouteId, int minimumTransferTime, SortedSet<Fun.Tuple2<Integer, Integer>> fromStopTimelineNodes) {
+    private void insertOutboundTransfers(String toStopId, String toRouteId, int minimumTransferTime, NavigableMap<Integer, Integer> fromStopTimelineNodes) {
         int stationNode = gtfsStorage.getStationNodes().get(toStopId);
         EdgeIterator i = graph.getBaseGraph().createEdgeExplorer().setBaseNode(stationNode);
         while (i.next()) {
             GtfsStorage.EdgeType edgeType = encoder.getEdgeType(i.getFlags());
             if (edgeType == GtfsStorage.EdgeType.ENTER_PT) {
-                String routeId = gtfsStorage.getRoutes().get(i.getEdge());
-                if (toRouteId == null || toRouteId.equals(routeId)) {
-                    fromStopTimelineNodes.forEach(e -> {
+                GtfsStorageI.PlatformDescriptor routeId = gtfsStorage.getRoutes().get(i.getEdge());
+                if (toRouteId == null || routeId instanceof GtfsStorageI.RouteTypePlatform || GtfsStorageI.PlatformDescriptor.route(toRouteId).equals(routeId)) {
+                    fromStopTimelineNodes.forEach((time, e) -> {
                         EdgeIterator j = graph.getBaseGraph().createEdgeExplorer().setBaseNode(i.getAdjNode());
                         while (j.next()) {
                             GtfsStorage.EdgeType edgeType2 = encoder.getEdgeType(j.getFlags());
                             if (edgeType2 == GtfsStorage.EdgeType.ENTER_TIME_EXPANDED_NETWORK) {
                                 int departureTime = (int) encoder.getTime(j.getFlags());
-                                if (departureTime < e.a + minimumTransferTime) {
+                                if (departureTime < time + minimumTransferTime) {
                                     continue;
                                 }
-                                EdgeIteratorState edge = graph.edge(e.b, j.getAdjNode());
+                                EdgeIteratorState edge = graph.edge(e, j.getAdjNode());
                                 edge.setFlags(encoder.setAccess(edge.getFlags(), true, false));
                                 setEdgeTypeAndClearDistance(edge, GtfsStorage.EdgeType.TRANSFER);
-                                edge.setFlags(encoder.setTime(edge.getFlags(), departureTime - e.a));
+                                edge.setFlags(encoder.setTime(edge.getFlags(), departureTime - time));
                                 break;
                             }
                         }
@@ -755,4 +671,20 @@ private BitSet getValidOn(BitSet validOnDay, int dayShift) {
         }
     }
 
+    private int routeType(GtfsStorageI.PlatformDescriptor platformDescriptor) {
+        if (platformDescriptor instanceof GtfsStorageI.RouteTypePlatform) {
+            return ((GtfsStorageI.RouteTypePlatform) platformDescriptor).route_type;
+        } else {
+            return feed.routes.get(((GtfsStorageI.RoutePlatform) platformDescriptor).route_id).route_type;
+        }
+    }
+
+    private String routeIdOrNull(GtfsStorageI.PlatformDescriptor platformDescriptor) {
+        if (platformDescriptor instanceof GtfsStorageI.RouteTypePlatform) {
+            return null;
+        } else {
+            return ((GtfsStorageI.RoutePlatform) platformDescriptor).route_id;
+        }
+    }
+
 }
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorage.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorage.java
index 8e94eaf6e3..cfbfcbe936 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorage.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorage.java
@@ -96,7 +96,7 @@ public int hashCode() {
 	private Map<Integer, byte[]> tripDescriptors;
 	private Map<Integer, Integer> stopSequences;
 
-	private Map<Integer, String> routes;
+	private Map<Integer, PlatformDescriptor> routes;
 
 	private Map<String, Fare> fares;
 	private Map<String, int[]> boardEdgesForTrip;
@@ -104,7 +104,7 @@ public int hashCode() {
 
 	private Map<String, Integer> stationNodes;
 
-	enum EdgeType {
+	public enum EdgeType {
 		HIGHWAY, ENTER_TIME_EXPANDED_NETWORK, LEAVE_TIME_EXPANDED_NETWORK, ENTER_PT, EXIT_PT, HOP, DWELL, BOARD, ALIGHT, OVERNIGHT, TRANSFER, WAIT, WAIT_ARRIVAL
     }
 
@@ -277,7 +277,7 @@ public long getCapacity() {
 	}
 
     @Override
-    public Map<Integer, String> getRoutes() {
+    public Map<Integer, PlatformDescriptor> getRoutes() {
         return routes;
     }
 
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorageI.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorageI.java
index 3b03cb553c..5d8b0fb8ed 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorageI.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/GtfsStorageI.java
@@ -20,15 +20,69 @@
 
 import com.conveyal.gtfs.GTFSFeed;
 import com.conveyal.gtfs.model.Fare;
+import com.conveyal.gtfs.model.Route;
 import com.google.transit.realtime.GtfsRealtime;
 import com.graphhopper.storage.StorableProperties;
 
+import java.io.Serializable;
 import java.util.Map;
+import java.util.Objects;
 
 // Used to mock GtfsStorage for GtfsReader, to reuse it for realtime updates.
 // GtfsReader basically emits things to be added as a stream of events.
 // TODO: Make that explicit
 public interface GtfsStorageI {
+
+    public abstract class PlatformDescriptor implements Serializable {
+
+        public static PlatformDescriptor route(String route_id) {
+            RoutePlatform routePlatform = new RoutePlatform();
+            routePlatform.route_id = route_id;
+            return routePlatform;
+        }
+
+        public static RouteTypePlatform routeType(int route_type) {
+            RouteTypePlatform routeTypePlatform = new RouteTypePlatform();
+            routeTypePlatform.route_type = route_type;
+            return routeTypePlatform;
+        }
+
+    }
+
+    class RoutePlatform extends PlatformDescriptor {
+        String route_id;
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            RoutePlatform that = (RoutePlatform) o;
+            return Objects.equals(route_id, that.route_id);
+        }
+
+        @Override
+        public int hashCode() {
+            return Objects.hash(route_id);
+        }
+    }
+
+    class RouteTypePlatform extends PlatformDescriptor {
+        int route_type;
+
+        @Override
+        public boolean equals(Object o) {
+            if (this == o) return true;
+            if (o == null || getClass() != o.getClass()) return false;
+            RouteTypePlatform that = (RouteTypePlatform) o;
+            return route_type == that.route_type;
+        }
+
+        @Override
+        public int hashCode() {
+            return Objects.hash(route_type);
+        }
+    }
+
     Map<String, Fare> getFares();
 
     Map<GtfsStorage.Validity, Integer> getOperatingDayPatterns();
@@ -49,5 +103,5 @@
 
     Map<String, Integer> getStationNodes();
 
-    Map<Integer, String> getRoutes();
+    Map<Integer, PlatformDescriptor> getRoutes();
 }
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Label.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Label.java
index 4a9ea82d7e..e5a124ca7d 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Label.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Label.java
@@ -23,7 +23,7 @@
 import java.time.Instant;
 import java.util.Iterator;
 
-class Label {
+public class Label {
 
     static class Transition {
         final Label label;
@@ -62,10 +62,10 @@ public String toString() {
         }
     }
 
-    final long currentTime;
+    public final long currentTime;
 
     final int edge;
-    final int adjNode;
+    public final int adjNode;
 
     final int nTransfers;
     final int nWalkDistanceConstraintViolations;
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/MultiCriteriaLabelSetting.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/MultiCriteriaLabelSetting.java
index 89afa87e61..e11661f904 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/MultiCriteriaLabelSetting.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/MultiCriteriaLabelSetting.java
@@ -17,14 +17,14 @@
  */
 package com.graphhopper.reader.gtfs;
 
-import com.google.common.collect.ArrayListMultimap;
-import com.google.common.collect.Multimap;
+import com.carrotsearch.hppc.IntObjectHashMap;
+import com.carrotsearch.hppc.IntObjectMap;
 import com.graphhopper.util.EdgeIterator;
-import com.graphhopper.util.EdgeIteratorState;
 
 import java.time.Instant;
 import java.util.*;
 import java.util.function.Consumer;
+import java.util.function.Predicate;
 import java.util.stream.Stream;
 import java.util.stream.StreamSupport;
 
@@ -37,14 +37,18 @@
  * @author Peter Karich
  * @author Wesam Herbawi
  */
-class MultiCriteriaLabelSetting {
+public class MultiCriteriaLabelSetting {
+
+    public interface SPTVisitor {
+        void visit(Label label);
+    }
 
     private final Comparator<Label> queueComparator;
     private final List<Label> targetLabels;
     private long startTime;
     private int blockedRouteTypes;
     private final PtFlagEncoder flagEncoder;
-    private final Multimap<Integer, Label> fromMap;
+    private final IntObjectMap<List<Label>> fromMap;
     private final PriorityQueue<Label> fromHeap;
     private final int maxVisitedNodes;
     private final boolean reverse;
@@ -57,7 +61,7 @@
     private double betaTransfers;
     private double betaWalkTime = 1.0;
 
-    MultiCriteriaLabelSetting(GraphExplorer explorer, PtFlagEncoder flagEncoder, boolean reverse, double maxWalkDistancePerLeg, boolean ptOnly, boolean mindTransfers, boolean profileQuery, int maxVisitedNodes, List<Label> solutions) {
+    public MultiCriteriaLabelSetting(GraphExplorer explorer, PtFlagEncoder flagEncoder, boolean reverse, double maxWalkDistancePerLeg, boolean ptOnly, boolean mindTransfers, boolean profileQuery, int maxVisitedNodes, List<Label> solutions) {
         this.flagEncoder = flagEncoder;
         this.maxVisitedNodes = maxVisitedNodes;
         this.explorer = explorer;
@@ -68,12 +72,13 @@
         this.profileQuery = profileQuery;
         this.targetLabels = solutions;
 
-        queueComparator = Comparator.<Label>comparingLong(l2 -> weight(l2))
-                .thenComparing(Comparator.comparingLong(l1 -> l1.nTransfers))
-                .thenComparing(Comparator.comparingLong(l -> departureTimeCriterion(l) != null ? departureTimeCriterion(l) : 0))
-                .thenComparing(Comparator.comparingLong(l2 -> l2.impossible ? 1 : 0));
+        queueComparator = Comparator
+                .comparingLong(this::weight)
+                .thenComparingLong(l1 -> l1.nTransfers)
+                .thenComparingLong(l -> departureTimeCriterion(l) != null ? departureTimeCriterion(l) : 0)
+                .thenComparingLong(l2 -> l2.impossible ? 1 : 0);
         fromHeap = new PriorityQueue<>(queueComparator);
-        fromMap = ArrayListMultimap.create();
+        fromMap = new IntObjectHashMap<>();
     }
 
     Stream<Label> calcLabels(int from, int to, Instant startTime, int blockedRouteTypes) {
@@ -84,6 +89,30 @@
                 .peek(label -> visitedNodes++);
     }
 
+    public void calcLabels(int from, int to, Instant startTime, int blockedRouteTypes, SPTVisitor visitor, Predicate<Label> predicate) {
+        this.startTime = startTime.toEpochMilli();
+        this.blockedRouteTypes = blockedRouteTypes;
+        Iterator<Label> iterator = StreamSupport.stream(new MultiCriteriaLabelSettingSpliterator(from, to), false).iterator();
+        Label l;
+        while (iterator.hasNext() && predicate.test(l = iterator.next())) {
+            visitor.visit(l);
+        }
+    }
+
+
+    public void calcLabelsAndNeighbors(int from, int to, Instant startTime, int blockedRouteTypes, SPTVisitor visitor, Predicate<Label> predicate) {
+        this.startTime = startTime.toEpochMilli();
+        this.blockedRouteTypes = blockedRouteTypes;
+        Iterator<Label> iterator = StreamSupport.stream(new MultiCriteriaLabelSettingSpliterator(from, to), false).iterator();
+        Label l;
+        while (iterator.hasNext() && predicate.test(l = iterator.next())) {
+            visitor.visit(l);
+        }
+        for (Label label : fromHeap) {
+            visitor.visit(label);
+        }
+    }
+
     // experimental
     void setBetaTransfers(double betaTransfers) {
         this.betaTransfers = betaTransfers;
@@ -104,7 +133,9 @@ void setBetaWalkTime(double betaWalkTime) {
             this.from = from;
             this.to = to;
             Label label = new Label(startTime, EdgeIterator.NO_EDGE, from, 0, 0, 0.0, null, 0, 0,false,null);
-            fromMap.put(from, label);
+            ArrayList<Label> labels = new ArrayList<>(1);
+            labels.add(label);
+            fromMap.put(from, labels);
             fromHeap.add(label);
         }
 
@@ -142,7 +173,11 @@ public boolean tryAdvance(Consumer<? super Label> action) {
                     long walkTime = label.walkTime + (edgeType == GtfsStorage.EdgeType.HIGHWAY || edgeType == GtfsStorage.EdgeType.ENTER_PT || edgeType == GtfsStorage.EdgeType.EXIT_PT ? ((reverse ? -1 : 1) * (nextTime - label.currentTime)) : 0);
                     int nWalkDistanceConstraintViolations = Math.min(1, label.nWalkDistanceConstraintViolations + (
                             isTryingToReEnterPtAfterWalking ? 1 : (label.walkDistanceOnCurrentLeg <= maxWalkDistancePerLeg && walkDistanceOnCurrentLeg > maxWalkDistancePerLeg ? 1 : 0)));
-                    Collection<Label> sptEntries = fromMap.get(edge.getAdjNode());
+                    List<Label> sptEntries = fromMap.get(edge.getAdjNode());
+                    if (sptEntries == null) {
+                        sptEntries = new ArrayList<>(1);
+                        fromMap.put(edge.getAdjNode(), sptEntries);
+                    }
                     boolean impossible = label.impossible
                             || explorer.isBlocked(edge)
                             || (!reverse) && edgeType == GtfsStorage.EdgeType.BOARD && label.residualDelay > 0
@@ -167,25 +202,25 @@ public boolean tryAdvance(Consumer<? super Label> action) {
                     }
                     if (!reverse && edgeType == GtfsStorage.EdgeType.LEAVE_TIME_EXPANDED_NETWORK && residualDelay > 0) {
                         Label newImpossibleLabelForDelayedTrip = new Label(nextTime, edge.getEdge(), edge.getAdjNode(), nTransfers, nWalkDistanceConstraintViolations, walkDistanceOnCurrentLeg, firstPtDepartureTime, walkTime, residualDelay, true, label);
-                        insertIfNotDominated(edge, sptEntries, newImpossibleLabelForDelayedTrip);
+                        insertIfNotDominated(sptEntries, newImpossibleLabelForDelayedTrip);
                         nextTime += residualDelay;
                         residualDelay = 0;
                         Label newLabel = new Label(nextTime, edge.getEdge(), edge.getAdjNode(), nTransfers, nWalkDistanceConstraintViolations, walkDistanceOnCurrentLeg, firstPtDepartureTime, walkTime, residualDelay, impossible, label);
-                        insertIfNotDominated(edge, sptEntries, newLabel);
+                        insertIfNotDominated(sptEntries, newLabel);
                     } else {
                         Label newLabel = new Label(nextTime, edge.getEdge(), edge.getAdjNode(), nTransfers, nWalkDistanceConstraintViolations, walkDistanceOnCurrentLeg, firstPtDepartureTime, walkTime, residualDelay, impossible, label);
-                        insertIfNotDominated(edge, sptEntries, newLabel);
+                        insertIfNotDominated(sptEntries, newLabel);
                     }
                 });
                 return true;
             }
         }
 
-        private void insertIfNotDominated(EdgeIteratorState edge, Collection<Label> sptEntries, Label label) {
+        private void insertIfNotDominated(Collection<Label> sptEntries, Label label) {
             if (isNotDominatedByAnyOf(label, sptEntries)) {
                 if (isNotDominatedByAnyOf(label, targetLabels)) {
                     removeDominated(label, sptEntries);
-                    fromMap.put(edge.getAdjNode(), label);
+                    sptEntries.add(label);
                     fromHeap.add(label);
                 }
             }
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/PtFlagEncoder.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/PtFlagEncoder.java
index e0a9ecf87d..f57d5b6877 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/PtFlagEncoder.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/PtFlagEncoder.java
@@ -95,7 +95,7 @@ long setValidityId(long flags, int validityId) {
 		return this.validityId.setValue(flags, validityId);
 	}
 
-	GtfsStorage.EdgeType getEdgeType(long flags) {
+	public GtfsStorage.EdgeType getEdgeType(long flags) {
 		return GtfsStorage.EdgeType.values()[(int) type.getValue(flags)];
 	}
 
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/RealtimeFeed.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/RealtimeFeed.java
index 714f7436d8..29f8af24be 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/RealtimeFeed.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/RealtimeFeed.java
@@ -319,7 +319,7 @@ public GraphExtension getExtension() {
                 }
 
                 @Override
-                public Map<Integer, String> getRoutes() {
+                public Map<Integer, PlatformDescriptor> getRoutes() {
                     return staticGtfs.getRoutes();
                 }
             };
@@ -327,7 +327,7 @@ public GraphExtension getExtension() {
             Instant timestamp = Instant.ofEpochSecond(feedMessage.getHeader().getTimestamp());
             LocalDate dateToChange = timestamp.atZone(timezone).toLocalDate(); //FIXME
             BitSet validOnDay = new BitSet();
-            LocalDate startDate = feed.calculateStats().getStartDate();
+            LocalDate startDate = feed.getStartDate();
             validOnDay.set((int) DAYS.between(startDate, dateToChange));
             feedMessage.getEntityList().stream()
                     .filter(GtfsRealtime.FeedEntity::hasTripUpdate)
@@ -392,7 +392,7 @@ public GraphExtension getExtension() {
                         GtfsReader.TripWithStopTimes tripWithStopTimes = new GtfsReader.TripWithStopTimes(trip, stopTimes, validOnDay, Collections.emptySet(), Collections.emptySet());
                         gtfsReader.addTrip(timezone, 0, new ArrayList<>(), tripWithStopTimes, tripUpdate.getTrip(), false);
                     });
-            gtfsReader.wireUpAdditionalDepartures(timezone);
+            gtfsReader.wireUpAdditionalDeparturesAndArrivals(timezone);
         });
 
         return new RealtimeFeed(staticGtfs, feedMessages, blockedEdges, delaysForBoardEdges, delaysForAlightEdges, additionalEdges, tripDescriptors, stopSequences, operatingDayPatterns, writableTimeZones);
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Transfers.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Transfers.java
index b819541b94..2de446bad3 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Transfers.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/Transfers.java
@@ -108,4 +108,11 @@ private Transfer findMostSpecificRule(List<Transfer> transfers, String fromRoute
         return transfersBySpecificity.get(0);
     }
 
+    public boolean hasNoRouteSpecificDepartureTransferRules(String stop_id) {
+        return transfersToStop.getOrDefault(stop_id, Collections.emptyList()).stream().allMatch(transfer -> transfer.to_route_id == null);
+    }
+
+    public boolean hasNoRouteSpecificArrivalTransferRules(String stop_id) {
+        return transfersFromStop.getOrDefault(stop_id, Collections.emptyList()).stream().allMatch(transfer -> transfer.from_route_id == null);
+    }
 }
diff --git a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/TripFromLabel.java b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/TripFromLabel.java
index 70b9f4550e..527c8ff864 100644
--- a/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/TripFromLabel.java
+++ b/reader-gtfs/src/main/java/com/graphhopper/reader/gtfs/TripFromLabel.java
@@ -29,9 +29,9 @@
 import com.graphhopper.routing.InstructionsFromEdges;
 import com.graphhopper.routing.weighting.Weighting;
 import com.graphhopper.util.*;
-import com.vividsolutions.jts.geom.Coordinate;
-import com.vividsolutions.jts.geom.Geometry;
-import com.vividsolutions.jts.geom.GeometryFactory;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.Geometry;
+import org.locationtech.jts.geom.GeometryFactory;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
diff --git a/reader-gtfs/src/test/java/com/graphhopper/GraphHopperGtfsIT.java b/reader-gtfs/src/test/java/com/graphhopper/GraphHopperGtfsIT.java
index dc19f9e50f..3650581939 100644
--- a/reader-gtfs/src/test/java/com/graphhopper/GraphHopperGtfsIT.java
+++ b/reader-gtfs/src/test/java/com/graphhopper/GraphHopperGtfsIT.java
@@ -446,15 +446,6 @@ public void testTransferRules() {
         );
         request.getHints().put(Parameters.PT.EARLIEST_DEPARTURE_TIME, LocalDateTime.of(2007,1,6,7,30).atZone(zoneId).toInstant());
 
-        response = graphHopper.route(request);
-        assertEquals("Ignoring transfer rules (free walking): Will be there at 8:10.", time(0, 40), response.getBest().getTime());
-
-        request = new GHRequest(
-                FROM_LAT, FROM_LON,
-                TO2_LAT, TO2_LON
-        );
-        request.getHints().put(Parameters.PT.EARLIEST_DEPARTURE_TIME, LocalDateTime.of(2007,1,6,7,30).atZone(zoneId).toInstant());
-
         response = graphHopper.route(request);
         assertEquals("Will still be there at 8:10 because there is a route-specific exception for this route.", time(0, 40), response.getBest().getTime());
 
diff --git a/reader-gtfs/src/test/java/com/graphhopper/GraphHopperMultimodalIT.java b/reader-gtfs/src/test/java/com/graphhopper/GraphHopperMultimodalIT.java
index 82ab0d73fc..d375208ebf 100644
--- a/reader-gtfs/src/test/java/com/graphhopper/GraphHopperMultimodalIT.java
+++ b/reader-gtfs/src/test/java/com/graphhopper/GraphHopperMultimodalIT.java
@@ -80,7 +80,7 @@ public void testDepartureTimeOfAccessLegInProfileQuery() {
         ghRequest.getHints().put(Parameters.PT.PROFILE_QUERY, true);
 
         GHResponse response = graphHopper.route(ghRequest);
-        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(247);
+        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(243);
 
         PathWrapper firstTransitSolution = response.getAll().stream().filter(p -> p.getLegs().size() > 1).findFirst().get(); // There can be a walk-only trip.
         assertThat(firstTransitSolution.getLegs().get(0).getDepartureTime().toInstant().atZone(zoneId).toLocalTime())
@@ -101,7 +101,7 @@ public void testDepartureTimeOfAccessLeg() {
         ghRequest.getHints().put("beta_walk_time", 2.0); // I somewhat dislike walking
 
         GHResponse response = graphHopper.route(ghRequest);
-        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(130);
+        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(129);
 
         PathWrapper firstTransitSolution = response.getAll().stream().filter(p -> p.getLegs().size() > 1).findFirst().get(); // There can be a walk-only trip.
         assertThat(firstTransitSolution.getLegs().get(0).getDepartureTime().toInstant().atZone(zoneId).toLocalTime())
@@ -125,7 +125,7 @@ public void testDepartureTimeOfAccessLeg() {
         // Now, the walk solution dominates, and we get no transit solution.
         ghRequest.getHints().put("beta_walk_time",1.0);
         response = graphHopper.route(ghRequest);
-        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(139);
+        assertThat(response.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(138);
         assertThat(response.getAll().stream().filter(p -> p.getLegs().size() > 1).findFirst()).isEmpty();
     }
 
@@ -184,14 +184,14 @@ public void testProfileQueryDoesntEndPrematurely() {
 
         ghRequest.getHints().put(Parameters.PT.LIMIT_SOLUTIONS, 1);
         GHResponse response1 = graphHopper.route(ghRequest);
-        assertThat(response1.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(143);
+        assertThat(response1.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(142);
         ghRequest.getHints().put(Parameters.PT.LIMIT_SOLUTIONS, 3);
         GHResponse response3 = graphHopper.route(ghRequest);
-        assertThat(response3.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(248);
+        assertThat(response3.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(230);
         assertThat(response1.getAll().get(0).getTime()).isEqualTo(response3.getAll().get(0).getTime());
         ghRequest.getHints().put(Parameters.PT.LIMIT_SOLUTIONS, 5);
         GHResponse response5 = graphHopper.route(ghRequest);
-        assertThat(response5.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(362);
+        assertThat(response5.getHints().getInt("visited_nodes.sum", Integer.MAX_VALUE)).isLessThanOrEqualTo(334);
         assertThat(response3.getAll().get(2).getTime()).isEqualTo(response5.getAll().get(2).getTime());
     }
 
diff --git a/reader-osm/src/test/java/com/graphhopper/reader/osm/GraphHopperOSMTest.java b/reader-osm/src/test/java/com/graphhopper/reader/osm/GraphHopperOSMTest.java
index befe7ae6aa..ef9655c33b 100644
--- a/reader-osm/src/test/java/com/graphhopper/reader/osm/GraphHopperOSMTest.java
+++ b/reader-osm/src/test/java/com/graphhopper/reader/osm/GraphHopperOSMTest.java
@@ -103,14 +103,14 @@ public void testLoadOSM() {
         closableInstance.close();
         try {
             rsp = closableInstance.route(new GHRequest(51.2492152, 9.4317166, 51.2, 9.4));
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertEquals("You need to create a new GraphHopper instance as it is already closed", ex.getMessage());
         }
 
         try {
             closableInstance.getLocationIndex().findClosest(51.2492152, 9.4317166, EdgeFilter.ALL_EDGES);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertEquals("You need to create a new LocationIndex instance as it is already closed", ex.getMessage());
         }
@@ -166,9 +166,9 @@ public void testLoadingWithDifferentCHConfig_issue471() {
                 setEncodingManager(new EncodingManager("car"));
         try {
             gh.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
-            assertTrue(ex.getMessage(), ex.getMessage().startsWith("Configured graph.ch.weightings:"));
+            assertTrue(ex.getMessage(), ex.getMessage().startsWith("You loaded a CH graph, but you did not specify graph.ch.weightings"));
         }
 
         Helper.removeDir(new File(ghLoc));
@@ -188,9 +188,9 @@ public void testLoadingWithDifferentCHConfig_issue471() {
                 setEncodingManager(new EncodingManager("car"));
         try {
             gh.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
-            assertTrue(ex.getMessage(), ex.getMessage().startsWith("Configured graph.ch.weightings:"));
+            assertTrue(ex.getMessage(), ex.getMessage().contains("is not contained in loaded weightings"));
         }
     }
 
@@ -257,7 +257,7 @@ public void run() {
             latch2.await(3, TimeUnit.SECONDS);
             // now importOrLoad should have create a lock which this load call does not like
             instance2.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (RuntimeException ex) {
             assertNotNull(ex);
             assertTrue(ex.getMessage(), ex.getMessage().startsWith("To avoid reading partial data"));
@@ -384,7 +384,7 @@ public void testFailsForWrongConfig() throws IOException {
                             put(Parameters.CH.PREPARE + "weightings", "no")).
                     setDataReaderFile(testOsm3);
             tmpGH.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertTrue(ex.getMessage(), ex.getMessage().startsWith("Encoding does not match"));
         }
@@ -400,7 +400,7 @@ public void testFailsForWrongConfig() throws IOException {
                 setDataReaderFile(testOsm3);
         try {
             instance.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertTrue(ex.getMessage(), ex.getMessage().startsWith("Configured graph.bytes_for_flags (8) is not equal to loaded 4"));
         }
@@ -414,7 +414,7 @@ public void testFailsForWrongConfig() throws IOException {
                     put("graph.flag_encoders", "car,foot")).
                     setDataReaderFile(testOsm3);
             tmpGH.load(ghLoc);
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertTrue(ex.getMessage(), ex.getMessage().startsWith("Encoding does not match"));
         }
@@ -430,7 +430,7 @@ public void testNoNPE_ifLoadNotSuccessful() {
             new File(ghLoc).mkdirs();
             assertFalse(instance.load(ghLoc));
             instance.route(new GHRequest(10, 40, 12, 32));
-            assertTrue(false);
+            fail();
         } catch (IllegalStateException ex) {
             assertEquals("Do a successful call to load or importOrLoad before routing", ex.getMessage());
         }
@@ -459,7 +459,7 @@ public DataReader importData() throws IOException {
         try {
             tmp.setDataReaderFile(testOsm);
             tmp.importData();
-            assertTrue(false);
+            fail();
         } catch (IllegalStateException ex) {
             assertEquals("Load graph before importing OSM data", ex.getMessage());
         }
@@ -480,7 +480,7 @@ public DataReader importData() throws IOException {
                 setGraphHopperLocation(ghLoc);
         try {
             instance.importOrLoad();
-            assertTrue(false);
+            fail();
         } catch (IllegalStateException ex) {
             assertEquals("Couldn't load from existing folder: " + ghLoc
                     + " but also cannot use file for DataReader as it wasn't specified!", ex.getMessage());
@@ -505,7 +505,7 @@ public DataReader importData() throws IOException {
                 setGraphHopperLocation(ghLoc);
         try {
             instance.importOrLoad();
-            assertTrue(false);
+            fail();
         } catch (Exception ex) {
             assertEquals("Couldn't load from existing folder: " + ghLoc
                     + " but also cannot use file for DataReader as it wasn't specified!", ex.getMessage());
@@ -756,7 +756,7 @@ public boolean isEnabled() {
         });
         instance.importOrLoad();
 
-        assertTrue(af == instance.getAlgorithmFactory(null));
+        assertSame(af, instance.getAlgorithmFactory(null));
 
         // test that hints are passed to algorithm opts
         final AtomicInteger cnt = new AtomicInteger(0);
@@ -886,8 +886,8 @@ public void testGetWeightingForCH() {
         GraphHopperStorage storage = new GraphHopperStorage(Arrays.asList(fwSimpleTruck, fwTruck), ramDir, em, false, new GraphExtension.NoOpExtension());
         decorator.addWeighting(fwSimpleTruck);
         decorator.addWeighting(fwTruck);
-        decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwSimpleTruck), fwSimpleTruck, TraversalMode.NODE_BASED));
-        decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwTruck), fwTruck, TraversalMode.NODE_BASED));
+        decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwSimpleTruck), TraversalMode.NODE_BASED));
+        decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwTruck), TraversalMode.NODE_BASED));
 
         HintsMap wMap = new HintsMap("fastest");
         wMap.put("vehicle", "truck");
@@ -899,8 +899,8 @@ public void testGetWeightingForCH() {
         decorator.addWeighting(fwTruck);
         decorator.addWeighting(fwSimpleTruck);
         try {
-            decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwSimpleTruck), fwSimpleTruck, TraversalMode.NODE_BASED));
-            assertTrue(false);
+            decorator.addPreparation(new PrepareContractionHierarchies(ramDir, storage, storage.getGraph(CHGraph.class, fwSimpleTruck), TraversalMode.NODE_BASED));
+            fail();
         } catch (Exception ex) {
         }
     }
diff --git a/reader-shp/pom.xml b/reader-shp/pom.xml
deleted file mode 100644
index 4b9040f1cd..0000000000
--- a/reader-shp/pom.xml
+++ /dev/null
@@ -1,86 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
-    <modelVersion>4.0.0</modelVersion>
-
-    <groupId>com.graphhopper</groupId>
-    <artifactId>graphhopper-reader-shp</artifactId>
-    <version>0.12-SNAPSHOT</version>
-    <packaging>jar</packaging>
-    <name>GraphHopper Reader for Shapefile Data</name>
-	
-    <properties>      
-        <geotools.version>19.0</geotools.version>
-    </properties>
-    	
-    <parent>
-        <groupId>com.graphhopper</groupId>
-        <artifactId>graphhopper-parent</artifactId>    	
-        <version>0.12-SNAPSHOT</version>
-    </parent>
-
-    <dependencies>
-        <dependency>
-            <groupId>com.graphhopper</groupId>
-            <artifactId>graphhopper-core</artifactId>
-            <version>${project.parent.version}</version>
-        </dependency>
-        
-        <dependency>
-            <groupId>org.geotools</groupId>
-            <artifactId>gt-shapefile</artifactId>
-            <version>${geotools.version}</version>
-        </dependency>
-		
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>slf4j-api</artifactId>
-            <version>${slf4j.version}</version>
-        </dependency>   
-        <dependency>
-            <groupId>org.slf4j</groupId>
-            <artifactId>slf4j-log4j12</artifactId>
-            <version>${slf4j.version}</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>log4j</groupId>
-            <artifactId>log4j</artifactId>
-            <version>${log4j.version}</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>junit</groupId>
-            <artifactId>junit</artifactId>
-            <version>4.12</version>
-            <scope>test</scope>
-        </dependency>
-        <dependency>
-            <groupId>com.graphhopper</groupId>
-            <artifactId>graphhopper-reader-osm</artifactId>
-            <version>${project.parent.version}</version>
-            <scope>test</scope>
-        </dependency>        
-    </dependencies>
-    <build>
-        <plugins>
-            <plugin>
-                <groupId>org.apache.maven.plugins</groupId>
-                <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
-                <configuration>
-                    <source>1.8</source>
-                    <target>1.8</target>
-                </configuration>
-            </plugin>
-        </plugins>
-    </build>
-    <repositories>
-        <repository>
-            <id>osgeo</id>
-            <name>Open Source Geospatial Foundation Repository</name>
-            <url>http://download.osgeo.org/webdav/geotools/</url>
-        </repository>
-    </repositories>
-	
-</project>
diff --git a/reader-shp/src/main/java/com/graphhopper/reader/shp/GraphHopperSHP.java b/reader-shp/src/main/java/com/graphhopper/reader/shp/GraphHopperSHP.java
deleted file mode 100644
index 296923156e..0000000000
--- a/reader-shp/src/main/java/com/graphhopper/reader/shp/GraphHopperSHP.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.reader.shp;
-
-import java.util.HashSet;
-
-import com.graphhopper.GraphHopper;
-import com.graphhopper.reader.DataReader;
-import com.graphhopper.reader.shp.OSMShapeFileReader.EdgeAddedListener;
-import com.graphhopper.storage.GraphHopperStorage;
-
-/**
- * This class is the main entry point to import from OpenStreetMap shape files similar to GraphHopperOSM which imports
- * OSM xml and pbf files.
- *
- * @author Phil
- */
-public class GraphHopperSHP extends GraphHopper {
-    private final HashSet<EdgeAddedListener> edgeAddedListeners = new HashSet<>();
-
-    @Override
-    protected DataReader createReader(GraphHopperStorage ghStorage) {
-        OSMShapeFileReader reader = new OSMShapeFileReader(ghStorage);
-        for (EdgeAddedListener l : edgeAddedListeners) {
-            reader.addListener(l);
-        }
-        return initDataReader(reader);
-    }
-
-    public void addListener(EdgeAddedListener l) {
-        edgeAddedListeners.add(l);
-    }
-
-}
diff --git a/reader-shp/src/main/java/com/graphhopper/reader/shp/OSMShapeFileReader.java b/reader-shp/src/main/java/com/graphhopper/reader/shp/OSMShapeFileReader.java
deleted file mode 100644
index 1228591d35..0000000000
--- a/reader-shp/src/main/java/com/graphhopper/reader/shp/OSMShapeFileReader.java
+++ /dev/null
@@ -1,362 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.reader.shp;
-
-import com.graphhopper.coll.GHObjectIntHashMap;
-import com.graphhopper.reader.DataReader;
-import com.graphhopper.reader.ReaderWay;
-import com.graphhopper.reader.dem.ElevationProvider;
-import com.graphhopper.storage.GraphHopperStorage;
-import com.graphhopper.util.DistanceCalc;
-import com.graphhopper.util.EdgeIteratorState;
-import com.graphhopper.util.Helper;
-import com.graphhopper.util.PointList;
-import com.graphhopper.util.shapes.GHPoint;
-import com.vividsolutions.jts.geom.Coordinate;
-import com.vividsolutions.jts.geom.LineString;
-import com.vividsolutions.jts.geom.MultiLineString;
-import org.geotools.data.DataStore;
-import org.geotools.feature.FeatureIterator;
-import org.opengis.feature.simple.SimpleFeature;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.HashSet;
-import java.util.List;
-
-import static com.graphhopper.util.Helper.*;
-
-/**
- * OSMShapeFileReader for files present at : http://download.geofabrik.de/ It
- * extracts the data as per the structure of shape files
- *
- * @author Vikas Veshishth
- * @author Philip Welch
- */
-public class OSMShapeFileReader extends ShapeFileReader {
-    private static final int COORD_STATE_UNKNOWN = 0;
-    private static final int COORD_STATE_PILLAR = -2;
-    private static final int FIRST_NODE_ID = 1;
-    private static final String[] DIRECT_COPY_TAGS = new String[]{"name"};
-    private File roadsFile;
-    private final GHObjectIntHashMap<Coordinate> coordState = new GHObjectIntHashMap<>(1000, 0.7f);
-    private final DistanceCalc distCalc = DIST_EARTH;
-    private static final Logger LOGGER = LoggerFactory.getLogger(OSMShapeFileReader.class);
-    private final HashSet<EdgeAddedListener> edgeAddedListeners = new HashSet<>();
-    private int nextNodeId = FIRST_NODE_ID;
-    private final String encoding = "utf8";
-
-    public OSMShapeFileReader(GraphHopperStorage ghStorage) {
-        super(ghStorage);
-    }
-
-    private List<Coordinate[]> getCoords(Object o) {
-        ArrayList<Coordinate[]> ret = new ArrayList<>();
-        if (o == null) {
-            return ret;
-        }
-
-        if (o instanceof LineString) {
-            ret.add(((LineString) o).getCoordinates());
-        } else if (o instanceof MultiLineString) {
-            MultiLineString mls = (MultiLineString) o;
-            int n = mls.getNumGeometries();
-            for (int i = 0; i < n; i++) {
-                ret.add(mls.getGeometryN(i).getCoordinates());
-            }
-        }
-
-        return ret;
-    }
-
-    @Override
-    void processJunctions() {
-        DataStore dataStore = null;
-        FeatureIterator<SimpleFeature> roads = null;
-
-        try {
-            dataStore = openShapefileDataStore(roadsFile, encoding);
-            roads = getFeatureIterator(dataStore);
-
-            HashSet<Coordinate> tmpSet = new HashSet<>();
-            while (roads.hasNext()) {
-                SimpleFeature road = roads.next();
-
-                for (Coordinate[] points : getCoords(road.getDefaultGeometry())) {
-                    tmpSet.clear();
-                    for (int i = 0; i < points.length; i++) {
-                        Coordinate c = points[i];
-
-                        // don't add the same coord twice for the same edge - happens with bad geometry, i.e.
-                        // duplicate coords or a road which forms a circle (e.g. roundabout)
-                        if (tmpSet.contains(c))
-                            continue;
-
-                        tmpSet.add(c);
-
-                        // skip if its already a node
-                        int state = coordState.get(c);
-                        if (state >= FIRST_NODE_ID) {
-                            continue;
-                        }
-
-                        if (i == 0 || i == points.length - 1 || state == COORD_STATE_PILLAR) {
-                            // turn into a node if its the first or last
-                            // point, or already appeared in another edge
-                            int nodeId = nextNodeId++;
-                            coordState.put(c, nodeId);
-                            saveTowerPosition(nodeId, c);
-                        } else if (state == COORD_STATE_UNKNOWN) {
-                            // mark it as a pillar (which may get upgraded
-                            // to an edge later)
-                            coordState.put(c, COORD_STATE_PILLAR);
-                        }
-                    }
-                }
-
-            }
-        } finally {
-            if (roads != null) {
-                roads.close();
-            }
-            if (dataStore != null) {
-                dataStore.dispose();
-            }
-        }
-
-        if (nextNodeId == FIRST_NODE_ID)
-            throw new IllegalArgumentException("No data found for roads file " + roadsFile);
-
-        LOGGER.info("Number of junction points : " + (nextNodeId - FIRST_NODE_ID));
-    }
-
-    @Override
-    void processRoads() {
-
-        DataStore dataStore = null;
-        FeatureIterator<SimpleFeature> roads = null;
-
-        try {
-            dataStore = openShapefileDataStore(roadsFile, encoding);
-            roads = getFeatureIterator(dataStore);
-
-            while (roads.hasNext()) {
-                SimpleFeature road = roads.next();
-
-                for (Coordinate[] points : getCoords(road.getDefaultGeometry())) {
-
-                    // Parse all points in the geometry, splitting into
-                    // individual graphhopper edges
-                    // whenever we find a node in the list of points
-                    Coordinate startTowerPnt = null;
-                    List<Coordinate> pillars = new ArrayList<Coordinate>();
-                    for (Coordinate point : points) {
-                        if (startTowerPnt == null) {
-                            startTowerPnt = point;
-                        } else {
-                            int state = coordState.get(point);
-                            if (state >= FIRST_NODE_ID) {
-                                int fromTowerNodeId = coordState.get(startTowerPnt);
-                                int toTowerNodeId = state;
-
-                                // get distance and estimated centres
-                                double distance = getWayLength(startTowerPnt, pillars, point);
-                                GHPoint estmCentre = new GHPoint(
-                                        0.5 * (lat(startTowerPnt) + lat(point)),
-                                        0.5 * (lng(startTowerPnt) + lng(point)));
-                                PointList pillarNodes = new PointList(pillars.size(), false);
-
-                                for (Coordinate pillar : pillars) {
-                                    pillarNodes.add(lat(pillar), lng(pillar));
-                                }
-
-                                addEdge(fromTowerNodeId, toTowerNodeId, road, distance, estmCentre,
-                                        pillarNodes);
-                                startTowerPnt = point;
-                                pillars.clear();
-                            } else {
-                                pillars.add(point);
-                            }
-                        }
-                    }
-                }
-
-            }
-        } finally {
-            if (roads != null) {
-                roads.close();
-            }
-
-            if (dataStore != null) {
-                dataStore.dispose();
-            }
-        }
-    }
-
-    private double getWayLength(Coordinate start, List<Coordinate> pillars, Coordinate end) {
-        double distance = 0;
-
-        Coordinate previous = start;
-        for (Coordinate point : pillars) {
-            distance += distCalc.calcDist(lat(previous), lng(previous), lat(point), lng(point));
-            previous = point;
-        }
-        distance += distCalc.calcDist(lat(previous), lng(previous), lat(end), lng(end));
-
-        return distance;
-    }
-
-    @Override
-    public DataReader setFile(File file) {
-        this.roadsFile = file;
-        return this;
-    }
-
-    @Override
-    public DataReader setElevationProvider(ElevationProvider ep) {
-        // Elevation not supported
-        return this;
-    }
-
-    @Override
-    public DataReader setWorkerThreads(int workerThreads) {
-        // Its only single-threaded
-        return this;
-    }
-
-    @Override
-    public DataReader setWayPointMaxDistance(double wayPointMaxDistance) {
-        // TODO Auto-generated method stub
-        return this;
-    }
-
-    @Override
-    public DataReader setSmoothElevation(boolean smoothElevation) {
-        // TODO implement elevation smoothing for shape files
-        return this;
-    }
-
-    @Override
-    public Date getDataDate() {
-        return null;
-    }
-
-    public static interface EdgeAddedListener {
-        void edgeAdded(ReaderWay way, EdgeIteratorState edge);
-    }
-
-    private void addEdge(int fromTower, int toTower, SimpleFeature road, double distance,
-                         GHPoint estmCentre, PointList pillarNodes) {
-        EdgeIteratorState edge = graph.edge(fromTower, toTower);
-
-        // read the OSM id, should never be null
-        long id = getOSMId(road);
-
-        // Make a temporary ReaderWay object with the properties we need so we
-        // can use the enocding manager
-        // We (hopefully don't need the node structure on here as we're only
-        // calling the flag
-        // encoders, which don't use this...
-        ReaderWay way = new ReaderWay(id);
-
-        way.setTag("estimated_distance", distance);
-        way.setTag("estimated_center", estmCentre);
-
-        // read the highway type
-        Object type = road.getAttribute("fclass");
-        if (type != null) {
-            way.setTag("highway", type.toString());
-        }
-
-        // read maxspeed filtering for 0 which for Geofabrik shapefiles appears
-        // to correspond to no tag
-        Object maxSpeed = road.getAttribute("maxspeed");
-        if (maxSpeed != null && !maxSpeed.toString().trim().equals("0")) {
-            way.setTag("maxspeed", maxSpeed.toString());
-        }
-
-        for (String tag : DIRECT_COPY_TAGS) {
-            Object val = road.getAttribute(tag);
-            if (val != null) {
-                way.setTag(tag, val.toString());
-            }
-        }
-
-        // read oneway
-        Object oneway = road.getAttribute("oneway");
-        if (oneway != null) {
-            // Geofabrik is using an odd convention for oneway field in
-            // shapefile.
-            // We map back to the standard convention so that tag can be dealt
-            // with correctly by the flag encoder.
-            String val = toLowerCase(oneway.toString().trim());
-            if (val.equals("b")) {
-                // both ways
-                val = "no";
-            } else if (val.equals("t")) {
-                // one way against the direction of digitisation
-                val = "-1";
-            } else if (val.equals("f")) {
-                // one way Forward in the direction of digitisation
-                val = "yes";
-            } else {
-                throw new RuntimeException("Unrecognised value of oneway field \"" + val
-                        + "\" found in road with OSM id " + id);
-            }
-
-            way.setTag("oneway", val);
-        }
-
-        // Process the flags using the encoders
-        long includeWay = encodingManager.acceptWay(way);
-        if (includeWay == 0) {
-            return;
-        }
-
-        // TODO we're not using the relation flags
-        long relationFlags = 0;
-
-        long wayFlags = encodingManager.handleWayTags(way, includeWay, relationFlags);
-        if (wayFlags == 0)
-            return;
-
-        edge.setDistance(distance);
-        edge.setFlags(wayFlags);
-        edge.setWayGeometry(pillarNodes);
-
-        if (edgeAddedListeners.size() > 0) {
-            // check size first so we only allocate the iterator if we have
-            // listeners
-            for (EdgeAddedListener l : edgeAddedListeners) {
-                l.edgeAdded(way, edge);
-            }
-        }
-    }
-
-    private long getOSMId(SimpleFeature road) {
-        long id = Long.parseLong(road.getAttribute("osm_id").toString());
-        return id;
-    }
-
-    public void addListener(EdgeAddedListener l) {
-        edgeAddedListeners.add(l);
-    }
-}
diff --git a/reader-shp/src/main/java/com/graphhopper/reader/shp/ShapeFileReader.java b/reader-shp/src/main/java/com/graphhopper/reader/shp/ShapeFileReader.java
deleted file mode 100644
index 27f7bfc343..0000000000
--- a/reader-shp/src/main/java/com/graphhopper/reader/shp/ShapeFileReader.java
+++ /dev/null
@@ -1,122 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.reader.shp;
-
-import java.io.File;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.geotools.data.DataStore;
-import org.geotools.data.DataStoreFinder;
-import org.geotools.data.FeatureSource;
-import org.geotools.feature.FeatureCollection;
-import org.geotools.feature.FeatureIterator;
-import org.opengis.feature.simple.SimpleFeature;
-import org.opengis.feature.simple.SimpleFeatureType;
-import org.opengis.filter.Filter;
-
-import com.graphhopper.reader.DataReader;
-import com.graphhopper.routing.util.EncodingManager;
-import com.graphhopper.storage.Graph;
-import com.graphhopper.storage.GraphHopperStorage;
-import com.graphhopper.storage.GraphStorage;
-import com.graphhopper.storage.NodeAccess;
-import com.vividsolutions.jts.geom.Coordinate;
-
-/**
- * ShapeFileReader takes care of reading a shape file and writing it to a road network graph
- *
- * @author Vikas Veshishth
- * @author Philip Welch
- */
-public abstract class ShapeFileReader implements DataReader {
-
-    private final GraphStorage graphStorage;
-    private final NodeAccess nodeAccess;
-    protected final Graph graph;
-    protected EncodingManager encodingManager;
-
-    public ShapeFileReader(GraphHopperStorage ghStorage) {
-        this.graphStorage = ghStorage;
-        this.graph = ghStorage;
-        this.nodeAccess = graph.getNodeAccess();
-        this.encodingManager = ghStorage.getEncodingManager();
-    }
-
-    @Override
-    public void readGraph() {
-        graphStorage.create(1000);
-        processJunctions();
-        processRoads();
-    }
-
-    abstract void processJunctions();
-
-    abstract void processRoads();
-
-    protected FeatureIterator<SimpleFeature> getFeatureIterator(DataStore dataStore) {
-        if (dataStore == null)
-            throw new IllegalArgumentException("DataStore cannot be null for getFeatureIterator");
-
-        try {
-            String typeName = dataStore.getTypeNames()[0];
-            FeatureSource<SimpleFeatureType, SimpleFeature> source = dataStore.getFeatureSource(typeName);
-            Filter filter = Filter.INCLUDE;
-            FeatureCollection<SimpleFeatureType, SimpleFeature> collection = source.getFeatures(filter);
-
-            FeatureIterator<SimpleFeature> features = collection.features();
-            return features;
-
-        } catch (Exception e) {
-            throw Utils.asUnchecked(e);
-        }
-    }
-
-    protected DataStore openShapefileDataStore(File file, String encoding) {
-        try {
-            Map<String, Object> map = new HashMap<String, Object>();
-            map.put("url", file.toURI().toURL());
-            map.put("charset", encoding);
-            DataStore ds = DataStoreFinder.getDataStore(map);
-            if (ds == null)
-                throw new IllegalArgumentException("Cannot find DataStore at " + file);
-            return ds;
-
-        } catch (Exception e) {
-            throw Utils.asUnchecked(e);
-        }
-    }
-
-    /*
-     * Get longitude using the current long-lat order convention
-     */
-    protected double lng(Coordinate coordinate) {
-        return coordinate.getOrdinate(0);
-    }
-
-    /*
-	 * Get latitude using the current long-lat order convention
-     */
-    protected double lat(Coordinate coordinate) {
-        return coordinate.getOrdinate(1);
-    }
-
-    protected void saveTowerPosition(int nodeId, Coordinate point) {
-        nodeAccess.setNode(nodeId, lat(point), lng(point));
-    }
-}
diff --git a/reader-shp/src/main/java/com/graphhopper/reader/shp/Utils.java b/reader-shp/src/main/java/com/graphhopper/reader/shp/Utils.java
deleted file mode 100644
index e434b1e66e..0000000000
--- a/reader-shp/src/main/java/com/graphhopper/reader/shp/Utils.java
+++ /dev/null
@@ -1,45 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.reader.shp;
-
-import com.graphhopper.util.PointList;
-import com.vividsolutions.jts.geom.Coordinate;
-import com.vividsolutions.jts.geom.GeometryFactory;
-
-/**
- * @author Phil
- */
-public class Utils {
-    public static String toWKT(PointList list) {
-        int n = list.size();
-        GeometryFactory factory = new GeometryFactory();
-        Coordinate[] coords = new Coordinate[n];
-        for (int i = 0; i < coords.length; i++) {
-            coords[i] = new Coordinate(list.getLon(i), list.getLat(i));
-        }
-        return factory.createLineString(coords).toText();
-    }
-
-    public static RuntimeException asUnchecked(Throwable e) {
-        if (RuntimeException.class.isInstance(e)) {
-            return (RuntimeException) e;
-        }
-        return new RuntimeException(e);
-    }
-
-}
diff --git a/reader-shp/src/test/java/com/graphhopper/reader/shp/ShapeFileReaderTest.java b/reader-shp/src/test/java/com/graphhopper/reader/shp/ShapeFileReaderTest.java
deleted file mode 100644
index 8bddc0545c..0000000000
--- a/reader-shp/src/test/java/com/graphhopper/reader/shp/ShapeFileReaderTest.java
+++ /dev/null
@@ -1,312 +0,0 @@
-/*
- *  Licensed to GraphHopper GmbH under one or more contributor
- *  license agreements. See the NOTICE file distributed with this work for
- *  additional information regarding copyright ownership.
- *
- *  GraphHopper GmbH licenses this file to you under the Apache License,
- *  Version 2.0 (the "License"); you may not use this file except in
- *  compliance with the License. You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-package com.graphhopper.reader.shp;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-
-import java.io.File;
-import java.net.URISyntaxException;
-import java.net.URL;
-import java.util.DoubleSummaryStatistics;
-import java.util.Random;
-
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import com.graphhopper.GHRequest;
-import com.graphhopper.GHResponse;
-import com.graphhopper.GraphHopper;
-import com.graphhopper.PathWrapper;
-import com.graphhopper.reader.osm.GraphHopperOSM;
-import com.graphhopper.routing.util.CarFlagEncoder;
-import com.graphhopper.routing.util.EncodingManager;
-import com.graphhopper.util.DistanceCalc;
-import com.graphhopper.util.Helper;
-import com.graphhopper.util.PointList;
-import com.graphhopper.util.shapes.GHPoint;
-
-/**
- * @author Vikas Veshishth
- * @author Philip Welch
- */
-public class ShapeFileReaderTest {
-
-    private static final String shapefile = "/data/gis.osm_roads_free_1.shp";
-    private static final String pbf = "/data/malta-latest.osm.pbf";
-    private static final String tempOutputDirFromShp = "target/test-db-shp";
-    private static final String tempOutputDirFromPbf = "target/test-db-pbf";
-    private static GraphHopper hopperShp;
-    private static GraphHopper hopperPbf;
-    private final DistanceCalc distCalc = Helper.DIST_EARTH;
-    private static Exception BEFORE_CLASS_EXCEPTION = null;
-
-    private static class FromToPair {
-        final GHPoint from;
-        final GHPoint to;
-
-        FromToPair(double fromLat, double fromLng, double toLat, double toLng) {
-            this(new GHPoint(fromLat, fromLng), new GHPoint(toLat, toLng));
-        }
-
-        FromToPair(GHPoint from, GHPoint to) {
-            this.from = from;
-            this.to = to;
-        }
-
-        PathWrapper getPath(GraphHopper hopper, boolean assertNoErrors) {
-            GHRequest request = new GHRequest(from, to).setVehicle("car");
-            GHResponse response = hopper.route(request);
-
-            if (assertNoErrors) {
-                assertFalse(response.hasErrors());
-            }
-
-            if (!response.hasErrors()) {
-                return response.getBest();
-            }
-            return null;
-        }
-
-    }
-
-    private static class ExpectedDuration extends FromToPair {
-        final double minSecs;
-        final double maxSecs;
-
-        private ExpectedDuration(double fromLat, double fromLng, double toLat, double toLng,
-                                 double minSecs, double maxSecs) {
-            super(fromLat, fromLng, toLat, toLng);
-            this.minSecs = minSecs;
-            this.maxSecs = maxSecs;
-        }
-    }
-
-    private static GraphHopper initHopper(GraphHopper gh, String inputFile, String outDir) {
-        URL resourceURL = ShapeFileReaderTest.class.getResource(inputFile);
-        try {
-            inputFile = new File(resourceURL.toURI()).getAbsolutePath();
-        } catch (Exception e) {
-            throw new RuntimeException(e);
-        }
-
-        // turn off geometry simplification so geometry should be the same
-        // between pbf and shapefile readers
-        gh.setWayPointMaxDistance(0);
-        return gh.setStoreOnFlush(false).setDataReaderFile(inputFile)
-                .setGraphHopperLocation(new File(outDir).getAbsolutePath())
-                .setEncodingManager(new EncodingManager(new CarFlagEncoder()))
-                .setCHEnabled(false).importOrLoad();
-
-    }
-
-    /**
-     * Build the graphs once only for the various tests
-     */
-    @BeforeClass
-    public static void setupBeforeClass() {
-        try {
-            new File(tempOutputDirFromShp).mkdirs();
-            new File(tempOutputDirFromPbf).mkdirs();
-
-            hopperShp = initHopper(new GraphHopperSHP(), shapefile, tempOutputDirFromShp);
-
-            hopperPbf = initHopper(new GraphHopperOSM(), pbf, tempOutputDirFromPbf);
-
-        } catch (Exception e) {
-            // Junit silently fails if we get an exception in the setup before
-            // class,
-            // so we record it here and explicitly rethrow it
-            BEFORE_CLASS_EXCEPTION = e;
-        }
-
-    }
-
-    @AfterClass
-    public static void teardownAfterClass() {
-        try {
-            hopperShp.close();
-            hopperShp.clean();
-        } catch (Exception e) {
-        }
-
-        try {
-            hopperPbf.close();
-            hopperPbf.clean();
-        } catch (Exception e) {
-        }
-
-    }
-
-    @Before
-    public void beforeTest() throws Exception {
-        // Rethrow the exception from @BeforeClass here so it doesn't silently
-        // fail.
-        // (Junit silently fails on exceptions thrown in @BeforeClass but not
-        // for
-        // exceptions thrown in @Before)
-        if (BEFORE_CLASS_EXCEPTION != null) {
-            throw BEFORE_CLASS_EXCEPTION;
-        }
-    }
-
-    @Test
-    public void testOneWay() {
-        // We setup 2 points very close together on a one-way street.
-        // As its a one way street, the ordering of the start and end requires
-        // going around the block to serve them.
-        // As the scenario is simple, we should get the same results from both
-        // shapefile and pbf.
-        // We should also get route distance to be many times physical distance
-        FromToPair pair = new FromToPair(35.898324, 14.510729, 35.898328, 14.510681);
-        PathWrapper shp = pair.getPath(hopperShp, true);
-        PathWrapper pbf = pair.getPath(hopperPbf, true);
-        double metresShp = shp.getDistance();
-        double metresPbf = pbf.getDistance();
-
-        // should be many times the physical separation between the points (as
-        // we had to go round the block)
-        double straightLineDistMetres = distCalc.calcDist(pair.from.lat, pair.from.lon, pair.to.lat,
-                pair.to.lon);
-        assertTrue(metresShp > straightLineDistMetres * 25);
-
-        // should be the same to within 1 cm
-        assertEquals(metresShp, metresPbf, 0.01);
-
-    }
-
-    @Test
-    public void testGeometrySingleEdgePath() {
-        // We choose a path along a single edge with a couple of minor bends,
-        // which we expect to give identical results...
-        FromToPair pair = new FromToPair(35.911694, 14.492303, 35.911494, 14.490489);
-        PointList shp = pair.getPath(hopperShp, true).getPoints();
-        PointList pbf = pair.getPath(hopperPbf, true).getPoints();
-
-        assertTrue("The chosen edge had a couple of bends!", shp.getSize() >= 2);
-        assertSameGeometry(shp, pbf);
-    }
-
-    private void assertSameGeometry(PointList shp, PointList pbf) {
-        assertEquals(shp.getSize(), pbf.getSize());
-
-        for (int i = 0; i < shp.getSize(); i++) {
-            assertEquals(shp.getLat(i), pbf.getLat(i), 0.0000001);
-            assertEquals(shp.getLon(i), pbf.getLon(i), 0.0000001);
-        }
-    }
-
-    @Test
-    public void testTravelTimesBetweenRandomLocations() {
-        int nTests = 200;
-        final Random random = new Random(123);
-        final GHPoint min = new GHPoint(35.882931, 14.403076);
-        final GHPoint max = new GHPoint(35.913523, 14.448566);
-
-        class RandPointGenerator {
-            double rand(double min, double max) {
-                return min + random.nextDouble() * (max - min);
-            }
-
-            GHPoint randPoint() {
-                return new GHPoint(rand(min.lat, max.lat), rand(min.lon, max.lon));
-            }
-
-        }
-        RandPointGenerator pointGenerator = new RandPointGenerator();
-
-        int nbFails = 0;
-        DoubleSummaryStatistics stats = new DoubleSummaryStatistics();
-        for (int i = 0; i < nTests; i++) {
-            FromToPair pair = new FromToPair(pointGenerator.randPoint(),
-                    pointGenerator.randPoint());
-
-            // paths from random points can fail to don't assert on failure
-            PathWrapper shpPath = pair.getPath(hopperShp, false);
-            PathWrapper pbfPath = pair.getPath(hopperPbf, false);
-
-            // paths between random points can fail to find a route (i.e. be off
-            // the road network)
-            if (shpPath == null || pbfPath == null) {
-                nbFails++;
-                continue;
-            }
-            double shpSecs = getSecondsTravel(shpPath);
-            double pbfSecs = getSecondsTravel(pbfPath);
-
-            double frac = shpSecs / pbfSecs;
-            double percentageDeviation = Math.abs(1.0 - frac) * 100;
-            stats.accept(percentageDeviation);
-        }
-
-        assertTrue("Number of fails should be small for the chosen box", nbFails < nTests / 3);
-
-        // Test mean fraction. There will be some deviation as not all tags are
-        // considered etc,
-        // but we expect it to be small for a large number of tests
-        double mean = stats.getAverage();
-        assertTrue("Should have a mean deviation in travel times of less than 1%", mean < 1.0);
-    }
-
-    @Test
-    public void testTravelTimesBetweenPredefinedLocations() throws URISyntaxException {
-
-        // try a couple of test points, with an expected time range that will
-        // only fail if something is really bad...
-        ExpectedDuration[] expected = new ExpectedDuration[]{
-                new ExpectedDuration(35.899167, 14.515171, 35.894126, 14.502983, 60,
-                        60 * 6),
-                new ExpectedDuration(35.899167, 14.515171, 35.877645, 14.398956, 8 * 60,
-                        25 * 60),
-                new ExpectedDuration(35.85817, 14.561348, 35.877645, 14.398956, 10 * 60,
-                        30 * 60),
-                new ExpectedDuration(35.812802, 14.528732, 35.979673, 14.335785, 20 * 60,
-                        50 * 60),};
-
-        // The chosen locations should have small deviations in travel times
-        double tolDiffFromPbf = 0.01;
-
-        for (ExpectedDuration ed : expected) {
-            double secsShp = getSecondsTravel(ed.getPath(hopperShp, true));
-            double secsPbf = getSecondsTravel(ed.getPath(hopperPbf, true));
-            double frac = secsShp / secsPbf;
-
-            String message = "From (" + ed.from + ") to (" + ed.to + ") expected " + ed.minSecs
-                    + " <= travelsecs <= " + ed.maxSecs + ", found " + secsShp
-                    + " secs, pbf was " + secsPbf + " secs, frac diff=" + frac;
-            assertTrue(message, secsShp >= ed.minSecs);
-            assertTrue(message, secsShp <= ed.maxSecs);
-
-            // we also use a tolerance difference with the pbf
-            assertTrue(frac > 1 - tolDiffFromPbf);
-            assertTrue(frac < 1 + tolDiffFromPbf);
-
-        }
-
-    }
-
-    private static double getSecondsTravel(PathWrapper pw) {
-        long millis = pw.getTime();
-        double secs = 0.001 * millis;
-        return secs;
-    }
-
-}
diff --git a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.cpg b/reader-shp/src/test/resources/data/gis.osm_roads_free_1.cpg
deleted file mode 100644
index 7edc66b06a..0000000000
--- a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.cpg
+++ /dev/null
@@ -1 +0,0 @@
-UTF-8
diff --git a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.dbf b/reader-shp/src/test/resources/data/gis.osm_roads_free_1.dbf
deleted file mode 100644
index 116ff9c648..0000000000
Binary files a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.dbf and /dev/null differ
diff --git a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.prj b/reader-shp/src/test/resources/data/gis.osm_roads_free_1.prj
deleted file mode 100644
index 8f73f480ff..0000000000
--- a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.prj
+++ /dev/null
@@ -1 +0,0 @@
-GEOGCS["GCS_WGS_1984",DATUM["D_WGS_1984",SPHEROID["WGS_1984",6378137,298.257223563]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]]
diff --git a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shp b/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shp
deleted file mode 100644
index 491be81e73..0000000000
Binary files a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shp and /dev/null differ
diff --git a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shx b/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shx
deleted file mode 100644
index 25718abea1..0000000000
Binary files a/reader-shp/src/test/resources/data/gis.osm_roads_free_1.shx and /dev/null differ
diff --git a/reader-shp/src/test/resources/data/malta-latest.osm.pbf b/reader-shp/src/test/resources/data/malta-latest.osm.pbf
deleted file mode 100644
index 6b84456772..0000000000
Binary files a/reader-shp/src/test/resources/data/malta-latest.osm.pbf and /dev/null differ
diff --git a/reader-shp/src/test/resources/log4j.xml b/reader-shp/src/test/resources/log4j.xml
deleted file mode 100644
index a9bb71c09f..0000000000
--- a/reader-shp/src/test/resources/log4j.xml
+++ /dev/null
@@ -1,21 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!DOCTYPE log4j:configuration SYSTEM "log4j.dtd">
-<log4j:configuration>
-    <appender name="stdout" class="org.apache.log4j.ConsoleAppender">
-        <layout class="org.apache.log4j.PatternLayout">
-            <param name="ConversionPattern" value="%d [%t] %-5p %c - %m%n"/>
-        </layout>
-    </appender>
-    <appender name="ASYNC" class="org.apache.log4j.AsyncAppender">
-        <param name="BufferSize" value="500"/>
-        <appender-ref ref="stdout"/>
-    </appender>    
-    <logger name="com.graphhopper" additivity="false">
-        <level value="warn" />
-        <appender-ref ref="ASYNC" />
-    </logger>
-    <root>
-        <priority value="warn"></priority>
-        <appender-ref ref="ASYNC"/>
-    </root>
-</log4j:configuration>
\ No newline at end of file
diff --git a/web-api/pom.xml b/web-api/pom.xml
index e5a1930fc9..ce0c0a9495 100644
--- a/web-api/pom.xml
+++ b/web-api/pom.xml
@@ -33,23 +33,9 @@
             <version>${jackson.version}</version>
         </dependency>
         <dependency>
-            <groupId>com.bedatadriven</groupId>
+            <groupId>com.graphhopper.external</groupId>
             <artifactId>jackson-datatype-jts</artifactId>
-            <version>2.4</version>
-            <exclusions>
-                <exclusion>
-                    <groupId>com.vividsolutions</groupId>
-                    <artifactId>jts</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>com.fasterxml.jackson.core</groupId>
-                    <artifactId>jackson-annotations</artifactId>
-                </exclusion>
-                <exclusion>
-                    <groupId>com.fasterxml.jackson.core</groupId>
-                    <artifactId>jackson-databind</artifactId>
-                </exclusion>
-            </exclusions>
+            <version>0.10-2.5-2</version>
         </dependency>
         <dependency>
             <groupId>io.dropwizard</groupId>
@@ -57,12 +43,6 @@
             <version>${dropwizard.version}</version>
             <scope>test</scope>
         </dependency>
-        <dependency>
-            <groupId>org.mockito</groupId>
-            <artifactId>mockito-core</artifactId>
-            <version>1.10.19</version>
-            <scope>test</scope>
-        </dependency>
     </dependencies>
 
     <build>
@@ -70,7 +50,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
                 <configuration>
                     <source>1.8</source>
                     <target>1.8</target>
diff --git a/web-api/src/main/java/com/graphhopper/jackson/Jackson.java b/web-api/src/main/java/com/graphhopper/jackson/Jackson.java
index 73305a2e69..15f8532eb5 100644
--- a/web-api/src/main/java/com/graphhopper/jackson/Jackson.java
+++ b/web-api/src/main/java/com/graphhopper/jackson/Jackson.java
@@ -18,6 +18,7 @@
 package com.graphhopper.jackson;
 
 import com.bedatadriven.jackson.datatype.jts.JtsModule;
+import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.databind.*;
 
 public class Jackson {
@@ -25,6 +26,7 @@ public static ObjectMapper newObjectMapper() {
         ObjectMapper objectMapper = new ObjectMapper();
         objectMapper.registerModule(new GraphHopperModule());
         objectMapper.registerModule(new JtsModule());
+        objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL);
         return objectMapper;
     }
 }
diff --git a/web-api/src/test/java/com/graphhopper/json/geo/JsonFeatureCollectionTest.java b/web-api/src/test/java/com/graphhopper/json/geo/JsonFeatureCollectionTest.java
index 094627e1c2..b013019705 100644
--- a/web-api/src/test/java/com/graphhopper/json/geo/JsonFeatureCollectionTest.java
+++ b/web-api/src/test/java/com/graphhopper/json/geo/JsonFeatureCollectionTest.java
@@ -20,11 +20,16 @@
 import com.fasterxml.jackson.databind.ObjectMapper;
 import com.graphhopper.jackson.Jackson;
 import com.graphhopper.util.PointList;
-import com.vividsolutions.jts.geom.LineString;
+import com.graphhopper.util.shapes.BBox;
 import org.junit.Assert;
 import org.junit.Test;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.GeometryFactory;
+import org.locationtech.jts.geom.LineString;
 
 import java.io.IOException;
+import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.Map;
 
 import static io.dropwizard.testing.FixtureHelpers.fixture;
@@ -36,6 +41,52 @@
 public class JsonFeatureCollectionTest {
     private final ObjectMapper objectMapper = Jackson.newObjectMapper();
 
+    @Test
+    public void testSerialization() throws IOException {
+        GeometryFactory geometryFactory = new GeometryFactory();
+
+        JsonFeatureCollection jsonFeatureCollection = new JsonFeatureCollection();
+        {
+            JsonFeature jsonFeature = new JsonFeature();
+            jsonFeature.setId("1");
+            HashMap<String, Object> properties = new HashMap<>();
+            properties.put("prop0", "value0");
+            jsonFeature.setProperties(properties);
+            jsonFeature.setGeometry(geometryFactory.createPoint(new Coordinate(102.0,0.5)));
+            jsonFeatureCollection.getFeatures().add(jsonFeature);
+        }
+        {
+            JsonFeature jsonFeature = new JsonFeature();
+            jsonFeature.setId("2");
+            Map<String, Object> properties = new LinkedHashMap<>();
+            properties.put("prop0", "value1");
+            properties.put("prop1", 2);
+            jsonFeature.setProperties(properties);
+            jsonFeature.setGeometry(geometryFactory.createLineString(new Coordinate[]{
+                    new Coordinate(102.0, 0.0),
+                    new Coordinate(103.0, 1.0),
+                    new Coordinate(104.0, 0.0),
+                    new Coordinate(105.0, 1.0)}));
+            jsonFeatureCollection.getFeatures().add(jsonFeature);
+        }
+        {
+            JsonFeature jsonFeature = new JsonFeature();
+            jsonFeature.setId("3");
+            Map<String, Object> properties = new LinkedHashMap<>();
+            properties.put("prop0", "value0");
+            Map<String, String> prop1 = new LinkedHashMap<>();
+            prop1.put("test", "a");
+            properties.put("prop1", prop1);
+            jsonFeature.setProperties(properties);
+            jsonFeature.setBbox(new BBox(102.0, 103.0, 0.0, 1));
+            jsonFeatureCollection.getFeatures().add(jsonFeature);
+        }
+
+        String expected = objectMapper.writeValueAsString(
+                objectMapper.readValue(fixture("fixtures/geojson1.json"), JsonFeatureCollection.class));
+        assertEquals(objectMapper.writeValueAsString(jsonFeatureCollection), expected);
+    }
+
     @Test
     public void testDeserialization() throws IOException {
         JsonFeatureCollection data = objectMapper.readValue(fixture("fixtures/geojson1.json"), JsonFeatureCollection.class);
@@ -57,7 +108,11 @@ public void testDeserialization() throws IOException {
         assertEquals(103.0, PointList.fromLineString((LineString) f2.getGeometry()).getLon(1), .1);
 
         JsonFeature f3 = data.getFeatures().get(2);
-        Assert.assertEquals("0.0,102.0,1.0,103.0", f3.getBBox().toString());
+        assertEquals(0.0, f3.getBBox().minLat, 0.0);
+        assertEquals(102.0, f3.getBBox().minLon, 0.0);
+        assertEquals(1.0, f3.getBBox().maxLat, 0.0);
+        assertEquals(103.0, f3.getBBox().maxLon, 0.0);
+
         assertEquals("a", ((Map) f3.getProperty("prop1")).get("test"));
     }
 
diff --git a/web-api/src/test/java/com/graphhopper/util/InstructionListRepresentationTest.java b/web-api/src/test/java/com/graphhopper/util/InstructionListRepresentationTest.java
index 7f2bf49710..e878add342 100644
--- a/web-api/src/test/java/com/graphhopper/util/InstructionListRepresentationTest.java
+++ b/web-api/src/test/java/com/graphhopper/util/InstructionListRepresentationTest.java
@@ -2,30 +2,18 @@
 
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import org.junit.Rule;
 import org.junit.Test;
-import org.mockito.Mock;
-import org.mockito.junit.MockitoJUnit;
-import org.mockito.junit.MockitoRule;
 
+import java.util.Collections;
+import java.util.Locale;
 import java.util.Map;
 
 import static org.junit.Assert.*;
-import static org.mockito.Matchers.any;
-import static org.mockito.Mockito.mockingDetails;
-import static org.mockito.Mockito.when;
 
 public class InstructionListRepresentationTest {
 
-    @Mock
-    Translation usTR;
-
-    @Rule
-    public MockitoRule mockitoRule = MockitoJUnit.rule();
-
     @Test
     public void testRoundaboutJsonIntegrity() {
-        when(usTR.tr("roundabout_exit_onto", 2, "streetname")).thenReturn("At roundabout, take exit 2 onto streetname");
         InstructionList il = new InstructionList(usTR);
 
         PointList pl = new PointList();
@@ -60,7 +48,6 @@ private String write(Map<String, Object> json) {
     // Roundabout with unknown dir of rotation
     @Test
     public void testRoundaboutJsonNaN() {
-        when(usTR.tr("roundabout_exit_onto", 2, "streetname")).thenReturn("At roundabout, take exit 2 onto streetname");
         InstructionList il = new InstructionList(usTR);
 
         PointList pl = new PointList();
@@ -81,5 +68,27 @@ public void testRoundaboutJsonNaN() {
         assertNotNull(write(json));
     }
 
+    static Translation usTR = new Translation() {
+        @Override
+        public String tr(String key, Object... params) {
+            if (key.equals("roundabout_exit_onto"))
+                return "At roundabout, take exit 2 onto streetname";
+            return key;
+        }
+
+        @Override
+        public Map<String, String> asMap() {
+            return Collections.emptyMap();
+        }
+
+        @Override
+        public Locale getLocale() {
+            return Locale.US;
+        }
 
+        @Override
+        public String getLanguage() {
+            return "en";
+        }
+    };
 }
diff --git a/web-api/src/test/resources/fixtures/geojson1.json b/web-api/src/test/resources/fixtures/geojson1.json
index d951eddd08..492aaac9a1 100644
--- a/web-api/src/test/resources/fixtures/geojson1.json
+++ b/web-api/src/test/resources/fixtures/geojson1.json
@@ -27,7 +27,7 @@
         {
             "id": 3,
             "type": "Feature",
-            "bbox": [0.0, 1, 102.0, 103.0],
+            "bbox": [102.0, 0.0, 103.0, 1],
             "properties": {
                 "prop0": "value0",
                 "prop1": {
diff --git a/web-bundle/pom.xml b/web-bundle/pom.xml
index 0e62020bba..6759685bdc 100644
--- a/web-bundle/pom.xml
+++ b/web-bundle/pom.xml
@@ -84,7 +84,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
                 <configuration>
                     <source>1.8</source>
                     <target>1.8</target>
diff --git a/web-bundle/src/main/java/com/graphhopper/http/GraphHopperBundle.java b/web-bundle/src/main/java/com/graphhopper/http/GraphHopperBundle.java
index b7bddf6b82..8e8c08ec5d 100644
--- a/web-bundle/src/main/java/com/graphhopper/http/GraphHopperBundle.java
+++ b/web-bundle/src/main/java/com/graphhopper/http/GraphHopperBundle.java
@@ -27,13 +27,12 @@
 import com.fasterxml.jackson.databind.module.SimpleModule;
 import com.fasterxml.jackson.databind.ser.BeanPropertyWriter;
 import com.fasterxml.jackson.databind.ser.BeanSerializerModifier;
-import com.fasterxml.jackson.databind.util.ISO8601DateFormat;
 import com.fasterxml.jackson.databind.util.StdDateFormat;
 import com.graphhopper.GraphHopper;
 import com.graphhopper.GraphHopperAPI;
 import com.graphhopper.http.health.GraphHopperHealthCheck;
 import com.graphhopper.http.health.GraphHopperStorageHealthCheck;
-import com.graphhopper.isochrone.algorithm.RasterHullBuilder;
+import com.graphhopper.isochrone.algorithm.DelaunayTriangulationIsolineBuilder;
 import com.graphhopper.jackson.GraphHopperModule;
 import com.graphhopper.reader.gtfs.GraphHopperGtfs;
 import com.graphhopper.reader.gtfs.GtfsStorage;
@@ -56,10 +55,7 @@
 import org.glassfish.hk2.utilities.binding.AbstractBinder;
 
 import javax.inject.Inject;
-import javax.ws.rs.WebApplicationException;
 import javax.ws.rs.ext.WriterInterceptor;
-import javax.ws.rs.ext.WriterInterceptorContext;
-import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
@@ -147,17 +143,17 @@ public void dispose(Boolean instance) {
         }
     }
 
-    static class RasterHullBuilderFactory implements Factory<RasterHullBuilder> {
+    static class RasterHullBuilderFactory implements Factory<DelaunayTriangulationIsolineBuilder> {
 
-        RasterHullBuilder builder = new RasterHullBuilder();
+        DelaunayTriangulationIsolineBuilder builder = new DelaunayTriangulationIsolineBuilder();
 
         @Override
-        public RasterHullBuilder provide() {
+        public DelaunayTriangulationIsolineBuilder provide() {
             return builder;
         }
 
         @Override
-        public void dispose(RasterHullBuilder rasterHullBuilder) {
+        public void dispose(DelaunayTriangulationIsolineBuilder delaunayTriangulationIsolineBuilder) {
         }
     }
 
@@ -230,12 +226,12 @@ protected void configure() {
                 bind(translationMap).to(TranslationMap.class);
                 bind(encodingManager).to(EncodingManager.class);
                 bind(graphHopperStorage).to(GraphHopperStorage.class);
-                bindFactory(RasterHullBuilderFactory.class).to(RasterHullBuilder.class);
+                bindFactory(RasterHullBuilderFactory.class).to(DelaunayTriangulationIsolineBuilder.class);
             }
         });
         environment.jersey().register(NearestResource.class);
         environment.jersey().register(RouteResource.class);
-        environment.jersey().register(IsochroneResource.class);
+        environment.jersey().register(new PtIsochroneResource(gtfsStorage, encodingManager, graphHopperStorage, locationIndex));
         environment.jersey().register(I18NResource.class);
         environment.jersey().register(InfoResource.class);
         // Say we only support pt, even though we now have several flag encoders. Yes, I know, we're almost there.
@@ -279,7 +275,7 @@ protected void configure() {
                 bindFactory(TranslationMapFactory.class).to(TranslationMap.class);
                 bindFactory(EncodingManagerFactory.class).to(EncodingManager.class);
                 bindFactory(GraphHopperStorageFactory.class).to(GraphHopperStorage.class);
-                bindFactory(RasterHullBuilderFactory.class).to(RasterHullBuilder.class);
+                bindFactory(RasterHullBuilderFactory.class).to(DelaunayTriangulationIsolineBuilder.class);
             }
         });
 
diff --git a/web-bundle/src/main/java/com/graphhopper/resources/IsochroneResource.java b/web-bundle/src/main/java/com/graphhopper/resources/IsochroneResource.java
index 4281e8fe46..4de5be3567 100644
--- a/web-bundle/src/main/java/com/graphhopper/resources/IsochroneResource.java
+++ b/web-bundle/src/main/java/com/graphhopper/resources/IsochroneResource.java
@@ -4,7 +4,8 @@
 import com.fasterxml.jackson.databind.node.ObjectNode;
 import com.graphhopper.GraphHopper;
 import com.graphhopper.isochrone.algorithm.Isochrone;
-import com.graphhopper.isochrone.algorithm.RasterHullBuilder;
+import com.graphhopper.isochrone.algorithm.DelaunayTriangulationIsolineBuilder;
+import com.graphhopper.json.geo.JsonFeature;
 import com.graphhopper.routing.QueryGraph;
 import com.graphhopper.routing.util.*;
 import com.graphhopper.routing.weighting.Weighting;
@@ -13,6 +14,8 @@
 import com.graphhopper.storage.index.QueryResult;
 import com.graphhopper.util.StopWatch;
 import com.graphhopper.util.shapes.GHPoint;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.GeometryFactory;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -23,10 +26,7 @@
 import javax.ws.rs.core.MediaType;
 import javax.ws.rs.core.Response;
 import javax.ws.rs.core.UriInfo;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
+import java.util.*;
 
 @Path("isochrone")
 public class IsochroneResource {
@@ -35,13 +35,14 @@
 
     private final GraphHopper graphHopper;
     private final EncodingManager encodingManager;
-    private final RasterHullBuilder rasterHullBuilder;
+    private final DelaunayTriangulationIsolineBuilder delaunayTriangulationIsolineBuilder;
+    private final GeometryFactory geometryFactory = new GeometryFactory();
 
     @Inject
-    public IsochroneResource(GraphHopper graphHopper, EncodingManager encodingManager, RasterHullBuilder rasterHullBuilder) {
+    public IsochroneResource(GraphHopper graphHopper, EncodingManager encodingManager, DelaunayTriangulationIsolineBuilder delaunayTriangulationIsolineBuilder) {
         this.graphHopper = graphHopper;
         this.encodingManager = encodingManager;
-        this.rasterHullBuilder = rasterHullBuilder;
+        this.delaunayTriangulationIsolineBuilder = delaunayTriangulationIsolineBuilder;
     }
 
     @GET
@@ -50,14 +51,14 @@ public Response doGet(
             @Context HttpServletRequest httpReq,
             @Context UriInfo uriInfo,
             @QueryParam("vehicle") @DefaultValue("car") String vehicle,
-            @QueryParam("buckets") @DefaultValue("1") int buckets,
+            @QueryParam("buckets") @DefaultValue("1") int nBuckets,
             @QueryParam("reverse_flow") @DefaultValue("false") boolean reverseFlow,
             @QueryParam("point") GHPoint point,
             @QueryParam("result") @DefaultValue("polygon") String resultStr,
             @QueryParam("time_limit") @DefaultValue("600") long timeLimitInSeconds,
             @QueryParam("distance_limit") @DefaultValue("-1") double distanceInMeter) {
 
-        if (buckets > 20 || buckets < 1)
+        if (nBuckets > 20 || nBuckets < 1)
             throw new IllegalArgumentException("Number of buckets has to be in the range [1, 20]");
 
         if (point == null)
@@ -86,32 +87,19 @@ public Response doGet(
         Isochrone isochrone = new Isochrone(queryGraph, weighting, reverseFlow);
 
         if (distanceInMeter > 0) {
-            double maxMeter = 50 * 1000;
-            if (distanceInMeter > maxMeter)
-                throw new IllegalArgumentException("Specify a limit of less than " + maxMeter / 1000f + "km");
-            if (buckets > (distanceInMeter / 500))
-                throw new IllegalArgumentException("Specify buckets less than the number of explored kilometers");
-
             isochrone.setDistanceLimit(distanceInMeter);
         } else {
-
-            long maxSeconds = 80 * 60;
-            if (timeLimitInSeconds > maxSeconds)
-                throw new IllegalArgumentException("Specify a limit of less than " + maxSeconds + " seconds");
-            if (buckets > (timeLimitInSeconds / 60))
-                throw new IllegalArgumentException("Specify buckets less than the number of explored minutes");
-
             isochrone.setTimeLimit(timeLimitInSeconds);
         }
 
-        List<List<Double[]>> list = isochrone.searchGPS(qr.getClosestNode(), buckets);
+        List<List<Coordinate>> buckets = isochrone.searchGPS(qr.getClosestNode(), nBuckets);
         if (isochrone.getVisitedNodes() > graphHopper.getMaxVisitedNodes() / 5) {
             throw new IllegalArgumentException("Server side reset: too many junction nodes would have to explored (" + isochrone.getVisitedNodes() + "). Let us know if you need this increased.");
         }
 
         int counter = 0;
-        for (List<Double[]> tmp : list) {
-            if (tmp.size() < 2) {
+        for (List<Coordinate> bucket : buckets) {
+            if (bucket.size() < 2) {
                 throw new IllegalArgumentException("Too few points found for bucket " + counter + ". "
                         + "Please try a different 'point', a smaller 'buckets' count or a larger 'time_limit'. "
                         + "And let us know if you think this is a bug!");
@@ -119,39 +107,29 @@ public Response doGet(
             counter++;
         }
 
-        Object calcRes;
         if ("pointlist".equalsIgnoreCase(resultStr)) {
-            calcRes = list;
-
+            logger.info("took: " + sw.getSeconds() + ", visited nodes:" + isochrone.getVisitedNodes() + ", " + uriInfo.getQueryParameters());
+            return Response.fromResponse(jsonSuccessResponse(buckets, sw.stop().getSeconds()))
+                    .header("X-GH-Took", "" + sw.stop().getSeconds() * 1000)
+                    .build();
         } else if ("polygon".equalsIgnoreCase(resultStr)) {
-            list = rasterHullBuilder.calcList(list, list.size() - 1);
-
-            ArrayList polyList = new ArrayList();
-            int index = 0;
-            for (List<Double[]> polygon : list) {
-                HashMap<String, Object> geoJsonMap = new HashMap<>();
-                HashMap<String, Object> propMap = new HashMap<>();
-                HashMap<String, Object> geometryMap = new HashMap<>();
-                polyList.add(geoJsonMap);
-                geoJsonMap.put("type", "Feature");
-                geoJsonMap.put("properties", propMap);
-                geoJsonMap.put("geometry", geometryMap);
-
-                propMap.put("bucket", index);
-                geometryMap.put("type", "Polygon");
-                // we have no holes => embed in yet another list
-                geometryMap.put("coordinates", Collections.singletonList(polygon));
-                index++;
+            ArrayList<JsonFeature> features = new ArrayList<>();
+            List<Coordinate[]> polygonShells = delaunayTriangulationIsolineBuilder.calcList(buckets, buckets.size() - 1);
+            for (Coordinate[] polygonShell : polygonShells) {
+                JsonFeature feature = new JsonFeature();
+                HashMap<String, Object> properties = new HashMap<>();
+                properties.put("bucket", features.size());
+                feature.setProperties(properties);
+                feature.setGeometry(geometryFactory.createPolygon(polygonShell));
+                features.add(feature);
             }
-            calcRes = polyList;
+            logger.info("took: " + sw.getSeconds() + ", visited nodes:" + isochrone.getVisitedNodes() + ", " + uriInfo.getQueryParameters());
+            return Response.fromResponse(jsonSuccessResponse(features, sw.stop().getSeconds()))
+                    .header("X-GH-Took", "" + sw.stop().getSeconds() * 1000)
+                    .build();
         } else {
             throw new IllegalArgumentException("type not supported:" + resultStr);
         }
-
-        logger.info("took: " + sw.getSeconds() + ", visited nodes:" + isochrone.getVisitedNodes() + ", " + uriInfo.getQueryParameters());
-        return Response.fromResponse(jsonSuccessResponse(calcRes, sw.stop().getSeconds()))
-                .header("X-GH-Took", "" + sw.stop().getSeconds() * 1000)
-                .build();
     }
 
     private Response jsonSuccessResponse(Object result, float took) {
@@ -164,7 +142,6 @@ private Response jsonSuccessResponse(Object result, float took) {
                 .add("GraphHopper")
                 .add("OpenStreetMap contributors");
         info.put("took", Math.round(took * 1000));
-
         return Response.ok(json).build();
     }
 }
diff --git a/web-bundle/src/main/java/com/graphhopper/resources/PtIsochroneResource.java b/web-bundle/src/main/java/com/graphhopper/resources/PtIsochroneResource.java
new file mode 100644
index 0000000000..9a39461cdf
--- /dev/null
+++ b/web-bundle/src/main/java/com/graphhopper/resources/PtIsochroneResource.java
@@ -0,0 +1,225 @@
+/*
+ *  Licensed to GraphHopper GmbH under one or more contributor
+ *  license agreements. See the NOTICE file distributed with this work for
+ *  additional information regarding copyright ownership.
+ *
+ *  GraphHopper GmbH licenses this file to you under the Apache License,
+ *  Version 2.0 (the "License"); you may not use this file except in
+ *  compliance with the License. You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an "AS IS" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package com.graphhopper.resources;
+
+import com.graphhopper.isochrone.algorithm.ContourBuilder;
+import com.graphhopper.json.geo.JsonFeature;
+import com.graphhopper.reader.gtfs.*;
+import com.graphhopper.routing.QueryGraph;
+import com.graphhopper.routing.util.AllEdgesIterator;
+import com.graphhopper.routing.util.DefaultEdgeFilter;
+import com.graphhopper.routing.util.EdgeFilter;
+import com.graphhopper.routing.util.EncodingManager;
+import com.graphhopper.routing.weighting.FastestWeighting;
+import com.graphhopper.storage.GraphHopperStorage;
+import com.graphhopper.storage.NodeAccess;
+import com.graphhopper.storage.index.LocationIndex;
+import com.graphhopper.storage.index.QueryResult;
+import com.graphhopper.util.EdgeIteratorState;
+import com.graphhopper.util.Parameters;
+import com.graphhopper.util.shapes.GHPoint;
+import org.locationtech.jts.geom.*;
+import org.locationtech.jts.index.strtree.STRtree;
+import org.locationtech.jts.triangulate.ConformingDelaunayTriangulator;
+import org.locationtech.jts.triangulate.ConstraintVertex;
+import org.locationtech.jts.triangulate.DelaunayTriangulationBuilder;
+import org.locationtech.jts.triangulate.quadedge.QuadEdge;
+import org.locationtech.jts.triangulate.quadedge.QuadEdgeSubdivision;
+import org.locationtech.jts.triangulate.quadedge.Vertex;
+
+import javax.ws.rs.*;
+import javax.ws.rs.core.MediaType;
+import java.time.Instant;
+import java.util.*;
+import java.util.function.Function;
+
+@Path("isochrone")
+public class PtIsochroneResource {
+
+    private static final double JTS_TOLERANCE = 0.00001;
+
+    private GtfsStorage gtfsStorage;
+    private EncodingManager encodingManager;
+    private GraphHopperStorage graphHopperStorage;
+    private LocationIndex locationIndex;
+//    private final STRtree spatialIndex;
+
+    private final Function<Label, Double> z = label -> (double) label.currentTime;
+
+    public PtIsochroneResource(GtfsStorage gtfsStorage, EncodingManager encodingManager, GraphHopperStorage graphHopperStorage, LocationIndex locationIndex) {
+        this.gtfsStorage = gtfsStorage;
+        this.encodingManager = encodingManager;
+        this.graphHopperStorage = graphHopperStorage;
+        this.locationIndex = locationIndex;
+//        spatialIndex = new STRtree();
+//        PtFlagEncoder ptFlagEncoder = (PtFlagEncoder) encodingManager.getEncoder("pt");
+//        AllEdgesIterator allEdges = graphHopperStorage.getAllEdges();
+//        while (allEdges.next()) {
+//            if (ptFlagEncoder.getEdgeType(allEdges.getFlags()) == GtfsStorage.EdgeType.HIGHWAY) {
+//                LineString geom = allEdges.fetchWayGeometry(3).toLineString(false);
+//                spatialIndex.insert(geom.getEnvelopeInternal(), allEdges.getEdge());
+//            }
+//        }
+    }
+
+    public static class Response {
+        public static class Info {
+            public List<String> copyrights = new ArrayList<>();
+        }
+        public List<JsonFeature> polygons = new ArrayList<>();
+        public Info info = new Info();
+    }
+
+    @GET
+    @Produces({MediaType.APPLICATION_JSON})
+    public Response doGet(
+            @QueryParam("point") GHPoint source,
+            @QueryParam("time_limit") @DefaultValue("600") long seconds,
+            @QueryParam("reverse_flow") @DefaultValue("false") boolean reverseFlow,
+            @QueryParam(Parameters.PT.EARLIEST_DEPARTURE_TIME) String departureTimeString,
+            @QueryParam(Parameters.PT.BLOCKED_ROUTE_TYPES) @DefaultValue("0") int blockedRouteTypes,
+            @QueryParam("result") @DefaultValue("multipolygon") String format) {
+        Instant initialTime;
+        try {
+            initialTime = Instant.parse(departureTimeString);
+        } catch (Exception e) {
+            throw new IllegalArgumentException(String.format(Locale.ROOT, "Illegal value for required parameter %s: [%s]", Parameters.PT.EARLIEST_DEPARTURE_TIME, departureTimeString));
+        }
+
+        double targetZ = initialTime.toEpochMilli() + seconds * 1000;
+
+        GeometryFactory geometryFactory = new GeometryFactory();
+        QueryGraph queryGraph = new QueryGraph(graphHopperStorage);
+        final EdgeFilter filter = DefaultEdgeFilter.allEdges(graphHopperStorage.getEncodingManager().getEncoder("foot"));
+        QueryResult queryResult = locationIndex.findClosest(source.lat, source.lon, filter);
+        queryGraph.lookup(Collections.singletonList(queryResult));
+        if (!queryResult.isValid()) {
+            throw new IllegalArgumentException("Cannot find point: " + source);
+        }
+
+        PtFlagEncoder ptFlagEncoder = (PtFlagEncoder) encodingManager.getEncoder("pt");
+        GraphExplorer graphExplorer = new GraphExplorer(queryGraph, new FastestWeighting(encodingManager.getEncoder("foot")), ptFlagEncoder, gtfsStorage, RealtimeFeed.empty(gtfsStorage), reverseFlow, Collections.emptyList(), false, 5.0);
+        MultiCriteriaLabelSetting router = new MultiCriteriaLabelSetting(graphExplorer, ptFlagEncoder, reverseFlow, Double.MAX_VALUE, false, false, false, 1000000, Collections.emptyList());
+
+        Map<Coordinate, Double> z1 = new HashMap<>();
+        NodeAccess nodeAccess = queryGraph.getNodeAccess();
+
+        MultiCriteriaLabelSetting.SPTVisitor sptVisitor = nodeLabel -> {
+            Coordinate nodeCoordinate = new Coordinate(nodeAccess.getLongitude(nodeLabel.adjNode), nodeAccess.getLatitude(nodeLabel.adjNode));
+            z1.merge(nodeCoordinate, this.z.apply(nodeLabel), Math::min);
+        };
+
+        if (format.equals("multipoint")) {
+            router.calcLabels(queryResult.getClosestNode(), -1, initialTime, blockedRouteTypes, sptVisitor, label -> label.currentTime <= targetZ);
+            MultiPoint exploredPoints = geometryFactory.createMultiPointFromCoords(z1.keySet().toArray(new Coordinate[0]));
+            return wrap(exploredPoints);
+        } else {
+            router.calcLabelsAndNeighbors(queryResult.getClosestNode(), -1, initialTime, blockedRouteTypes, sptVisitor, label -> label.currentTime <= targetZ);
+            MultiPoint exploredPointsAndNeighbors = geometryFactory.createMultiPointFromCoords(z1.keySet().toArray(new Coordinate[0]));
+
+            // This is what we need to do once we can do bounding-box queries on our spatial index.
+            // Then it should be impossible for unreachable encroaching points to not be found.
+
+//            spatialIndex.query(exploredPointsAndNeighbors.getEnvelopeInternal(), edgeId -> {
+//                EdgeIteratorState e = graphHopperStorage.getEdgeIteratorState((int) edgeId, Integer.MIN_VALUE);
+//                Coordinate nodeCoordinate = new Coordinate(nodeAccess.getLongitude(e.getBaseNode()), nodeAccess.getLatitude(e.getBaseNode()));
+//                z1.merge(nodeCoordinate, Double.MAX_VALUE, Math::min);
+//                nodeCoordinate = new Coordinate(nodeAccess.getLongitude(e.getAdjNode()), nodeAccess.getLatitude(e.getAdjNode()));
+//                z1.merge(nodeCoordinate, Double.MAX_VALUE, Math::min);
+//            });
+//            exploredPointsAndNeighbors = geometryFactory.createMultiPointFromCoords(z1.keySet().toArray(new Coordinate[0]));
+
+            CoordinateList siteCoords = DelaunayTriangulationBuilder.extractUniqueCoordinates(exploredPointsAndNeighbors);
+            List<ConstraintVertex> constraintVertices = new ArrayList<>();
+            for (Object siteCoord : siteCoords) {
+                Coordinate coord = (Coordinate) siteCoord;
+                constraintVertices.add(new ConstraintVertex(coord));
+            }
+
+            ConformingDelaunayTriangulator cdt = new ConformingDelaunayTriangulator(constraintVertices, JTS_TOLERANCE);
+            cdt.setConstraints(new ArrayList(), new ArrayList());
+            cdt.formInitialDelaunay();
+
+            QuadEdgeSubdivision tin = cdt.getSubdivision();
+
+            for (Vertex vertex : (Collection<Vertex>) tin.getVertices(true)) {
+                if (tin.isFrameVertex(vertex)) {
+                    vertex.setZ(Double.MAX_VALUE);
+                } else {
+                    Double aDouble = z1.get(vertex.getCoordinate());
+                    if (aDouble != null) {
+                        vertex.setZ(aDouble);
+                    } else {
+                        vertex.setZ(Double.MAX_VALUE);
+                    }
+                }
+            }
+
+            ContourBuilder contourBuilder = new ContourBuilder(tin);
+            MultiPolygon isoline = contourBuilder.computeIsoline(targetZ);
+
+            // debugging tool
+            if (format.equals("triangulation")) {
+                Response response = new Response();
+                for (Vertex vertex : (Collection<Vertex>) tin.getVertices(true)) {
+                    JsonFeature feature = new JsonFeature();
+                    feature.setGeometry(geometryFactory.createPoint(vertex.getCoordinate()));
+                    HashMap<String, Object> properties = new HashMap<>();
+                    properties.put("z", vertex.getZ());
+                    feature.setProperties(properties);
+                    response.polygons.add(feature);
+                }
+                for (QuadEdge edge : (Collection<QuadEdge>) tin.getPrimaryEdges(false)) {
+                    JsonFeature feature = new JsonFeature();
+                    feature.setGeometry(edge.toLineSegment().toGeometry(geometryFactory));
+                    HashMap<String, Object> properties = new HashMap<>();
+                    feature.setProperties(properties);
+                    response.polygons.add(feature);
+                }
+                JsonFeature feature = new JsonFeature();
+                feature.setGeometry(isoline);
+                HashMap<String, Object> properties = new HashMap<>();
+                properties.put("z", targetZ);
+                feature.setProperties(properties);
+                response.polygons.add(feature);
+                response.info.copyrights.add("GraphHopper");
+                response.info.copyrights.add("OpenStreetMap contributors");
+                return response;
+            } else {
+                return wrap(isoline);
+            }
+        }
+
+    }
+
+    private Response wrap(Geometry isoline) {
+        JsonFeature feature = new JsonFeature();
+        feature.setGeometry(isoline);
+        HashMap<String, Object> properties = new HashMap<>();
+        properties.put("bucket", 0);
+        feature.setProperties(properties);
+
+        Response response = new Response();
+        response.polygons.add(feature);
+        response.info.copyrights.add("GraphHopper");
+        response.info.copyrights.add("OpenStreetMap contributors");
+        return response;
+    }
+
+}
diff --git a/web/pom.xml b/web/pom.xml
index 70b36f6ca9..68455453d3 100644
--- a/web/pom.xml
+++ b/web/pom.xml
@@ -68,7 +68,6 @@
             <plugin>
                 <groupId>org.apache.maven.plugins</groupId>
                 <artifactId>maven-compiler-plugin</artifactId>
-                <version>3.5.1</version>
                 <configuration>
                     <source>1.8</source>
                     <target>1.8</target>
diff --git a/web/src/test/java/com/graphhopper/http/isochrone/PtIsochroneResourceTest.java b/web/src/test/java/com/graphhopper/http/isochrone/PtIsochroneResourceTest.java
new file mode 100644
index 0000000000..3848316bbb
--- /dev/null
+++ b/web/src/test/java/com/graphhopper/http/isochrone/PtIsochroneResourceTest.java
@@ -0,0 +1,118 @@
+/*
+ *  Licensed to GraphHopper GmbH under one or more contributor
+ *  license agreements. See the NOTICE file distributed with this work for
+ *  additional information regarding copyright ownership.
+ *
+ *  GraphHopper GmbH licenses this file to you under the Apache License,
+ *  Version 2.0 (the "License"); you may not use this file except in
+ *  compliance with the License. You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an "AS IS" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package com.graphhopper.http.isochrone;
+
+import com.graphhopper.http.GHPointConverterProvider;
+import com.graphhopper.jackson.Jackson;
+import com.graphhopper.reader.gtfs.GraphHopperGtfs;
+import com.graphhopper.reader.gtfs.GtfsStorage;
+import com.graphhopper.reader.gtfs.PtFlagEncoder;
+import com.graphhopper.resources.PtIsochroneResource;
+import com.graphhopper.routing.util.CarFlagEncoder;
+import com.graphhopper.routing.util.EncodingManager;
+import com.graphhopper.routing.util.FootFlagEncoder;
+import com.graphhopper.storage.GHDirectory;
+import com.graphhopper.storage.GraphHopperStorage;
+import com.graphhopper.storage.index.LocationIndex;
+import com.graphhopper.util.Helper;
+import io.dropwizard.testing.junit.ResourceTestRule;
+import org.junit.AfterClass;
+import org.junit.ClassRule;
+import org.junit.Test;
+import org.locationtech.jts.geom.Coordinate;
+import org.locationtech.jts.geom.Geometry;
+import org.locationtech.jts.geom.GeometryFactory;
+
+import javax.ws.rs.client.Invocation;
+import javax.ws.rs.client.WebTarget;
+import java.io.File;
+import java.time.LocalDateTime;
+import java.time.ZoneId;
+import java.util.Arrays;
+import java.util.Collections;
+
+import static org.junit.Assert.assertFalse;
+import static org.junit.Assert.assertTrue;
+
+public class PtIsochroneResourceTest {
+
+    private static final String GRAPH_LOC = "target/PtIsochroneResourceTest";
+    private static final ZoneId zoneId = ZoneId.of("America/Los_Angeles");
+    private static GraphHopperStorage graphHopperStorage;
+    private static LocationIndex locationIndex;
+    private static PtIsochroneResource isochroneResource;
+    private GeometryFactory geometryFactory = new GeometryFactory();
+
+    static {
+        Helper.removeDir(new File(GRAPH_LOC));
+        final PtFlagEncoder ptFlagEncoder = new PtFlagEncoder();
+        final CarFlagEncoder carFlagEncoder = new CarFlagEncoder();
+        final FootFlagEncoder footFlagEncoder = new FootFlagEncoder();
+
+        EncodingManager encodingManager = new EncodingManager(Arrays.asList(carFlagEncoder, footFlagEncoder, ptFlagEncoder), 8);
+        GHDirectory directory = GraphHopperGtfs.createGHDirectory(GRAPH_LOC);
+        GtfsStorage gtfsStorage = GraphHopperGtfs.createGtfsStorage();
+        graphHopperStorage = GraphHopperGtfs.createOrLoad(directory, encodingManager, ptFlagEncoder, gtfsStorage, Collections.singleton("../reader-gtfs/files/sample-feed.zip"), Collections.emptyList());
+        locationIndex = GraphHopperGtfs.createOrLoadIndex(directory, graphHopperStorage);
+        isochroneResource = new PtIsochroneResource(gtfsStorage, graphHopperStorage.getEncodingManager(), graphHopperStorage, locationIndex);
+    }
+
+    @ClassRule
+    public static final ResourceTestRule resources = ResourceTestRule.builder()
+            .addProvider(new GHPointConverterProvider())
+            .setMapper(Jackson.newObjectMapper())
+            .addResource(isochroneResource)
+            .build();
+
+
+    @Test
+    public void testIsoline() {
+        WebTarget webTarget = resources
+                .target("/isochrone")
+                .queryParam("point", "36.914893,-116.76821") // NADAV
+                .queryParam("pt.earliest_departure_time", LocalDateTime.of(2007, 1, 1, 0, 0, 0).atZone(zoneId).toInstant())
+                .queryParam("time_limit", 6 * 60 * 60 + 49 * 60); // exactly the time I should arrive at NANAA
+        Invocation.Builder request = webTarget.request();
+        PtIsochroneResource.Response isochroneResponse = request.get(PtIsochroneResource.Response.class);
+        Geometry isoline = isochroneResponse.polygons.get(0).getGeometry();
+        // NADAV is in
+        assertTrue(isoline.covers(geometryFactory.createPoint(makePrecise(new Coordinate(-116.76821, 36.914893)))));
+        // NANAA is in
+        assertTrue(isoline.covers(geometryFactory.createPoint(makePrecise(new Coordinate(-116.761472, 36.914944)))));
+        // DADAN is in
+        assertTrue(isoline.covers(geometryFactory.createPoint(makePrecise(new Coordinate(-116.768242, 36.909489)))));
+        // EMSI is in
+        assertTrue(isoline.covers(geometryFactory.createPoint(makePrecise(new Coordinate(-116.76218, 36.905697)))));
+        // STAGECOACH is out
+        assertFalse(isoline.covers(geometryFactory.createPoint(makePrecise(new Coordinate(-116.751677, 36.915682)))));
+    }
+
+    // Snap coordinate to GraphHopper's implicit grid of allowable points.
+    // Otherwise, we can't reliably use coordinates from input data in tests.
+    private Coordinate makePrecise(Coordinate coordinate) {
+        return new Coordinate(Helper.intToDegree(Helper.degreeToInt(coordinate.x)), Helper.intToDegree(Helper.degreeToInt(coordinate.y)));
+    }
+
+    @AfterClass
+    public static void close() {
+        graphHopperStorage.close();
+        locationIndex.close();
+    }
+
+}
diff --git a/web/src/test/java/com/graphhopper/http/resources/RouteResourceTest.java b/web/src/test/java/com/graphhopper/http/resources/RouteResourceTest.java
index f2872157f1..fb5cd545c8 100644
--- a/web/src/test/java/com/graphhopper/http/resources/RouteResourceTest.java
+++ b/web/src/test/java/com/graphhopper/http/resources/RouteResourceTest.java
@@ -246,7 +246,7 @@ public void testPathDetailsWithoutGraphHopperWeb() throws Exception {
         int firstLink = edgeIds.get(0).get(2).asInt();
         int lastLink = edgeIds.get(edgeIds.size() - 1).get(2).asInt();
         assertEquals(880, firstLink);
-        assertEquals(1419, lastLink);
+        assertEquals(1420, lastLink);
     }
 
     @Test
