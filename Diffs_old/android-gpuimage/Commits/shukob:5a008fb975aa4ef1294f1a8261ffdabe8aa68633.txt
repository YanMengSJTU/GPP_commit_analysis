diff --git a/library/src/jp/co/cyberagent/android/gpuimage/GPUImageTextureRenderer.java b/library/src/jp/co/cyberagent/android/gpuimage/GPUImageTextureRenderer.java
index be3046c6..7fc2aa8e 100644
--- a/library/src/jp/co/cyberagent/android/gpuimage/GPUImageTextureRenderer.java
+++ b/library/src/jp/co/cyberagent/android/gpuimage/GPUImageTextureRenderer.java
@@ -20,6 +20,7 @@
 import android.graphics.SurfaceTexture;
 import android.hardware.Camera;
 import android.opengl.GLES20;
+import android.opengl.GLUtils;
 import android.os.Build;
 import android.os.Handler;
 import android.os.Looper;
@@ -199,11 +200,11 @@ protected void initGL() {
         eglSurface = egl.eglCreateWindowSurface(eglDisplay, eglConfig, outputTexture, null);
 
         if (eglSurface == null || eglSurface == EGL10.EGL_NO_SURFACE) {
-            throw new RuntimeException("GL Error: ");// + GLUtils.getEGLErrorString(egl.eglGetError()));
+            throw new RuntimeException("GL Error: " + GLUtils.getEGLErrorString(egl.eglGetError()));
         }
 
         if (!egl.eglMakeCurrent(eglDisplay, eglSurface, eglSurface, eglContext)) {
-            throw new RuntimeException("GL Make current error: ");// + GLUtils.getEGLErrorString(egl.eglGetError()));
+            throw new RuntimeException("GL Make current error: " + GLUtils.getEGLErrorString(egl.eglGetError()));
         }
     }
 
@@ -236,7 +237,7 @@ protected EGLConfig chooseEglConfig() {
         int[] configSpec = getConfig();
 
         if (!egl.eglChooseConfig(eglDisplay, configSpec, configs, 1, configsCount)) {
-            throw new IllegalArgumentException("Failed to choose config: ");// + GLUtils.getEGLErrorString(egl.eglGetError()));
+            throw new IllegalArgumentException("Failed to choose config: " + GLUtils.getEGLErrorString(egl.eglGetError()));
         } else if (configsCount[0] > 0) {
             return configs[0];
         }
@@ -305,14 +306,22 @@ protected boolean draw() {
         GLES20.glClearColor(0.0f, 0.0f, 0.0f, 0.0f);
         GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);
         mNoFilter.onDraw(textures[0], mGLCubeBuffer, mGLTextureBuffer);
+
+
         GLES20.glBindFramebuffer(GLES20.GL_FRAMEBUFFER, 0);
         GLES20.glViewport(0, 0, mOutputWidth, mOutputHeight);
         GLES20.glClearColor(0.0f, 0.0f, 0.0f, 0.0f);
         GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);
         mFilter.onDraw(offScreenTextures[0], screenCubeBuffer, screenTextureBuffer);
+
+        onDrawAfterNoFilter();
         return true;
     }
 
+    protected void onDrawAfterNoFilter() {
+
+    }
+
 
     protected void initGLComponents() {
         setupTexture();
@@ -349,7 +358,7 @@ public void run() {
     public void checkGlError(String op) {
         int error;
         while ((error = GLES20.glGetError()) != GLES20.GL_NO_ERROR) {
-            Log.e("SurfaceTest", op + ": glError ");// + GLUtils.getEGLErrorString(error));
+            Log.e("SurfaceTest", op + ": glError " + GLUtils.getEGLErrorString(error));
         }
     }
 
diff --git a/sample/build.gradle b/sample/build.gradle
index 1299d10d..209e09ba 100644
--- a/sample/build.gradle
+++ b/sample/build.gradle
@@ -19,6 +19,7 @@ android {
             renderscript.srcDirs = ['src']
             res.srcDirs = ['res']
             assets.srcDirs = ['assets']
+            jniLibs.srcDirs = ['jniLibs']
         }
 
         instrumentTest.setRoot('tests')
@@ -39,4 +40,6 @@ dependencies {
     compile 'com.android.support:support-v4:21.+'
     compile 'com.github.skonb:fenster:78b6a3e3a5'
     compile 'com.github.wseemann:FFmpegMediaMetadataRetriever:1.0.3'
+    compile 'org.bytedeco:javacv:1.1'
+    compile 'org.bytedeco:javacpp:1.1'
 }
diff --git a/sample/src/jp/co/cyberagent/android/gpuimage/sample/GPUImageRecordableTextureRenderer.java b/sample/src/jp/co/cyberagent/android/gpuimage/sample/GPUImageRecordableTextureRenderer.java
new file mode 100644
index 00000000..d70a20b7
--- /dev/null
+++ b/sample/src/jp/co/cyberagent/android/gpuimage/sample/GPUImageRecordableTextureRenderer.java
@@ -0,0 +1,159 @@
+package jp.co.cyberagent.android.gpuimage.sample;
+
+import android.opengl.GLES20;
+import android.opengl.GLES30;
+import android.os.Environment;
+
+import org.bytedeco.javacpp.avcodec;
+import org.bytedeco.javacpp.opencv_core;
+import org.bytedeco.javacpp.opencv_imgproc;
+import org.bytedeco.javacv.FFmpegFrameRecorder;
+import org.bytedeco.javacv.Frame;
+import org.bytedeco.javacv.FrameRecorder;
+import org.bytedeco.javacv.OpenCVFrameConverter;
+
+import java.io.File;
+import java.nio.ByteBuffer;
+
+import jp.co.cyberagent.android.gpuimage.GPUImageFilter;
+import jp.co.cyberagent.android.gpuimage.GPUImageTextureRenderer;
+
+/**
+ * Created by skonb on 16/02/25.
+ */
+public class GPUImageRecordableTextureRenderer extends GPUImageTextureRenderer {
+
+    static class CONSTANTS {
+
+        public final static String METADATA_REQUEST_BUNDLE_TAG = "requestMetaData";
+        public final static String FILE_START_NAME = "VMS_";
+        public final static String VIDEO_EXTENSION = ".mp4";
+        public final static String DCIM_FOLDER = "/DCIM";
+        public final static String CAMERA_FOLDER = "/Camera/GPUImage";
+        public final static String TEMP_FOLDER = "/Temp";
+        public final static String CAMERA_FOLDER_PATH = Environment.getExternalStorageDirectory().toString() + CONSTANTS.DCIM_FOLDER + CONSTANTS.CAMERA_FOLDER;
+        public final static String TEMP_FOLDER_PATH = Environment.getExternalStorageDirectory().toString() + CONSTANTS.DCIM_FOLDER + CONSTANTS.CAMERA_FOLDER + CONSTANTS.TEMP_FOLDER;
+        public final static String VIDEO_CONTENT_URI = "content://media/external/video/media";
+
+        public final static String KEY_DELETE_FOLDER_FROM_SDCARD = "deleteFolderFromSDCard";
+
+        public final static String RECEIVER_ACTION_SAVE_FRAME = "com.javacv.recorder.intent.action.SAVE_FRAME";
+        public final static String RECEIVER_CATEGORY_SAVE_FRAME = "com.javacv.recorder";
+        public final static String TAG_SAVE_FRAME = "saveFrame";
+
+        public final static int RESOLUTION_HIGH = 1300;
+        public final static int RESOLUTION_MEDIUM = 500;
+        public final static int RESOLUTION_LOW = 180;
+
+        public final static int RESOLUTION_HIGH_VALUE = 2;
+        public final static int RESOLUTION_MEDIUM_VALUE = 1;
+        public final static int RESOLUTION_LOW_VALUE = 0;
+    }
+
+    private static String genrateFilePath(String uniqueId, boolean isFinalPath, File tempFolderPath) {
+        String fileName = CONSTANTS.FILE_START_NAME + uniqueId + CONSTANTS.VIDEO_EXTENSION;
+        String dirPath = "";
+        if (isFinalPath) {
+            new File(CONSTANTS.CAMERA_FOLDER_PATH).mkdirs();
+            dirPath = CONSTANTS.CAMERA_FOLDER_PATH;
+        } else
+            dirPath = tempFolderPath.getAbsolutePath();
+        String filePath = dirPath + "/" + fileName;
+        return filePath;
+    }
+
+    public static String createTempPath(File tempFolderPath) {
+        long dateTaken = System.currentTimeMillis();
+        String filePath = genrateFilePath(String.valueOf(dateTaken), false, tempFolderPath);
+        return filePath;
+    }
+
+
+    public static File getTempFolderPath() {
+        File tempFolder = new File(CONSTANTS.TEMP_FOLDER_PATH + "_" + System.currentTimeMillis());
+        return tempFolder;
+    }
+
+    FFmpegFrameRecorder frameRecorder;
+
+    public GPUImageRecordableTextureRenderer() {
+        createFile();
+    }
+
+    public GPUImageRecordableTextureRenderer(GPUImageFilter filter) {
+        super(filter);
+        createFile();
+    }
+
+    String outputFilePath;
+
+    public void createFile() {
+        if (outputFilePath == null) {
+            File tempFolder = getTempFolderPath();
+            tempFolder.mkdirs();
+            outputFilePath = createTempPath(tempFolder);
+        }
+    }
+
+    static final int GL_BGR = 0x80E0;
+
+    opencv_core.IplImage rgbaImage;
+    opencv_core.IplImage bgraImage;
+    long startedTime = 0;
+
+
+    @Override
+    protected void onDrawAfterNoFilter() {
+        int width = mOutputWidth, height = mOutputHeight;
+        if (running) {
+            if (frameRecorder == null && width > 0 && height > 0) {
+                frameRecorder = new FFmpegFrameRecorder(outputFilePath, width, height, 1);
+                frameRecorder.setFormat("mp4");
+                frameRecorder.setVideoCodec(avcodec.AV_CODEC_ID_MPEG4);
+                rgbaImage = opencv_core.IplImage.create(width, height, opencv_core.IPL_DEPTH_8U, 4);
+                bgraImage = opencv_core.IplImage.create(width, height, opencv_core.IPL_DEPTH_8U, 3);
+                try {
+                    frameRecorder.start();
+                    startedTime = System.currentTimeMillis();
+                } catch (FrameRecorder.Exception e) {
+                    e.printStackTrace();
+                }
+            }
+            if (frameRecorder != null) {
+                GLES20.glPixelStorei(GLES20.GL_PACK_ALIGNMENT, 1);
+                GLES30.glPixelStorei(GLES30.GL_UNPACK_ALIGNMENT, 1);
+                ByteBuffer buffer = (ByteBuffer) rgbaImage.createBuffer().position(0);
+                bgraImage.createBuffer(0);
+                GLES20.glReadPixels(0, 0, width, height, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, buffer);
+                opencv_imgproc.cvCvtColor(rgbaImage, bgraImage, opencv_imgproc.CV_RGBA2BGR);
+                opencv_core.cvFlip(bgraImage);
+                Frame frame = new OpenCVFrameConverter.ToIplImage().convert(bgraImage);
+                synchronized (this) {
+                    try {
+                        if (running) {
+                            frameRecorder.setTimestamp(1000 * (System.currentTimeMillis() - startedTime));
+                            frameRecorder.record(frame);
+                        }
+                    } catch (FrameRecorder.Exception e) {
+                        e.printStackTrace();
+                    }
+                }
+            }
+        }
+    }
+
+    @Override
+    public void onPause() {
+        super.onPause();
+        if (frameRecorder != null) {
+            try {
+                synchronized (this) {
+                    frameRecorder.stop();
+                }
+
+            } catch (FrameRecorder.Exception e) {
+                e.printStackTrace();
+            }
+        }
+    }
+}
diff --git a/sample/src/jp/co/cyberagent/android/gpuimage/sample/activity/ActivityMovie.java b/sample/src/jp/co/cyberagent/android/gpuimage/sample/activity/ActivityMovie.java
index 3e9eab59..94e29987 100644
--- a/sample/src/jp/co/cyberagent/android/gpuimage/sample/activity/ActivityMovie.java
+++ b/sample/src/jp/co/cyberagent/android/gpuimage/sample/activity/ActivityMovie.java
@@ -27,6 +27,7 @@
 import jp.co.cyberagent.android.gpuimage.GPUImageWhiteBalanceFilter;
 import jp.co.cyberagent.android.gpuimage.Rotation;
 import jp.co.cyberagent.android.gpuimage.sample.GPUImageFilterTools;
+import jp.co.cyberagent.android.gpuimage.sample.GPUImageRecordableTextureRenderer;
 import jp.co.cyberagent.android.gpuimage.sample.R;
 import wseemann.media.FFmpegMediaMetadataRetriever;
 
@@ -36,7 +37,7 @@
     FensterVideoView videoView;
     GPUImageFilter filter = null;
 
-    class Renderer extends GPUImageTextureRenderer implements FensterVideoView.Renderer {
+    class Renderer extends GPUImageRecordableTextureRenderer implements FensterVideoView.Renderer {
         public Renderer() {
             super();
         }
