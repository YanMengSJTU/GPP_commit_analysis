diff --git a/RELEASENOTES.md b/RELEASENOTES.md
index f7a11eb0ec..93b9ca4115 100644
--- a/RELEASENOTES.md
+++ b/RELEASENOTES.md
@@ -1,8 +1,15 @@
 # Release notes #
 
-### Current dev branch (from r1.4.2) ###
-
-* Nothing yet.
+### r.1.5.0 ###
+
+* Multi-track support.
+* DASH: Limited support for multi-period manifests.
+* HLS: Smoother format adaptation.
+* HLS: Support for MP3 media segments.
+* TTML: Support for most embedded TTML styling.
+* WebVTT: Enhanced positioning support.
+* Initial playback tests.
+* Misc bug fixes.
 
 ### r1.4.2 ###
 
@@ -20,7 +27,7 @@
 * Support for extracting Matroska streams (implemented by WebmExtractor).
 * Support for tx3g captions in MP4 streams.
 * Support for H.265 in MPEG-TS streams on supported devices.
-* HLS: Added support for MPEG audio (e.g. MP3).
+* HLS: Added support for MPEG audio (e.g. MP3) in TS media segments.
 * HLS: Improved robustness against missing chunks and variants.
 * MP4: Added support for embedded MPEG audio (e.g. MP3).
 * TTML: Improved handling of whitespace.
diff --git a/demo/src/main/AndroidManifest.xml b/demo/src/main/AndroidManifest.xml
index 5212346bab..1575a1e6b7 100644
--- a/demo/src/main/AndroidManifest.xml
+++ b/demo/src/main/AndroidManifest.xml
@@ -16,8 +16,8 @@
 
 <manifest xmlns:android="http://schemas.android.com/apk/res/android"
     package="com.google.android.exoplayer.demo"
-    android:versionCode="1402"
-    android:versionName="1.4.2"
+    android:versionCode="1500"
+    android:versionName="1.5.0"
     android:theme="@style/RootTheme">
 
   <uses-permission android:name="android.permission.INTERNET"/>
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/EventLogger.java b/demo/src/main/java/com/google/android/exoplayer/demo/EventLogger.java
index d0201fbc61..821bd3b679 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/EventLogger.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/EventLogger.java
@@ -47,7 +47,7 @@
 
   private long sessionStartTimeMs;
   private long[] loadStartTimeMs;
-  private long[] seekRangeValuesUs;
+  private long[] availableRangeValuesUs;
 
   public EventLogger() {
     loadStartTimeMs = new long[DemoPlayer.RENDERER_COUNT];
@@ -76,8 +76,10 @@ public void onError(Exception e) {
   }
 
   @Override
-  public void onVideoSizeChanged(int width, int height, float pixelWidthHeightRatio) {
-    Log.d(TAG, "videoSizeChanged [" + width + ", " + height + ", " + pixelWidthHeightRatio + "]");
+  public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+      float pixelWidthHeightRatio) {
+    Log.d(TAG, "videoSizeChanged [" + width + ", " + height + ", " + unappliedRotationDegrees
+        + ", " + pixelWidthHeightRatio + "]");
   }
 
   // DemoPlayer.InfoListener
@@ -95,7 +97,7 @@ public void onDroppedFrames(int count, long elapsed) {
 
   @Override
   public void onLoadStarted(int sourceId, long length, int type, int trigger, Format format,
-      int mediaStartTimeMs, int mediaEndTimeMs) {
+      long mediaStartTimeMs, long mediaEndTimeMs) {
     loadStartTimeMs[sourceId] = SystemClock.elapsedRealtime();
     if (VerboseLogUtil.isTagEnabled(TAG)) {
       Log.v(TAG, "loadStart [" + getSessionTimeString() + ", " + sourceId + ", " + type
@@ -105,7 +107,7 @@ public void onLoadStarted(int sourceId, long length, int type, int trigger, Form
 
   @Override
   public void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Format format,
-       int mediaStartTimeMs, int mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs) {
+       long mediaStartTimeMs, long mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs) {
     if (VerboseLogUtil.isTagEnabled(TAG)) {
       long downloadTime = SystemClock.elapsedRealtime() - loadStartTimeMs[sourceId];
       Log.v(TAG, "loadEnd [" + getSessionTimeString() + ", " + sourceId + ", " + downloadTime
@@ -114,13 +116,13 @@ public void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigge
   }
 
   @Override
-  public void onVideoFormatEnabled(Format format, int trigger, int mediaTimeMs) {
+  public void onVideoFormatEnabled(Format format, int trigger, long mediaTimeMs) {
     Log.d(TAG, "videoFormat [" + getSessionTimeString() + ", " + format.id + ", "
         + Integer.toString(trigger) + "]");
   }
 
   @Override
-  public void onAudioFormatEnabled(Format format, int trigger, int mediaTimeMs) {
+  public void onAudioFormatEnabled(Format format, int trigger, long mediaTimeMs) {
     Log.d(TAG, "audioFormat [" + getSessionTimeString() + ", " + format.id + ", "
         + Integer.toString(trigger) + "]");
   }
@@ -169,10 +171,10 @@ public void onDecoderInitialized(String decoderName, long elapsedRealtimeMs,
   }
 
   @Override
-  public void onSeekRangeChanged(TimeRange seekRange) {
-    seekRangeValuesUs = seekRange.getCurrentBoundsUs(seekRangeValuesUs);
-    Log.d(TAG, "seekRange [ " + seekRange.type + ", " + seekRangeValuesUs[0] + ", "
-        + seekRangeValuesUs[1] + "]");
+  public void onAvailableRangeChanged(TimeRange availableRange) {
+    availableRangeValuesUs = availableRange.getCurrentBoundsUs(availableRangeValuesUs);
+    Log.d(TAG, "availableRange [" + availableRange.isStatic() + ", " + availableRangeValuesUs[0]
+        + ", " + availableRangeValuesUs[1] + "]");
   }
 
   private void printInternalError(String type, Exception e) {
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java b/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
index a075f53971..8f4d3e16cc 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/PlayerActivity.java
@@ -17,6 +17,7 @@
 
 import com.google.android.exoplayer.AspectRatioFrameLayout;
 import com.google.android.exoplayer.ExoPlayer;
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.audio.AudioCapabilitiesReceiver;
 import com.google.android.exoplayer.demo.player.DashRendererBuilder;
@@ -33,6 +34,7 @@
 import com.google.android.exoplayer.text.Cue;
 import com.google.android.exoplayer.text.SubtitleLayout;
 import com.google.android.exoplayer.util.DebugTextViewHelper;
+import com.google.android.exoplayer.util.MimeTypes;
 import com.google.android.exoplayer.util.Util;
 import com.google.android.exoplayer.util.VerboseLogUtil;
 
@@ -66,6 +68,7 @@
 import java.net.CookieManager;
 import java.net.CookiePolicy;
 import java.util.List;
+import java.util.Locale;
 import java.util.Map;
 
 /**
@@ -119,7 +122,6 @@
   private String contentId;
 
   private AudioCapabilitiesReceiver audioCapabilitiesReceiver;
-  private AudioCapabilities audioCapabilities;
 
   // Activity lifecycle
 
@@ -148,13 +150,12 @@ public boolean onTouch(View view, MotionEvent motionEvent) {
     root.setOnKeyListener(new OnKeyListener() {
       @Override
       public boolean onKey(View v, int keyCode, KeyEvent event) {
-        if (keyCode == KeyEvent.KEYCODE_MEDIA_PLAY_PAUSE) {
-          return mediaController.dispatchKeyEvent(event);
+        if (keyCode == KeyEvent.KEYCODE_BACK || keyCode == KeyEvent.KEYCODE_MENU) {
+          return false;
         }
-        return false;
+        return mediaController.dispatchKeyEvent(event);
       }
     });
-    audioCapabilitiesReceiver = new AudioCapabilitiesReceiver(getApplicationContext(), this);
 
     shutterView = findViewById(R.id.shutter);
     debugRootView = findViewById(R.id.controls_root);
@@ -179,15 +180,20 @@ public boolean onKey(View v, int keyCode, KeyEvent event) {
     if (currentHandler != defaultCookieManager) {
       CookieHandler.setDefault(defaultCookieManager);
     }
+
+    audioCapabilitiesReceiver = new AudioCapabilitiesReceiver(this, this);
+    audioCapabilitiesReceiver.register();
   }
 
   @Override
   public void onResume() {
     super.onResume();
     configureSubtitleView();
-
-    // The player will be prepared on receiving audio capabilities.
-    audioCapabilitiesReceiver.register();
+    if (player == null) {
+      preparePlayer(true);
+    } else {
+      player.setBackgrounded(false);
+    }
   }
 
   @Override
@@ -198,13 +204,13 @@ public void onPause() {
     } else {
       player.setBackgrounded(true);
     }
-    audioCapabilitiesReceiver.unregister();
     shutterView.setVisibility(View.VISIBLE);
   }
 
   @Override
   public void onDestroy() {
     super.onDestroy();
+    audioCapabilitiesReceiver.unregister();
     releasePlayer();
   }
 
@@ -213,7 +219,7 @@ public void onDestroy() {
   @Override
   public void onClick(View view) {
     if (view == retryButton) {
-      preparePlayer();
+      preparePlayer(true);
     }
   }
 
@@ -221,14 +227,14 @@ public void onClick(View view) {
 
   @Override
   public void onAudioCapabilitiesChanged(AudioCapabilities audioCapabilities) {
-    boolean audioCapabilitiesChanged = !audioCapabilities.equals(this.audioCapabilities);
-    if (player == null || audioCapabilitiesChanged) {
-      this.audioCapabilities = audioCapabilities;
-      releasePlayer();
-      preparePlayer();
-    } else if (player != null) {
-      player.setBackgrounded(false);
+    if (player == null) {
+      return;
     }
+    boolean backgrounded = player.getBackgrounded();
+    boolean playWhenReady = player.getPlayWhenReady();
+    releasePlayer();
+    preparePlayer(playWhenReady);
+    player.setBackgrounded(backgrounded);
   }
 
   // Internal methods
@@ -241,9 +247,9 @@ private RendererBuilder getRendererBuilder() {
             new SmoothStreamingTestMediaDrmCallback());
       case TYPE_DASH:
         return new DashRendererBuilder(this, userAgent, contentUri.toString(),
-            new WidevineTestMediaDrmCallback(contentId), audioCapabilities);
+            new WidevineTestMediaDrmCallback(contentId));
       case TYPE_HLS:
-        return new HlsRendererBuilder(this, userAgent, contentUri.toString(), audioCapabilities);
+        return new HlsRendererBuilder(this, userAgent, contentUri.toString());
       case TYPE_OTHER:
         return new ExtractorRendererBuilder(this, userAgent, contentUri);
       default:
@@ -251,7 +257,7 @@ private RendererBuilder getRendererBuilder() {
     }
   }
 
-  private void preparePlayer() {
+  private void preparePlayer(boolean playWhenReady) {
     if (player == null) {
       player = new DemoPlayer(getRendererBuilder());
       player.addListener(this);
@@ -275,7 +281,7 @@ private void preparePlayer() {
       updateButtonVisibilities();
     }
     player.setSurface(surfaceView.getHolder().getSurface());
-    player.setPlayWhenReady(true);
+    player.setPlayWhenReady(playWhenReady);
   }
 
   private void releasePlayer() {
@@ -338,7 +344,8 @@ public void onError(Exception e) {
   }
 
   @Override
-  public void onVideoSizeChanged(int width, int height, float pixelWidthAspectRatio) {
+  public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+      float pixelWidthAspectRatio) {
     shutterView.setVisibility(View.GONE);
     videoFrame.setAspectRatio(
         height == 0 ? 1 : (width * pixelWidthAspectRatio) / height);
@@ -431,23 +438,68 @@ public boolean onMenuItemClick(MenuItem item) {
     });
     Menu menu = popup.getMenu();
     // ID_OFFSET ensures we avoid clashing with Menu.NONE (which equals 0)
-    menu.add(MENU_GROUP_TRACKS, DemoPlayer.DISABLED_TRACK + ID_OFFSET, Menu.NONE, R.string.off);
-    if (trackCount == 1 && TextUtils.isEmpty(player.getTrackName(trackType, 0))) {
-      menu.add(MENU_GROUP_TRACKS, DemoPlayer.PRIMARY_TRACK + ID_OFFSET, Menu.NONE, R.string.on);
-    } else {
-      for (int i = 0; i < trackCount; i++) {
-        menu.add(MENU_GROUP_TRACKS, i + ID_OFFSET, Menu.NONE, player.getTrackName(trackType, i));
-      }
+    menu.add(MENU_GROUP_TRACKS, DemoPlayer.TRACK_DISABLED + ID_OFFSET, Menu.NONE, R.string.off);
+    for (int i = 0; i < trackCount; i++) {
+      menu.add(MENU_GROUP_TRACKS, i + ID_OFFSET, Menu.NONE,
+          buildTrackName(player.getTrackFormat(trackType, i)));
     }
     menu.setGroupCheckable(MENU_GROUP_TRACKS, true, true);
-    menu.findItem(player.getSelectedTrackIndex(trackType) + ID_OFFSET).setChecked(true);
+    menu.findItem(player.getSelectedTrack(trackType) + ID_OFFSET).setChecked(true);
+  }
+
+  private static String buildTrackName(MediaFormat format) {
+    if (format.adaptive) {
+      return "auto";
+    }
+    String trackName;
+    if (MimeTypes.isVideo(format.mimeType)) {
+      trackName = joinWithSeparator(joinWithSeparator(buildResolutionString(format),
+          buildBitrateString(format)), buildTrackIdString(format));
+    } else if (MimeTypes.isAudio(format.mimeType)) {
+      trackName = joinWithSeparator(joinWithSeparator(joinWithSeparator(buildLanguageString(format),
+          buildAudioPropertyString(format)), buildBitrateString(format)),
+          buildTrackIdString(format));
+    } else {
+      trackName = joinWithSeparator(joinWithSeparator(buildLanguageString(format),
+          buildBitrateString(format)), buildTrackIdString(format));
+    }
+    return trackName.length() == 0 ? "unknown" : trackName;
+  }
+
+  private static String buildResolutionString(MediaFormat format) {
+    return format.width == MediaFormat.NO_VALUE || format.height == MediaFormat.NO_VALUE
+        ? "" : format.width + "x" + format.height;
+  }
+
+  private static String buildAudioPropertyString(MediaFormat format) {
+    return format.channelCount == MediaFormat.NO_VALUE || format.sampleRate == MediaFormat.NO_VALUE
+        ? "" : format.channelCount + "ch, " + format.sampleRate + "Hz";
+  }
+
+  private static String buildLanguageString(MediaFormat format) {
+    return TextUtils.isEmpty(format.language) || "und".equals(format.language) ? ""
+        : format.language;
+  }
+
+  private static String buildBitrateString(MediaFormat format) {
+    return format.bitrate == MediaFormat.NO_VALUE ? ""
+        : String.format(Locale.US, "%.2fMbit", format.bitrate / 1000000f);
+  }
+
+  private static String joinWithSeparator(String first, String second) {
+    return first.length() == 0 ? second : (second.length() == 0 ? first : first + ", " + second);
+  }
+
+  private static String buildTrackIdString(MediaFormat format) {
+    return format.trackId == MediaFormat.NO_VALUE ? ""
+        : String.format(Locale.US, " (%d)", format.trackId);
   }
 
   private boolean onTrackItemClick(MenuItem item, int type) {
     if (player == null || item.getGroupId() != MENU_GROUP_TRACKS) {
       return false;
     }
-    player.selectTrack(type, item.getItemId() - ID_OFFSET);
+    player.setSelectedTrack(type, item.getItemId() - ID_OFFSET);
     return true;
   }
 
@@ -518,17 +570,17 @@ public void surfaceDestroyed(SurfaceHolder holder) {
   }
 
   private void configureSubtitleView() {
-    CaptionStyleCompat captionStyle;
-    float captionFontScale;
+    CaptionStyleCompat style;
+    float fontScale;
     if (Util.SDK_INT >= 19) {
-      captionStyle = getUserCaptionStyleV19();
-      captionFontScale = getUserCaptionFontScaleV19();
+      style = getUserCaptionStyleV19();
+      fontScale = getUserCaptionFontScaleV19();
     } else {
-      captionStyle = CaptionStyleCompat.DEFAULT;
-      captionFontScale = 1.0f;
+      style = CaptionStyleCompat.DEFAULT;
+      fontScale = 1.0f;
     }
-    subtitleLayout.setStyle(captionStyle);
-    subtitleLayout.setFontScale(captionFontScale);
+    subtitleLayout.setStyle(style);
+    subtitleLayout.setFractionalTextSize(SubtitleLayout.DEFAULT_TEXT_SIZE_FRACTION * fontScale);
   }
 
   @TargetApi(19)
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/player/DashRendererBuilder.java b/demo/src/main/java/com/google/android/exoplayer/demo/player/DashRendererBuilder.java
index a097db7745..219a62fd1e 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/player/DashRendererBuilder.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/player/DashRendererBuilder.java
@@ -15,28 +15,21 @@
  */
 package com.google.android.exoplayer.demo.player;
 
-import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.DefaultLoadControl;
 import com.google.android.exoplayer.LoadControl;
 import com.google.android.exoplayer.MediaCodecAudioTrackRenderer;
-import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
 import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
-import com.google.android.exoplayer.SampleSource;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.chunk.ChunkSampleSource;
 import com.google.android.exoplayer.chunk.ChunkSource;
-import com.google.android.exoplayer.chunk.Format;
-import com.google.android.exoplayer.chunk.FormatEvaluator;
 import com.google.android.exoplayer.chunk.FormatEvaluator.AdaptiveEvaluator;
-import com.google.android.exoplayer.chunk.MultiTrackChunkSource;
-import com.google.android.exoplayer.chunk.VideoFormatSelectorUtil;
 import com.google.android.exoplayer.dash.DashChunkSource;
+import com.google.android.exoplayer.dash.DefaultDashTrackSelector;
 import com.google.android.exoplayer.dash.mpd.AdaptationSet;
 import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
 import com.google.android.exoplayer.dash.mpd.MediaPresentationDescriptionParser;
 import com.google.android.exoplayer.dash.mpd.Period;
-import com.google.android.exoplayer.dash.mpd.Representation;
 import com.google.android.exoplayer.dash.mpd.UtcTimingElement;
 import com.google.android.exoplayer.dash.mpd.UtcTimingElementResolver;
 import com.google.android.exoplayer.dash.mpd.UtcTimingElementResolver.UtcTimingCallback;
@@ -45,8 +38,6 @@
 import com.google.android.exoplayer.drm.StreamingDrmSessionManager;
 import com.google.android.exoplayer.drm.UnsupportedDrmException;
 import com.google.android.exoplayer.text.TextTrackRenderer;
-import com.google.android.exoplayer.text.ttml.TtmlParser;
-import com.google.android.exoplayer.text.webvtt.WebvttParser;
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.upstream.DefaultAllocator;
 import com.google.android.exoplayer.upstream.DefaultBandwidthMeter;
@@ -61,8 +52,6 @@
 import android.util.Log;
 
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
 
 /**
  * A {@link RendererBuilder} for DASH.
@@ -73,7 +62,7 @@
 
   private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
   private static final int VIDEO_BUFFER_SEGMENTS = 200;
-  private static final int AUDIO_BUFFER_SEGMENTS = 60;
+  private static final int AUDIO_BUFFER_SEGMENTS = 54;
   private static final int TEXT_BUFFER_SEGMENTS = 2;
   private static final int LIVE_EDGE_LATENCY_MS = 30000;
 
@@ -81,39 +70,24 @@
   private static final int SECURITY_LEVEL_1 = 1;
   private static final int SECURITY_LEVEL_3 = 3;
 
-  /**
-   * Passthrough audio formats (encodings) in order of decreasing priority.
-   */
-  private static final int[] PASSTHROUGH_ENCODINGS_PRIORITY =
-      new int[] {C.ENCODING_E_AC3, C.ENCODING_AC3};
-  /**
-   * Passthrough audio codecs corresponding to the encodings in
-   * {@link #PASSTHROUGH_ENCODINGS_PRIORITY}.
-   */
-  private static final String[] PASSTHROUGH_CODECS_PRIORITY =
-      new String[] {"ec-3", "ac-3"};
-
   private final Context context;
   private final String userAgent;
   private final String url;
   private final MediaDrmCallback drmCallback;
-  private final AudioCapabilities audioCapabilities;
 
   private AsyncRendererBuilder currentAsyncBuilder;
 
   public DashRendererBuilder(Context context, String userAgent, String url,
-      MediaDrmCallback drmCallback, AudioCapabilities audioCapabilities) {
+      MediaDrmCallback drmCallback) {
     this.context = context;
     this.userAgent = userAgent;
     this.url = url;
     this.drmCallback = drmCallback;
-    this.audioCapabilities = audioCapabilities;
   }
 
   @Override
   public void buildRenderers(DemoPlayer player) {
-    currentAsyncBuilder = new AsyncRendererBuilder(context, userAgent, url, drmCallback,
-        audioCapabilities, player);
+    currentAsyncBuilder = new AsyncRendererBuilder(context, userAgent, url, drmCallback, player);
     currentAsyncBuilder.init();
   }
 
@@ -131,7 +105,6 @@ public void cancel() {
     private final Context context;
     private final String userAgent;
     private final MediaDrmCallback drmCallback;
-    private final AudioCapabilities audioCapabilities;
     private final DemoPlayer player;
     private final ManifestFetcher<MediaPresentationDescription> manifestFetcher;
     private final UriDataSource manifestDataSource;
@@ -141,11 +114,10 @@ public void cancel() {
     private long elapsedRealtimeOffset;
 
     public AsyncRendererBuilder(Context context, String userAgent, String url,
-        MediaDrmCallback drmCallback, AudioCapabilities audioCapabilities, DemoPlayer player) {
+        MediaDrmCallback drmCallback, DemoPlayer player) {
       this.context = context;
       this.userAgent = userAgent;
       this.drmCallback = drmCallback;
-      this.audioCapabilities = audioCapabilities;
       this.player = player;
       MediaPresentationDescriptionParser parser = new MediaPresentationDescriptionParser();
       manifestDataSource = new DefaultUriDataSource(context, userAgent);
@@ -206,29 +178,17 @@ public void onTimestampError(UtcTimingElement utcTiming, IOException e) {
     }
 
     private void buildRenderers() {
-      Period period = manifest.periods.get(0);
+      Period period = manifest.getPeriod(0);
       Handler mainHandler = player.getMainHandler();
       LoadControl loadControl = new DefaultLoadControl(new DefaultAllocator(BUFFER_SEGMENT_SIZE));
       DefaultBandwidthMeter bandwidthMeter = new DefaultBandwidthMeter(mainHandler, player);
 
       boolean hasContentProtection = false;
-      int videoAdaptationSetIndex = period.getAdaptationSetIndex(AdaptationSet.TYPE_VIDEO);
-      int audioAdaptationSetIndex = period.getAdaptationSetIndex(AdaptationSet.TYPE_AUDIO);
-      AdaptationSet videoAdaptationSet = null;
-      AdaptationSet audioAdaptationSet = null;
-      if (videoAdaptationSetIndex != -1) {
-        videoAdaptationSet = period.adaptationSets.get(videoAdaptationSetIndex);
-        hasContentProtection |= videoAdaptationSet.hasContentProtection();
-      }
-      if (audioAdaptationSetIndex != -1) {
-        audioAdaptationSet = period.adaptationSets.get(audioAdaptationSetIndex);
-        hasContentProtection |= audioAdaptationSet.hasContentProtection();
-      }
-
-      // Fail if we have neither video or audio.
-      if (videoAdaptationSet == null && audioAdaptationSet == null) {
-        player.onRenderersError(new IllegalStateException("No video or audio adaptation sets"));
-        return;
+      for (int i = 0; i < period.adaptationSets.size(); i++) {
+        AdaptationSet adaptationSet = period.adaptationSets.get(i);
+        if (adaptationSet.type != AdaptationSet.TYPE_UNKNOWN) {
+          hasContentProtection |= adaptationSet.hasContentProtection();
+        }
       }
 
       // Check drm support if necessary.
@@ -243,154 +203,54 @@ private void buildRenderers() {
         try {
           drmSessionManager = StreamingDrmSessionManager.newWidevineInstance(
               player.getPlaybackLooper(), drmCallback, null, player.getMainHandler(), player);
-          filterHdContent = videoAdaptationSet != null && videoAdaptationSet.hasContentProtection()
-              && getWidevineSecurityLevel(drmSessionManager) != SECURITY_LEVEL_1;
+          filterHdContent = getWidevineSecurityLevel(drmSessionManager) != SECURITY_LEVEL_1;
         } catch (UnsupportedDrmException e) {
           player.onRenderersError(e);
           return;
         }
       }
 
-      // Determine which video representations we should use for playback.
-      int[] videoRepresentationIndices = null;
-      if (videoAdaptationSet != null) {
-        try {
-          videoRepresentationIndices = VideoFormatSelectorUtil.selectVideoFormatsForDefaultDisplay(
-              context, videoAdaptationSet.representations, null, filterHdContent);
-        } catch (DecoderQueryException e) {
-          player.onRenderersError(e);
-          return;
-        }
-      }
-
       // Build the video renderer.
-      final MediaCodecVideoTrackRenderer videoRenderer;
-      if (videoRepresentationIndices == null || videoRepresentationIndices.length == 0) {
-        videoRenderer = null;
-      } else {
-        DataSource videoDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-        ChunkSource videoChunkSource = new DashChunkSource(manifestFetcher,
-            videoAdaptationSetIndex, videoRepresentationIndices, videoDataSource,
-            new AdaptiveEvaluator(bandwidthMeter), LIVE_EDGE_LATENCY_MS, elapsedRealtimeOffset,
-            mainHandler, player);
-        ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
-            VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_VIDEO);
-        videoRenderer = new MediaCodecVideoTrackRenderer(videoSampleSource, drmSessionManager, true,
-            MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, null, mainHandler, player, 50);
-      }
-
-      // Build the audio chunk sources.
-      List<ChunkSource> audioChunkSourceList = new ArrayList<>();
-      List<String> audioTrackNameList = new ArrayList<>();
-      if (audioAdaptationSet != null) {
-        DataSource audioDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-        FormatEvaluator audioEvaluator = new FormatEvaluator.FixedEvaluator();
-        List<Representation> audioRepresentations = audioAdaptationSet.representations;
-        List<String> codecs = new ArrayList<>();
-        for (int i = 0; i < audioRepresentations.size(); i++) {
-          Format format = audioRepresentations.get(i).format;
-          audioTrackNameList.add(format.id + " (" + format.numChannels + "ch, " +
-              format.audioSamplingRate + "Hz)");
-          audioChunkSourceList.add(new DashChunkSource(manifestFetcher, audioAdaptationSetIndex,
-              new int[] {i}, audioDataSource, audioEvaluator, LIVE_EDGE_LATENCY_MS,
-              elapsedRealtimeOffset, mainHandler, player));
-          codecs.add(format.codecs);
-        }
-
-        if (audioCapabilities != null) {
-          // If there are any passthrough audio encodings available, select the highest priority
-          // supported format (e.g. E-AC-3) and remove other tracks.
-          for (int i = 0; i < PASSTHROUGH_CODECS_PRIORITY.length; i++) {
-            String codec = PASSTHROUGH_CODECS_PRIORITY[i];
-            int encoding = PASSTHROUGH_ENCODINGS_PRIORITY[i];
-            if (codecs.indexOf(codec) == -1 || !audioCapabilities.supportsEncoding(encoding)) {
-              continue;
-            }
-
-            for (int j = audioRepresentations.size() - 1; j >= 0; j--) {
-              if (!audioRepresentations.get(j).format.codecs.equals(codec)) {
-                audioTrackNameList.remove(j);
-                audioChunkSourceList.remove(j);
-              }
-            }
-            break;
-          }
-        }
-      }
+      DataSource videoDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
+      ChunkSource videoChunkSource = new DashChunkSource(manifestFetcher,
+          DefaultDashTrackSelector.newVideoInstance(context, true, filterHdContent),
+          videoDataSource, new AdaptiveEvaluator(bandwidthMeter), LIVE_EDGE_LATENCY_MS,
+          elapsedRealtimeOffset, mainHandler, player);
+      ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
+          VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_VIDEO);
+      TrackRenderer videoRenderer = new MediaCodecVideoTrackRenderer(videoSampleSource,
+          drmSessionManager, true, MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, null,
+          mainHandler, player, 50);
 
       // Build the audio renderer.
-      final String[] audioTrackNames;
-      final MultiTrackChunkSource audioChunkSource;
-      final TrackRenderer audioRenderer;
-      if (audioChunkSourceList.isEmpty()) {
-        audioTrackNames = null;
-        audioChunkSource = null;
-        audioRenderer = null;
-      } else {
-        audioTrackNames = new String[audioTrackNameList.size()];
-        audioTrackNameList.toArray(audioTrackNames);
-        audioChunkSource = new MultiTrackChunkSource(audioChunkSourceList);
-        SampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
-            AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_AUDIO);
-        audioRenderer = new MediaCodecAudioTrackRenderer(audioSampleSource, drmSessionManager, true,
-            mainHandler, player);
-      }
-
-      // Build the text chunk sources.
+      DataSource audioDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
+      ChunkSource audioChunkSource = new DashChunkSource(manifestFetcher,
+          DefaultDashTrackSelector.newAudioInstance(), audioDataSource, null, LIVE_EDGE_LATENCY_MS,
+          elapsedRealtimeOffset, mainHandler, player);
+      ChunkSampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
+          AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_AUDIO);
+      TrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(audioSampleSource,
+          drmSessionManager, true, mainHandler, player, AudioCapabilities.getCapabilities(context));
+
+      // Build the text renderer.
       DataSource textDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-      FormatEvaluator textEvaluator = new FormatEvaluator.FixedEvaluator();
-      List<ChunkSource> textChunkSourceList = new ArrayList<>();
-      List<String> textTrackNameList = new ArrayList<>();
-      for (int i = 0; i < period.adaptationSets.size(); i++) {
-        AdaptationSet adaptationSet = period.adaptationSets.get(i);
-        if (adaptationSet.type == AdaptationSet.TYPE_TEXT) {
-          List<Representation> representations = adaptationSet.representations;
-          for (int j = 0; j < representations.size(); j++) {
-            Representation representation = representations.get(j);
-            textTrackNameList.add(representation.format.id);
-            textChunkSourceList.add(new DashChunkSource(manifestFetcher, i, new int[] {j},
-                textDataSource, textEvaluator, LIVE_EDGE_LATENCY_MS, elapsedRealtimeOffset,
-                mainHandler, player));
-          }
-        }
-      }
-
-      // Build the text renderers
-      final String[] textTrackNames;
-      final MultiTrackChunkSource textChunkSource;
-      final TrackRenderer textRenderer;
-      if (textChunkSourceList.isEmpty()) {
-        textTrackNames = null;
-        textChunkSource = null;
-        textRenderer = null;
-      } else {
-        textTrackNames = new String[textTrackNameList.size()];
-        textTrackNameList.toArray(textTrackNames);
-        textChunkSource = new MultiTrackChunkSource(textChunkSourceList);
-        SampleSource textSampleSource = new ChunkSampleSource(textChunkSource, loadControl,
-            TEXT_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_TEXT);
-        textRenderer = new TextTrackRenderer(textSampleSource, player, mainHandler.getLooper(),
-            new TtmlParser(), new WebvttParser());
-      }
+      ChunkSource textChunkSource = new DashChunkSource(manifestFetcher,
+          DefaultDashTrackSelector.newTextInstance(), textDataSource, null, LIVE_EDGE_LATENCY_MS,
+          elapsedRealtimeOffset, mainHandler, player);
+      ChunkSampleSource textSampleSource = new ChunkSampleSource(textChunkSource, loadControl,
+          TEXT_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_TEXT);
+      TrackRenderer textRenderer = new TextTrackRenderer(textSampleSource, player,
+          mainHandler.getLooper());
 
       // Invoke the callback.
-      String[][] trackNames = new String[DemoPlayer.RENDERER_COUNT][];
-      trackNames[DemoPlayer.TYPE_AUDIO] = audioTrackNames;
-      trackNames[DemoPlayer.TYPE_TEXT] = textTrackNames;
-
-      MultiTrackChunkSource[] multiTrackChunkSources =
-          new MultiTrackChunkSource[DemoPlayer.RENDERER_COUNT];
-      multiTrackChunkSources[DemoPlayer.TYPE_AUDIO] = audioChunkSource;
-      multiTrackChunkSources[DemoPlayer.TYPE_TEXT] = textChunkSource;
-
       TrackRenderer[] renderers = new TrackRenderer[DemoPlayer.RENDERER_COUNT];
       renderers[DemoPlayer.TYPE_VIDEO] = videoRenderer;
       renderers[DemoPlayer.TYPE_AUDIO] = audioRenderer;
       renderers[DemoPlayer.TYPE_TEXT] = textRenderer;
-      player.onRenderers(trackNames, multiTrackChunkSources, renderers, bandwidthMeter);
+      player.onRenderers(renderers, bandwidthMeter);
     }
 
     private static int getWidevineSecurityLevel(StreamingDrmSessionManager sessionManager) {
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/player/DemoPlayer.java b/demo/src/main/java/com/google/android/exoplayer/demo/player/DemoPlayer.java
index d8366f9207..982ef6c790 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/player/DemoPlayer.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/player/DemoPlayer.java
@@ -23,12 +23,12 @@
 import com.google.android.exoplayer.MediaCodecTrackRenderer;
 import com.google.android.exoplayer.MediaCodecTrackRenderer.DecoderInitializationException;
 import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.TimeRange;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.audio.AudioTrack;
 import com.google.android.exoplayer.chunk.ChunkSampleSource;
 import com.google.android.exoplayer.chunk.Format;
-import com.google.android.exoplayer.chunk.MultiTrackChunkSource;
 import com.google.android.exoplayer.dash.DashChunkSource;
 import com.google.android.exoplayer.drm.StreamingDrmSessionManager;
 import com.google.android.exoplayer.hls.HlsSampleSource;
@@ -89,7 +89,8 @@
   public interface Listener {
     void onStateChanged(boolean playWhenReady, int playbackState);
     void onError(Exception e);
-    void onVideoSizeChanged(int width, int height, float pixelWidthHeightRatio);
+    void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+        float pixelWidthHeightRatio);
   }
 
   /**
@@ -114,17 +115,17 @@
    * A listener for debugging information.
    */
   public interface InfoListener {
-    void onVideoFormatEnabled(Format format, int trigger, int mediaTimeMs);
-    void onAudioFormatEnabled(Format format, int trigger, int mediaTimeMs);
+    void onVideoFormatEnabled(Format format, int trigger, long mediaTimeMs);
+    void onAudioFormatEnabled(Format format, int trigger, long mediaTimeMs);
     void onDroppedFrames(int count, long elapsed);
     void onBandwidthSample(int elapsedMs, long bytes, long bitrateEstimate);
     void onLoadStarted(int sourceId, long length, int type, int trigger, Format format,
-        int mediaStartTimeMs, int mediaEndTimeMs);
+        long mediaStartTimeMs, long mediaEndTimeMs);
     void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Format format,
-        int mediaStartTimeMs, int mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs);
+        long mediaStartTimeMs, long mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs);
     void onDecoderInitialized(String decoderName, long elapsedRealtimeMs,
         long initializationDurationMs);
-    void onSeekRangeChanged(TimeRange seekRange);
+    void onAvailableRangeChanged(TimeRange availableRange);
   }
 
   /**
@@ -147,9 +148,8 @@ void onDecoderInitialized(String decoderName, long elapsedRealtimeMs,
   public static final int STATE_BUFFERING = ExoPlayer.STATE_BUFFERING;
   public static final int STATE_READY = ExoPlayer.STATE_READY;
   public static final int STATE_ENDED = ExoPlayer.STATE_ENDED;
-
-  public static final int DISABLED_TRACK = -1;
-  public static final int PRIMARY_TRACK = 0;
+  public static final int TRACK_DISABLED = ExoPlayer.TRACK_DISABLED;
+  public static final int TRACK_DEFAULT = ExoPlayer.TRACK_DEFAULT;
 
   public static final int RENDERER_COUNT = 4;
   public static final int TYPE_VIDEO = 0;
@@ -178,9 +178,6 @@ void onDecoderInitialized(String decoderName, long elapsedRealtimeMs,
   private int videoTrackToRestore;
 
   private BandwidthMeter bandwidthMeter;
-  private MultiTrackChunkSource[] multiTrackSources;
-  private String[][] trackNames;
-  private int[] selectedTracks;
   private boolean backgrounded;
 
   private CaptionListener captionListener;
@@ -197,9 +194,8 @@ public DemoPlayer(RendererBuilder rendererBuilder) {
     listeners = new CopyOnWriteArrayList<>();
     lastReportedPlaybackState = STATE_IDLE;
     rendererBuildingState = RENDERER_BUILDING_STATE_IDLE;
-    selectedTracks = new int[RENDERER_COUNT];
     // Disable text initially.
-    selectedTracks[TYPE_TEXT] = DISABLED_TRACK;
+    player.setSelectedTrack(TYPE_TEXT, TRACK_DISABLED);
   }
 
   public PlayerControl getPlayerControl() {
@@ -245,39 +241,39 @@ public void blockingClearSurface() {
   }
 
   public int getTrackCount(int type) {
-    return !player.getRendererHasMedia(type) ? 0 : trackNames[type].length;
+    return player.getTrackCount(type);
   }
 
-  public String getTrackName(int type, int index) {
-    return trackNames[type][index];
+  public MediaFormat getTrackFormat(int type, int index) {
+    return player.getTrackFormat(type, index);
   }
 
-  public int getSelectedTrackIndex(int type) {
-    return selectedTracks[type];
+  public int getSelectedTrack(int type) {
+    return player.getSelectedTrack(type);
   }
 
-  public void selectTrack(int type, int index) {
-    if (selectedTracks[type] == index) {
-      return;
-    }
-    selectedTracks[type] = index;
-    pushTrackSelection(type, true);
-    if (type == TYPE_TEXT && index == DISABLED_TRACK && captionListener != null) {
+  public void setSelectedTrack(int type, int index) {
+    player.setSelectedTrack(type, index);
+    if (type == TYPE_TEXT && index < 0 && captionListener != null) {
       captionListener.onCues(Collections.<Cue>emptyList());
     }
   }
 
+  public boolean getBackgrounded() {
+    return backgrounded;
+  }
+
   public void setBackgrounded(boolean backgrounded) {
     if (this.backgrounded == backgrounded) {
       return;
     }
     this.backgrounded = backgrounded;
     if (backgrounded) {
-      videoTrackToRestore = getSelectedTrackIndex(TYPE_VIDEO);
-      selectTrack(TYPE_VIDEO, DISABLED_TRACK);
+      videoTrackToRestore = getSelectedTrack(TYPE_VIDEO);
+      setSelectedTrack(TYPE_VIDEO, TRACK_DISABLED);
       blockingClearSurface();
     } else {
-      selectTrack(TYPE_VIDEO, videoTrackToRestore);
+      setSelectedTrack(TYPE_VIDEO, videoTrackToRestore);
     }
   }
 
@@ -288,7 +284,6 @@ public void prepare() {
     rendererBuilder.cancel();
     videoFormat = null;
     videoRenderer = null;
-    multiTrackSources = null;
     rendererBuildingState = RENDERER_BUILDING_STATE_BUILDING;
     maybeReportPlayerState();
     rendererBuilder.buildRenderers(this);
@@ -297,51 +292,25 @@ public void prepare() {
   /**
    * Invoked with the results from a {@link RendererBuilder}.
    *
-   * @param trackNames The names of the available tracks, indexed by {@link DemoPlayer} TYPE_*
-   *     constants. May be null if the track names are unknown. An individual element may be null
-   *     if the track names are unknown for the corresponding type.
-   * @param multiTrackSources Sources capable of switching between multiple available tracks,
-   *     indexed by {@link DemoPlayer} TYPE_* constants. May be null if there are no types with
-   *     multiple tracks. An individual element may be null if it does not have multiple tracks.
    * @param renderers Renderers indexed by {@link DemoPlayer} TYPE_* constants. An individual
    *     element may be null if there do not exist tracks of the corresponding type.
    * @param bandwidthMeter Provides an estimate of the currently available bandwidth. May be null.
    */
-  /* package */ void onRenderers(String[][] trackNames,
-      MultiTrackChunkSource[] multiTrackSources, TrackRenderer[] renderers,
-      BandwidthMeter bandwidthMeter) {
-    // Normalize the results.
-    if (trackNames == null) {
-      trackNames = new String[RENDERER_COUNT][];
-    }
-    if (multiTrackSources == null) {
-      multiTrackSources = new MultiTrackChunkSource[RENDERER_COUNT];
-    }
-    for (int rendererIndex = 0; rendererIndex < RENDERER_COUNT; rendererIndex++) {
-      if (renderers[rendererIndex] == null) {
+  /* package */ void onRenderers(TrackRenderer[] renderers, BandwidthMeter bandwidthMeter) {
+    for (int i = 0; i < RENDERER_COUNT; i++) {
+      if (renderers[i] == null) {
         // Convert a null renderer to a dummy renderer.
-        renderers[rendererIndex] = new DummyTrackRenderer();
-      }
-      if (trackNames[rendererIndex] == null) {
-        // Convert a null trackNames to an array of suitable length.
-        int trackCount = multiTrackSources[rendererIndex] != null
-            ? multiTrackSources[rendererIndex].getTrackCount() : 1;
-        trackNames[rendererIndex] = new String[trackCount];
+        renderers[i] = new DummyTrackRenderer();
       }
     }
     // Complete preparation.
-    this.trackNames = trackNames;
     this.videoRenderer = renderers[TYPE_VIDEO];
     this.codecCounters = videoRenderer instanceof MediaCodecTrackRenderer
         ? ((MediaCodecTrackRenderer) videoRenderer).codecCounters
         : renderers[TYPE_AUDIO] instanceof MediaCodecTrackRenderer
         ? ((MediaCodecTrackRenderer) renderers[TYPE_AUDIO]).codecCounters : null;
-    this.multiTrackSources = multiTrackSources;
     this.bandwidthMeter = bandwidthMeter;
     pushSurface(false);
-    pushTrackSelection(TYPE_VIDEO, true);
-    pushTrackSelection(TYPE_AUDIO, true);
-    pushTrackSelection(TYPE_TEXT, true);
     player.prepare(renderers);
     rendererBuildingState = RENDERER_BUILDING_STATE_BUILT;
   }
@@ -377,7 +346,6 @@ public void release() {
     player.release();
   }
 
-
   public int getPlaybackState() {
     if (rendererBuildingState == RENDERER_BUILDING_STATE_BUILDING) {
       return STATE_PREPARING;
@@ -445,9 +413,10 @@ public void onPlayerError(ExoPlaybackException exception) {
   }
 
   @Override
-  public void onVideoSizeChanged(int width, int height, float pixelWidthHeightRatio) {
+  public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+      float pixelWidthHeightRatio) {
     for (Listener listener : listeners) {
-      listener.onVideoSizeChanged(width, height, pixelWidthHeightRatio);
+      listener.onVideoSizeChanged(width, height, unappliedRotationDegrees, pixelWidthHeightRatio);
     }
   }
 
@@ -466,7 +435,8 @@ public void onBandwidthSample(int elapsedMs, long bytes, long bitrateEstimate) {
   }
 
   @Override
-  public void onDownstreamFormatChanged(int sourceId, Format format, int trigger, int mediaTimeMs) {
+  public void onDownstreamFormatChanged(int sourceId, Format format, int trigger,
+      long mediaTimeMs) {
     if (infoListener == null) {
       return;
     }
@@ -478,6 +448,11 @@ public void onDownstreamFormatChanged(int sourceId, Format format, int trigger,
     }
   }
 
+  @Override
+  public void onDrmKeysLoaded() {
+    // Do nothing.
+  }
+
   @Override
   public void onDrmSessionManagerError(Exception e) {
     if (internalErrorListener != null) {
@@ -530,22 +505,22 @@ public void onLoadError(int sourceId, IOException e) {
 
   @Override
   public void onCues(List<Cue> cues) {
-    if (captionListener != null && selectedTracks[TYPE_TEXT] != DISABLED_TRACK) {
+    if (captionListener != null && getSelectedTrack(TYPE_TEXT) != TRACK_DISABLED) {
       captionListener.onCues(cues);
     }
   }
 
   @Override
   public void onMetadata(Map<String, Object> metadata) {
-    if (id3MetadataListener != null && selectedTracks[TYPE_METADATA] != DISABLED_TRACK) {
+    if (id3MetadataListener != null && getSelectedTrack(TYPE_METADATA) != TRACK_DISABLED) {
       id3MetadataListener.onId3Metadata(metadata);
     }
   }
 
   @Override
-  public void onSeekRangeChanged(TimeRange seekRange) {
+  public void onAvailableRangeChanged(TimeRange availableRange) {
     if (infoListener != null) {
-      infoListener.onSeekRangeChanged(seekRange);
+      infoListener.onAvailableRangeChanged(availableRange);
     }
   }
 
@@ -561,7 +536,7 @@ public void onDrawnToSurface(Surface surface) {
 
   @Override
   public void onLoadStarted(int sourceId, long length, int type, int trigger, Format format,
-      int mediaStartTimeMs, int mediaEndTimeMs) {
+      long mediaStartTimeMs, long mediaEndTimeMs) {
     if (infoListener != null) {
       infoListener.onLoadStarted(sourceId, length, type, trigger, format, mediaStartTimeMs,
           mediaEndTimeMs);
@@ -570,7 +545,7 @@ public void onLoadStarted(int sourceId, long length, int type, int trigger, Form
 
   @Override
   public void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Format format,
-      int mediaStartTimeMs, int mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs) {
+      long mediaStartTimeMs, long mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs) {
     if (infoListener != null) {
       infoListener.onLoadCompleted(sourceId, bytesLoaded, type, trigger, format, mediaStartTimeMs,
           mediaEndTimeMs, elapsedRealtimeMs, loadDurationMs);
@@ -583,7 +558,7 @@ public void onLoadCanceled(int sourceId, long bytesLoaded) {
   }
 
   @Override
-  public void onUpstreamDiscarded(int sourceId, int mediaStartTimeMs, int mediaEndTimeMs) {
+  public void onUpstreamDiscarded(int sourceId, long mediaStartTimeMs, long mediaEndTimeMs) {
     // Do nothing.
   }
 
@@ -613,25 +588,4 @@ private void pushSurface(boolean blockForSurfacePush) {
     }
   }
 
-  private void pushTrackSelection(int type, boolean allowRendererEnable) {
-    if (multiTrackSources == null) {
-      return;
-    }
-
-    int trackIndex = selectedTracks[type];
-    if (trackIndex == DISABLED_TRACK) {
-      player.setRendererEnabled(type, false);
-    } else if (multiTrackSources[type] == null) {
-      player.setRendererEnabled(type, allowRendererEnable);
-    } else {
-      boolean playWhenReady = player.getPlayWhenReady();
-      player.setPlayWhenReady(false);
-      player.setRendererEnabled(type, false);
-      player.sendMessage(multiTrackSources[type], MultiTrackChunkSource.MSG_SELECT_TRACK,
-          trackIndex);
-      player.setRendererEnabled(type, allowRendererEnable);
-      player.setPlayWhenReady(playWhenReady);
-    }
-  }
-
 }
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/player/ExtractorRendererBuilder.java b/demo/src/main/java/com/google/android/exoplayer/demo/player/ExtractorRendererBuilder.java
index 2dd56fdc23..9a9718f883 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/player/ExtractorRendererBuilder.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/player/ExtractorRendererBuilder.java
@@ -18,6 +18,7 @@
 import com.google.android.exoplayer.MediaCodecAudioTrackRenderer;
 import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
+import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.demo.player.DemoPlayer.RendererBuilder;
 import com.google.android.exoplayer.extractor.Extractor;
 import com.google.android.exoplayer.extractor.ExtractorSampleSource;
@@ -38,7 +39,7 @@
 public class ExtractorRendererBuilder implements RendererBuilder {
 
   private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
-  private static final int BUFFER_SEGMENT_COUNT = 160;
+  private static final int BUFFER_SEGMENT_COUNT = 256;
 
   private final Context context;
   private final String userAgent;
@@ -64,7 +65,7 @@ public void buildRenderers(DemoPlayer player) {
         null, true, MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, null, player.getMainHandler(),
         player, 50);
     MediaCodecAudioTrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(sampleSource,
-        null, true, player.getMainHandler(), player);
+        null, true, player.getMainHandler(), player, AudioCapabilities.getCapabilities(context));
     TrackRenderer textRenderer = new TextTrackRenderer(sampleSource, player,
         player.getMainHandler().getLooper());
 
@@ -73,7 +74,7 @@ public void buildRenderers(DemoPlayer player) {
     renderers[DemoPlayer.TYPE_VIDEO] = videoRenderer;
     renderers[DemoPlayer.TYPE_AUDIO] = audioRenderer;
     renderers[DemoPlayer.TYPE_TEXT] = textRenderer;
-    player.onRenderers(null, null, renderers, bandwidthMeter);
+    player.onRenderers(renderers, bandwidthMeter);
   }
 
   @Override
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/player/HlsRendererBuilder.java b/demo/src/main/java/com/google/android/exoplayer/demo/player/HlsRendererBuilder.java
index a4703e9f01..16441c2277 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/player/HlsRendererBuilder.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/player/HlsRendererBuilder.java
@@ -51,28 +51,24 @@
  */
 public class HlsRendererBuilder implements RendererBuilder {
 
-  private static final int BUFFER_SEGMENT_SIZE = 256 * 1024;
-  private static final int BUFFER_SEGMENTS = 64;
+  private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
+  private static final int BUFFER_SEGMENTS = 256;
 
   private final Context context;
   private final String userAgent;
   private final String url;
-  private final AudioCapabilities audioCapabilities;
 
   private AsyncRendererBuilder currentAsyncBuilder;
 
-  public HlsRendererBuilder(Context context, String userAgent, String url,
-      AudioCapabilities audioCapabilities) {
+  public HlsRendererBuilder(Context context, String userAgent, String url) {
     this.context = context;
     this.userAgent = userAgent;
     this.url = url;
-    this.audioCapabilities = audioCapabilities;
   }
 
   @Override
   public void buildRenderers(DemoPlayer player) {
-    currentAsyncBuilder = new AsyncRendererBuilder(context, userAgent, url, audioCapabilities,
-        player);
+    currentAsyncBuilder = new AsyncRendererBuilder(context, userAgent, url, player);
     currentAsyncBuilder.init();
   }
 
@@ -89,18 +85,15 @@ public void cancel() {
     private final Context context;
     private final String userAgent;
     private final String url;
-    private final AudioCapabilities audioCapabilities;
     private final DemoPlayer player;
     private final ManifestFetcher<HlsPlaylist> playlistFetcher;
 
     private boolean canceled;
 
-    public AsyncRendererBuilder(Context context, String userAgent, String url,
-        AudioCapabilities audioCapabilities, DemoPlayer player) {
+    public AsyncRendererBuilder(Context context, String userAgent, String url, DemoPlayer player) {
       this.context = context;
       this.userAgent = userAgent;
       this.url = url;
-      this.audioCapabilities = audioCapabilities;
       this.player = player;
       HlsPlaylistParser parser = new HlsPlaylistParser();
       playlistFetcher = new ManifestFetcher<>(url, new DefaultUriDataSource(context, userAgent),
@@ -152,12 +145,13 @@ public void onSingleManifest(HlsPlaylist manifest) {
 
       DataSource dataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
       HlsChunkSource chunkSource = new HlsChunkSource(dataSource, url, manifest, bandwidthMeter,
-          variantIndices, HlsChunkSource.ADAPTIVE_MODE_SPLICE, audioCapabilities);
+          variantIndices, HlsChunkSource.ADAPTIVE_MODE_SPLICE);
       HlsSampleSource sampleSource = new HlsSampleSource(chunkSource, loadControl,
           BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player, DemoPlayer.TYPE_VIDEO);
       MediaCodecVideoTrackRenderer videoRenderer = new MediaCodecVideoTrackRenderer(sampleSource,
           MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, mainHandler, player, 50);
-      MediaCodecAudioTrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(sampleSource);
+      MediaCodecAudioTrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(sampleSource,
+          null, true, player.getMainHandler(), player, AudioCapabilities.getCapabilities(context));
       MetadataTrackRenderer<Map<String, Object>> id3Renderer = new MetadataTrackRenderer<>(
           sampleSource, new Id3Parser(), player, mainHandler.getLooper());
       Eia608TrackRenderer closedCaptionRenderer = new Eia608TrackRenderer(sampleSource, player,
@@ -168,7 +162,7 @@ public void onSingleManifest(HlsPlaylist manifest) {
       renderers[DemoPlayer.TYPE_AUDIO] = audioRenderer;
       renderers[DemoPlayer.TYPE_METADATA] = id3Renderer;
       renderers[DemoPlayer.TYPE_TEXT] = closedCaptionRenderer;
-      player.onRenderers(null, null, renderers, bandwidthMeter);
+      player.onRenderers(renderers, bandwidthMeter);
     }
 
   }
diff --git a/demo/src/main/java/com/google/android/exoplayer/demo/player/SmoothStreamingRendererBuilder.java b/demo/src/main/java/com/google/android/exoplayer/demo/player/SmoothStreamingRendererBuilder.java
index 4e80aa4bfe..c8f20b4e2f 100644
--- a/demo/src/main/java/com/google/android/exoplayer/demo/player/SmoothStreamingRendererBuilder.java
+++ b/demo/src/main/java/com/google/android/exoplayer/demo/player/SmoothStreamingRendererBuilder.java
@@ -18,26 +18,23 @@
 import com.google.android.exoplayer.DefaultLoadControl;
 import com.google.android.exoplayer.LoadControl;
 import com.google.android.exoplayer.MediaCodecAudioTrackRenderer;
-import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
 import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
+import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.chunk.ChunkSampleSource;
 import com.google.android.exoplayer.chunk.ChunkSource;
-import com.google.android.exoplayer.chunk.FormatEvaluator;
 import com.google.android.exoplayer.chunk.FormatEvaluator.AdaptiveEvaluator;
-import com.google.android.exoplayer.chunk.MultiTrackChunkSource;
-import com.google.android.exoplayer.chunk.VideoFormatSelectorUtil;
 import com.google.android.exoplayer.demo.player.DemoPlayer.RendererBuilder;
 import com.google.android.exoplayer.drm.DrmSessionManager;
 import com.google.android.exoplayer.drm.MediaDrmCallback;
 import com.google.android.exoplayer.drm.StreamingDrmSessionManager;
 import com.google.android.exoplayer.drm.UnsupportedDrmException;
+import com.google.android.exoplayer.smoothstreaming.DefaultSmoothStreamingTrackSelector;
 import com.google.android.exoplayer.smoothstreaming.SmoothStreamingChunkSource;
 import com.google.android.exoplayer.smoothstreaming.SmoothStreamingManifest;
 import com.google.android.exoplayer.smoothstreaming.SmoothStreamingManifest.StreamElement;
 import com.google.android.exoplayer.smoothstreaming.SmoothStreamingManifestParser;
 import com.google.android.exoplayer.text.TextTrackRenderer;
-import com.google.android.exoplayer.text.ttml.TtmlParser;
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.upstream.DefaultAllocator;
 import com.google.android.exoplayer.upstream.DefaultBandwidthMeter;
@@ -51,7 +48,6 @@
 import android.os.Handler;
 
 import java.io.IOException;
-import java.util.Arrays;
 
 /**
  * A {@link RendererBuilder} for SmoothStreaming.
@@ -60,7 +56,7 @@
 
   private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
   private static final int VIDEO_BUFFER_SEGMENTS = 200;
-  private static final int AUDIO_BUFFER_SEGMENTS = 60;
+  private static final int AUDIO_BUFFER_SEGMENTS = 54;
   private static final int TEXT_BUFFER_SEGMENTS = 2;
   private static final int LIVE_EDGE_LATENCY_MS = 30000;
 
@@ -159,126 +155,46 @@ public void onSingleManifest(SmoothStreamingManifest manifest) {
         }
       }
 
-      // Obtain stream elements for playback.
-      int audioStreamElementCount = 0;
-      int textStreamElementCount = 0;
-      int videoStreamElementIndex = -1;
-      for (int i = 0; i < manifest.streamElements.length; i++) {
-        if (manifest.streamElements[i].type == StreamElement.TYPE_AUDIO) {
-          audioStreamElementCount++;
-        } else if (manifest.streamElements[i].type == StreamElement.TYPE_TEXT) {
-          textStreamElementCount++;
-        } else if (videoStreamElementIndex == -1
-            && manifest.streamElements[i].type == StreamElement.TYPE_VIDEO) {
-          videoStreamElementIndex = i;
-        }
-      }
-
-      // Determine which video tracks we should use for playback.
-      int[] videoTrackIndices = null;
-      if (videoStreamElementIndex != -1) {
-        try {
-          videoTrackIndices = VideoFormatSelectorUtil.selectVideoFormatsForDefaultDisplay(context,
-              Arrays.asList(manifest.streamElements[videoStreamElementIndex].tracks), null, false);
-        } catch (DecoderQueryException e) {
-          player.onRenderersError(e);
-          return;
-        }
-      }
-
       // Build the video renderer.
-      final MediaCodecVideoTrackRenderer videoRenderer;
-      if (videoTrackIndices == null || videoTrackIndices.length == 0) {
-        videoRenderer = null;
-      } else {
-        DataSource videoDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-        ChunkSource videoChunkSource = new SmoothStreamingChunkSource(manifestFetcher,
-            videoStreamElementIndex, videoTrackIndices, videoDataSource,
-            new AdaptiveEvaluator(bandwidthMeter), LIVE_EDGE_LATENCY_MS);
-        ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
-            VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_VIDEO);
-        videoRenderer = new MediaCodecVideoTrackRenderer(videoSampleSource, drmSessionManager, true,
-            MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, null, mainHandler, player, 50);
-      }
+      DataSource videoDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
+      ChunkSource videoChunkSource = new SmoothStreamingChunkSource(manifestFetcher,
+          new DefaultSmoothStreamingTrackSelector(context, StreamElement.TYPE_VIDEO),
+          videoDataSource, new AdaptiveEvaluator(bandwidthMeter), LIVE_EDGE_LATENCY_MS);
+      ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
+          VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_VIDEO);
+      TrackRenderer videoRenderer = new MediaCodecVideoTrackRenderer(videoSampleSource,
+          drmSessionManager, true, MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 5000, null,
+          mainHandler, player, 50);
 
       // Build the audio renderer.
-      final String[] audioTrackNames;
-      final MultiTrackChunkSource audioChunkSource;
-      final MediaCodecAudioTrackRenderer audioRenderer;
-      if (audioStreamElementCount == 0) {
-        audioTrackNames = null;
-        audioChunkSource = null;
-        audioRenderer = null;
-      } else {
-        audioTrackNames = new String[audioStreamElementCount];
-        ChunkSource[] audioChunkSources = new ChunkSource[audioStreamElementCount];
-        DataSource audioDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-        FormatEvaluator audioFormatEvaluator = new FormatEvaluator.FixedEvaluator();
-        audioStreamElementCount = 0;
-        for (int i = 0; i < manifest.streamElements.length; i++) {
-          if (manifest.streamElements[i].type == StreamElement.TYPE_AUDIO) {
-            audioTrackNames[audioStreamElementCount] = manifest.streamElements[i].name;
-            audioChunkSources[audioStreamElementCount] = new SmoothStreamingChunkSource(
-                manifestFetcher, i, new int[] {0}, audioDataSource, audioFormatEvaluator,
-                LIVE_EDGE_LATENCY_MS);
-            audioStreamElementCount++;
-          }
-        }
-        audioChunkSource = new MultiTrackChunkSource(audioChunkSources);
-        ChunkSampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
-            AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_AUDIO);
-        audioRenderer = new MediaCodecAudioTrackRenderer(audioSampleSource, drmSessionManager, true,
-            mainHandler, player);
-      }
+      DataSource audioDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
+      ChunkSource audioChunkSource = new SmoothStreamingChunkSource(manifestFetcher,
+          new DefaultSmoothStreamingTrackSelector(context, StreamElement.TYPE_AUDIO),
+          audioDataSource, null, LIVE_EDGE_LATENCY_MS);
+      ChunkSampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
+          AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_AUDIO);
+      TrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(audioSampleSource,
+          drmSessionManager, true, mainHandler, player, AudioCapabilities.getCapabilities(context));
 
       // Build the text renderer.
-      final String[] textTrackNames;
-      final MultiTrackChunkSource textChunkSource;
-      final TrackRenderer textRenderer;
-      if (textStreamElementCount == 0) {
-        textTrackNames = null;
-        textChunkSource = null;
-        textRenderer = null;
-      } else {
-        textTrackNames = new String[textStreamElementCount];
-        ChunkSource[] textChunkSources = new ChunkSource[textStreamElementCount];
-        DataSource ttmlDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
-        FormatEvaluator ttmlFormatEvaluator = new FormatEvaluator.FixedEvaluator();
-        textStreamElementCount = 0;
-        for (int i = 0; i < manifest.streamElements.length; i++) {
-          if (manifest.streamElements[i].type == StreamElement.TYPE_TEXT) {
-            textTrackNames[textStreamElementCount] = manifest.streamElements[i].language;
-            textChunkSources[textStreamElementCount] = new SmoothStreamingChunkSource(
-                manifestFetcher, i, new int[] {0}, ttmlDataSource, ttmlFormatEvaluator,
-                LIVE_EDGE_LATENCY_MS);
-            textStreamElementCount++;
-          }
-        }
-        textChunkSource = new MultiTrackChunkSource(textChunkSources);
-        ChunkSampleSource ttmlSampleSource = new ChunkSampleSource(textChunkSource, loadControl,
-            TEXT_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
-            DemoPlayer.TYPE_TEXT);
-        textRenderer = new TextTrackRenderer(ttmlSampleSource, player, mainHandler.getLooper(),
-            new TtmlParser());
-      }
+      DataSource textDataSource = new DefaultUriDataSource(context, bandwidthMeter, userAgent);
+      ChunkSource textChunkSource = new SmoothStreamingChunkSource(manifestFetcher,
+          new DefaultSmoothStreamingTrackSelector(context, StreamElement.TYPE_TEXT),
+          textDataSource, null, LIVE_EDGE_LATENCY_MS);
+      ChunkSampleSource textSampleSource = new ChunkSampleSource(textChunkSource, loadControl,
+          TEXT_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, mainHandler, player,
+          DemoPlayer.TYPE_TEXT);
+      TrackRenderer textRenderer = new TextTrackRenderer(textSampleSource, player,
+          mainHandler.getLooper());
 
       // Invoke the callback.
-      String[][] trackNames = new String[DemoPlayer.RENDERER_COUNT][];
-      trackNames[DemoPlayer.TYPE_AUDIO] = audioTrackNames;
-      trackNames[DemoPlayer.TYPE_TEXT] = textTrackNames;
-
-      MultiTrackChunkSource[] multiTrackChunkSources =
-          new MultiTrackChunkSource[DemoPlayer.RENDERER_COUNT];
-      multiTrackChunkSources[DemoPlayer.TYPE_AUDIO] = audioChunkSource;
-      multiTrackChunkSources[DemoPlayer.TYPE_TEXT] = textChunkSource;
-
       TrackRenderer[] renderers = new TrackRenderer[DemoPlayer.RENDERER_COUNT];
       renderers[DemoPlayer.TYPE_VIDEO] = videoRenderer;
       renderers[DemoPlayer.TYPE_AUDIO] = audioRenderer;
       renderers[DemoPlayer.TYPE_TEXT] = textRenderer;
-      player.onRenderers(trackNames, multiTrackChunkSources, renderers, bandwidthMeter);
+      player.onRenderers(renderers, bandwidthMeter);
     }
 
   }
diff --git a/demo/src/main/res/layout/player_activity.xml b/demo/src/main/res/layout/player_activity.xml
index 9b8925cce6..ae0aa5f1d2 100644
--- a/demo/src/main/res/layout/player_activity.xml
+++ b/demo/src/main/res/layout/player_activity.xml
@@ -31,15 +31,15 @@
         android:layout_height="match_parent"
         android:layout_gravity="center"/>
 
-    <com.google.android.exoplayer.text.SubtitleLayout android:id="@+id/subtitles"
-        android:layout_width="match_parent"
-        android:layout_height="match_parent"/>
-
     <View android:id="@+id/shutter"
         android:layout_width="match_parent"
         android:layout_height="match_parent"
         android:background="@android:color/black"/>
 
+    <com.google.android.exoplayer.text.SubtitleLayout android:id="@+id/subtitles"
+        android:layout_width="match_parent"
+        android:layout_height="match_parent"/>
+
   </com.google.android.exoplayer.AspectRatioFrameLayout>
 
   <LinearLayout
diff --git a/demo/src/main/res/values/strings.xml b/demo/src/main/res/values/strings.xml
index 3b2b190a1b..1c2e68494f 100644
--- a/demo/src/main/res/values/strings.xml
+++ b/demo/src/main/res/values/strings.xml
@@ -37,14 +37,10 @@
 
   <string name="off">[off]</string>
 
-  <string name="on">[on]</string>
-
   <string name="drm_error_not_supported">Protected content not supported on API levels below 18</string>
 
   <string name="drm_error_unsupported_scheme">This device does not support the required DRM scheme</string>
 
   <string name="drm_error_unknown">An unknown DRM error occurred</string>
 
-  <string name="failed">Playback failed</string>
-
 </resources>
diff --git a/demo_misc/webm_sw_decoder/src/main/AndroidManifest.xml b/demo_misc/webm_sw_decoder/src/main/AndroidManifest.xml
index e07f7f34bc..72070a4162 100644
--- a/demo_misc/webm_sw_decoder/src/main/AndroidManifest.xml
+++ b/demo_misc/webm_sw_decoder/src/main/AndroidManifest.xml
@@ -17,8 +17,8 @@
 <manifest xmlns:android="http://schemas.android.com/apk/res/android"
     xmlns:tools="http://schemas.android.com/tools"
     package="com.google.android.exoplayer.demo.webm"
-    android:versionCode="1402"
-    android:versionName="1.4.2"
+    android:versionCode="1500"
+    android:versionName="1.5.0"
     android:theme="@style/RootTheme">
 
   <uses-permission android:name="android.permission.INTERNET"/>
diff --git a/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/DashRendererBuilder.java b/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/DashRendererBuilder.java
index 377d7611ae..f199091cb2 100644
--- a/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/DashRendererBuilder.java
+++ b/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/DashRendererBuilder.java
@@ -22,9 +22,7 @@
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.chunk.ChunkSampleSource;
 import com.google.android.exoplayer.chunk.ChunkSource;
-import com.google.android.exoplayer.chunk.FormatEvaluator;
 import com.google.android.exoplayer.chunk.FormatEvaluator.AdaptiveEvaluator;
-import com.google.android.exoplayer.chunk.MultiTrackChunkSource;
 import com.google.android.exoplayer.dash.DashChunkSource;
 import com.google.android.exoplayer.dash.mpd.AdaptationSet;
 import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
@@ -40,7 +38,8 @@
 import com.google.android.exoplayer.upstream.DefaultUriDataSource;
 import com.google.android.exoplayer.util.ManifestFetcher;
 import com.google.android.exoplayer.util.ManifestFetcher.ManifestCallback;
-import com.google.android.exoplayer.util.MimeTypes;
+
+import android.text.TextUtils;
 
 import java.io.IOException;
 import java.util.ArrayList;
@@ -83,17 +82,21 @@ public void onSingleManifest(MediaPresentationDescription manifest) {
     DefaultBandwidthMeter bandwidthMeter = new DefaultBandwidthMeter(null, null);
 
     // Obtain Representations for playback.
-    ArrayList<Representation> audioRepresentationsList = new ArrayList<>();
+    Representation audioRepresentation = null;
+    boolean audioRepresentationIsOpus = false;
     ArrayList<Representation> videoRepresentationsList = new ArrayList<>();
-    Period period = manifest.periods.get(0);
+    Period period = manifest.getPeriod(0);
     for (int i = 0; i < period.adaptationSets.size(); i++) {
       AdaptationSet adaptationSet = period.adaptationSets.get(i);
       int adaptationSetType = adaptationSet.type;
       for (int j = 0; j < adaptationSet.representations.size(); j++) {
         Representation representation = adaptationSet.representations.get(j);
-        if (adaptationSetType == AdaptationSet.TYPE_AUDIO) {
-          audioRepresentationsList.add(representation);
-        } else if (adaptationSetType == AdaptationSet.TYPE_VIDEO) {
+        String codecs = representation.format.codecs;
+        if (adaptationSetType == AdaptationSet.TYPE_AUDIO && audioRepresentation == null) {
+          audioRepresentation = representation;
+          audioRepresentationIsOpus = !TextUtils.isEmpty(codecs) && codecs.startsWith("opus");
+        } else if (adaptationSetType == AdaptationSet.TYPE_VIDEO && !TextUtils.isEmpty(codecs)
+            && codecs.startsWith("vp9")) {
           videoRepresentationsList.add(representation);
         }
       }
@@ -105,14 +108,9 @@ public void onSingleManifest(MediaPresentationDescription manifest) {
     LibvpxVideoTrackRenderer videoRenderer = null;
     if (!videoRepresentationsList.isEmpty()) {
       DataSource videoDataSource = new DefaultUriDataSource(player, bandwidthMeter, userAgent);
-      ChunkSource videoChunkSource;
-      String mimeType = videoRepresentations[0].format.mimeType;
-      if (mimeType.equals(MimeTypes.VIDEO_WEBM)) {
-        videoChunkSource = new DashChunkSource(videoDataSource,
-            new AdaptiveEvaluator(bandwidthMeter), videoRepresentations);
-      } else {
-        throw new IllegalStateException("Unexpected mime type: " + mimeType);
-      }
+      ChunkSource videoChunkSource = new DashChunkSource(videoDataSource,
+          new AdaptiveEvaluator(bandwidthMeter), manifest.getPeriodDuration(0),
+          AdaptationSet.TYPE_VIDEO, videoRepresentations);
       ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
           VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE);
       videoRenderer = new LibvpxVideoTrackRenderer(videoSampleSource,
@@ -120,21 +118,16 @@ public void onSingleManifest(MediaPresentationDescription manifest) {
     }
 
     // Build the audio renderer.
-    MultiTrackChunkSource audioChunkSource = null;
-    TrackRenderer audioRenderer = null;
-    if (!audioRepresentationsList.isEmpty()) {
+    TrackRenderer audioRenderer;
+    if (audioRepresentation == null) {
+      audioRenderer = null;
+    } else {
       DataSource audioDataSource = new DefaultUriDataSource(player, bandwidthMeter, userAgent);
-      ChunkSource[] audioChunkSources = new ChunkSource[audioRepresentationsList.size()];
-      FormatEvaluator audioEvaluator = new FormatEvaluator.FixedEvaluator();
-      for (int i = 0; i < audioRepresentationsList.size(); i++) {
-        Representation representation = audioRepresentationsList.get(i);
-        audioChunkSources[i] = new DashChunkSource(audioDataSource,
-            audioEvaluator, representation);
-      }
-      audioChunkSource = new MultiTrackChunkSource(audioChunkSources);
+      DashChunkSource audioChunkSource = new DashChunkSource(audioDataSource, null,
+            manifest.getPeriodDuration(0), AdaptationSet.TYPE_AUDIO, audioRepresentation);
       SampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
           AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE);
-      if (manifestUrl.contains("opus")) { // TODO: Need a better logic here.
+      if (audioRepresentationIsOpus) {
         audioRenderer = new LibopusAudioTrackRenderer(audioSampleSource);
       } else {
         audioRenderer = new MediaCodecAudioTrackRenderer(audioSampleSource);
diff --git a/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/VideoPlayer.java b/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/VideoPlayer.java
index c855cd63ed..1de59c9131 100644
--- a/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/VideoPlayer.java
+++ b/demo_misc/webm_sw_decoder/src/main/java/com/google/android/exoplayer/demo/webm/VideoPlayer.java
@@ -61,7 +61,6 @@
   private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
   private static final int BUFFER_SEGMENT_COUNT = 160;
 
-
   private boolean isDash;
   private String manifestUrl;
   private boolean useOpenGL;
@@ -274,7 +273,7 @@ private void stopPlayback() {
   }
 
   private void toggleControlsVisibility()  {
-    if (mediaController != null) {
+    if (mediaController != null && player != null) {
       if (mediaController.isShowing()) {
         mediaController.hide();
       } else {
diff --git a/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/LibopusAudioTrackRenderer.java b/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/LibopusAudioTrackRenderer.java
index 2ab807f899..e8fd8c8306 100644
--- a/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/LibopusAudioTrackRenderer.java
+++ b/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/LibopusAudioTrackRenderer.java
@@ -21,7 +21,7 @@
 import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.MediaFormatHolder;
 import com.google.android.exoplayer.SampleSource;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+import com.google.android.exoplayer.SampleSourceTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.audio.AudioTrack;
 import com.google.android.exoplayer.ext.opus.OpusDecoderWrapper.InputBuffer;
@@ -30,8 +30,8 @@
 
 import android.os.Handler;
 
-import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.nio.ByteOrder;
 import java.util.List;
 
 /**
@@ -39,7 +39,8 @@
  *
  * @author vigneshv@google.com (Vignesh Venkatasubramanian)
  */
-public class LibopusAudioTrackRenderer extends TrackRenderer implements MediaClock {
+public final class LibopusAudioTrackRenderer extends SampleSourceTrackRenderer
+    implements MediaClock {
 
   /**
    * Interface definition for a callback to be notified of {@link LibopusAudioTrackRenderer} events.
@@ -76,7 +77,6 @@
    */
   public static final int MSG_SET_VOLUME = 1;
 
-  private final SampleSourceReader source;
   private final Handler eventHandler;
   private final EventListener eventListener;
   private final MediaFormatHolder formatHolder;
@@ -86,7 +86,6 @@
   private InputBuffer inputBuffer;
   private OutputBuffer outputBuffer;
 
-  private int trackIndex;
   private long currentPositionUs;
   private boolean allowPositionDiscontinuity;
   private boolean inputStreamEnded;
@@ -112,7 +111,7 @@ public LibopusAudioTrackRenderer(SampleSource source) {
    */
   public LibopusAudioTrackRenderer(SampleSource source, Handler eventHandler,
       EventListener eventListener) {
-    this.source = source.register();
+    super(source);
     this.eventHandler = eventHandler;
     this.eventListener = eventListener;
     this.audioSessionId = AudioTrack.SESSION_ID_NOT_SET;
@@ -126,20 +125,15 @@ protected MediaClock getMediaClock() {
   }
 
   @Override
-  protected int doPrepare(long positionUs) {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < trackCount; i++) {
-      if (source.getTrackInfo(i).mimeType.equalsIgnoreCase(MimeTypes.AUDIO_OPUS)
-          || source.getTrackInfo(i).mimeType.equalsIgnoreCase(MimeTypes.AUDIO_WEBM)) {
-        trackIndex = i;
-        return TrackRenderer.STATE_PREPARED;
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
+  protected boolean handlesTrack(MediaFormat mediaFormat) {
+    return MimeTypes.AUDIO_OPUS.equalsIgnoreCase(mediaFormat.mimeType);
+  }
+
+  @Override
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
+    seekToInternal(positionUs);
   }
 
   @Override
@@ -147,8 +141,8 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
     if (outputStreamEnded) {
       return;
     }
-    sourceIsReady = source.continueBuffering(trackIndex, positionUs);
-    checkForDiscontinuity();
+    sourceIsReady = continueBufferingSource(positionUs);
+    checkForDiscontinuity(positionUs);
 
     // Try and read a format if we don't have one already.
     if (format == null && !readFormat(positionUs)) {
@@ -170,12 +164,13 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
       long codecDelayNs = -1;
       long seekPreRollNs = -1;
       if (initializationData.size() == 3) {
-        if (initializationData.get(1).length != Long.SIZE
-            || initializationData.get(2).length != Long.SIZE) {
+        if (initializationData.get(1).length != 8 || initializationData.get(2).length != 8) {
           throw new ExoPlaybackException("Invalid Codec Delay or Seek Preroll");
         }
-        codecDelayNs = ByteBuffer.wrap(initializationData.get(1)).getLong();
-        seekPreRollNs = ByteBuffer.wrap(initializationData.get(2)).getLong();
+        codecDelayNs =
+            ByteBuffer.wrap(initializationData.get(1)).order(ByteOrder.LITTLE_ENDIAN).getLong();
+        seekPreRollNs =
+            ByteBuffer.wrap(initializationData.get(2)).order(ByteOrder.LITTLE_ENDIAN).getLong();
       }
       try {
         decoder = new OpusDecoderWrapper(initializationData.get(0), codecDelayNs, seekPreRollNs);
@@ -189,7 +184,7 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
     // Rendering loop.
     try {
       renderBuffer();
-      while (feedInputBuffer()) {}
+      while (feedInputBuffer(positionUs)) {}
     } catch (AudioTrack.InitializationException e) {
       notifyAudioTrackInitializationError(e);
       throw new ExoPlaybackException(e);
@@ -217,6 +212,7 @@ private void renderBuffer() throws OpusDecoderException, AudioTrack.Initializati
 
     if (outputBuffer.getFlag(OpusDecoderWrapper.FLAG_END_OF_STREAM)) {
       outputStreamEnded = true;
+      audioTrack.handleEndOfStream();
       decoder.releaseOutputBuffer(outputBuffer);
       outputBuffer = null;
       return;
@@ -249,7 +245,7 @@ private void renderBuffer() throws OpusDecoderException, AudioTrack.Initializati
     }
   }
 
-  private boolean feedInputBuffer() throws OpusDecoderException {
+  private boolean feedInputBuffer(long positionUs) throws OpusDecoderException {
     if (inputStreamEnded) {
       return false;
     }
@@ -261,8 +257,7 @@ private boolean feedInputBuffer() throws OpusDecoderException {
       }
     }
 
-    int result = source.readData(trackIndex, currentPositionUs, formatHolder,
-        inputBuffer.sampleHolder, false);
+    int result = readSource(positionUs, formatHolder, inputBuffer.sampleHolder, false);
     if (result == SampleSource.NOTHING_READ) {
       return false;
     }
@@ -291,11 +286,11 @@ private boolean feedInputBuffer() throws OpusDecoderException {
     return true;
   }
 
-  private void checkForDiscontinuity() {
+  private void checkForDiscontinuity(long positionUs) {
     if (decoder == null) {
       return;
     }
-    int result = source.readData(trackIndex, currentPositionUs, formatHolder, null, true);
+    int result = readSource(positionUs, formatHolder, null, true);
     if (result == SampleSource.DISCONTINUITY_READ) {
       flushDecoder();
     }
@@ -310,8 +305,7 @@ private void flushDecoder() {
 
   @Override
   protected boolean isEnded() {
-    return outputStreamEnded && (!audioTrack.hasPendingData()
-        || !audioTrack.hasEnoughDataToBeginPlayback());
+    return outputStreamEnded && !audioTrack.hasPendingData();
   }
 
   @Override
@@ -319,11 +313,6 @@ protected boolean isReady() {
     return audioTrack.hasPendingData() || (format != null && sourceIsReady);
   }
 
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
-  }
-
   @Override
   public long getPositionUs() {
     long newCurrentPositionUs = audioTrack.getCurrentPositionUs(isEnded());
@@ -335,14 +324,9 @@ public long getPositionUs() {
     return currentPositionUs;
   }
 
-  @Override
-  protected long getBufferedPositionUs() {
-    return source.getBufferedPositionUs();
-  }
-
   @Override
   protected void seekTo(long positionUs) throws ExoPlaybackException {
-    source.seekToUs(positionUs);
+    super.seekTo(positionUs);
     seekToInternal(positionUs);
   }
 
@@ -350,18 +334,11 @@ private void seekToInternal(long positionUs) {
     audioTrack.reset();
     currentPositionUs = positionUs;
     allowPositionDiscontinuity = true;
-    source.seekToUs(positionUs);
     inputStreamEnded = false;
     outputStreamEnded = false;
     sourceIsReady = false;
   }
 
-  @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
-    seekToInternal(positionUs);
-  }
-
   @Override
   protected void onStarted() {
     audioTrack.play();
@@ -373,41 +350,27 @@ protected void onStopped() {
   }
 
   @Override
-  protected void onReleased() {
-    source.release();
-  }
-
-  @Override
-  protected void onDisabled() {
-    if (decoder != null) {
-      decoder.release();
-      decoder = null;
-    }
+  protected void onDisabled() throws ExoPlaybackException {
+    inputBuffer = null;
+    outputBuffer = null;
+    format = null;
     audioSessionId = AudioTrack.SESSION_ID_NOT_SET;
     try {
+      if (decoder != null) {
+        decoder.release();
+        decoder = null;
+      }
       audioTrack.release();
     } finally {
-      inputBuffer = null;
-      outputBuffer = null;
-      format = null;
-      source.disable(trackIndex);
-    }
-  }
-
-  @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
-    try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
+      super.onDisabled();
     }
   }
 
   private boolean readFormat(long positionUs) {
-    int result = source.readData(trackIndex, positionUs, formatHolder, null, false);
+    int result = readSource(positionUs, formatHolder, null, false);
     if (result == SampleSource.FORMAT_READ) {
       format = formatHolder.format;
-      audioTrack.reconfigure(format.getFrameworkMediaFormatV16());
+      audioTrack.reconfigure(format.getFrameworkMediaFormatV16(), false);
       return true;
     }
     return false;
diff --git a/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/OpusDecoderWrapper.java b/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/OpusDecoderWrapper.java
index 074fc43f7d..3687bde27b 100644
--- a/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/OpusDecoderWrapper.java
+++ b/extensions/opus/src/main/java/com/google/android/exoplayer/ext/opus/OpusDecoderWrapper.java
@@ -203,6 +203,7 @@ private boolean decodeBuffer(OpusDecoder decoder) throws InterruptedException,
     }
 
     // Decode.
+    boolean skipBuffer = false;
     if (inputBuffer.getFlag(FLAG_END_OF_STREAM)) {
       outputBuffer.setFlag(FLAG_END_OF_STREAM);
     } else {
@@ -221,13 +222,14 @@ private boolean decodeBuffer(OpusDecoder decoder) throws InterruptedException,
       if (skipSamples > 0) {
         int bytesPerSample = opusHeader.channelCount * 2;
         int skipBytes = skipSamples * bytesPerSample;
-        if (outputBuffer.size < skipBytes) {
+        if (outputBuffer.size <= skipBytes) {
           skipSamples -= outputBuffer.size / bytesPerSample;
           outputBuffer.size = 0;
+          skipBuffer = true;
         } else {
           skipSamples = 0;
-          outputBuffer.data.position(skipBytes);
           outputBuffer.size -= skipBytes;
+          outputBuffer.data.position(skipBytes);
         }
       }
     }
@@ -235,7 +237,7 @@ private boolean decodeBuffer(OpusDecoder decoder) throws InterruptedException,
     synchronized (lock) {
       if (flushDecodedOutputBuffer
           || inputBuffer.sampleHolder.isDecodeOnly()
-          || outputBuffer.size == 0) {
+          || skipBuffer) {
         // In the following cases, we make the output buffer available again rather than queuing it
         // to be consumed:
         // 1) A flush occured whilst we were decoding.
@@ -322,7 +324,7 @@ public InputBuffer() {
     }
 
     public void reset() {
-      sampleHolder.data.clear();
+      sampleHolder.clearData();
       flags = 0;
     }
 
diff --git a/extensions/opus/src/main/jni/convert_android_asm.sh b/extensions/opus/src/main/jni/convert_android_asm.sh
index 6d75f094ae..c789c66a1a 100755
--- a/extensions/opus/src/main/jni/convert_android_asm.sh
+++ b/extensions/opus/src/main/jni/convert_android_asm.sh
@@ -31,7 +31,7 @@ while read file; do
     ${ASM_CONVERTER} "${file}" > "${gnu_file}"
     # The ASM conversion script replaces includes with *_gnu.S. So, replace
     # occurences of "*-gnu.S" with "*_gnu.s".
-    sed -i "s/-gnu\.S/_gnu\.s/g" "${gnu_file}"
+    perl -pi -e "s/-gnu\.S/_gnu\.s/g" "${gnu_file}"
     rm -f "${file}"
   fi
 done < <(find . -iname '*.s')
diff --git a/extensions/vp9/README.md b/extensions/vp9/README.md
index 0250cfc8a5..121a3cf5d1 100644
--- a/extensions/vp9/README.md
+++ b/extensions/vp9/README.md
@@ -112,17 +112,20 @@ libvpx is optimized for various architectures (like neon, x86, etc.). The `gener
 * armeabi-v7a (choose this to enable neon optimizations)
 * mips
 * x86
+* arm64-v8a
+* mips64
+* x86_64
 * all (will result in a larger binary but will cover all architectures)
 
 You can build for a specific architecture in two ways:
 
 * Method 1 (edit `Application.mk`)
-  * Edit `${VP9_EXT_PATH}/jni/Application.mk` and add the following line `APP_ABI := <arch>` (where `<arch>` is one of the above 4 architectures)
+  * Edit `${VP9_EXT_PATH}/jni/Application.mk` and add the following line `APP_ABI := <arch>` (where `<arch>` is one of the above 7 architectures)
 * Method 2 (pass NDK build flag)
   * Right click on ExoPlayerExt-VP9 in the Project Explorer pane and choose Properties
   * Click on C/C++ Build
   * Uncheck `Use default build command`
-  * In `Build Command` enter: `ndk-build APP_ABI=<arch>` (where `<arch>` is one of the above 4 architectures)
+  * In `Build Command` enter: `ndk-build APP_ABI=<arch>` (where `<arch>` is one of the above 7 architectures)
   * Click Apply
 
 ## Other Things to Note ##
diff --git a/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/LibvpxVideoTrackRenderer.java b/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/LibvpxVideoTrackRenderer.java
index 4c8745d006..d19a0992b9 100644
--- a/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/LibvpxVideoTrackRenderer.java
+++ b/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/LibvpxVideoTrackRenderer.java
@@ -15,12 +15,13 @@
  */
 package com.google.android.exoplayer.ext.vp9;
 
+import com.google.android.exoplayer.CodecCounters;
 import com.google.android.exoplayer.ExoPlaybackException;
 import com.google.android.exoplayer.ExoPlayer;
 import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.MediaFormatHolder;
 import com.google.android.exoplayer.SampleSource;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+import com.google.android.exoplayer.SampleSourceTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.ext.vp9.VpxDecoderWrapper.InputBuffer;
 import com.google.android.exoplayer.ext.vp9.VpxDecoderWrapper.OutputBuffer;
@@ -32,12 +33,10 @@
 import android.os.SystemClock;
 import android.view.Surface;
 
-import java.io.IOException;
-
 /**
  * Decodes and renders video using the native VP9 decoder.
  */
-public class LibvpxVideoTrackRenderer extends TrackRenderer {
+public final class LibvpxVideoTrackRenderer extends SampleSourceTrackRenderer {
 
   /**
    * Interface definition for a callback to be notified of {@link LibvpxVideoTrackRenderer} events.
@@ -91,7 +90,8 @@
   public static final int MSG_SET_SURFACE = 1;
   public static final int MSG_SET_VPX_SURFACE_VIEW = 2;
 
-  private final SampleSourceReader source;
+  public final CodecCounters codecCounters = new CodecCounters();
+
   private final boolean scaleToFit;
   private final Handler eventHandler;
   private final EventListener eventListener;
@@ -110,7 +110,6 @@
   private VpxVideoSurfaceView vpxVideoSurfaceView;
   private boolean outputRgb;
 
-  private int trackIndex;
   private boolean inputStreamEnded;
   private boolean outputStreamEnded;
   private boolean sourceIsReady;
@@ -141,7 +140,7 @@ public LibvpxVideoTrackRenderer(SampleSource source, boolean scaleToFit) {
    */
   public LibvpxVideoTrackRenderer(SampleSource source, boolean scaleToFit,
       Handler eventHandler, EventListener eventListener, int maxDroppedFrameCountToNotify) {
-    this.source = source.register();
+    super(source);
     this.scaleToFit = scaleToFit;
     this.eventHandler = eventHandler;
     this.eventListener = eventListener;
@@ -152,20 +151,8 @@ public LibvpxVideoTrackRenderer(SampleSource source, boolean scaleToFit,
   }
 
   @Override
-  protected int doPrepare(long positionUs) throws ExoPlaybackException {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < trackCount; i++) {
-      if (source.getTrackInfo(i).mimeType.equalsIgnoreCase(MimeTypes.VIDEO_VP9)
-          || source.getTrackInfo(i).mimeType.equalsIgnoreCase(MimeTypes.VIDEO_WEBM)) {
-        trackIndex = i;
-        return TrackRenderer.STATE_PREPARED;
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
+  protected boolean handlesTrack(MediaFormat mediaFormat) {
+    return MimeTypes.VIDEO_VP9.equalsIgnoreCase(mediaFormat.mimeType);
   }
 
   @Override
@@ -173,7 +160,7 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
     if (outputStreamEnded) {
       return;
     }
-    sourceIsReady = source.continueBuffering(trackIndex, positionUs);
+    sourceIsReady = continueBufferingSource(positionUs);
     checkForDiscontinuity(positionUs);
 
     // Try and read a format if we don't have one already.
@@ -223,6 +210,7 @@ private void processOutputBuffer(long positionUs, long elapsedRealtimeUs)
 
     if (timeToRenderUs < -30000 || outputBuffer.timestampUs < positionUs) {
       // Drop frame if we are too late.
+      codecCounters.droppedOutputBufferCount++;
       droppedFrameCount++;
       if (droppedFrameCount == maxDroppedFrameCountToNotify) {
         notifyAndResetDroppedFrameCount();
@@ -231,8 +219,8 @@ private void processOutputBuffer(long positionUs, long elapsedRealtimeUs)
       return;
     }
 
-    // If we have not renderered any frame so far (either initially or immediately following a
-    // seek), render one frame irresepective of the state.
+    // If we have not rendered any frame so far (either initially or immediately following a seek),
+    // render one frame irrespective of the state.
     if (!renderedFirstFrame) {
       renderBuffer();
       renderedFirstFrame = true;
@@ -246,8 +234,7 @@ private void processOutputBuffer(long positionUs, long elapsedRealtimeUs)
 
     if (timeToRenderUs > 11000) {
       try {
-        // Subtracting 10000 rather than 11000 ensures that the sleep time
-        // will be at least 1ms.
+        // Subtracting 10000 rather than 11000 ensures that the sleep time will be at least 1ms.
         Thread.sleep((timeToRenderUs - 10000) / 1000);
       } catch (InterruptedException e) {
         Thread.currentThread().interrupt();
@@ -257,6 +244,7 @@ private void processOutputBuffer(long positionUs, long elapsedRealtimeUs)
   }
 
   private void renderBuffer() throws VpxDecoderException {
+    codecCounters.renderedOutputBufferCount++;
     notifyIfVideoSizeChanged(outputBuffer);
     if (outputRgb) {
       renderRgbFrame(outputBuffer, scaleToFit);
@@ -302,7 +290,7 @@ private boolean feedInputBuffer(long positionUs) throws VpxDecoderException {
       }
     }
 
-    int result = source.readData(trackIndex, positionUs, formatHolder, inputBuffer.sampleHolder,
+    int result = readSource(positionUs, formatHolder, inputBuffer.sampleHolder,
         false);
     if (result == SampleSource.NOTHING_READ) {
       return false;
@@ -334,7 +322,7 @@ private void checkForDiscontinuity(long positionUs) {
     if (decoder == null) {
       return;
     }
-    int result = source.readData(trackIndex, positionUs, formatHolder, null, true);
+    int result = readSource(positionUs, formatHolder, null, true);
     if (result == SampleSource.DISCONTINUITY_READ) {
       flushDecoder();
     }
@@ -356,25 +344,16 @@ protected boolean isReady() {
     return format != null && sourceIsReady;
   }
 
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
-  }
-
-  @Override
-  protected long getBufferedPositionUs() {
-    return source.getBufferedPositionUs();
-  }
-
   @Override
   protected void seekTo(long positionUs) throws ExoPlaybackException {
-    source.seekToUs(positionUs);
+    super.seekTo(positionUs);
     seekToInternal();
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     seekToInternal();
   }
 
@@ -397,33 +376,22 @@ protected void onStopped() {
   }
 
   @Override
-  protected void onReleased() {
-    source.release();
-  }
-
-  @Override
-  protected void onDisabled() {
-    if (decoder != null) {
-      decoder.release();
-      decoder = null;
-    }
+  protected void onDisabled() throws ExoPlaybackException {
     inputBuffer = null;
     outputBuffer = null;
     format = null;
-    source.disable(trackIndex);
-  }
-
-  @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
     try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
+      if (decoder != null) {
+        decoder.release();
+        decoder = null;
+      }
+    } finally {
+      super.onDisabled();
     }
   }
 
   private boolean readFormat(long positionUs) {
-    int result = source.readData(trackIndex, positionUs, formatHolder, null, false);
+    int result = readSource(positionUs, formatHolder, null, false);
     if (result == SampleSource.FORMAT_READ) {
       format = formatHolder.format;
       return true;
diff --git a/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/VpxDecoderWrapper.java b/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/VpxDecoderWrapper.java
index b108ca7eb2..49e063b52a 100644
--- a/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/VpxDecoderWrapper.java
+++ b/extensions/vp9/src/main/java/com/google/android/exoplayer/ext/vp9/VpxDecoderWrapper.java
@@ -72,7 +72,7 @@ public InputBuffer getInputBuffer() throws VpxDecoderException {
       }
       InputBuffer inputBuffer = availableInputBuffers[--availableInputBufferCount];
       inputBuffer.flags = 0;
-      inputBuffer.sampleHolder.data.clear();
+      inputBuffer.sampleHolder.clearData();
       return inputBuffer;
     }
   }
diff --git a/extensions/vp9/src/main/jni/generate_libvpx_android_configs.sh b/extensions/vp9/src/main/jni/generate_libvpx_android_configs.sh
index d86978bd18..951dcc0dfe 100755
--- a/extensions/vp9/src/main/jni/generate_libvpx_android_configs.sh
+++ b/extensions/vp9/src/main/jni/generate_libvpx_android_configs.sh
@@ -31,7 +31,7 @@ shift 1
 # configuration parameters common to all architectures
 common_params="--disable-examples --disable-docs --enable-realtime-only"
 common_params+=" --disable-vp8 --disable-vp9-encoder --disable-webm-io"
-common_params+=" --disable-libyuv --disable-runtime-cpu-detect"
+common_params+=" --disable-vp10 --disable-libyuv --disable-runtime-cpu-detect"
 
 # configuration parameters for various architectures
 arch[0]="armeabi-v7a"
@@ -40,15 +40,27 @@ config[0]+=" --enable-neon-asm"
 
 arch[1]="armeabi"
 config[1]="--target=armv7-android-gcc --sdk-path=$ndk --disable-neon"
-config[1]+=" --disable-neon-asm"
+config[1]+=" --disable-neon-asm --disable-media"
 
 arch[2]="mips"
 config[2]="--force-target=mips32-android-gcc --sdk-path=$ndk"
 
 arch[3]="x86"
-config[3]="--force-target=x86-android-gcc --sdk-path=$ndk --disable-sse3"
-config[3]+=" --disable-ssse3 --disable-sse4_1 --disable-avx --disable-avx2"
-config[3]+=" --enable-pic"
+config[3]="--force-target=x86-android-gcc --sdk-path=$ndk --disable-sse2"
+config[3]+=" --disable-sse3 --disable-ssse3 --disable-sse4_1 --disable-avx"
+config[3]+=" --disable-avx2 --enable-pic"
+
+arch[4]="arm64-v8a"
+config[4]="--force-target=armv8-android-gcc --sdk-path=$ndk --disable-neon"
+config[4]+=" --disable-neon-asm"
+
+arch[5]="x86_64"
+config[5]="--force-target=x86_64-android-gcc --sdk-path=$ndk --disable-sse2"
+config[5]+=" --disable-sse3 --disable-ssse3 --disable-sse4_1 --disable-avx"
+config[5]+=" --disable-avx2 --enable-pic --disable-neon --disable-neon-asm"
+
+arch[6]="mips64"
+config[6]="--force-target=mips64-android-gcc --sdk-path=$ndk"
 
 limit=$((${#arch[@]} - 1))
 
@@ -56,9 +68,10 @@ limit=$((${#arch[@]} - 1))
 # everything else will be removed.
 allowed_files="libvpx_srcs.txt vpx_config.c vpx_config.h vpx_scale_rtcd.h"
 allowed_files+=" vp8_rtcd.h vp9_rtcd.h vpx_version.h vpx_config.asm"
+allowed_files+=" vpx_dsp_rtcd.h"
 
 remove_trailing_whitespace() {
-  sed -i 's/\s\+$//' "$@"
+  perl -pi -e 's/\s\+$//' "$@"
 }
 
 convert_asm() {
@@ -66,10 +79,15 @@ convert_asm() {
     while read file; do
       case "${file}" in
         *.asm.s)
-          asm_file="libvpx/${file%.s}"
-          cat "${asm_file}" | libvpx/build/make/ads2gas.pl > "libvpx/${file}"
-          remove_trailing_whitespace "libvpx/${file}"
-          rm "${asm_file}"
+          # Some files may already have been processed (there are duplicated
+          # .asm.s files for vp8 in the armeabi/armeabi-v7a configurations).
+          file="libvpx/${file}"
+          if [[ ! -e "${file}" ]]; then
+            asm_file="${file%.s}"
+            cat "${asm_file}" | libvpx/build/make/ads2gas.pl > "${file}"
+            remove_trailing_whitespace "${file}"
+            rm "${asm_file}"
+          fi
           ;;
       esac
     done < libvpx_android_configs/${arch[${i}]}/libvpx_srcs.txt
@@ -80,7 +98,7 @@ extglob_status="$(shopt extglob | cut -f2)"
 shopt -s extglob
 for i in $(seq 0 ${limit}); do
   mkdir -p "libvpx_android_configs/${arch[${i}]}"
-  cd "libvpx_android_configs/${arch[${i}]}"
+  pushd "libvpx_android_configs/${arch[${i}]}"
 
   # configure and make
   echo "build_android_configs: "
@@ -93,7 +111,7 @@ for i in $(seq 0 ${limit}); do
   rm -rf !(${allowed_files// /|})
   remove_trailing_whitespace *
 
-  cd ../..
+  popd
 done
 
 # restore extglob status as it was before
diff --git a/library/build.gradle b/library/build.gradle
index 4ed58a5b5f..257c5b4a34 100644
--- a/library/build.gradle
+++ b/library/build.gradle
@@ -77,7 +77,7 @@ publish {
     userOrg = 'google'
     groupId = 'com.google.android.exoplayer'
     artifactId = 'exoplayer'
-    version = 'r1.4.2'
+    version = 'r1.5.0'
     description = 'The ExoPlayer library.'
     website = 'https://github.com/google/ExoPlayer'
 }
diff --git a/library/src/androidTest/AndroidManifest.xml b/library/src/androidTest/AndroidManifest.xml
index eb07d822e3..0e6eba8cbd 100644
--- a/library/src/androidTest/AndroidManifest.xml
+++ b/library/src/androidTest/AndroidManifest.xml
@@ -16,7 +16,7 @@
 
 <manifest xmlns:android="http://schemas.android.com/apk/res/android"
     xmlns:tools="http://schemas.android.com/tools"
-    package="com.google.android.exoplayer.tests">
+    package="com.google.android.exoplayer.test">
 
   <uses-sdk android:minSdkVersion="9" android:targetSdkVersion="22"/>
 
@@ -27,7 +27,7 @@
   </application>
 
   <instrumentation
-      android:targetPackage="com.google.android.exoplayer.tests"
+      android:targetPackage="com.google.android.exoplayer.test"
       android:name="android.test.InstrumentationTestRunner"
       tools:replace="android:targetPackage"/>
 
diff --git a/library/src/androidTest/assets/subrip/no_end_timecodes b/library/src/androidTest/assets/subrip/no_end_timecodes
new file mode 100644
index 0000000000..0a856c6994
--- /dev/null
+++ b/library/src/androidTest/assets/subrip/no_end_timecodes
@@ -0,0 +1,11 @@
+1
+00:00:00,000 -->
+SubRip doesn't technically allow missing end timecodes.
+
+2
+00:00:02,345 -->
+We interpret it to mean that a subtitle extends to the start of the next one.
+
+3
+00:00:03,456 -->
+Or to the end of the media.
\ No newline at end of file
diff --git a/library/src/androidTest/assets/subrip/typical b/library/src/androidTest/assets/subrip/typical
index 800b0678c5..1c8ce4dd43 100644
--- a/library/src/androidTest/assets/subrip/typical
+++ b/library/src/androidTest/assets/subrip/typical
@@ -5,4 +5,8 @@ This is the first subtitle.
 2
 00:00:02,345 --> 00:00:03,456
 This is the second subtitle.
-Second subtitle with second line.
\ No newline at end of file
+Second subtitle with second line.
+
+3
+00:00:04,567 --> 00:00:08,901
+This is the third subtitle.
\ No newline at end of file
diff --git a/library/src/androidTest/assets/subrip/typical_extra_blank_line b/library/src/androidTest/assets/subrip/typical_extra_blank_line
new file mode 100644
index 0000000000..83508dd733
--- /dev/null
+++ b/library/src/androidTest/assets/subrip/typical_extra_blank_line
@@ -0,0 +1,13 @@
+1
+00:00:00,000 --> 00:00:01,234
+This is the first subtitle.
+
+
+2
+00:00:02,345 --> 00:00:03,456
+This is the second subtitle.
+Second subtitle with second line.
+
+3
+00:00:04,567 --> 00:00:08,901
+This is the third subtitle.
\ No newline at end of file
diff --git a/library/src/androidTest/assets/subrip/typical_missing_sequence b/library/src/androidTest/assets/subrip/typical_missing_sequence
new file mode 100644
index 0000000000..9318ba3239
--- /dev/null
+++ b/library/src/androidTest/assets/subrip/typical_missing_sequence
@@ -0,0 +1,11 @@
+1
+00:00:00,000 --> 00:00:01,234
+This is the first subtitle.
+
+00:00:02,345 --> 00:00:03,456
+This is the second subtitle.
+Second subtitle with second line.
+
+3
+00:00:04,567 --> 00:00:08,901
+This is the third subtitle.
\ No newline at end of file
diff --git a/library/src/androidTest/assets/subrip/typical_missing_timecode b/library/src/androidTest/assets/subrip/typical_missing_timecode
new file mode 100644
index 0000000000..b9c999ada9
--- /dev/null
+++ b/library/src/androidTest/assets/subrip/typical_missing_timecode
@@ -0,0 +1,11 @@
+1
+00:00:00,000 --> 00:00:01,234
+This is the first subtitle.
+
+2
+This is the second subtitle.
+Second subtitle with second line.
+
+3
+00:00:04,567 --> 00:00:08,901
+This is the third subtitle.
\ No newline at end of file
diff --git a/library/src/androidTest/assets/ttml/chain_multiple_styles.xml b/library/src/androidTest/assets/ttml/chain_multiple_styles.xml
new file mode 100644
index 0000000000..7bcce6527d
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/chain_multiple_styles.xml
@@ -0,0 +1,31 @@
+<tt xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata" xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+  xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+  xmlns="http://www.w3.org/ns/ttml"
+  xmlns="http://www.w3.org/2006/10/ttaf1">
+  <head>
+    <styling>
+      <style id="s0"
+        tts:backgroundColor="blue"
+        tts:color="black"
+        tts:fontWeight="bold" />
+      <style id="s1"
+        tts:backgroundColor="black"
+        tts:color="red"
+        tts:fontFamily="sansSerif"
+        tts:fontStyle="italic"
+        tts:textDecoration="lineThrough" />
+      <!-- multiple ids defined -->
+      <style style="s0 s1" id="s2"
+        tts:fontFamily="serif"
+        tts:backgroundColor="red" />
+      <style style="s1 s0" id="s3"
+        tts:fontFamily="serif"
+        tts:backgroundColor="red" />
+    </styling>
+  </head>
+  <body>
+    <div>
+      <p style="s2" begin="10s" end="18s">text 1</p>
+    </div>
+  </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/inherit_and_override_style.xml b/library/src/androidTest/assets/ttml/inherit_and_override_style.xml
new file mode 100644
index 0000000000..599e22ef1b
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/inherit_and_override_style.xml
@@ -0,0 +1,30 @@
+<tt xmlns="http://www.w3.org/ns/ttml"
+    xmlns="http://www.w3.org/2006/10/ttaf1"
+    xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+    xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+    xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata">
+    <head>
+        <styling>
+            <style id="s0"
+                tts:fontWeight="bold"
+                tts:fontStyle="italic"
+                tts:fontFamily="serif"
+                tts:textDecoration="underline"
+                tts:backgroundColor="blue"
+                tts:color="yellow"/>
+        </styling>
+    </head>
+    <body>
+        <div>
+            <p style="s0" begin="10s" end="18s">text 1</p>
+        </div>
+        <div>
+            <p style="s0" begin="20s" end="28s"
+                tts:fontWeight="normal"
+                tts:fontFamily="sansSerif"
+                tts:backgroundColor="red"
+                tts:color="yellow"
+                >text 2</p>
+        </div>
+    </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/inherit_global_and_parent.xml b/library/src/androidTest/assets/ttml/inherit_global_and_parent.xml
new file mode 100644
index 0000000000..126bfcdba2
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/inherit_global_and_parent.xml
@@ -0,0 +1,35 @@
+<tt xmlns="http://www.w3.org/ns/ttml"
+    xmlns="http://www.w3.org/2006/10/ttaf1"
+    xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+    xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+    xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata">
+    <head>
+        <styling>
+            <style id="s0"
+                tts:fontWeight="bold"
+                tts:fontStyle="italic"
+                tts:fontFamily="serif"
+                tts:textDecoration="underline"
+                tts:backgroundColor="blue"
+                tts:color="yellow"/>
+        </styling>
+    </head>
+    <body tts:textAlign="center">
+        <div tts:fontWeight="normal"
+            tts:fontStyle="normal"
+            tts:fontFamily="sansSerif"
+            tts:textDecoration="lineThrough"
+            tts:backgroundColor="red"
+            tts:color="lime">
+            <p begin="10s" end="18s">text 1</p>
+        </div>
+        <div tts:fontWeight="normal"
+            tts:fontStyle="normal"
+            tts:fontFamily="sansSerif"
+            tts:textDecoration="lineThrough"
+            tts:backgroundColor="red"
+            tts:color="lime">
+            <p style="s0" begin="20s" end="28s">text 2</p>
+        </div>
+    </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/inherit_multiple_styles.xml b/library/src/androidTest/assets/ttml/inherit_multiple_styles.xml
new file mode 100644
index 0000000000..3ee089c3ff
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/inherit_multiple_styles.xml
@@ -0,0 +1,45 @@
+<tt xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata" xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+  xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+  xmlns="http://www.w3.org/ns/ttml"
+  xmlns="http://www.w3.org/2006/10/ttaf1">
+  <head>
+    <styling>
+      <style id="s0"
+        tts:backgroundColor="blue"
+        tts:color="black"
+        tts:fontWeight="bold" />
+      <style id="s1"
+        tts:backgroundColor="black"
+        tts:color="red"
+        tts:fontFamily="sansSerif"
+        tts:fontStyle="italic"
+        tts:textDecoration="lineThrough" />
+      <style id="s2"
+        tts:backgroundColor="red" />
+      <style id="s3"
+        tts:backgroundColor="green"
+        tts:textDecoration="lineThrough" />
+    </styling>
+  </head>
+  <body>
+    <div>
+      <p style="s0 s1" begin="10s" end="18s" tts:color="yellow">text 1</p>
+    </div>
+    <div>
+      <p style="s0 s1" begin="20s" end="28s">text 2</p>
+    </div>
+    <div tts:color="yellow" tts:textDecoration="underline" tts:fontStyle="italic" tts:fontFamily="sansSerifInline">
+      <p style="s2                           s3" begin="30s" end="38s">text 2.5</p>
+    </div>
+    <div>
+      <!-- empty style attribute -->
+      <p style=" " begin="40s" end="48s">text 3</p>
+    </div>
+    <div>
+      <p style="not_existing" begin="50s" end="58s">text 4</p>
+    </div>
+    <div>
+      <p style="not_existing s2" begin="60s" end="68s">text 5</p>
+    </div>
+  </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/inherit_style.xml b/library/src/androidTest/assets/ttml/inherit_style.xml
new file mode 100644
index 0000000000..808087960c
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/inherit_style.xml
@@ -0,0 +1,22 @@
+<tt xmlns="http://www.w3.org/ns/ttml"
+    xmlns="http://www.w3.org/2006/10/ttaf1"
+    xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+    xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+    xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata">
+    <head>
+        <styling>
+            <style id="s0"
+                tts:fontWeight="bold"
+                tts:fontStyle="italic"
+                tts:fontFamily="serif"
+                tts:textDecoration="underline"
+                tts:backgroundColor="blue"
+                tts:color="yellow"/>
+        </styling>
+    </head>
+    <body>
+        <div>
+            <p style="s0" begin="10s" end="18s">text 1</p>
+        </div>
+    </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/inline_style_attributes.xml b/library/src/androidTest/assets/ttml/inline_style_attributes.xml
new file mode 100644
index 0000000000..3d7f4a7d77
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/inline_style_attributes.xml
@@ -0,0 +1,25 @@
+<tt xmlns="http://www.w3.org/ns/ttml"
+    xmlns="http://www.w3.org/2006/10/ttaf1"
+    xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+    xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+    xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata">
+    <body>
+        <div>
+            <p begin="10s" end="18s"
+                tts:fontWeight="bold"
+                tts:fontStyle="italic"
+                tts:fontFamily="serif"
+                tts:textDecoration="underline"
+                tts:backgroundColor="blue"
+                tts:color="yellow">text 1</p>
+        </div>
+        <div tts:fontWeight="normal"
+            tts:fontStyle="italic"
+            tts:fontFamily="sansSerif"
+            tts:textDecoration="lineThrough"
+            tts:backgroundColor="cyan"
+            tts:color="lime">
+            <p begin="20s" end="28s">text 2</p>
+        </div>
+    </body>
+</tt>
diff --git a/library/src/androidTest/assets/ttml/namespace_confusion.xml b/library/src/androidTest/assets/ttml/namespace_confusion.xml
new file mode 100644
index 0000000000..5b9025cd94
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/namespace_confusion.xml
@@ -0,0 +1,17 @@
+<tt xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata" 
+    xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+    xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+    xmlns="http://www.w3.org/ns/ttml"
+    xmlns="http://www.w3.org/2006/10/ttaf1">
+  <body>
+    <div>
+      <p begin="10s" end="18s"
+          tts:backgroundColor="black"
+          abc:fontFamily="sansSerif"
+          def:fontStyle="italic"
+          ghi:textDecoration="lineThrough"
+          jkl:color="yellow">text 1</p>
+    </div>
+  </body>
+</tt>
+
diff --git a/library/src/androidTest/assets/ttml/namespace_not_declared.xml b/library/src/androidTest/assets/ttml/namespace_not_declared.xml
new file mode 100644
index 0000000000..25e8369a34
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/namespace_not_declared.xml
@@ -0,0 +1,13 @@
+<tt>
+  <body>
+    <div>
+      <p begin="10s" end="18s"
+          tts:backgroundColor="black"
+          abc:fontFamily="sansSerif"
+          def:fontStyle="italic"
+          ghi:textDecoration="lineThrough"
+          jkl:color="yellow">text 1</p>
+    </div>
+  </body>
+</tt>
+
diff --git a/library/src/androidTest/assets/ttml/no_underline_linethrough.xml b/library/src/androidTest/assets/ttml/no_underline_linethrough.xml
new file mode 100644
index 0000000000..d7092a9415
--- /dev/null
+++ b/library/src/androidTest/assets/ttml/no_underline_linethrough.xml
@@ -0,0 +1,21 @@
+<tt xmlns:ttm="http://www.w3.org/2006/10/ttaf1#metadata" xmlns:ttp="http://www.w3.org/2006/10/ttaf1#parameter"
+  xmlns:tts="http://www.w3.org/2006/10/ttaf1#style"
+  xmlns="http://www.w3.org/ns/ttml"
+  xmlns="http://www.w3.org/2006/10/ttaf1">
+  <head>
+    <styling>
+      <style id="s0"
+        tts:textDecoration="underline"/>
+      <style id="s1"
+        tts:textDecoration="lineThrough"/>
+    </styling>
+  </head>
+  <body>
+    <div>
+      <p style="s0" begin="10s" end="18s" tts:textDecoration="noUnderline">text 1</p>
+    </div>
+    <div>
+      <p style="s1" begin="20s" end="28s" tts:textDecoration="noLineThrough">text 1</p>
+    </div>
+  </body>
+</tt>
diff --git a/library/src/androidTest/assets/webvtt/live_typical b/library/src/androidTest/assets/webvtt/live_typical
deleted file mode 100644
index 9f4864b690..0000000000
--- a/library/src/androidTest/assets/webvtt/live_typical
+++ /dev/null
@@ -1,9 +0,0 @@
-EXO-HEADER=OFFSET:-5000000
-WEBVTT
-X-TIMESTAMP-MAP=LOCAL:00:00.000,MPEGTS:450000
-
-00:00.000 --> 00:01.234
-This is the first subtitle.
-
-00:02.345 --> 00:03.456
-This is the second subtitle.
diff --git a/library/src/androidTest/assets/webvtt/typical b/library/src/androidTest/assets/webvtt/typical
index 7bd3ca9198..d4298da516 100644
--- a/library/src/androidTest/assets/webvtt/typical
+++ b/library/src/androidTest/assets/webvtt/typical
@@ -1,5 +1,4 @@
 WEBVTT # This comment is allowed
-X-TIMESTAMP-MAP=LOCAL:00:00.000,MPEGTS:450000
 
 00:00.000 --> 00:01.234
 This is the first subtitle.
diff --git a/library/src/androidTest/assets/webvtt/typical_with_comments b/library/src/androidTest/assets/webvtt/typical_with_comments
new file mode 100644
index 0000000000..9b75c00945
--- /dev/null
+++ b/library/src/androidTest/assets/webvtt/typical_with_comments
@@ -0,0 +1,20 @@
+WEBVTT
+
+NOTE
+This is a comment block
+with multiple lines
+
+1
+00:00.000 --> 00:01.234
+This is the first subtitle.
+
+NOTE Single line comment with a space
+
+NOTE	Single line comment with a tab
+
+2
+00:02.345 --> 00:03.456
+This is the second subtitle.
+
+NOTE
+File ending with a comment
diff --git a/library/src/androidTest/assets/webvtt/typical_with_identifiers b/library/src/androidTest/assets/webvtt/typical_with_identifiers
index e2c5df065b..f6ac990e99 100644
--- a/library/src/androidTest/assets/webvtt/typical_with_identifiers
+++ b/library/src/androidTest/assets/webvtt/typical_with_identifiers
@@ -1,5 +1,4 @@
 WEBVTT
-X-TIMESTAMP-MAP=LOCAL:00:00.000,MPEGTS:450000
 
 1
 00:00.000 --> 00:01.234
diff --git a/library/src/androidTest/assets/webvtt/with_positioning b/library/src/androidTest/assets/webvtt/with_positioning
new file mode 100644
index 0000000000..e50163a64c
--- /dev/null
+++ b/library/src/androidTest/assets/webvtt/with_positioning
@@ -0,0 +1,28 @@
+WEBVTT
+
+NOTE Position with percentage and position alignment
+
+00:00:00.000 --> 00:00:01.234 position:10%,start align:start size:35%
+This is the first subtitle.
+
+NOTE Wrong position provided. It should be provided as
+a percentage value
+
+00:02.345 --> 00:03.456 position:10 align:end size:35%
+This is the second subtitle.
+
+NOTE Line as percentage and line alignment
+
+00:04.000 --> 00:05.000 line:45%,end align:middle size:35%
+This is the third subtitle.
+
+NOTE Line as absolute negative number and without line alignment.
+
+00:06.000 --> 00:07.000 line:-10 align:middle
+This is the fourth subtitle.
+
+NOTE The positioning alignment should be inherited from align.
+
+00:07.000 --> 00:08.000 position:10% align:end size:10%
+This is the fifth subtitle.
+
diff --git a/library/src/androidTest/assets/webvtt/typical_with_tags b/library/src/androidTest/assets/webvtt/with_tags
similarity index 85%
rename from library/src/androidTest/assets/webvtt/typical_with_tags
rename to library/src/androidTest/assets/webvtt/with_tags
index aecf1cb2b7..56610f84fc 100644
--- a/library/src/androidTest/assets/webvtt/typical_with_tags
+++ b/library/src/androidTest/assets/webvtt/with_tags
@@ -1,5 +1,4 @@
 WEBVTT
-X-TIMESTAMP-MAP=LOCAL:00:00.000,MPEGTS:450000
 
 00:00.000 --> 00:01.234
 This is the <i>first</i> subtitle.
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/MediaFormatTest.java b/library/src/androidTest/java/com/google/android/exoplayer/MediaFormatTest.java
index 62e4ce044f..a22bc07567 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/MediaFormatTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/MediaFormatTest.java
@@ -17,17 +17,20 @@
 
 import com.google.android.exoplayer.util.Util;
 
+import android.annotation.SuppressLint;
 import android.annotation.TargetApi;
 
 import junit.framework.TestCase;
 
+import java.nio.ByteBuffer;
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
 
 /**
  * Unit test for {@link MediaFormat}.
  */
-public class MediaFormatTest extends TestCase {
+public final class MediaFormatTest extends TestCase {
 
   public void testConversionToFrameworkFormat() {
     if (Util.SDK_INT < 16) {
@@ -41,20 +44,68 @@ public void testConversionToFrameworkFormat() {
     initData.add(initData1);
     initData.add(initData2);
 
+    testConversionToFrameworkFormatV16(MediaFormat.createVideoFormat(
+        MediaFormat.NO_VALUE, "video/xyz", 5000, 102400, 1000L, 1280, 720, initData));
+    testConversionToFrameworkFormatV16(MediaFormat.createVideoFormat(
+        MediaFormat.NO_VALUE, "video/xyz", 5000, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US, 1280, 720,
+        null));
+    testConversionToFrameworkFormatV16(MediaFormat.createAudioFormat(
+        MediaFormat.NO_VALUE, "audio/xyz", 500, 128, 1000L, 5, 44100, initData, null));
+    testConversionToFrameworkFormatV16(MediaFormat.createAudioFormat(
+        MediaFormat.NO_VALUE, "audio/xyz", 500, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US, 5, 44100,
+        null, null));
     testConversionToFrameworkFormatV16(
-        MediaFormat.createVideoFormat("video/xyz", 102400, 1000L, 1280, 720, 1.5f, initData));
+        MediaFormat.createTextFormat(MediaFormat.NO_VALUE, "text/xyz", MediaFormat.NO_VALUE, 1000L,
+            "eng"));
     testConversionToFrameworkFormatV16(
-        MediaFormat.createAudioFormat("audio/xyz", 102400, 1000L, 5, 44100, initData));
+        MediaFormat.createTextFormat(MediaFormat.NO_VALUE, "text/xyz", MediaFormat.NO_VALUE,
+            C.UNKNOWN_TIME_US, null));
   }
 
+  @SuppressLint("InlinedApi")
   @TargetApi(16)
-  private void testConversionToFrameworkFormatV16(MediaFormat format) {
-    // Convert to a framework MediaFormat and back again.
-    MediaFormat convertedFormat = MediaFormat.createFromFrameworkMediaFormatV16(
-        format.getFrameworkMediaFormatV16());
-    // Assert that we end up with an equivalent object to the one we started with.
-    assertEquals(format.hashCode(), convertedFormat.hashCode());
-    assertEquals(format, convertedFormat);
+  private static void testConversionToFrameworkFormatV16(MediaFormat in) {
+    android.media.MediaFormat out = in.getFrameworkMediaFormatV16();
+    assertEquals(in.mimeType, out.getString(android.media.MediaFormat.KEY_MIME));
+    assertOptionalV16(out, android.media.MediaFormat.KEY_LANGUAGE, in.language);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_MAX_INPUT_SIZE, in.maxInputSize);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_WIDTH, in.width);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_HEIGHT, in.height);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_CHANNEL_COUNT, in.channelCount);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_SAMPLE_RATE, in.sampleRate);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_MAX_WIDTH, in.maxWidth);
+    assertOptionalV16(out, android.media.MediaFormat.KEY_MAX_HEIGHT, in.maxHeight);
+    for (int i = 0; i < in.initializationData.size(); i++) {
+      byte[] originalData = in.initializationData.get(i);
+      ByteBuffer frameworkBuffer = out.getByteBuffer("csd-" + i);
+      byte[] frameworkData = Arrays.copyOf(frameworkBuffer.array(), frameworkBuffer.limit());
+      assertTrue(Arrays.equals(originalData, frameworkData));
+    }
+    if (in.durationUs == C.UNKNOWN_TIME_US) {
+      assertFalse(out.containsKey(android.media.MediaFormat.KEY_DURATION));
+    } else {
+      assertEquals(in.durationUs, out.getLong(android.media.MediaFormat.KEY_DURATION));
+    }
+  }
+
+  @TargetApi(16)
+  private static void assertOptionalV16(android.media.MediaFormat format, String key,
+      String value) {
+    if (value == null) {
+      assertFalse(format.containsKey(key));
+    } else {
+      assertEquals(value, format.getString(key));
+    }
+  }
+
+  @TargetApi(16)
+  private static void assertOptionalV16(android.media.MediaFormat format, String key,
+      int value) {
+    if (value == MediaFormat.NO_VALUE) {
+      assertFalse(format.containsKey(key));
+    } else {
+      assertEquals(value, format.getInteger(key));
+    }
   }
 
 }
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/TimeRangeTest.java b/library/src/androidTest/java/com/google/android/exoplayer/TimeRangeTest.java
index 58df649d65..dee65dd768 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/TimeRangeTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/TimeRangeTest.java
@@ -15,6 +15,8 @@
  */
 package com.google.android.exoplayer;
 
+import com.google.android.exoplayer.TimeRange.StaticTimeRange;
+
 import junit.framework.TestCase;
 
 /**
@@ -22,14 +24,14 @@
  */
 public class TimeRangeTest extends TestCase {
 
-  public void testEquals() {
-    TimeRange timeRange1 = new TimeRange(TimeRange.TYPE_SNAPSHOT, 0, 30000000);
+  public void testStaticEquals() {
+    TimeRange timeRange1 = new StaticTimeRange(0, 30000000);
     assertTrue(timeRange1.equals(timeRange1));
 
-    TimeRange timeRange2 = new TimeRange(TimeRange.TYPE_SNAPSHOT, 0, 30000000);
+    TimeRange timeRange2 = new StaticTimeRange(0, 30000000);
     assertTrue(timeRange1.equals(timeRange2));
 
-    TimeRange timeRange3 = new TimeRange(TimeRange.TYPE_SNAPSHOT, 0, 60000000);
+    TimeRange timeRange3 = new StaticTimeRange(0, 60000000);
     assertFalse(timeRange1.equals(timeRange3));
   }
 
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/dash/DashChunkSourceTest.java b/library/src/androidTest/java/com/google/android/exoplayer/dash/DashChunkSourceTest.java
index db387c179a..955d10ada5 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/dash/DashChunkSourceTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/dash/DashChunkSourceTest.java
@@ -18,13 +18,10 @@
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
-import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.TimeRange;
-import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.chunk.ChunkOperationHolder;
 import com.google.android.exoplayer.chunk.Format;
-import com.google.android.exoplayer.chunk.FormatEvaluator;
-import com.google.android.exoplayer.chunk.FormatEvaluator.FixedEvaluator;
+import com.google.android.exoplayer.chunk.InitializationChunk;
 import com.google.android.exoplayer.chunk.MediaChunk;
 import com.google.android.exoplayer.dash.mpd.AdaptationSet;
 import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
@@ -41,11 +38,10 @@
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.util.FakeClock;
 import com.google.android.exoplayer.util.ManifestFetcher;
+import com.google.android.exoplayer.util.Util;
 
 import android.test.InstrumentationTestCase;
 
-import org.mockito.Mock;
-
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
@@ -55,8 +51,6 @@
  */
 public class DashChunkSourceTest extends InstrumentationTestCase {
 
-  private static final FormatEvaluator EVALUATOR = new FixedEvaluator();
-
   private static final long VOD_DURATION_MS = 30000;
 
   private static final long LIVE_SEGMENT_COUNT = 5;
@@ -64,12 +58,12 @@
   private static final long LIVE_DURATION_MS = LIVE_SEGMENT_COUNT * LIVE_SEGMENT_DURATION_MS;
   private static final long LIVE_TIMESHIFT_BUFFER_DEPTH_MS = LIVE_DURATION_MS;
 
-  private static final long AVAILABILITY_START_TIME_MS = 60000;
-  private static final long AVAILABILITY_REALTIME_OFFSET_MS = 1000;
-  private static final long AVAILABILITY_CURRENT_TIME_MS =
-      AVAILABILITY_START_TIME_MS + LIVE_TIMESHIFT_BUFFER_DEPTH_MS - AVAILABILITY_REALTIME_OFFSET_MS;
+  private static final int MULTI_PERIOD_COUNT = 2;
+  private static final long MULTI_PERIOD_VOD_DURATION_MS = VOD_DURATION_MS * MULTI_PERIOD_COUNT;
+  private static final long MULTI_PERIOD_LIVE_DURATION_MS = LIVE_DURATION_MS * MULTI_PERIOD_COUNT;
 
-  private static final long LIVE_SEEK_BEYOND_EDGE_MS = 60000;
+  private static final long AVAILABILITY_START_TIME_MS = 60000;
+  private static final long ELAPSED_REALTIME_OFFSET_MS = 1000;
 
   private static final int TALL_HEIGHT = 200;
   private static final int WIDE_WIDTH = 400;
@@ -81,385 +75,420 @@
   private static final Format WIDE_VIDEO =
       new Format("3", "video/mp4", WIDE_WIDTH, 50, -1, -1, -1, 1000);
 
-  @Mock private DataSource mockDataSource;
-
   @Override
   public void setUp() throws Exception {
     TestUtil.setUpMockito(this);
   }
 
-  public void testMaxVideoDimensions() {
-    DashChunkSource chunkSource = new DashChunkSource(generateVodMpd(), AdaptationSet.TYPE_VIDEO,
-        null, null, null);
-    MediaFormat out = MediaFormat.createVideoFormat("video/h264", 1, 1, 1, 1, null);
-    chunkSource.getMaxVideoDimensions(out);
+  public void testGetAvailableRangeOnVod() {
+    DashChunkSource chunkSource = new DashChunkSource(buildVodMpd(),
+        DefaultDashTrackSelector.newVideoInstance(null, false, false), null, null);
+    chunkSource.prepare();
+    chunkSource.enable(0);
+    TimeRange availableRange = chunkSource.getAvailableRange();
 
-    assertEquals(WIDE_WIDTH, out.getMaxVideoWidth());
-    assertEquals(TALL_HEIGHT, out.getMaxVideoHeight());
-  }
+    checkAvailableRange(availableRange, 0, VOD_DURATION_MS * 1000);
 
-  public void testGetSeekRangeOnVod() {
-    DashChunkSource chunkSource = new DashChunkSource(generateVodMpd(), AdaptationSet.TYPE_VIDEO,
-        null, null, mock(FormatEvaluator.class));
-    chunkSource.enable();
-    TimeRange seekRange = chunkSource.getSeekRange();
-
-    checkSeekRange(seekRange, 0, VOD_DURATION_MS * 1000);
-
-    long[] seekRangeValuesMs = seekRange.getCurrentBoundsMs(null);
+    long[] seekRangeValuesMs = availableRange.getCurrentBoundsMs(null);
     assertEquals(0, seekRangeValuesMs[0]);
     assertEquals(VOD_DURATION_MS, seekRangeValuesMs[1]);
   }
 
-  public void testMaxVideoDimensionsLegacy() {
-    SingleSegmentBase segmentBase1 = new SingleSegmentBase("https://example.com/1.mp4");
-    Representation representation1 =
-        Representation.newInstance(0, 0, null, 0, TALL_VIDEO, segmentBase1);
-
-    SingleSegmentBase segmentBase2 = new SingleSegmentBase("https://example.com/2.mp4");
-    Representation representation2 =
-        Representation.newInstance(0, 0, null, 0, WIDE_VIDEO, segmentBase2);
-
-    DashChunkSource chunkSource = new DashChunkSource(null, null, representation1, representation2);
-    MediaFormat out = MediaFormat.createVideoFormat("video/h264", 1, 1, 1, 1, null);
-    chunkSource.getMaxVideoDimensions(out);
-
-    assertEquals(WIDE_WIDTH, out.getMaxVideoWidth());
-    assertEquals(TALL_HEIGHT, out.getMaxVideoHeight());
-  }
-
-  public void testLiveEdgeNoLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 0;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 4000;
-    long chunkEndTimeMs = 5000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
-
-  public void testLiveEdgeAlmostNoLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 1;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 4000;
-    long chunkEndTimeMs = 5000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
-
-  public void testLiveEdge500msLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 500;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 4000;
-    long chunkEndTimeMs = 5000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  public void testGetAvailableRangeOnLiveWithTimeline() {
+    MediaPresentationDescription mpd = buildLiveMpdWithTimeline(LIVE_DURATION_MS, 0);
+    DashChunkSource chunkSource = buildDashChunkSource(mpd);
+    TimeRange availableRange = chunkSource.getAvailableRange();
+    checkAvailableRange(availableRange, 0, LIVE_DURATION_MS * 1000);
   }
 
-  public void testLiveEdge1000msLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 1000;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 4000;
-    long chunkEndTimeMs = 5000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  public void testGetAvailableRangeOnMultiPeriodVod() {
+    DashChunkSource chunkSource = new DashChunkSource(buildMultiPeriodVodMpd(),
+        DefaultDashTrackSelector.newVideoInstance(null, false, false), null, null);
+    chunkSource.prepare();
+    chunkSource.enable(0);
+    TimeRange availableRange = chunkSource.getAvailableRange();
+    checkAvailableRange(availableRange, 0, MULTI_PERIOD_VOD_DURATION_MS * 1000);
   }
 
-  public void testLiveEdge1001msLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 1001;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 3000;
-    long chunkEndTimeMs = 4000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  public void testGetSeekRangeOnMultiPeriodLiveWithTimeline() {
+    MediaPresentationDescription mpd = buildMultiPeriodLiveMpdWithTimeline();
+    DashChunkSource chunkSource = buildDashChunkSource(mpd);
+    TimeRange availableRange = chunkSource.getAvailableRange();
+    checkAvailableRange(availableRange, 0, MULTI_PERIOD_LIVE_DURATION_MS * 1000);
   }
 
-  public void testLiveEdge2500msLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 2500;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 2000;
-    long chunkEndTimeMs = 3000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
+  public void testSegmentIndexInitializationOnVod() {
+    DashChunkSource chunkSource = new DashChunkSource(buildVodMpd(),
+        DefaultDashTrackSelector.newVideoInstance(null, false, false), mock(DataSource.class),
+        null);
+    chunkSource.prepare();
+    chunkSource.enable(0);
 
-  public void testLiveEdgeVeryHighLatency() {
-    long startTimeMs = 0;
-    long liveEdgeLatencyMs = 10000;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 0;
-    long seekRangeEndMs = 0;
-    long chunkStartTimeMs = 0;
-    long chunkEndTimeMs = 1000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
-
-  public void testLiveEdgeNoLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 0;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 7000;
-    long chunkEndTimeMs = 8000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
-
-  public void testLiveEdgeAlmostNoLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 1;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 7000;
-    long chunkEndTimeMs = 8000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
+    List<MediaChunk> queue = new ArrayList<>();
+    ChunkOperationHolder out = new ChunkOperationHolder();
 
-  public void testLiveEdge500msLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 500;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 7000;
-    long chunkEndTimeMs = 8000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
+    // request first chunk; should get back initialization chunk
+    chunkSource.getChunkOperation(queue, 0, 0, out);
 
-  public void testLiveEdge1000msLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 1000;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 7000;
-    long chunkEndTimeMs = 8000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-  }
-
-  public void testLiveEdge1001msLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 1001;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 6000;
-    long chunkEndTimeMs = 7000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    assertNotNull(out.chunk);
+    assertNotNull(((InitializationChunk) out.chunk).dataSpec);
   }
 
-  public void testLiveEdge2500msLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 2500;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000 + LIVE_DURATION_MS - liveEdgeLatencyMs;
-    long chunkStartTimeMs = 5000;
-    long chunkEndTimeMs = 6000;
-
-    checkLiveTimelineConsistency(startTimeMs, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  public void testSegmentRequestSequenceOnMultiPeriodLiveWithTimeline() {
+    MediaPresentationDescription mpd = buildMultiPeriodLiveMpdWithTimeline();
+    DashChunkSource chunkSource = buildDashChunkSource(mpd);
+    checkSegmentRequestSequenceOnMultiPeriodLive(chunkSource);
   }
 
-  public void testLiveEdgeVeryHighLatencyInProgress() {
-    long startTimeMs = 3000;
-    long liveEdgeLatencyMs = 10000;
-    long seekPositionMs = LIVE_SEEK_BEYOND_EDGE_MS;
-    long seekRangeStartMs = 3000;
-    long seekRangeEndMs = 3000;
-    long chunkStartTimeMs = 3000;
-    long chunkEndTimeMs = 4000;
-
-    checkLiveEdgeLatencyWithTimeline(startTimeMs, 0, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-    checkLiveEdgeLatencyWithTemplateAndUnlimitedTimeshift(startTimeMs, liveEdgeLatencyMs,
-        seekPositionMs, 0, 0, 1000);
-    checkLiveEdgeLatencyWithTemplateAndLimitedTimeshift(startTimeMs, liveEdgeLatencyMs,
-        seekPositionMs, seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  public void testSegmentRequestSequenceOnMultiPeriodLiveWithTemplate() {
+    MediaPresentationDescription mpd = buildMultiPeriodLiveMpdWithTemplate();
+    DashChunkSource chunkSource = buildDashChunkSource(mpd);
+    checkSegmentRequestSequenceOnMultiPeriodLive(chunkSource);
   }
 
-  private static Representation generateVodRepresentation(long startTimeMs, long duration,
-      Format format) {
-    SingleSegmentBase segmentBase = new SingleSegmentBase("https://example.com/1.mp4");
-    return Representation.newInstance(startTimeMs, duration, null, 0, format, segmentBase);
-  }
+  public void testLiveEdgeLatency() {
+    long availableRangeStartMs = 0;
+    long availableRangeEndMs = LIVE_DURATION_MS;
+    long seekPositionMs = LIVE_DURATION_MS;
 
-  private static Representation generateSegmentTimelineRepresentation(long segmentStartMs,
-      long periodStartMs, long duration) {
+    long chunkStartTimeMs = 4000;
+    long chunkEndTimeMs = 5000;
+    // Test with 1-1000ms latency.
+    long liveEdgeLatency = 1;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    liveEdgeLatency = 1000;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+
+    chunkStartTimeMs = 3000;
+    chunkEndTimeMs = 4000;
+    // Test with 1001-2000ms latency.
+    liveEdgeLatency = 1001;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    liveEdgeLatency = 2000;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+
+    chunkStartTimeMs = 0;
+    chunkEndTimeMs = 1000;
+    // Test with 9001-10000 latency.
+    liveEdgeLatency = 9001;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    liveEdgeLatency = 10000;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+
+    // Test with 10001 latency. Seek position will be bounded to the first chunk.
+    liveEdgeLatency = 10001;
+    checkLiveEdgeConsistency(LIVE_DURATION_MS, 0, liveEdgeLatency, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  }
+
+  // Private methods.
+
+  private static Representation buildVodRepresentation(Format format) {
+    RangedUri rangedUri = new RangedUri("https://example.com/1.mp4", null, 0, 100);
+    SingleSegmentBase segmentBase = new SingleSegmentBase(rangedUri, 1, 0,
+        "https://example.com/1.mp4", 0, -1);
+    return Representation.newInstance(null, 0, format, segmentBase);
+  }
+
+  private static Representation buildSegmentTimelineRepresentation(long timelineDurationMs,
+      long timelineStartTimeMs) {
     List<SegmentTimelineElement> segmentTimeline = new ArrayList<>();
     List<RangedUri> mediaSegments = new ArrayList<>();
-    long segmentStartTimeMs = segmentStartMs;
+    long segmentStartTimeMs = timelineStartTimeMs;
     long byteStart = 0;
-    for (int i = 0; i < (duration / LIVE_SEGMENT_DURATION_MS); i++) {
+    // Create all but the last segment with LIVE_SEGMENT_DURATION_MS.
+    int segmentCount = (int) Util.ceilDivide(timelineDurationMs, LIVE_SEGMENT_DURATION_MS);
+    for (int i = 0; i < segmentCount - 1; i++) {
       segmentTimeline.add(new SegmentTimelineElement(segmentStartTimeMs, LIVE_SEGMENT_DURATION_MS));
       mediaSegments.add(new RangedUri("", "", byteStart, 500L));
       segmentStartTimeMs += LIVE_SEGMENT_DURATION_MS;
       byteStart += 500;
     }
-
-    int startNumber = (int) ((periodStartMs + segmentStartMs) / LIVE_SEGMENT_DURATION_MS);
-    MultiSegmentBase segmentBase = new SegmentList(null, 1000, 0,
-        TrackRenderer.UNKNOWN_TIME_US, startNumber, TrackRenderer.UNKNOWN_TIME_US, segmentTimeline,
+    // The final segment duration is calculated so that the total duration is timelineDurationMs.
+    long finalSegmentDurationMs = (timelineStartTimeMs + timelineDurationMs) - segmentStartTimeMs;
+    segmentTimeline.add(new SegmentTimelineElement(segmentStartTimeMs, finalSegmentDurationMs));
+    mediaSegments.add(new RangedUri("", "", byteStart, 500L));
+    segmentStartTimeMs += finalSegmentDurationMs;
+    byteStart += 500;
+    // Construct the list.
+    MultiSegmentBase segmentBase = new SegmentList(null, 1000, 0, 0, 0, segmentTimeline,
         mediaSegments);
-    return Representation.newInstance(periodStartMs, TrackRenderer.UNKNOWN_TIME_US, null, 0,
-        REGULAR_VIDEO, segmentBase);
+    return Representation.newInstance(null, 0, REGULAR_VIDEO, segmentBase);
   }
 
-  private static MediaPresentationDescription generateMpd(boolean live,
-      List<Representation> representations, boolean limitTimeshiftBuffer) {
-    Representation firstRepresentation = representations.get(0);
-    AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_UNKNOWN, representations);
-    Period period = new Period(null, firstRepresentation.periodStartMs,
-        firstRepresentation.periodDurationMs, Collections.singletonList(adaptationSet));
-    long duration = (live) ? TrackRenderer.UNKNOWN_TIME_US
-        : firstRepresentation.periodDurationMs - firstRepresentation.periodStartMs;
-    return new MediaPresentationDescription(AVAILABILITY_START_TIME_MS, duration, -1, live, -1,
+  private static Representation buildSegmentTemplateRepresentation() {
+    UrlTemplate initializationTemplate = null;
+    UrlTemplate mediaTemplate = UrlTemplate.compile("$RepresentationID$/$Number$");
+    MultiSegmentBase segmentBase = new SegmentTemplate(null, 1000, 0, 0, LIVE_SEGMENT_DURATION_MS,
+        null, initializationTemplate, mediaTemplate, "http://www.youtube.com");
+    return Representation.newInstance(null, 0, REGULAR_VIDEO, segmentBase);
+  }
+
+  private static MediaPresentationDescription buildMpd(long durationMs,
+      List<Representation> representations, boolean live, boolean limitTimeshiftBuffer) {
+    AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_VIDEO, representations);
+    Period period = new Period(null, 0, Collections.singletonList(adaptationSet));
+    return new MediaPresentationDescription(AVAILABILITY_START_TIME_MS, durationMs, -1, live, -1,
         (limitTimeshiftBuffer) ? LIVE_TIMESHIFT_BUFFER_DEPTH_MS : -1, null, null,
         Collections.singletonList(period));
   }
 
-  private static MediaPresentationDescription generateVodMpd() {
-    List<Representation> representations = new ArrayList<>();
-
-    representations.add(generateVodRepresentation(0, VOD_DURATION_MS, TALL_VIDEO));
-    representations.add(generateVodRepresentation(0, VOD_DURATION_MS, WIDE_VIDEO));
+  private static MediaPresentationDescription buildMultiPeriodMpd(long durationMs,
+      List<Period> periods, boolean live, boolean limitTimeshiftBuffer) {
+    return new MediaPresentationDescription(AVAILABILITY_START_TIME_MS, durationMs, -1, live, -1,
+        (limitTimeshiftBuffer) ? LIVE_TIMESHIFT_BUFFER_DEPTH_MS : -1,
+        null, null, periods);
+  }
 
-    return generateMpd(false, representations, false);
+  private static MediaPresentationDescription buildVodMpd() {
+    List<Representation> representations = new ArrayList<>();
+    representations.add(buildVodRepresentation(TALL_VIDEO));
+    representations.add(buildVodRepresentation(WIDE_VIDEO));
+    return buildMpd(VOD_DURATION_MS, representations, false, false);
+  }
+
+  private static MediaPresentationDescription buildMultiPeriodVodMpd() {
+    List<Period> periods = new ArrayList<>();
+    long timeMs = 0;
+    long periodDurationMs = VOD_DURATION_MS;
+    for (int i = 0; i < 2; i++) {
+      Representation representation = buildVodRepresentation(REGULAR_VIDEO);
+      AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_VIDEO,
+          Collections.singletonList(representation));
+      Period period = new Period(null, timeMs, Collections.singletonList(adaptationSet));
+      periods.add(period);
+      timeMs += periodDurationMs;
+    }
+    return buildMultiPeriodMpd(timeMs, periods, false, false);
   }
 
-  private static MediaPresentationDescription generateLiveMpdWithTimeline(long segmentStartMs,
-      long periodStartMs, long durationMs) {
-    return generateMpd(true, Collections.singletonList(generateSegmentTimelineRepresentation(
-        segmentStartMs, periodStartMs, durationMs)), false);
+  private static MediaPresentationDescription buildLiveMpdWithTimeline(long durationMs,
+      long timelineStartTimeMs) {
+    Representation representation = buildSegmentTimelineRepresentation(
+        durationMs - timelineStartTimeMs, timelineStartTimeMs);
+    return buildMpd(durationMs, Collections.singletonList(representation), true, false);
   }
 
-  private static MediaPresentationDescription generateLiveMpdWithTemplate(
+  private static MediaPresentationDescription buildLiveMpdWithTemplate(long durationMs,
       boolean limitTimeshiftBuffer) {
-    List<Representation> representations = new ArrayList<>();
+    Representation representation = buildSegmentTemplateRepresentation();
+    return buildMpd(durationMs, Collections.singletonList(representation), true,
+        limitTimeshiftBuffer);
+  }
+
+  private static MediaPresentationDescription buildMultiPeriodLiveMpdWithTimeline() {
+    List<Period> periods = new ArrayList<>();
+    long periodStartTimeMs = 0;
+    long periodDurationMs = LIVE_DURATION_MS;
+    for (int i = 0; i < MULTI_PERIOD_COUNT; i++) {
+      Representation representation = buildSegmentTimelineRepresentation(LIVE_DURATION_MS, 0);
+      AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_VIDEO,
+          Collections.singletonList(representation));
+      Period period = new Period(null, periodStartTimeMs, Collections.singletonList(adaptationSet));
+      periods.add(period);
+      periodStartTimeMs += periodDurationMs;
+    }
+    return buildMultiPeriodMpd(periodDurationMs, periods, true, false);
+  }
+
+  private static MediaPresentationDescription buildMultiPeriodLiveMpdWithTemplate() {
+    List<Period> periods = new ArrayList<>();
+    long periodStartTimeMs = 0;
+    long periodDurationMs = LIVE_DURATION_MS;
+    for (int i = 0; i < MULTI_PERIOD_COUNT; i++) {
+      Representation representation = buildSegmentTemplateRepresentation();
+      AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_VIDEO,
+          Collections.singletonList(representation));
+      Period period = new Period(null, periodStartTimeMs, Collections.singletonList(adaptationSet));
+      periods.add(period);
+      periodStartTimeMs += periodDurationMs;
+    }
+    return buildMultiPeriodMpd(MULTI_PERIOD_LIVE_DURATION_MS, periods, true, false);
+  }
 
-    UrlTemplate initializationTemplate = null;
-    UrlTemplate mediaTemplate = UrlTemplate.compile("$RepresentationID$/$Number$");
-    MultiSegmentBase segmentBase = new SegmentTemplate(null, 1000, 0,
-        TrackRenderer.UNKNOWN_TIME_US, 0, LIVE_SEGMENT_DURATION_MS, null,
-        initializationTemplate, mediaTemplate, "http://www.youtube.com");
-    Representation representation = Representation.newInstance(0, TrackRenderer.UNKNOWN_TIME_US,
-        null, 0, REGULAR_VIDEO, segmentBase);
-    representations.add(representation);
-
-    return generateMpd(true, representations, limitTimeshiftBuffer);
+  private static DashChunkSource buildDashChunkSource(MediaPresentationDescription mpd) {
+    return buildDashChunkSource(mpd, false, 0);
   }
 
-  private DashChunkSource setupDashChunkSource(MediaPresentationDescription mpd, long periodStartMs,
-      long liveEdgeLatencyMs) {
+  private static DashChunkSource buildDashChunkSource(MediaPresentationDescription mpd,
+      boolean startAtLiveEdge, long liveEdgeLatencyMs) {
     @SuppressWarnings("unchecked")
     ManifestFetcher<MediaPresentationDescription> manifestFetcher = mock(ManifestFetcher.class);
     when(manifestFetcher.getManifest()).thenReturn(mpd);
     DashChunkSource chunkSource = new DashChunkSource(manifestFetcher, mpd,
-        AdaptationSet.TYPE_VIDEO, null, mockDataSource, EVALUATOR,
-        new FakeClock(AVAILABILITY_CURRENT_TIME_MS + periodStartMs), liveEdgeLatencyMs * 1000,
-        AVAILABILITY_REALTIME_OFFSET_MS * 1000, false, null, null);
-    chunkSource.enable();
+        DefaultDashTrackSelector.newVideoInstance(null, false, false), mock(DataSource.class), null,
+        new FakeClock(mpd.availabilityStartTime + mpd.duration - ELAPSED_REALTIME_OFFSET_MS),
+        liveEdgeLatencyMs * 1000, ELAPSED_REALTIME_OFFSET_MS * 1000, startAtLiveEdge, null, null);
+    chunkSource.prepare();
+    chunkSource.enable(0);
     return chunkSource;
   }
 
-  private void checkSeekRange(TimeRange seekRange, long startTimeUs, long endTimeUs) {
+  private static void checkAvailableRange(TimeRange seekRange, long startTimeUs, long endTimeUs) {
     long[] seekRangeValuesUs = seekRange.getCurrentBoundsUs(null);
     assertEquals(startTimeUs, seekRangeValuesUs[0]);
     assertEquals(endTimeUs, seekRangeValuesUs[1]);
   }
 
-  private void checkLiveEdgeLatency(DashChunkSource chunkSource, List<MediaChunk> queue,
-      ChunkOperationHolder out, long seekPositionMs, long seekRangeStartMs, long seekRangeEndMs,
-      long chunkStartTimeMs, long chunkEndTimeMs) {
-    chunkSource.getChunkOperation(queue, seekPositionMs * 1000, 0, out);
-    TimeRange seekRange = chunkSource.getSeekRange();
+  private static void checkLiveEdgeConsistency(long durationMs, long timelineStartMs,
+      long liveEdgeLatencyMs, long seekPositionMs, long availableRangeStartMs,
+      long availableRangeEndMs, long chunkStartTimeMs, long chunkEndTimeMs) {
+    checkLiveEdgeConsistencyWithTimeline(durationMs, timelineStartMs, liveEdgeLatencyMs,
+        seekPositionMs, availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs,
+        chunkEndTimeMs);
+    checkLiveEdgeConsistencyWithTemplateAndUnlimitedTimeshift(durationMs, liveEdgeLatencyMs,
+        seekPositionMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    checkLiveEdgeConsistencyWithTemplateAndLimitedTimeshift(durationMs, liveEdgeLatencyMs,
+        seekPositionMs, availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs,
+        chunkEndTimeMs);
+  }
 
-    assertNotNull(out.chunk);
-    checkSeekRange(seekRange, seekRangeStartMs * 1000, seekRangeEndMs * 1000);
-    assertEquals(chunkStartTimeMs * 1000, ((MediaChunk) out.chunk).startTimeUs);
-    assertEquals(chunkEndTimeMs * 1000, ((MediaChunk) out.chunk).endTimeUs);
+  private static void checkLiveEdgeConsistencyWithTimeline(long durationMs, long timelineStartMs,
+      long liveEdgeLatencyMs, long seekPositionMs, long availableRangeStartMs,
+      long availableRangeEndMs, long chunkStartTimeMs, long chunkEndTimeMs) {
+    MediaPresentationDescription mpd = buildLiveMpdWithTimeline(durationMs, timelineStartMs);
+    checkLiveEdgeConsistency(mpd, liveEdgeLatencyMs, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
   }
 
-  private void checkLiveEdgeLatency(MediaPresentationDescription mpd, long periodStartMs,
-      long liveEdgeLatencyMs, long seekPositionMs, long seekRangeStartMs, long seekRangeEndMs,
+  private static void checkLiveEdgeConsistencyWithTemplateAndUnlimitedTimeshift(long durationMs,
+      long liveEdgeLatencyMs, long availablePositionMs, long availableRangeEndMs,
       long chunkStartTimeMs, long chunkEndTimeMs) {
-    DashChunkSource chunkSource = setupDashChunkSource(mpd, periodStartMs, liveEdgeLatencyMs);
-    List<MediaChunk> queue = new ArrayList<>();
-    ChunkOperationHolder out = new ChunkOperationHolder();
-    checkLiveEdgeLatency(chunkSource, queue, out, seekPositionMs, seekRangeStartMs, seekRangeEndMs,
-        chunkStartTimeMs, chunkEndTimeMs);
+    MediaPresentationDescription mpd = buildLiveMpdWithTemplate(durationMs, false);
+    checkLiveEdgeConsistency(mpd, liveEdgeLatencyMs, availablePositionMs, 0,
+        availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
   }
 
-  private void checkLiveEdgeLatencyWithTimeline(long segmentStartMs, long periodStartMs,
-      long liveEdgeLatencyMs, long seekPositionMs, long seekRangeStartMs, long seekRangeEndMs,
-      long chunkStartTimeMs, long chunkEndTimeMs) {
-    MediaPresentationDescription mpd = generateLiveMpdWithTimeline(segmentStartMs, periodStartMs,
-        LIVE_DURATION_MS);
-    checkLiveEdgeLatency(mpd, periodStartMs, liveEdgeLatencyMs, seekPositionMs, seekRangeStartMs,
-        seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  private static void checkLiveEdgeConsistencyWithTemplateAndLimitedTimeshift(long durationMs,
+      long liveEdgeLatencyMs, long seekPositionMs, long availableRangeStartMs,
+      long availableRangeEndMs, long chunkStartTimeMs, long chunkEndTimeMs) {
+    MediaPresentationDescription mpd = buildLiveMpdWithTemplate(durationMs, true);
+    checkLiveEdgeConsistency(mpd, liveEdgeLatencyMs, seekPositionMs, availableRangeStartMs,
+        availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
   }
 
-  private void checkLiveEdgeLatencyWithTemplateAndUnlimitedTimeshift(long startTimeMs,
-      long liveEdgeLatencyMs, long seekPositionMs, long seekRangeEndMs,
-      long chunkStartTimeMs, long chunkEndTimeMs) {
-    MediaPresentationDescription mpd = generateLiveMpdWithTemplate(false);
-    checkLiveEdgeLatency(mpd, startTimeMs, liveEdgeLatencyMs, seekPositionMs, 0, seekRangeEndMs,
-        chunkStartTimeMs, chunkEndTimeMs);
+  private static void checkLiveEdgeConsistency(MediaPresentationDescription mpd,
+      long liveEdgeLatencyMs, long seekPositionMs, long availableRangeStartMs,
+      long availableRangeEndMs, long chunkStartTimeMs, long chunkEndTimeMs) {
+    DashChunkSource chunkSource = buildDashChunkSource(mpd, true, liveEdgeLatencyMs);
+    List<MediaChunk> queue = new ArrayList<>();
+    ChunkOperationHolder out = new ChunkOperationHolder();
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs, availableRangeStartMs,
+        availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
   }
 
-  private void checkLiveEdgeLatencyWithTemplateAndLimitedTimeshift(long startTimeMs,
-      long liveEdgeLatencyMs, long seekPositionMs, long seekRangeStartMs, long seekRangeEndMs,
-      long chunkStartTimeMs, long chunkEndTimeMs) {
-    MediaPresentationDescription mpd = generateLiveMpdWithTemplate(true);
-    checkLiveEdgeLatency(mpd, startTimeMs, liveEdgeLatencyMs, seekPositionMs, seekRangeStartMs,
-        seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  private static void checkLiveEdgeConsistency(DashChunkSource chunkSource, List<MediaChunk> queue,
+      ChunkOperationHolder out, long seekPositionMs, long availableRangeStartMs,
+      long availableRangeEndMs, long chunkStartTimeMs, long chunkEndTimeMs) {
+    chunkSource.getChunkOperation(queue, seekPositionMs * 1000, 0, out);
+    TimeRange availableRange = chunkSource.getAvailableRange();
+    checkAvailableRange(availableRange, availableRangeStartMs * 1000, availableRangeEndMs * 1000);
+    if (chunkStartTimeMs < availableRangeEndMs) {
+      assertNotNull(out.chunk);
+      assertEquals(chunkStartTimeMs * 1000, ((MediaChunk) out.chunk).startTimeUs);
+      assertEquals(chunkEndTimeMs * 1000, ((MediaChunk) out.chunk).endTimeUs);
+    } else {
+      assertNull(out.chunk);
+    }
   }
 
-  private void checkLiveTimelineConsistency(long startTimeMs, long liveEdgeLatencyMs,
-      long seekPositionMs, long seekRangeStartMs, long seekRangeEndMs, long chunkStartTimeMs,
-      long chunkEndTimeMs) {
-    checkLiveEdgeLatencyWithTimeline(startTimeMs, 0, liveEdgeLatencyMs, seekPositionMs,
-        seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-    checkLiveEdgeLatencyWithTemplateAndUnlimitedTimeshift(startTimeMs, liveEdgeLatencyMs,
-        seekPositionMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
-    checkLiveEdgeLatencyWithTemplateAndLimitedTimeshift(startTimeMs, liveEdgeLatencyMs,
-        seekPositionMs, seekRangeStartMs, seekRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+  private static void checkSegmentRequestSequenceOnMultiPeriodLive(DashChunkSource chunkSource) {
+    List<MediaChunk> queue = new ArrayList<>();
+    ChunkOperationHolder out = new ChunkOperationHolder();
+
+    long seekPositionMs = 0;
+    long availableRangeStartMs = 0;
+    long availableRangeEndMs = MULTI_PERIOD_LIVE_DURATION_MS;
+    long chunkStartTimeMs = 0;
+    long chunkEndTimeMs = 1000;
+
+    // request first chunk
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request second chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request third chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request fourth chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request fifth chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request sixth chunk; this is the first chunk in the 2nd period
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request seventh chunk;
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request eigth chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request ninth chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request tenth chunk
+    chunkStartTimeMs += 1000;
+    chunkEndTimeMs += 1000;
+    out.chunk = null;
+    checkLiveEdgeConsistency(chunkSource, queue, out, seekPositionMs,
+        availableRangeStartMs, availableRangeEndMs, chunkStartTimeMs, chunkEndTimeMs);
+    queue.add((MediaChunk) out.chunk);
+
+    // request "eleventh" chunk; this chunk isn't available yet, so we should get null
+    out.chunk = null;
+    chunkSource.getChunkOperation(queue, seekPositionMs * 1000, 0, out);
+    assertNull(out.chunk);
   }
 
 }
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/dash/mpd/RepresentationTest.java b/library/src/androidTest/java/com/google/android/exoplayer/dash/mpd/RepresentationTest.java
index dc0ca5047b..03f987cff6 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/dash/mpd/RepresentationTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/dash/mpd/RepresentationTest.java
@@ -30,12 +30,11 @@ public void testGetCacheKey() {
     String uri = "http://www.google.com";
     SegmentBase base = new SingleSegmentBase(new RangedUri(uri, null, 0, 1), 1, 0, uri, 1, 1);
     Format format = new Format("0", MimeTypes.VIDEO_MP4, 1920, 1080, -1, 0, 0, 2500000);
-    Representation representation = Representation.newInstance(-1, -1, "test_stream_1", 3,
-        format, base);
+    Representation representation = Representation.newInstance("test_stream_1", 3, format, base);
     assertEquals("test_stream_1.0.3", representation.getCacheKey());
 
     format = new Format("150", MimeTypes.VIDEO_MP4, 1920, 1080, -1, 0, 0, 2500000);
-    representation = Representation.newInstance(-1, -1, "test_stream_1", -1, format, base);
+    representation = Representation.newInstance("test_stream_1", -1, format, base);
     assertEquals("test_stream_1.150.-1", representation.getCacheKey());
   }
 
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/extractor/mp4/Mp4ExtractorTest.java b/library/src/androidTest/java/com/google/android/exoplayer/extractor/mp4/Mp4ExtractorTest.java
index d3480164e2..7b2d9acf0b 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/extractor/mp4/Mp4ExtractorTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/extractor/mp4/Mp4ExtractorTest.java
@@ -77,8 +77,9 @@
       + "000000000000000000000000000003");
 
   /** String of hexadecimal bytes containing a tkhd payload with an unknown duration. */
-  private static final byte[] TKHD_PAYLOAD =
-      getByteArray("0000000000000000000000000000000000000000FFFFFFFF");
+  private static final byte[] TKHD_PAYLOAD = getByteArray(
+      "00000007D1F0C7BFD1F0C7BF0000000000000000FFFFFFFF00000000000000000000000000000000000100"
+      + "0000000000000000000000000000010000000000000000000000000000400000000780000004380000");
 
   /** Video frame timestamps in time units. */
   private static final int[] SAMPLE_TIMESTAMPS = {0, 2, 3, 5, 6, 7};
@@ -87,7 +88,7 @@
   /** Indices of key-frames. */
   private static final boolean[] SAMPLE_IS_SYNC = {true, false, false, false, true, true};
   /** Indices of video frame chunk offsets. */
-  private static final int[] CHUNK_OFFSETS = {1080, 2000, 3000, 4000};
+  private static final int[] CHUNK_OFFSETS = {1200, 2120, 3120, 4120};
   /** Numbers of video frames in each chunk. */
   private static final int[] SAMPLES_IN_CHUNK = {2, 2, 1, 1};
   /** The mdat box must be large enough to avoid reading chunk sample data out of bounds. */
@@ -399,7 +400,7 @@ private static int getSampleOffset(int index) {
                             atom(Atom.TYPE_stsc, getStsc()),
                             atom(Atom.TYPE_stsz, getStsz()),
                             atom(Atom.TYPE_stco, getStco())))))),
-        atom(Atom.TYPE_mdat, getMdat(mp4vFormat ? 1048 : 1038, !mp4vFormat)));
+        atom(Atom.TYPE_mdat, getMdat(mp4vFormat ? 1168 : 1158, !mp4vFormat)));
   }
 
   /** Gets a valid MP4 file with audio/video tracks and without a synchronization table. */
@@ -435,7 +436,7 @@ private static int getSampleOffset(int index) {
                             atom(Atom.TYPE_stsc, getStsc()),
                             atom(Atom.TYPE_stsz, getStsz()),
                             atom(Atom.TYPE_stco, getStco())))))),
-        atom(Atom.TYPE_mdat, getMdat(mp4vFormat ? 992 : 982, !mp4vFormat)));
+        atom(Atom.TYPE_mdat, getMdat(mp4vFormat ? 1112 : 1102, !mp4vFormat)));
   }
 
   private static Mp4Atom atom(int type, Mp4Atom... containedMp4Atoms) {
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/StreamBuilder.java b/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/StreamBuilder.java
index e644cc0624..f50bb6a2f9 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/StreamBuilder.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/StreamBuilder.java
@@ -91,41 +91,44 @@ public StreamBuilder setInfo(int timecodeScale, long durationTimecode,
     return this;
   }
 
-  public StreamBuilder addVp9Track(int width, int height,
+  public StreamBuilder addVp9Track(byte trackNumber, int width, int height,
       ContentEncodingSettings contentEncodingSettings) {
-    trackEntries.add(createVideoTrackEntry("V_VP9", width, height, contentEncodingSettings, null));
+    trackEntries.add(createVideoTrackEntry(trackNumber, "V_VP9", width, height,
+        contentEncodingSettings, null));
     return this;
   }
 
-  public StreamBuilder addH264Track(int width, int height, byte[] codecPrivate) {
-    trackEntries.add(createVideoTrackEntry("V_MPEG4/ISO/AVC", width, height, null, codecPrivate));
+  public StreamBuilder addH264Track(byte trackNumber, int width, int height, byte[] codecPrivate) {
+    trackEntries.add(createVideoTrackEntry(trackNumber, "V_MPEG4/ISO/AVC", width, height, null,
+        codecPrivate));
     return this;
   }
 
-  public StreamBuilder addOpusTrack(int channelCount, int sampleRate, int codecDelay,
-      int seekPreRoll, byte[] codecPrivate) {
-    trackEntries.add(createAudioTrackEntry("A_OPUS", channelCount, sampleRate, codecPrivate,
-        codecDelay, seekPreRoll, NO_VALUE));
+  public StreamBuilder addOpusTrack(byte trackNumber, int channelCount, int sampleRate,
+      int codecDelay, int seekPreRoll, byte[] codecPrivate) {
+    trackEntries.add(createAudioTrackEntry(trackNumber, "A_OPUS", channelCount, sampleRate,
+        codecPrivate, codecDelay, seekPreRoll, NO_VALUE));
     return this;
   }
 
-  public StreamBuilder addOpusTrack(int channelCount, int sampleRate, int codecDelay,
-      int seekPreRoll, byte[] codecPrivate, int defaultDurationNs) {
-    trackEntries.add(createAudioTrackEntry("A_OPUS", channelCount, sampleRate, codecPrivate,
-        codecDelay, seekPreRoll, defaultDurationNs));
+  public StreamBuilder addOpusTrack(byte trackNumber, int channelCount, int sampleRate,
+      int codecDelay, int seekPreRoll, byte[] codecPrivate, int defaultDurationNs) {
+    trackEntries.add(createAudioTrackEntry(trackNumber, "A_OPUS", channelCount, sampleRate,
+        codecPrivate, codecDelay, seekPreRoll, defaultDurationNs));
     return this;
   }
 
-  public StreamBuilder addVorbisTrack(int channelCount, int sampleRate, byte[] codecPrivate) {
-    trackEntries.add(createAudioTrackEntry("A_VORBIS", channelCount, sampleRate, codecPrivate,
-        NO_VALUE, NO_VALUE, NO_VALUE));
+  public StreamBuilder addVorbisTrack(byte trackNumber, int channelCount, int sampleRate,
+      byte[] codecPrivate) {
+    trackEntries.add(createAudioTrackEntry(trackNumber, "A_VORBIS", channelCount, sampleRate,
+        codecPrivate, NO_VALUE, NO_VALUE, NO_VALUE));
     return this;
   }
 
-  public StreamBuilder addUnsupportedTrack() {
+  public StreamBuilder addUnsupportedTrack(byte trackNumber) {
     trackEntries.add(element(0xAE, // TrackEntry
         element(0x86, "D_WEBVTT/metadata".getBytes()), // CodecID
-        element(0xD7, (byte) 0x03), // TrackNumber
+        element(0xD7, trackNumber), // TrackNumber
         element(0x83, (byte) 0x11))); // TrackType
     return this;
   }
@@ -252,8 +255,8 @@ private EbmlElement createInfoElement(int timecodeScale, long durationTimecode,
         durationFirst ? timescaleElement : durationElement);
   }
 
-  private static EbmlElement createVideoTrackEntry(String codecId, int pixelWidth, int pixelHeight,
-      ContentEncodingSettings contentEncodingSettings, byte[] codecPrivate) {
+  private static EbmlElement createVideoTrackEntry(byte trackNumber, String codecId, int pixelWidth,
+      int pixelHeight, ContentEncodingSettings contentEncodingSettings, byte[] codecPrivate) {
     byte[] widthBytes = getIntegerBytes(pixelWidth);
     byte[] heightBytes = getIntegerBytes(pixelHeight);
     EbmlElement contentEncodingSettingsElement;
@@ -297,7 +300,7 @@ private static EbmlElement createVideoTrackEntry(String codecId, int pixelWidth,
 
     return element(0xAE, // TrackEntry
         element(0x86, codecId.getBytes()), // CodecID
-        element(0xD7, (byte) 0x01), // TrackNumber
+        element(0xD7, trackNumber), // TrackNumber
         element(0x83, (byte) 0x01), // TrackType
         contentEncodingSettingsElement,
         element(0xE0, // Video
@@ -306,13 +309,14 @@ private static EbmlElement createVideoTrackEntry(String codecId, int pixelWidth,
         codecPrivateElement);
   }
 
-  private static EbmlElement createAudioTrackEntry(String codecId, int channelCount, int sampleRate,
-      byte[] codecPrivate, int codecDelay, int seekPreRoll, int defaultDurationNs) {
+  private static EbmlElement createAudioTrackEntry(byte trackNumber, String codecId,
+      int channelCount, int sampleRate, byte[] codecPrivate, int codecDelay, int seekPreRoll,
+      int defaultDurationNs) {
     byte channelCountByte = (byte) (channelCount & 0xFF);
     byte[] sampleRateDoubleBytes = getLongBytes(Double.doubleToLongBits(sampleRate));
     return element(0xAE, // TrackEntry
         element(0x86, codecId.getBytes()), // CodecID
-        element(0xD7, (byte) 0x02), // TrackNumber
+        element(0xD7, trackNumber), // TrackNumber
         element(0x83, (byte) 0x02), // TrackType
         // CodecDelay
         codecDelay != NO_VALUE ? element(0x56AA, getIntegerBytes(codecDelay)) : empty(),
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/WebmExtractorTest.java b/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/WebmExtractorTest.java
index 0c0e916596..e463a17e82 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/WebmExtractorTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/extractor/webm/WebmExtractorTest.java
@@ -34,6 +34,7 @@
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.nio.ByteOrder;
 import java.util.Arrays;
 import java.util.UUID;
 
@@ -59,6 +60,11 @@
       0x40, 0x1E, 0xFF, 0xE1, 0x00, 0x17, 0x67, 0x4D, 0x40, 0x1E, 0xE8, 0x80, 0x50, 0x17, 0xFC,
       0xB8, 0x08, 0x80, 0x00, 0x01, 0xF4, 0x80, 0x00, 0x75, 0x30, 0x07, 0x8B, 0x16, 0x89, 0x01,
       0x00, 0x04, 0x68, 0xEB, 0xEF, 0x20);
+  private static final byte VIDEO_TRACK_NUMBER = 0x01;
+  private static final byte AUDIO_TRACK_NUMBER = 0x02;
+  private static final byte UNSUPPORTED_TRACK_NUMBER = 0x03;
+  private static final byte SECOND_VIDEO_TRACK_NUMBER = 0x04;
+  private static final byte SECOND_AUDIO_TRACK_NUMBER = 0x05;
 
   private static final UUID WIDEVINE_UUID = new UUID(0xEDEF8BA979D64ACEL, 0xA3C827DCD51D21EDL);
   private static final UUID ZERO_UUID = new UUID(0, 0);
@@ -85,13 +91,13 @@ public void testReadInitializationSegment() throws IOException, InterruptedExcep
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -99,7 +105,7 @@ public void testReadSegmentTwice() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
@@ -107,7 +113,7 @@ public void testReadSegmentTwice() throws IOException, InterruptedException {
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -115,14 +121,14 @@ public void testPrepareOpus() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -130,13 +136,14 @@ public void testPrepareVorbis() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVorbisTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, getVorbisCodecPrivate())
+        .addVorbisTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE,
+            getVorbisCodecPrivate())
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_VORBIS);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_VORBIS);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -144,13 +151,13 @@ public void testPrepareH264() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(MATROSKA_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addH264Track(TEST_WIDTH, TEST_HEIGHT, TEST_H264_CODEC_PRIVATE)
+        .addH264Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, TEST_H264_CODEC_PRIVATE)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertH264VideoFormat(DEFAULT_TIMECODE_SCALE);
+    assertH264VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -158,8 +165,8 @@ public void testPrepareTwoTracks() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .build(1);
 
@@ -167,8 +174,8 @@ public void testPrepareTwoTracks() throws IOException, InterruptedException {
 
     assertTracksEnded();
     assertEquals(2, extractorOutput.numberOfTracks);
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -176,9 +183,9 @@ public void testPrepareThreeTracks() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addUnsupportedTrack()
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addUnsupportedTrack(UNSUPPORTED_TRACK_NUMBER)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .build(1);
 
@@ -187,8 +194,8 @@ public void testPrepareThreeTracks() throws IOException, InterruptedException {
     assertTracksEnded();
     // Even though the input stream has 3 tracks, only 2 of them are supported and will be reported.
     assertEquals(2, extractorOutput.numberOfTracks);
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -196,21 +203,22 @@ public void testPrepareFourTracks() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addVorbisTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, getVorbisCodecPrivate())
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
-            TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addVorbisTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE,
+            getVorbisCodecPrivate())
+        .addVp9Track(SECOND_VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addOpusTrack(SECOND_AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE,
+            TEST_CODEC_DELAY, TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    // Even though the input stream has 4 supported tracks, only the first video and audio track
-    // will be reported.
-    assertEquals(2, extractorOutput.numberOfTracks);
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_VORBIS);
+    assertEquals(4, extractorOutput.numberOfTracks);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_VORBIS);
+    assertVp9VideoFormat(SECOND_VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(SECOND_AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
   }
 
@@ -219,13 +227,13 @@ public void testPrepareContentEncodingEncryption() throws IOException, Interrupt
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
     assertIndex(DEFAULT_TIMECODE_SCALE, 1);
     DrmInitData drmInitData = extractorOutput.drmInitData;
     assertNotNull(drmInitData);
@@ -237,13 +245,13 @@ public void testPrepareThreeCuePoints() throws IOException, InterruptedException
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(3);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
     assertIndex(DEFAULT_TIMECODE_SCALE, 3);
   }
 
@@ -267,13 +275,13 @@ private void testPrepareTimecodeScale(int timecodeScale, boolean omitTimecodeSca
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(timecodeScale, TEST_DURATION_TIMECODE, omitTimecodeScaleIfDefault, afterDuration)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(3);
 
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(timecodeScale);
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, timecodeScale);
     assertIndex(timecodeScale, 3);
   }
 
@@ -282,7 +290,7 @@ public void testPrepareNoCuesElement() throws IOException, InterruptedException
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, media)
         .build(0);
@@ -297,7 +305,7 @@ public void testAcceptsWebmDocType() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
@@ -309,7 +317,7 @@ public void testAcceptsMatroskaDocType() throws IOException, InterruptedExceptio
     byte[] data = new StreamBuilder()
         .setHeader(MATROSKA_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(1);
 
     TestUtil.consumeTestData(extractor, data);
@@ -321,7 +329,7 @@ public void testPrepareInvalidDocType() throws IOException, InterruptedException
     byte[] data = new StreamBuilder()
         .setHeader("webB")
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -336,7 +344,7 @@ public void testPrepareInvalidContentEncodingOrder() throws IOException, Interru
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -351,7 +359,7 @@ public void testPrepareInvalidContentEncodingScope() throws IOException, Interru
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -367,7 +375,7 @@ public void testPrepareInvalidContentCompAlgo()
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -382,7 +390,7 @@ public void testPrepareInvalidContentEncAlgo() throws IOException, InterruptedEx
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -397,7 +405,7 @@ public void testPrepareInvalidAESSettingsCipherMode() throws IOException, Interr
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .build(1);
     try {
       TestUtil.consumeTestData(extractor, data);
@@ -412,7 +420,7 @@ public void testReadSampleKeyframe() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, media)
         .build(1);
@@ -420,8 +428,8 @@ public void testReadSampleKeyframe() throws IOException, InterruptedException {
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, media, 0, true, false, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, media, 0, true, false, null, getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadSampleKeyframeStripped() throws IOException, InterruptedException {
@@ -432,7 +440,7 @@ public void testReadSampleKeyframeStripped() throws IOException, InterruptedExce
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, sampleBytes)
         .build(1);
@@ -440,8 +448,9 @@ public void testReadSampleKeyframeStripped() throws IOException, InterruptedExce
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, unstrippedSampleBytes, 0, true, false, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, unstrippedSampleBytes, 0, true, false, null,
+        getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadSampleKeyframeManyBytesStripped() throws IOException, InterruptedException {
@@ -452,7 +461,7 @@ public void testReadSampleKeyframeManyBytesStripped() throws IOException, Interr
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, sampleBytes)
         .build(1);
@@ -460,8 +469,9 @@ public void testReadSampleKeyframeManyBytesStripped() throws IOException, Interr
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, unstrippedSampleBytes, 0, true, false, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, unstrippedSampleBytes, 0, true, false, null,
+        getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadTwoTrackSamples() throws IOException, InterruptedException {
@@ -469,8 +479,8 @@ public void testReadTwoTrackSamples() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, media)
@@ -482,10 +492,10 @@ public void testReadTwoTrackSamples() throws IOException, InterruptedException {
 
     assertTracksEnded();
     assertEquals(2, extractorOutput.numberOfTracks);
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
-    assertSample(0, media, 0, true, false, null, getVideoOutput());
-    assertSample(0, media, 0, true, false, null, getAudioOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertSample(0, media, 0, true, false, null, getTrackOutput(VIDEO_TRACK_NUMBER));
+    assertSample(0, media, 0, true, false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
   }
 
   public void testReadTwoTrackSamplesWithSkippedTrack() throws IOException, InterruptedException {
@@ -493,9 +503,9 @@ public void testReadTwoTrackSamplesWithSkippedTrack() throws IOException, Interr
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addUnsupportedTrack()
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addUnsupportedTrack(UNSUPPORTED_TRACK_NUMBER)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .addSimpleBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, media)
@@ -509,10 +519,10 @@ public void testReadTwoTrackSamplesWithSkippedTrack() throws IOException, Interr
 
     assertTracksEnded();
     assertEquals(2, extractorOutput.numberOfTracks);
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
-    assertSample(0, media, 0, true, false, null, getVideoOutput());
-    assertSample(0, media, 0, true, false, null, getAudioOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertSample(0, media, 0, true, false, null, getTrackOutput(VIDEO_TRACK_NUMBER));
+    assertSample(0, media, 0, true, false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
   }
 
   public void testReadBlock() throws IOException, InterruptedException {
@@ -520,7 +530,7 @@ public void testReadBlock() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
             TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE)
         .addBlockMedia(2 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             true /* keyframe */, false /* invisible */, media)
@@ -529,8 +539,8 @@ public void testReadBlock() throws IOException, InterruptedException {
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
-    assertSample(0, media, 0, true, false, null, getAudioOutput());
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertSample(0, media, 0, true, false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
   }
 
   public void testReadBlockNonKeyframe() throws IOException, InterruptedException {
@@ -538,7 +548,7 @@ public void testReadBlockNonKeyframe() throws IOException, InterruptedException
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addBlockMedia(1 /* trackNumber */, 0 /* clusterTimecode */, 0 /* blockTimecode */,
             false /* keyframe */, false /* invisible */, media)
         .build(1);
@@ -546,8 +556,8 @@ public void testReadBlockNonKeyframe() throws IOException, InterruptedException
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, media, 0, false, false, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, media, 0, false, false, null, getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadEncryptedFrame() throws IOException, InterruptedException {
@@ -556,7 +566,7 @@ public void testReadEncryptedFrame() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .addSimpleBlockEncryptedMedia(1 /* trackNumber */, 0 /* clusterTimecode */,
             0 /* blockTimecode */, true /* keyframe */, false /* invisible */,
             true /* validSignalByte */, media)
@@ -565,8 +575,9 @@ public void testReadEncryptedFrame() throws IOException, InterruptedException {
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, media, 0, true, false, TEST_ENCRYPTION_KEY_ID, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, media, 0, true, false, TEST_ENCRYPTION_KEY_ID,
+        getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadEncryptedFrameWithInvalidSignalByte()
@@ -576,7 +587,7 @@ public void testReadEncryptedFrameWithInvalidSignalByte()
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, settings)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, settings)
         .addSimpleBlockEncryptedMedia(1 /* trackNumber */, 0 /* clusterTimecode */,
             0 /* blockTimecode */, true /* keyframe */, false /* invisible */,
             false /* validSignalByte */, media)
@@ -596,7 +607,7 @@ public void testReadSampleInvisible() throws IOException, InterruptedException {
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addSimpleBlockMedia(1 /* trackNumber */, 12 /* clusterTimecode */, 13 /* blockTimecode */,
             false /* keyframe */, true /* invisible */, media)
         .build(1);
@@ -604,8 +615,8 @@ public void testReadSampleInvisible() throws IOException, InterruptedException {
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, media, 25000, false, true, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, media, 25000, false, true, null, getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadSampleCustomTimecodeScale() throws IOException, InterruptedException {
@@ -614,7 +625,7 @@ public void testReadSampleCustomTimecodeScale() throws IOException, InterruptedE
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(timecodeScale, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addSimpleBlockMedia(1 /* trackNumber */, 12 /* clusterTimecode */, 13 /* blockTimecode */,
             false /* keyframe */, false /* invisible */, media)
         .build(1);
@@ -622,8 +633,8 @@ public void testReadSampleCustomTimecodeScale() throws IOException, InterruptedE
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(timecodeScale);
-    assertSample(0, media, 25, false, false, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, timecodeScale);
+    assertSample(0, media, 25, false, false, null, getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadSampleNegativeSimpleBlockTimecode() throws IOException, InterruptedException {
@@ -631,7 +642,7 @@ public void testReadSampleNegativeSimpleBlockTimecode() throws IOException, Inte
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addVp9Track(TEST_WIDTH, TEST_HEIGHT, null)
+        .addVp9Track(VIDEO_TRACK_NUMBER, TEST_WIDTH, TEST_HEIGHT, null)
         .addSimpleBlockMedia(1 /* trackNumber */, 13 /* clusterTimecode */, -12 /* blockTimecode */,
             true /* keyframe */, true /* invisible */, media)
         .build(1);
@@ -639,8 +650,8 @@ public void testReadSampleNegativeSimpleBlockTimecode() throws IOException, Inte
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertVp9VideoFormat(DEFAULT_TIMECODE_SCALE);
-    assertSample(0, media, 1000, true, true, null, getVideoOutput());
+    assertVp9VideoFormat(VIDEO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE);
+    assertSample(0, media, 1000, true, true, null, getTrackOutput(VIDEO_TRACK_NUMBER));
   }
 
   public void testReadSampleWithFixedSizeLacing() throws IOException, InterruptedException {
@@ -648,8 +659,8 @@ public void testReadSampleWithFixedSizeLacing() throws IOException, InterruptedE
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY, TEST_SEEK_PRE_ROLL,
-            TEST_OPUS_CODEC_PRIVATE, TEST_DEFAULT_DURATION_NS)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+            TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE, TEST_DEFAULT_DURATION_NS)
         .addSimpleBlockMediaWithFixedSizeLacing(2 /* trackNumber */, 0 /* clusterTimecode */,
             0 /* blockTimecode */, 20, media)
         .build(1);
@@ -657,11 +668,11 @@ public void testReadSampleWithFixedSizeLacing() throws IOException, InterruptedE
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     for (int i = 0; i < 20; i++) {
       long expectedTimeUs = i * TEST_DEFAULT_DURATION_NS / 1000;
       assertSample(i, Arrays.copyOfRange(media, i * 5, i * 5 + 5), expectedTimeUs, true, false,
-          null, getAudioOutput());
+          null, getTrackOutput(AUDIO_TRACK_NUMBER));
     }
   }
 
@@ -670,8 +681,8 @@ public void testReadSampleWithXiphLacing() throws IOException, InterruptedExcept
     byte[] data = new StreamBuilder()
         .setHeader(WEBM_DOC_TYPE)
         .setInfo(DEFAULT_TIMECODE_SCALE, TEST_DURATION_TIMECODE)
-        .addOpusTrack(TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY, TEST_SEEK_PRE_ROLL,
-            TEST_OPUS_CODEC_PRIVATE, TEST_DEFAULT_DURATION_NS)
+        .addOpusTrack(AUDIO_TRACK_NUMBER, TEST_CHANNEL_COUNT, TEST_SAMPLE_RATE, TEST_CODEC_DELAY,
+            TEST_SEEK_PRE_ROLL, TEST_OPUS_CODEC_PRIVATE, TEST_DEFAULT_DURATION_NS)
         .addSimpleBlockMediaWithXiphLacing(2 /* trackNumber */, 0 /* clusterTimecode */,
             0 /* blockTimecode */, media, 256, 1, 243)
         .build(1);
@@ -679,31 +690,25 @@ public void testReadSampleWithXiphLacing() throws IOException, InterruptedExcept
     TestUtil.consumeTestData(extractor, data);
 
     assertTracksEnded();
-    assertAudioFormat(DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
+    assertAudioFormat(AUDIO_TRACK_NUMBER, DEFAULT_TIMECODE_SCALE, MimeTypes.AUDIO_OPUS);
     assertSample(0, Arrays.copyOfRange(media, 0, 256), 0 * TEST_DEFAULT_DURATION_NS / 1000, true,
-        false, null, getAudioOutput());
+        false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
     assertSample(1, Arrays.copyOfRange(media, 256, 257), 1 * TEST_DEFAULT_DURATION_NS / 1000, true,
-        false, null, getAudioOutput());
+        false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
     assertSample(2, Arrays.copyOfRange(media, 257, 300), 2 * TEST_DEFAULT_DURATION_NS / 1000, true,
-        false, null, getAudioOutput());
-  }
-
-  private FakeTrackOutput getVideoOutput() {
-    // In the sample data the video track has id 1.
-    return extractorOutput.trackOutputs.get(1);
+        false, null, getTrackOutput(AUDIO_TRACK_NUMBER));
   }
 
-  private FakeTrackOutput getAudioOutput() {
-    // In the sample data the video track has id 2.
-    return extractorOutput.trackOutputs.get(2);
+  private FakeTrackOutput getTrackOutput(int trackNumber) {
+    return extractorOutput.trackOutputs.get(trackNumber);
   }
 
   private void assertTracksEnded() {
     assertTrue(extractorOutput.tracksEnded);
   }
 
-  private void assertVp9VideoFormat(int timecodeScale) {
-    MediaFormat format = getVideoOutput().format;
+  private void assertVp9VideoFormat(int trackNumber, int timecodeScale) {
+    MediaFormat format = getTrackOutput(trackNumber).format;
     assertEquals(Util.scaleLargeTimestamp(TEST_DURATION_TIMECODE, timecodeScale, 1000),
         format.durationUs);
     assertEquals(TEST_WIDTH, format.width);
@@ -711,8 +716,8 @@ private void assertVp9VideoFormat(int timecodeScale) {
     assertEquals(MimeTypes.VIDEO_VP9, format.mimeType);
   }
 
-  private void assertH264VideoFormat(int timecodeScale) {
-    MediaFormat format = getVideoOutput().format;
+  private void assertH264VideoFormat(int trackNumber, int timecodeScale) {
+    MediaFormat format = getTrackOutput(trackNumber).format;
     assertEquals(Util.scaleLargeTimestamp(TEST_DURATION_TIMECODE, timecodeScale, 1000),
         format.durationUs);
     assertEquals(TEST_WIDTH, format.width);
@@ -720,8 +725,8 @@ private void assertH264VideoFormat(int timecodeScale) {
     assertEquals(MimeTypes.VIDEO_H264, format.mimeType);
   }
 
-  private void assertAudioFormat(int timecodeScale, String expectedMimeType) {
-    MediaFormat format = getAudioOutput().format;
+  private void assertAudioFormat(int trackNumber, int timecodeScale, String expectedMimeType) {
+    MediaFormat format = getTrackOutput(trackNumber).format;
     assertEquals(Util.scaleLargeTimestamp(TEST_DURATION_TIMECODE, timecodeScale, 1000),
         format.durationUs);
     assertEquals(TEST_CHANNEL_COUNT, format.channelCount);
@@ -731,8 +736,10 @@ private void assertAudioFormat(int timecodeScale, String expectedMimeType) {
       assertEquals(3, format.initializationData.size());
       android.test.MoreAsserts.assertEquals(TEST_OPUS_CODEC_PRIVATE,
           format.initializationData.get(0));
-      assertEquals(TEST_CODEC_DELAY, ByteBuffer.wrap(format.initializationData.get(1)).getLong());
-      assertEquals(TEST_SEEK_PRE_ROLL, ByteBuffer.wrap(format.initializationData.get(2)).getLong());
+      assertEquals(TEST_CODEC_DELAY, ByteBuffer.wrap(format.initializationData.get(1))
+          .order(ByteOrder.LITTLE_ENDIAN).getLong());
+      assertEquals(TEST_SEEK_PRE_ROLL, ByteBuffer.wrap(format.initializationData.get(2))
+          .order(ByteOrder.LITTLE_ENDIAN).getLong());
     } else if (MimeTypes.AUDIO_VORBIS.equals(expectedMimeType)) {
       assertEquals(2, format.initializationData.size());
       assertEquals(TEST_VORBIS_INFO_SIZE, format.initializationData.get(0).length);
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/subrip/SubripParserTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/subrip/SubripParserTest.java
index 7459442fb2..076185019d 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/text/subrip/SubripParserTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/subrip/SubripParserTest.java
@@ -15,7 +15,7 @@
  */
 package com.google.android.exoplayer.text.subrip;
 
-import com.google.android.exoplayer.C;
+import com.google.android.exoplayer.ParserException;
 
 import android.test.InstrumentationTestCase;
 
@@ -27,40 +27,129 @@
  */
 public final class SubripParserTest extends InstrumentationTestCase {
 
-  private static final String TYPICAL_SUBRIP_FILE = "subrip/typical";
-  private static final String EMPTY_SUBRIP_FILE = "subrip/empty";
+  private static final String EMPTY_FILE = "subrip/empty";
+  private static final String TYPICAL_FILE = "subrip/typical";
+  private static final String TYPICAL_EXTRA_BLANK_LINE = "subrip/typical_extra_blank_line";
+  private static final String TYPICAL_MISSING_TIMECODE = "subrip/typical_missing_timecode";
+  private static final String TYPICAL_MISSING_SEQUENCE = "subrip/typical_missing_sequence";
+  private static final String NO_END_TIMECODES_FILE = "subrip/no_end_timecodes";
 
-  public void testParseNullSubripFile() throws IOException {
-    SubripParser parser = new SubripParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets().open(EMPTY_SUBRIP_FILE);
-    SubripSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+  public void testParseEmpty() throws IOException {
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(EMPTY_FILE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
     // Assert that the subtitle is empty.
     assertEquals(0, subtitle.getEventTimeCount());
     assertTrue(subtitle.getCues(0).isEmpty());
   }
 
-  public void testParseTypicalSubripFile() throws IOException {
-    SubripParser parser = new SubripParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets().open(TYPICAL_SUBRIP_FILE);
-    SubripSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+  public void testParseTypical() throws IOException {
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(TYPICAL_FILE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
+    assertEquals(6, subtitle.getEventTimeCount());
+    assertTypicalCue1(subtitle, 0);
+    assertTypicalCue2(subtitle, 2);
+    assertTypicalCue3(subtitle, 4);
+  }
+
+  public void testParseTypicalExtraBlankLine() throws IOException {
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(TYPICAL_EXTRA_BLANK_LINE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
+    assertEquals(6, subtitle.getEventTimeCount());
+    assertTypicalCue1(subtitle, 0);
+    assertTypicalCue2(subtitle, 2);
+    assertTypicalCue3(subtitle, 4);
+  }
+
+  public void testParseTypicalMissingTimecode() throws IOException {
+    // Strict parsing should fail.
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(TYPICAL_MISSING_TIMECODE);
+    try {
+      parser.parse(inputStream);
+      fail();
+    } catch (ParserException e) {
+      // Expected.
+    }
+
+    // Non-strict parsing should succeed, parsing the first and third cues only.
+    parser = new SubripParser(false);
+    inputStream = getInputStream(TYPICAL_MISSING_TIMECODE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
+    assertEquals(4, subtitle.getEventTimeCount());
+    assertTypicalCue1(subtitle, 0);
+    assertTypicalCue3(subtitle, 2);
+  }
+
+  public void testParseTypicalMissingSequence() throws IOException {
+    // Strict parsing should fail.
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(TYPICAL_MISSING_SEQUENCE);
+    try {
+      parser.parse(inputStream);
+      fail();
+    } catch (ParserException e) {
+      // Expected.
+    }
 
-    // Test start time and event count.
-    assertEquals(0, subtitle.getStartTime());
+    // Non-strict parsing should succeed, parsing the first and third cues only.
+    parser = new SubripParser(false);
+    inputStream = getInputStream(TYPICAL_MISSING_SEQUENCE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
     assertEquals(4, subtitle.getEventTimeCount());
+    assertTypicalCue1(subtitle, 0);
+    assertTypicalCue3(subtitle, 2);
+  }
+
+  public void testParseNoEndTimecodes() throws IOException {
+    SubripParser parser = new SubripParser(true);
+    InputStream inputStream = getInputStream(NO_END_TIMECODES_FILE);
+    SubripSubtitle subtitle = parser.parse(inputStream);
+
+    // Test event count.
+    assertEquals(3, subtitle.getEventTimeCount());
 
     // Test first cue.
     assertEquals(0, subtitle.getEventTime(0));
-    assertEquals("This is the first subtitle.",
+    assertEquals("SubRip doesn't technically allow missing end timecodes.",
         subtitle.getCues(subtitle.getEventTime(0)).get(0).text.toString());
-    assertEquals(1234000, subtitle.getEventTime(1));
 
     // Test second cue.
-    assertEquals(2345000, subtitle.getEventTime(2));
-    assertEquals("This is the second subtitle.\nSecond subtitle with second line.",
+    assertEquals(2345000, subtitle.getEventTime(1));
+    assertEquals("We interpret it to mean that a subtitle extends to the start of the next one.",
+        subtitle.getCues(subtitle.getEventTime(1)).get(0).text.toString());
+
+    // Test third cue.
+    assertEquals(3456000, subtitle.getEventTime(2));
+    assertEquals("Or to the end of the media.",
         subtitle.getCues(subtitle.getEventTime(2)).get(0).text.toString());
-    assertEquals(3456000, subtitle.getEventTime(3));
+  }
+
+  private InputStream getInputStream(String fileName) throws IOException {
+    return getInstrumentation().getContext().getResources().getAssets().open(fileName);
+  }
+
+  private static void assertTypicalCue1(SubripSubtitle subtitle, int eventIndex) {
+    assertEquals(0, subtitle.getEventTime(eventIndex));
+    assertEquals("This is the first subtitle.",
+        subtitle.getCues(subtitle.getEventTime(eventIndex)).get(0).text.toString());
+    assertEquals(1234000, subtitle.getEventTime(eventIndex + 1));
+  }
+
+  private static void assertTypicalCue2(SubripSubtitle subtitle, int eventIndex) {
+    assertEquals(2345000, subtitle.getEventTime(eventIndex));
+    assertEquals("This is the second subtitle.\nSecond subtitle with second line.",
+        subtitle.getCues(subtitle.getEventTime(eventIndex)).get(0).text.toString());
+    assertEquals(3456000, subtitle.getEventTime(eventIndex + 1));
+  }
+
+  private static void assertTypicalCue3(SubripSubtitle subtitle, int eventIndex) {
+    assertEquals(4567000, subtitle.getEventTime(eventIndex));
+    assertEquals("This is the third subtitle.",
+        subtitle.getCues(subtitle.getEventTime(eventIndex)).get(0).text.toString());
+    assertEquals(8901000, subtitle.getEventTime(eventIndex + 1));
   }
 
 }
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlParserTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlParserTest.java
new file mode 100644
index 0000000000..9d5d953977
--- /dev/null
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlParserTest.java
@@ -0,0 +1,328 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.text.ttml;
+
+import com.google.android.exoplayer.text.Cue;
+
+import android.graphics.Color;
+import android.test.InstrumentationTestCase;
+import android.text.Layout;
+import android.text.SpannableStringBuilder;
+import android.text.style.AlignmentSpan;
+import android.text.style.BackgroundColorSpan;
+import android.text.style.ForegroundColorSpan;
+import android.text.style.StrikethroughSpan;
+import android.text.style.StyleSpan;
+import android.text.style.TypefaceSpan;
+import android.text.style.UnderlineSpan;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Unit test for {@link TtmlParser}.
+ */
+public final class TtmlParserTest extends InstrumentationTestCase {
+
+  private static final String INLINE_ATTRIBUTES_TTML_FILE =
+      "ttml/inline_style_attributes.xml";
+  private static final String INHERIT_STYLE_TTML_FILE =
+      "ttml/inherit_style.xml";
+  private static final String INHERIT_STYLE_OVERRIDE_TTML_FILE =
+      "ttml/inherit_and_override_style.xml";
+  private static final String INHERIT_GLOBAL_AND_PARENT_TTML_FILE =
+      "ttml/inherit_global_and_parent.xml";
+  private static final String INHERIT_MULTIPLE_STYLES_TTML_FILE =
+      "ttml/inherit_multiple_styles.xml";
+  private static final String CHAIN_MULTIPLE_STYLES_TTML_FILE =
+      "ttml/chain_multiple_styles.xml";
+  private static final String NO_UNDERLINE_LINETHROUGH_TTML_FILE =
+      "ttml/no_underline_linethrough.xml";
+  private static final String NAMESPACE_CONFUSION_TTML_FILE =
+      "ttml/namespace_confusion.xml";
+  private static final String NAMESPACE_NOT_DECLARED_TTML_FILE =
+      "ttml/namespace_not_declared.xml";
+
+  public void testInlineAttributes() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INLINE_ATTRIBUTES_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode firstDiv = queryChildrenForTag(body, TtmlNode.TAG_DIV, 0);
+    TtmlStyle firstPStyle = queryChildrenForTag(firstDiv, TtmlNode.TAG_P, 0).style;
+    assertEquals(Color.parseColor("yellow"), firstPStyle.getColor());
+    assertEquals(Color.parseColor("blue"), firstPStyle.getBackgroundColor());
+    assertEquals("serif", firstPStyle.getFontFamily());
+    assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, firstPStyle.getStyle());
+    assertTrue(firstPStyle.isUnderline());
+  }
+
+  public void testInheritInlineAttributes() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INLINE_ATTRIBUTES_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+    assertSpans(subtitle, 20, "text 2", "sansSerif", TtmlStyle.STYLE_ITALIC,
+        Color.CYAN, Color.parseColor("lime"), false, true, null);
+  }
+
+  public void testInheritGlobalStyle() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_STYLE_TTML_FILE);
+    assertEquals(2, subtitle.getEventTimeCount());
+    assertSpans(subtitle, 10, "text 1", "serif", TtmlStyle.STYLE_BOLD_ITALIC,
+        Color.BLUE, Color.YELLOW, true, false, null);
+  }
+
+  public void testInheritGlobalStyleOverriddenByInlineAttributes() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_STYLE_OVERRIDE_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    assertSpans(subtitle, 10, "text 1", "serif", TtmlStyle.STYLE_BOLD_ITALIC, Color.BLUE,
+        Color.YELLOW, true, false, null);
+    assertSpans(subtitle, 20, "text 2", "sansSerif", TtmlStyle.STYLE_ITALIC, Color.RED,
+        Color.YELLOW, true, false, null);
+  }
+
+  public void testInheritGlobalAndParent() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_GLOBAL_AND_PARENT_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    assertSpans(subtitle, 10, "text 1", "sansSerif", TtmlStyle.STYLE_NORMAL,
+        Color.RED, Color.parseColor("lime"), false, true, Layout.Alignment.ALIGN_CENTER);
+    assertSpans(subtitle, 20, "text 2", "serif", TtmlStyle.STYLE_BOLD_ITALIC,
+        Color.BLUE, Color.YELLOW, true, true, Layout.Alignment.ALIGN_CENTER);
+  }
+
+  public void testInheritMultipleStyles() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    assertSpans(subtitle, 10, "text 1", "sansSerif", TtmlStyle.STYLE_BOLD_ITALIC,
+        Color.BLUE, Color.YELLOW, false, true, null);
+  }
+
+  public void testInheritMultipleStylesWithoutLocalAttributes() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    assertSpans(subtitle, 20, "text 2", "sansSerif", TtmlStyle.STYLE_BOLD_ITALIC,
+        Color.BLUE, Color.BLACK, false, true, null);
+
+  }
+
+  public void testMergeMultipleStylesWithParentStyle() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    assertSpans(subtitle, 30, "text 2.5", "sansSerifInline", TtmlStyle.STYLE_ITALIC,
+        Color.RED, Color.YELLOW, true, true, null);
+  }
+
+  public void testEmptyStyleAttribute() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode fourthDiv = queryChildrenForTag(body, TtmlNode.TAG_DIV, 3);
+
+    assertNull(queryChildrenForTag(fourthDiv, TtmlNode.TAG_P, 0).getStyleIds());
+  }
+
+  public void testNonexistingStyleId() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode fifthDiv = queryChildrenForTag(body, TtmlNode.TAG_DIV, 4);
+
+    assertEquals(1, queryChildrenForTag(fifthDiv, TtmlNode.TAG_P, 0).getStyleIds().length);
+  }
+
+  public void testNonExistingAndExistingStyleIdWithRedundantSpaces() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(INHERIT_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(12, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode sixthDiv = queryChildrenForTag(body, TtmlNode.TAG_DIV, 5);
+
+    String[] styleIds = queryChildrenForTag(sixthDiv, TtmlNode.TAG_P, 0).getStyleIds();
+    assertEquals(2, styleIds.length);
+  }
+
+  public void testMultipleChaining() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(CHAIN_MULTIPLE_STYLES_TTML_FILE);
+    assertEquals(2, subtitle.getEventTimeCount());
+
+    Map<String, TtmlStyle> globalStyles = subtitle.getGlobalStyles();
+
+    TtmlStyle style = globalStyles.get("s2");
+    assertEquals("serif", style.getFontFamily());
+    assertEquals(Color.RED, style.getBackgroundColor());
+    assertEquals(Color.BLACK, style.getColor());
+    assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, style.getStyle());
+    assertTrue(style.isLinethrough());
+
+    style = globalStyles.get("s3");
+    // only difference: color must be RED
+    assertEquals(Color.RED, style.getColor());
+    assertEquals("serif", style.getFontFamily());
+    assertEquals(Color.RED, style.getBackgroundColor());
+    assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, style.getStyle());
+    assertTrue(style.isLinethrough());
+  }
+
+  public void testNoUnderline() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(NO_UNDERLINE_LINETHROUGH_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode div = queryChildrenForTag(body, TtmlNode.TAG_DIV, 0);
+
+    TtmlStyle style = queryChildrenForTag(div, TtmlNode.TAG_P, 0).style;
+    assertFalse("noUnderline from inline attribute expected", style.isUnderline());
+  }
+
+  public void testNoLinethrough() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(NO_UNDERLINE_LINETHROUGH_TTML_FILE);
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode div = queryChildrenForTag(body, TtmlNode.TAG_DIV, 1);
+
+    TtmlStyle style = queryChildrenForTag(div, TtmlNode.TAG_P, 0).style;
+    assertFalse("noLineThrough from inline attribute expected in second pNode",
+        style.isLinethrough());
+  }
+
+  public void testNamspaceConfusionDoesNotHurt() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(NAMESPACE_CONFUSION_TTML_FILE);
+    assertEquals(2, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode div = queryChildrenForTag(body, TtmlNode.TAG_DIV, 0);
+    TtmlStyle style = queryChildrenForTag(div, TtmlNode.TAG_P, 0).style;
+
+    assertNotNull(style);
+    assertEquals(Color.BLACK, style.getBackgroundColor());
+    assertEquals(Color.YELLOW, style.getColor());
+    assertEquals(TtmlStyle.STYLE_ITALIC, style.getStyle());
+    assertEquals("sansSerif", style.getFontFamily());
+    assertFalse(style.isUnderline());
+    assertTrue(style.isLinethrough());
+
+  }
+
+  public void testNamespaceNotDeclared() throws IOException {
+    TtmlSubtitle subtitle = getSubtitle(NAMESPACE_NOT_DECLARED_TTML_FILE);
+    assertEquals(2, subtitle.getEventTimeCount());
+
+    TtmlNode root = subtitle.getRoot();
+    TtmlNode body = queryChildrenForTag(root, TtmlNode.TAG_BODY, 0);
+    TtmlNode div = queryChildrenForTag(body, TtmlNode.TAG_DIV, 0);
+    TtmlStyle style = queryChildrenForTag(div, TtmlNode.TAG_P, 0).style;
+
+    assertNotNull(style);
+    assertEquals(Color.BLACK, style.getBackgroundColor());
+    assertEquals(Color.YELLOW, style.getColor());
+    assertEquals(TtmlStyle.STYLE_ITALIC, style.getStyle());
+    assertEquals("sansSerif", style.getFontFamily());
+    assertFalse(style.isUnderline());
+    assertTrue(style.isLinethrough());
+
+  }
+
+  private void assertSpans(TtmlSubtitle subtitle, int second,
+      String text, String font, int fontStyle,
+      int backgroundColor, int color, boolean isUnderline,
+      boolean isLinethrough, Layout.Alignment alignment) {
+
+    long timeUs = second * 1000000;
+    List<Cue> cues = subtitle.getCues(timeUs);
+
+    assertEquals(1, cues.size());
+    assertEquals(text, String.valueOf(cues.get(0).text));
+
+    assertEquals("single cue expected for timeUs: " + timeUs, 1, cues.size());
+    SpannableStringBuilder spannable = (SpannableStringBuilder) cues.get(0).text;
+
+    TypefaceSpan[] typefaceSpans = spannable.getSpans(0, spannable.length(), TypefaceSpan.class);
+    assertEquals(font, typefaceSpans[typefaceSpans.length - 1].getFamily());
+
+    StyleSpan[] styleSpans = spannable.getSpans(0, spannable.length(), StyleSpan.class);
+    assertEquals(fontStyle, styleSpans[styleSpans.length - 1].getStyle());
+
+    UnderlineSpan[] underlineSpans = spannable.getSpans(0, spannable.length(),
+        UnderlineSpan.class);
+    assertEquals(isUnderline ? "must be underlined" : "must not be underlined",
+        isUnderline ? 1 : 0, underlineSpans.length);
+
+    StrikethroughSpan[] striketroughSpans = spannable.getSpans(0, spannable.length(),
+        StrikethroughSpan.class);
+    assertEquals(isLinethrough ? "must be strikethrough" : "must not be strikethrough",
+        isLinethrough ? 1 : 0, striketroughSpans.length);
+
+    BackgroundColorSpan[] backgroundColorSpans =
+        spannable.getSpans(0, spannable.length(), BackgroundColorSpan.class);
+    if (backgroundColor != 0) {
+      assertEquals(backgroundColor, backgroundColorSpans[backgroundColorSpans.length - 1]
+          .getBackgroundColor());
+    } else {
+      assertEquals(0, backgroundColorSpans.length);
+    }
+
+    ForegroundColorSpan[] foregroundColorSpans =
+        spannable.getSpans(0, spannable.length(), ForegroundColorSpan.class);
+    assertEquals(color, foregroundColorSpans[foregroundColorSpans.length - 1].getForegroundColor());
+
+    if (alignment != null) {
+      AlignmentSpan.Standard[] alignmentSpans =
+          spannable.getSpans(0, spannable.length(), AlignmentSpan.Standard.class);
+      assertEquals(1, alignmentSpans.length);
+      assertEquals(alignment, alignmentSpans[0].getAlignment());
+    } else {
+      assertEquals(0, spannable.getSpans
+          (0, spannable.length(), AlignmentSpan.Standard.class).length);
+    }
+  }
+
+  private TtmlNode queryChildrenForTag(TtmlNode node, String tag, int pos) {
+    int count = 0;
+    for (int i = 0; i < node.getChildCount(); i++) {
+      if (tag.equals(node.getChild(i).tag)) {
+        if (pos == count++) {
+          return node.getChild(i);
+        }
+      }
+    }
+    return null;
+  }
+
+  private TtmlSubtitle getSubtitle(String file) throws IOException {
+    TtmlParser ttmlParser = new TtmlParser(false);
+    InputStream inputStream = getInstrumentation().getContext()
+        .getResources().getAssets().open(file);
+
+    return (TtmlSubtitle) ttmlParser.parse(inputStream);
+  }
+}
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtilTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtilTest.java
new file mode 100644
index 0000000000..bdfeda663b
--- /dev/null
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtilTest.java
@@ -0,0 +1,111 @@
+package com.google.android.exoplayer.text.ttml;
+/*
+ * Copyright (C) 2015 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import android.graphics.Color;
+import android.test.InstrumentationTestCase;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Unit test for <code>TtmlRenderUtil</code>
+ */
+public class TtmlRenderUtilTest extends InstrumentationTestCase {
+
+  public void testResolveStyleNoStyleAtAll() {
+    assertNull(TtmlRenderUtil.resolveStyle(null, null, null));
+  }
+  public void testResolveStyleSingleReferentialStyle() {
+    Map<String, TtmlStyle> globalStyles = getGlobalStyles();
+    String[] styleIds = {"s0"};
+
+    assertSame(globalStyles.get("s0"),
+        TtmlRenderUtil.resolveStyle(null, styleIds, globalStyles));
+  }
+  public void testResolveStyleMultipleReferentialStyles() {
+    Map<String, TtmlStyle> globalStyles = getGlobalStyles();
+    String[] styleIds = {"s0", "s1"};
+
+    TtmlStyle resolved = TtmlRenderUtil.resolveStyle(null, styleIds, globalStyles);
+    assertNotSame(globalStyles.get("s0"), resolved);
+    assertNotSame(globalStyles.get("s1"), resolved);
+    assertNull(resolved.getId());
+
+    // inherited from s0
+    assertEquals(Color.BLACK, resolved.getBackgroundColor());
+    // inherited from s1
+    assertEquals(Color.RED, resolved.getColor());
+    // merged from s0 and s1
+    assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, resolved.getStyle());
+  }
+
+  public void testResolveMergeSingleReferentialStyleIntoInlineStyle() {
+    Map<String, TtmlStyle> globalStyles = getGlobalStyles();
+    String[] styleIds = {"s0"};
+    TtmlStyle style = new TtmlStyle();
+    style.setBackgroundColor(Color.YELLOW);
+
+    TtmlStyle resolved = TtmlRenderUtil.resolveStyle(style, styleIds, globalStyles);
+    assertSame(style, resolved);
+
+    // inline attribute not overridden
+    assertEquals(Color.YELLOW, resolved.getBackgroundColor());
+    // inherited from referential style
+    assertEquals(TtmlStyle.STYLE_BOLD, resolved.getStyle());
+  }
+
+
+  public void testResolveMergeMultipleReferentialStylesIntoInlineStyle() {
+    Map<String, TtmlStyle> globalStyles = getGlobalStyles();
+    String[] styleIds = {"s0", "s1"};
+    TtmlStyle style = new TtmlStyle();
+    style.setBackgroundColor(Color.YELLOW);
+
+    TtmlStyle resolved = TtmlRenderUtil.resolveStyle(style, styleIds, globalStyles);
+    assertSame(style, resolved);
+
+    // inline attribute not overridden
+    assertEquals(Color.YELLOW, resolved.getBackgroundColor());
+    // inherited from both referential style
+    assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, resolved.getStyle());
+  }
+
+  public void testResolveStyleOnlyInlineStyle() {
+    TtmlStyle inlineStyle = new TtmlStyle();
+    assertSame(inlineStyle, TtmlRenderUtil.resolveStyle(inlineStyle, null, null));
+  }
+
+  private Map<String, TtmlStyle> getGlobalStyles() {
+    Map<String, TtmlStyle> globalStyles = new HashMap<>();
+
+    TtmlStyle s0 = new TtmlStyle();
+    s0.setId("s0");
+    s0.setBackgroundColor(Color.BLACK);
+    s0.setBold(true);
+    globalStyles.put(s0.getId(), s0);
+
+    TtmlStyle s1 = new TtmlStyle();
+    s1.setId("s1");
+    s1.setBackgroundColor(Color.RED);
+    s1.setColor(Color.RED);
+    s1.setItalic(true);
+    globalStyles.put(s1.getId(), s1);
+
+    return globalStyles;
+  }
+
+}
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlStyleTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlStyleTest.java
new file mode 100644
index 0000000000..c452f68327
--- /dev/null
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/ttml/TtmlStyleTest.java
@@ -0,0 +1,155 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.text.ttml;
+
+import android.graphics.Color;
+import android.test.InstrumentationTestCase;
+
+/**
+ * Unit test for {@link TtmlStyle}.
+ */
+public final class TtmlStyleTest extends InstrumentationTestCase {
+
+    private static final String FONT_FAMILY = "serif";
+    private static final String ID = "id";
+    public static final int FOREGROUND_COLOR = Color.WHITE;
+    public static final int BACKGROUND_COLOR = Color.BLACK;
+    private TtmlStyle style;
+
+    @Override
+    public void setUp() throws Exception {
+        super.setUp();
+        style = new TtmlStyle();
+    }
+
+    public void testInheritStyle() {
+        style.inherit(createAncestorStyle());
+        assertNull("id must not be inherited", style.getId());
+        assertTrue(style.isUnderline());
+        assertTrue(style.isLinethrough());
+        assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, style.getStyle());
+        assertEquals(FONT_FAMILY, style.getFontFamily());
+        assertEquals(Color.WHITE, style.getColor());
+        assertFalse("do not inherit backgroundColor", style.hasBackgroundColorSpecified());
+    }
+
+    public void testChainStyle() {
+        style.chain(createAncestorStyle());
+        assertNull("id must not be inherited", style.getId());
+        assertTrue(style.isUnderline());
+        assertTrue(style.isLinethrough());
+        assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, style.getStyle());
+        assertEquals(FONT_FAMILY, style.getFontFamily());
+        assertEquals(FOREGROUND_COLOR, style.getColor());
+        // do inherit backgroundColor when chaining
+        assertEquals("do not inherit backgroundColor when chaining",
+            BACKGROUND_COLOR, style.getBackgroundColor());
+    }
+
+    public void testGetInheritableStyle() {
+        // same instance as long as everything can be inherited
+        assertSame(style, style.getInheritableStyle());
+        style.inherit(createAncestorStyle());
+        assertSame(style, style.getInheritableStyle());
+        // after setting a property which is not inheritable
+        // we expect the inheritable style to be another instance
+        style.setBackgroundColor(0);
+        TtmlStyle inheritableStyle = style.getInheritableStyle();
+        assertNotSame(style, inheritableStyle);
+        // and subsequent call give always the same instance
+        assertSame(inheritableStyle, style.getInheritableStyle());
+
+        boolean exceptionThrown = false;
+        try {
+          // setting properties after calling getInheritableStyle gives an exception
+          style.setItalic(true);
+        } catch (IllegalStateException e) {
+          exceptionThrown = true;
+        }
+        assertTrue(exceptionThrown);
+    }
+
+    private TtmlStyle createAncestorStyle() {
+        TtmlStyle ancestor = new TtmlStyle();
+        ancestor.setId(ID);
+        ancestor.setItalic(true);
+        ancestor.setBold(true);
+        ancestor.setBackgroundColor(BACKGROUND_COLOR);
+        ancestor.setColor(FOREGROUND_COLOR);
+        ancestor.setLinethrough(true);
+        ancestor.setUnderline(true);
+        ancestor.setFontFamily(FONT_FAMILY);
+        return ancestor;
+    }
+
+    public void testStyle() {
+        assertEquals(TtmlStyle.UNSPECIFIED, style.getStyle());
+        style.setItalic(true);
+        assertEquals(TtmlStyle.STYLE_ITALIC, style.getStyle());
+        style.setBold(true);
+        assertEquals(TtmlStyle.STYLE_BOLD_ITALIC, style.getStyle());
+        style.setItalic(false);
+        assertEquals(TtmlStyle.STYLE_BOLD, style.getStyle());
+        style.setBold(false);
+        assertEquals(TtmlStyle.STYLE_NORMAL, style.getStyle());
+    }
+
+    public void testLinethrough() {
+        assertFalse(style.isLinethrough());
+        style.setLinethrough(true);
+        assertTrue(style.isLinethrough());
+        style.setLinethrough(false);
+        assertFalse(style.isLinethrough());
+    }
+
+    public void testUnderline() {
+        assertFalse(style.isUnderline());
+        style.setUnderline(true);
+        assertTrue(style.isUnderline());
+        style.setUnderline(false);
+        assertFalse(style.isUnderline());
+    }
+
+    public void testFontFamily() {
+        assertNull(style.getFontFamily());
+        style.setFontFamily(FONT_FAMILY);
+        assertEquals(FONT_FAMILY, style.getFontFamily());
+        style.setFontFamily(null);
+        assertNull(style.getFontFamily());
+    }
+
+    public void testColor() {
+        assertFalse(style.hasColorSpecified());
+        style.setColor(Color.BLACK);
+        assertEquals(Color.BLACK, style.getColor());
+        assertTrue(style.hasColorSpecified());
+    }
+
+    public void testBackgroundColor() {
+        assertFalse(style.hasBackgroundColorSpecified());
+        style.setBackgroundColor(Color.BLACK);
+        assertEquals(Color.BLACK, style.getBackgroundColor());
+        assertTrue(style.hasBackgroundColorSpecified());
+    }
+
+    public void testId() {
+        assertNull(style.getId());
+        style.setId(ID);
+        assertEquals(ID, style.getId());
+        style.setId(null);
+        assertNull(style.getId());
+    }
+}
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttParserTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttParserTest.java
index e8bb58ed9f..b0d7271c9c 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttParserTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttParserTest.java
@@ -15,145 +15,146 @@
  */
 package com.google.android.exoplayer.text.webvtt;
 
-import com.google.android.exoplayer.C;
+import com.google.android.exoplayer.text.Cue;
 
 import android.test.InstrumentationTestCase;
+import android.text.Layout.Alignment;
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.List;
 
 /**
  * Unit test for {@link WebvttParser}.
  */
 public class WebvttParserTest extends InstrumentationTestCase {
 
-  private static final String TYPICAL_WEBVTT_FILE = "webvtt/typical";
-  private static final String TYPICAL_WITH_IDS_WEBVTT_FILE = "webvtt/typical_with_identifiers";
-  private static final String TYPICAL_WITH_TAGS_WEBVTT_FILE = "webvtt/typical_with_tags";
-  private static final String LIVE_TYPICAL_WEBVTT_FILE = "webvtt/live_typical";
-  private static final String EMPTY_WEBVTT_FILE = "webvtt/empty";
+  private static final String TYPICAL_FILE = "webvtt/typical";
+  private static final String TYPICAL_WITH_IDS_FILE = "webvtt/typical_with_identifiers";
+  private static final String TYPICAL_WITH_COMMENTS_FILE = "webvtt/typical_with_comments";
+  private static final String WITH_POSITIONING_FILE = "webvtt/with_positioning";
+  private static final String WITH_TAGS_FILE = "webvtt/with_tags";
+  private static final String EMPTY_FILE = "webvtt/empty";
 
-  public void testParseNullWebvttFile() throws IOException {
+  public void testParseEmpty() throws IOException {
     WebvttParser parser = new WebvttParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets().open(EMPTY_WEBVTT_FILE);
-
+    InputStream inputStream = getInstrumentation().getContext().getResources().getAssets()
+        .open(EMPTY_FILE);
     try {
-      parser.parse(inputStream, C.UTF8_NAME, 0);
+      parser.parse(inputStream);
       fail("Expected IOException");
     } catch (IOException expected) {
       // Do nothing.
     }
   }
 
-  public void testParseTypicalWebvttFile() throws IOException {
+  public void testParseTypical() throws IOException {
     WebvttParser parser = new WebvttParser();
     InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets().open(TYPICAL_WEBVTT_FILE);
-    WebvttSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+        getInstrumentation().getContext().getResources().getAssets().open(TYPICAL_FILE);
+    WebvttSubtitle subtitle = parser.parse(inputStream);
 
-    // test start time and event count
-    long startTimeUs = 5000000;
-    assertEquals(startTimeUs, subtitle.getStartTime());
+    // test event count
     assertEquals(4, subtitle.getEventTimeCount());
 
-    // test first cue
-    assertEquals(startTimeUs, subtitle.getEventTime(0));
-    assertEquals("This is the first subtitle.",
-        subtitle.getCues(subtitle.getEventTime(0)).get(0).text.toString());
-    assertEquals(startTimeUs + 1234000, subtitle.getEventTime(1));
-
-    // test second cue
-    assertEquals(startTimeUs + 2345000, subtitle.getEventTime(2));
-    assertEquals("This is the second subtitle.",
-        subtitle.getCues(subtitle.getEventTime(2)).get(0).text.toString());
-    assertEquals(startTimeUs + 3456000, subtitle.getEventTime(3));
+    // test cues
+    assertCue(subtitle, 0, 0, 1234000, "This is the first subtitle.");
+    assertCue(subtitle, 2, 2345000, 3456000, "This is the second subtitle.");
   }
 
-  public void testParseTypicalWithIdsWebvttFile() throws IOException {
+  public void testParseTypicalWithIds() throws IOException {
     WebvttParser parser = new WebvttParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets()
-          .open(TYPICAL_WITH_IDS_WEBVTT_FILE);
-    WebvttSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+    InputStream inputStream = getInstrumentation().getContext().getResources().getAssets()
+        .open(TYPICAL_WITH_IDS_FILE);
+    WebvttSubtitle subtitle = parser.parse(inputStream);
 
-    // test start time and event count
-    long startTimeUs = 5000000;
-    assertEquals(startTimeUs, subtitle.getStartTime());
+    // test event count
     assertEquals(4, subtitle.getEventTimeCount());
 
-    // test first cue
-    assertEquals(startTimeUs, subtitle.getEventTime(0));
-    assertEquals("This is the first subtitle.",
-        subtitle.getCues(subtitle.getEventTime(0)).get(0).text.toString());
-    assertEquals(startTimeUs + 1234000, subtitle.getEventTime(1));
-
-    // test second cue
-    assertEquals(startTimeUs + 2345000, subtitle.getEventTime(2));
-    assertEquals("This is the second subtitle.",
-        subtitle.getCues(subtitle.getEventTime(2)).get(0).text.toString());
-    assertEquals(startTimeUs + 3456000, subtitle.getEventTime(3));
+    // test cues
+    assertCue(subtitle, 0, 0, 1234000, "This is the first subtitle.");
+    assertCue(subtitle, 2, 2345000, 3456000, "This is the second subtitle.");
   }
 
-  public void testParseTypicalWithTagsWebvttFile() throws IOException {
+  public void testParseTypicalWithComments() throws IOException {
     WebvttParser parser = new WebvttParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets()
-          .open(TYPICAL_WITH_TAGS_WEBVTT_FILE);
-    WebvttSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+    InputStream inputStream = getInstrumentation().getContext().getResources().getAssets()
+        .open(TYPICAL_WITH_COMMENTS_FILE);
+    WebvttSubtitle subtitle = parser.parse(inputStream);
+
+    // test event count
+    assertEquals(4, subtitle.getEventTimeCount());
+
+    // test cues
+    assertCue(subtitle, 0, 0, 1234000, "This is the first subtitle.");
+    assertCue(subtitle, 2, 2345000, 3456000, "This is the second subtitle.");
+  }
+
+  public void testParseWithTags() throws IOException {
+    WebvttParser parser = new WebvttParser();
+    InputStream inputStream = getInstrumentation().getContext().getResources().getAssets()
+        .open(WITH_TAGS_FILE);
+    WebvttSubtitle subtitle = parser.parse(inputStream);
 
-    // test start time and event count
-    long startTimeUs = 5000000;
-    assertEquals(startTimeUs, subtitle.getStartTime());
+    // test event count
     assertEquals(8, subtitle.getEventTimeCount());
 
-    // test first cue
-    assertEquals(startTimeUs, subtitle.getEventTime(0));
-    assertEquals("This is the first subtitle.",
-        subtitle.getCues(subtitle.getEventTime(0)).get(0).text.toString());
-    assertEquals(startTimeUs + 1234000, subtitle.getEventTime(1));
-
-    // test second cue
-    assertEquals(startTimeUs + 2345000, subtitle.getEventTime(2));
-    assertEquals("This is the second subtitle.",
-        subtitle.getCues(subtitle.getEventTime(2)).get(0).text.toString());
-    assertEquals(startTimeUs + 3456000, subtitle.getEventTime(3));
-
-    // test third cue
-    assertEquals(startTimeUs + 4000000, subtitle.getEventTime(4));
-    assertEquals("This is the third subtitle.",
-        subtitle.getCues(subtitle.getEventTime(4)).get(0).text.toString());
-    assertEquals(startTimeUs + 5000000, subtitle.getEventTime(5));
-
-    // test fourth cue
-    assertEquals(startTimeUs + 6000000, subtitle.getEventTime(6));
-    assertEquals("This is the <fourth> &subtitle.",
-        subtitle.getCues(subtitle.getEventTime(6)).get(0).text.toString());
-    assertEquals(startTimeUs + 7000000, subtitle.getEventTime(7));
+    // test cues
+    assertCue(subtitle, 0, 0, 1234000, "This is the first subtitle.");
+    assertCue(subtitle, 2, 2345000, 3456000, "This is the second subtitle.");
+    assertCue(subtitle, 4, 4000000, 5000000, "This is the third subtitle.");
+    assertCue(subtitle, 6, 6000000, 7000000, "This is the <fourth> &subtitle.");
   }
 
-  public void testParseLiveTypicalWebvttFile() throws IOException {
+  public void testParseWithPositioning() throws IOException {
     WebvttParser parser = new WebvttParser();
-    InputStream inputStream =
-        getInstrumentation().getContext().getResources().getAssets().open(LIVE_TYPICAL_WEBVTT_FILE);
-    WebvttSubtitle subtitle = parser.parse(inputStream, C.UTF8_NAME, 0);
+    InputStream inputStream = getInstrumentation().getContext().getResources().getAssets()
+        .open(WITH_POSITIONING_FILE);
+    WebvttSubtitle subtitle = parser.parse(inputStream);
+
+    // test event count
+    assertEquals(10, subtitle.getEventTimeCount());
+
+    // test cues
+    assertCue(subtitle, 0, 0, 1234000, "This is the first subtitle.", Alignment.ALIGN_NORMAL,
+        Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.TYPE_UNSET, 0.1f, Cue.ANCHOR_TYPE_START, 0.35f);
+    assertCue(subtitle, 2, 2345000, 3456000, "This is the second subtitle.",
+        Alignment.ALIGN_OPPOSITE, Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.TYPE_UNSET, Cue.DIMEN_UNSET,
+        Cue.TYPE_UNSET, 0.35f);
+    assertCue(subtitle, 4, 4000000, 5000000, "This is the third subtitle.",
+        Alignment.ALIGN_CENTER, 0.45f, Cue.LINE_TYPE_FRACTION, Cue.ANCHOR_TYPE_END, Cue.DIMEN_UNSET,
+        Cue.TYPE_UNSET, 0.35f);
+    assertCue(subtitle, 6, 6000000, 7000000, "This is the fourth subtitle.",
+        Alignment.ALIGN_CENTER, -10f, Cue.LINE_TYPE_NUMBER, Cue.TYPE_UNSET, Cue.DIMEN_UNSET,
+        Cue.TYPE_UNSET, Cue.DIMEN_UNSET);
+    assertCue(subtitle, 8, 7000000, 8000000, "This is the fifth subtitle.",
+        Alignment.ALIGN_OPPOSITE, Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.TYPE_UNSET, 0.1f,
+        Cue.ANCHOR_TYPE_END, 0.1f);
+  }
 
-    // test start time and event count
-    long startTimeUs = 0;
-    assertEquals(startTimeUs, subtitle.getStartTime());
-    assertEquals(4, subtitle.getEventTimeCount());
+  private static void assertCue(WebvttSubtitle subtitle, int eventTimeIndex, long startTimeUs,
+      int endTimeUs, String text) {
+    assertCue(subtitle, eventTimeIndex, startTimeUs, endTimeUs, text, null, Cue.DIMEN_UNSET,
+        Cue.TYPE_UNSET, Cue.TYPE_UNSET, Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.DIMEN_UNSET);
+  }
 
-    // test first cue
-    assertEquals(startTimeUs, subtitle.getEventTime(0));
-    assertEquals("This is the first subtitle.",
-        subtitle.getCues(subtitle.getEventTime(0)).get(0).text.toString());
-    assertEquals(startTimeUs + 1234000, subtitle.getEventTime(1));
-
-    // test second cue
-    assertEquals(startTimeUs + 2345000, subtitle.getEventTime(2));
-    assertEquals("This is the second subtitle.",
-        subtitle.getCues(subtitle.getEventTime(2)).get(0).text.toString());
-    assertEquals(startTimeUs + 3456000, subtitle.getEventTime(3));
+  private static void assertCue(WebvttSubtitle subtitle, int eventTimeIndex, long startTimeUs,
+      int endTimeUs, String text, Alignment textAlignment, float line, int lineType, int lineAnchor,
+      float position, int positionAnchor, float size) {
+    assertEquals(startTimeUs, subtitle.getEventTime(eventTimeIndex));
+    assertEquals(endTimeUs, subtitle.getEventTime(eventTimeIndex + 1));
+    List<Cue> cues = subtitle.getCues(subtitle.getEventTime(eventTimeIndex));
+    assertEquals(1, cues.size());
+    // Assert cue properties
+    Cue cue = cues.get(0);
+    assertEquals(text, cue.text.toString());
+    assertEquals(textAlignment, cue.textAlignment);
+    assertEquals(line, cue.line);
+    assertEquals(lineType, cue.lineType);
+    assertEquals(lineAnchor, cue.lineAnchor);
+    assertEquals(position, cue.position);
+    assertEquals(positionAnchor, cue.positionAnchor);
+    assertEquals(size, cue.size);
   }
 
 }
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitleTest.java b/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitleTest.java
index e8ce0b387c..675c84dd8a 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitleTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitleTest.java
@@ -32,7 +32,7 @@
   private static final String FIRST_AND_SECOND_SUBTITLE_STRING =
       FIRST_SUBTITLE_STRING + "\n" + SECOND_SUBTITLE_STRING;
 
-  private WebvttSubtitle emptySubtitle = new WebvttSubtitle(new ArrayList<WebvttCue>(), 0);
+  private WebvttSubtitle emptySubtitle = new WebvttSubtitle(new ArrayList<WebvttCue>());
 
   private ArrayList<WebvttCue> simpleSubtitleCues = new ArrayList<>();
   {
@@ -42,7 +42,7 @@
     WebvttCue secondCue = new WebvttCue(3000000, 4000000, SECOND_SUBTITLE_STRING);
     simpleSubtitleCues.add(secondCue);
   }
-  private WebvttSubtitle simpleSubtitle = new WebvttSubtitle(simpleSubtitleCues, 0);
+  private WebvttSubtitle simpleSubtitle = new WebvttSubtitle(simpleSubtitleCues);
 
   private ArrayList<WebvttCue> overlappingSubtitleCues = new ArrayList<>();
   {
@@ -52,7 +52,7 @@
     WebvttCue secondCue = new WebvttCue(2000000, 4000000, SECOND_SUBTITLE_STRING);
     overlappingSubtitleCues.add(secondCue);
   }
-  private WebvttSubtitle overlappingSubtitle = new WebvttSubtitle(overlappingSubtitleCues, 0);
+  private WebvttSubtitle overlappingSubtitle = new WebvttSubtitle(overlappingSubtitleCues);
 
   private ArrayList<WebvttCue> nestedSubtitleCues = new ArrayList<>();
   {
@@ -62,7 +62,7 @@
     WebvttCue secondCue = new WebvttCue(2000000, 3000000, SECOND_SUBTITLE_STRING);
     nestedSubtitleCues.add(secondCue);
   }
-  private WebvttSubtitle nestedSubtitle = new WebvttSubtitle(nestedSubtitleCues, 0);
+  private WebvttSubtitle nestedSubtitle = new WebvttSubtitle(nestedSubtitleCues);
 
   public void testEventCount() {
     assertEquals(0, emptySubtitle.getEventTimeCount());
@@ -71,13 +71,6 @@ public void testEventCount() {
     assertEquals(4, nestedSubtitle.getEventTimeCount());
   }
 
-  public void testStartTime() {
-    assertEquals(0, emptySubtitle.getStartTime());
-    assertEquals(0, simpleSubtitle.getStartTime());
-    assertEquals(0, overlappingSubtitle.getStartTime());
-    assertEquals(0, nestedSubtitle.getStartTime());
-  }
-
   public void testLastEventTime() {
     assertEquals(-1, emptySubtitle.getLastEventTime());
     assertEquals(4000000, simpleSubtitle.getLastEventTime());
diff --git a/library/src/androidTest/java/com/google/android/exoplayer/util/UtilTest.java b/library/src/androidTest/java/com/google/android/exoplayer/util/UtilTest.java
index 00d4a60fe4..7ffff22960 100644
--- a/library/src/androidTest/java/com/google/android/exoplayer/util/UtilTest.java
+++ b/library/src/androidTest/java/com/google/android/exoplayer/util/UtilTest.java
@@ -144,4 +144,21 @@ public void testParseXsDateTime() throws ParseException {
     assertEquals(1407322800000L, Util.parseXsDateTime("2014-08-06T11:00:00Z"));
   }
 
+  public void testLongSplitting() {
+    assertLongSplittingForValue(Long.MIN_VALUE);
+    assertLongSplittingForValue(Long.MIN_VALUE + 1);
+    assertLongSplittingForValue(-1);
+    assertLongSplittingForValue(0);
+    assertLongSplittingForValue(1);
+    assertLongSplittingForValue(Long.MAX_VALUE - 1);
+    assertLongSplittingForValue(Long.MAX_VALUE);
+  }
+
+  private static void assertLongSplittingForValue(long value) {
+    int topBits = Util.getTopInt(value);
+    int bottomBots = Util.getBottomInt(value);
+    long reconstructedValue = Util.getLong(topBits, bottomBots);
+    assertEquals(value, reconstructedValue);
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/C.java b/library/src/main/java/com/google/android/exoplayer/C.java
index af6e619a6d..145e151099 100644
--- a/library/src/main/java/com/google/android/exoplayer/C.java
+++ b/library/src/main/java/com/google/android/exoplayer/C.java
@@ -90,18 +90,6 @@
    */
   public static final int RESULT_END_OF_INPUT = -1;
 
-  /**
-   * A prefix for custom ExoPlayer WebVTT headers.
-   */
-  public static final String WEBVTT_EXO_HEADER = "EXO-HEADER";
-
-  /**
-   * An element of a custom ExoPlayer WebVTT header. An {@code WEBVTT_OFFSET + value} element can
-   * be added to a custom ExoPlayer WebVTT header to specify an offset time (in microseconds) that
-   * should be added to the embedded MPEGTS value.
-   */
-  public static final String WEBVTT_EXO_HEADER_OFFSET = "OFFSET:";
-
   private C() {}
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/DummyTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/DummyTrackRenderer.java
index 1a1305898e..c1e91b2904 100644
--- a/library/src/main/java/com/google/android/exoplayer/DummyTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/DummyTrackRenderer.java
@@ -18,15 +18,25 @@
 /**
  * A {@link TrackRenderer} that does nothing.
  * <p>
- * This renderer returns {@link TrackRenderer#STATE_IGNORE} from {@link #doPrepare(long)} in order
- * to request that it should be ignored. {@link IllegalStateException} is thrown from all methods
- * that are documented to indicate that they should not be invoked unless the renderer is prepared.
+ * This renderer returns 0 from {@link #getTrackCount()} in order to request that it should be
+ * ignored. {@link IllegalStateException} is thrown from all other methods documented to indicate
+ * that they should not be invoked unless the renderer is prepared.
  */
 public final class DummyTrackRenderer extends TrackRenderer {
 
   @Override
-  protected int doPrepare(long positionUs) {
-    return STATE_IGNORE;
+  protected boolean doPrepare(long positionUs) throws ExoPlaybackException {
+    return true;
+  }
+
+  @Override
+  protected int getTrackCount() {
+    return 0;
+  }
+
+  @Override
+  protected MediaFormat getFormat(int track) {
+    throw new IllegalStateException();
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/ExoPlayer.java b/library/src/main/java/com/google/android/exoplayer/ExoPlayer.java
index e54645e095..de0c73bdb1 100644
--- a/library/src/main/java/com/google/android/exoplayer/ExoPlayer.java
+++ b/library/src/main/java/com/google/android/exoplayer/ExoPlayer.java
@@ -74,7 +74,7 @@
  * <h3>Player state</h3>
  *
  * <p>The components of an {@link ExoPlayer}'s state can be divided into two distinct groups. State
- * accessed by {@link #getRendererEnabled(int)} and {@link #getPlayWhenReady()} are only ever
+ * accessed by {@link #getSelectedTrack(int)} and {@link #getPlayWhenReady()} is only ever
  * changed by invoking the player's methods, and are never changed as a result of operations that
  * have been performed asynchronously by the playback thread. In contrast, the playback state
  * accessed by {@link #getPlaybackState()} is only ever changed as a result of operations
@@ -219,6 +219,18 @@ public static ExoPlayer newInstance(int rendererCount) {
    * The player has finished playing the media.
    */
   public static final int STATE_ENDED = 5;
+
+  /**
+   * A value that can be passed as the second argument to {@link #setSelectedTrack(int, int)} to
+   * disable the renderer.
+   */
+  public static final int TRACK_DISABLED = -1;
+  /**
+   * A value that can be passed as the second argument to {@link #setSelectedTrack(int, int)} to
+   * select the default track.
+   */
+  public static final int TRACK_DEFAULT = 0;
+
   /**
    * Represents an unknown time or duration.
    */
@@ -266,27 +278,72 @@ public static ExoPlayer newInstance(int rendererCount) {
    * <p>
    * Always returns false whilst the player is in the {@link #STATE_PREPARING} state.
    *
+   * @deprecated Use {@code getTrackCount(rendererIndex) > 0}.
    * @param rendererIndex The index of the renderer.
    * @return True if the renderer has media to play, false otherwise.
    */
+  @Deprecated
   public boolean getRendererHasMedia(int rendererIndex);
 
   /**
    * Sets whether the renderer at the given index is enabled.
    *
+   * @deprecated Use {@code setSelectedTrack(rendererIndex, trackIndex)}. Passing
+   *     {@link #TRACK_DEFAULT} as {@code trackIndex} is equivalent to enabling the renderer with
+   *     this method. Passing {@link #TRACK_DISABLED} is equivalent to disabling the renderer.
    * @param rendererIndex The index of the renderer.
    * @param enabled Whether the renderer at the given index should be enabled.
    */
+  @Deprecated
   public void setRendererEnabled(int rendererIndex, boolean enabled);
 
   /**
    * Whether the renderer at the given index is enabled.
    *
+   * @deprecated Use {@code getSelectedTrack(rendererIndex)}. A non-negative return value from that
+   *     method is equivalent to this method returning true. A negative return value is equivalent
+   *     to this method returning false.
    * @param rendererIndex The index of the renderer.
    * @return Whether the renderer is enabled.
    */
+  @Deprecated
   public boolean getRendererEnabled(int rendererIndex);
 
+  /**
+   * Returns the number of tracks exposed by the specified renderer.
+   *
+   * @param rendererIndex The index of the renderer.
+   * @return The number of tracks.
+   */
+  public int getTrackCount(int rendererIndex);
+
+  /**
+   * Returns the format of a track.
+   *
+   * @param rendererIndex The index of the renderer.
+   * @param trackIndex The index of the track.
+   * @return The format of the track.
+   */
+  public MediaFormat getTrackFormat(int rendererIndex, int trackIndex);
+
+  /**
+   * Selects a track for the specified renderer.
+   *
+   * @param rendererIndex The index of the renderer.
+   * @param trackIndex The index of the track. A negative value or a value greater than or equal to
+   *     the renderer's track count will disable the renderer.
+   */
+  public void setSelectedTrack(int rendererIndex, int trackIndex);
+
+  /**
+   * Returns the index of the currently selected track for the specified renderer.
+   *
+   * @param rendererIndex The index of the renderer.
+   * @return The selected track. A negative value or a value greater than or equal to the renderer's
+   *     track count indicates that the renderer is disabled.
+   */
+  public int getSelectedTrack(int rendererIndex);
+
   /**
    * Sets whether playback should proceed when {@link #getPlaybackState()} == {@link #STATE_READY}.
    * If the player is already in this state, then this method can be used to pause and resume
diff --git a/library/src/main/java/com/google/android/exoplayer/ExoPlayerImpl.java b/library/src/main/java/com/google/android/exoplayer/ExoPlayerImpl.java
index 6729bfddd8..2924a3ba6c 100644
--- a/library/src/main/java/com/google/android/exoplayer/ExoPlayerImpl.java
+++ b/library/src/main/java/com/google/android/exoplayer/ExoPlayerImpl.java
@@ -34,8 +34,8 @@
   private final Handler eventHandler;
   private final ExoPlayerImplInternal internalPlayer;
   private final CopyOnWriteArraySet<Listener> listeners;
-  private final boolean[] rendererHasMediaFlags;
-  private final boolean[] rendererEnabledFlags;
+  private final MediaFormat[][] trackFormats;
+  private final int[] selectedTrackIndices;
 
   private boolean playWhenReady;
   private int playbackState;
@@ -58,18 +58,15 @@ public ExoPlayerImpl(int rendererCount, int minBufferMs, int minRebufferMs) {
     this.playWhenReady = false;
     this.playbackState = STATE_IDLE;
     this.listeners = new CopyOnWriteArraySet<>();
-    this.rendererHasMediaFlags = new boolean[rendererCount];
-    this.rendererEnabledFlags = new boolean[rendererCount];
-    for (int i = 0; i < rendererEnabledFlags.length; i++) {
-      rendererEnabledFlags[i] = true;
-    }
+    this.trackFormats = new MediaFormat[rendererCount][];
+    this.selectedTrackIndices = new int[rendererCount];
     eventHandler = new Handler() {
       @Override
       public void handleMessage(Message msg) {
         ExoPlayerImpl.this.handleEvent(msg);
       }
     };
-    internalPlayer = new ExoPlayerImplInternal(eventHandler, playWhenReady, rendererEnabledFlags,
+    internalPlayer = new ExoPlayerImplInternal(eventHandler, playWhenReady, selectedTrackIndices,
         minBufferMs, minRebufferMs);
   }
 
@@ -95,26 +92,49 @@ public int getPlaybackState() {
 
   @Override
   public void prepare(TrackRenderer... renderers) {
-    Arrays.fill(rendererHasMediaFlags, false);
+    Arrays.fill(trackFormats, null);
     internalPlayer.prepare(renderers);
   }
 
+  @Deprecated
   @Override
   public boolean getRendererHasMedia(int rendererIndex) {
-    return rendererHasMediaFlags[rendererIndex];
+    return getTrackCount(rendererIndex) > 0;
   }
 
+  @Deprecated
   @Override
   public void setRendererEnabled(int rendererIndex, boolean enabled) {
-    if (rendererEnabledFlags[rendererIndex] != enabled) {
-      rendererEnabledFlags[rendererIndex] = enabled;
-      internalPlayer.setRendererEnabled(rendererIndex, enabled);
-    }
+    setSelectedTrack(rendererIndex, enabled ? ExoPlayer.TRACK_DEFAULT : ExoPlayer.TRACK_DISABLED);
   }
 
+  @Deprecated
   @Override
   public boolean getRendererEnabled(int rendererIndex) {
-    return rendererEnabledFlags[rendererIndex];
+    return getSelectedTrack(rendererIndex) >= 0;
+  }
+
+  @Override
+  public int getTrackCount(int rendererIndex) {
+    return trackFormats[rendererIndex] != null ? trackFormats[rendererIndex].length : 0;
+  }
+
+  @Override
+  public MediaFormat getTrackFormat(int rendererIndex, int trackIndex) {
+    return trackFormats[rendererIndex][trackIndex];
+  }
+
+  @Override
+  public void setSelectedTrack(int rendererIndex, int trackIndex) {
+    if (selectedTrackIndices[rendererIndex] != trackIndex) {
+      selectedTrackIndices[rendererIndex] = trackIndex;
+      internalPlayer.setRendererSelectedTrack(rendererIndex, trackIndex);
+    }
+  }
+
+  @Override
+  public int getSelectedTrack(int rendererIndex) {
+    return selectedTrackIndices[rendererIndex];
   }
 
   @Override
@@ -192,9 +212,7 @@ public int getBufferedPercentage() {
   /* package */ void handleEvent(Message msg) {
     switch (msg.what) {
       case ExoPlayerImplInternal.MSG_PREPARED: {
-        boolean[] rendererHasMediaFlags = (boolean[]) msg.obj;
-        System.arraycopy(rendererHasMediaFlags, 0, this.rendererHasMediaFlags, 0,
-            rendererHasMediaFlags.length);
+        System.arraycopy(msg.obj, 0, trackFormats, 0, trackFormats.length);
         playbackState = msg.arg1;
         for (Listener listener : listeners) {
           listener.onPlayerStateChanged(playWhenReady, playbackState);
diff --git a/library/src/main/java/com/google/android/exoplayer/ExoPlayerImplInternal.java b/library/src/main/java/com/google/android/exoplayer/ExoPlayerImplInternal.java
index 4737a36919..e239cbe442 100644
--- a/library/src/main/java/com/google/android/exoplayer/ExoPlayerImplInternal.java
+++ b/library/src/main/java/com/google/android/exoplayer/ExoPlayerImplInternal.java
@@ -19,6 +19,7 @@
 import com.google.android.exoplayer.util.Assertions;
 import com.google.android.exoplayer.util.PriorityHandlerThread;
 import com.google.android.exoplayer.util.TraceUtil;
+import com.google.android.exoplayer.util.Util;
 
 import android.os.Handler;
 import android.os.HandlerThread;
@@ -30,7 +31,9 @@
 import android.util.Pair;
 
 import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.List;
+import java.util.concurrent.atomic.AtomicInteger;
 
 /**
  * Implements the internal behavior of {@link ExoPlayerImpl}.
@@ -53,7 +56,7 @@
   private static final int MSG_RELEASE = 5;
   private static final int MSG_SEEK_TO = 6;
   private static final int MSG_DO_SOME_WORK = 7;
-  private static final int MSG_SET_RENDERER_ENABLED = 8;
+  private static final int MSG_SET_RENDERER_SELECTED_TRACK = 8;
   private static final int MSG_CUSTOM = 9;
 
   private static final int PREPARE_INTERVAL_MS = 10;
@@ -64,11 +67,13 @@
   private final HandlerThread internalPlaybackThread;
   private final Handler eventHandler;
   private final StandaloneMediaClock standaloneMediaClock;
-  private final boolean[] rendererEnabledFlags;
+  private final AtomicInteger pendingSeekCount;
+  private final List<TrackRenderer> enabledRenderers;
+  private final MediaFormat[][] trackFormats;
+  private final int[] selectedTrackIndices;
   private final long minBufferUs;
   private final long minRebufferUs;
 
-  private final List<TrackRenderer> enabledRenderers;
   private TrackRenderer[] renderers;
   private TrackRenderer rendererMediaClockSource;
   private MediaClock rendererMediaClock;
@@ -79,6 +84,7 @@
   private int state;
   private int customMessagesSent = 0;
   private int customMessagesProcessed = 0;
+  private long lastSeekPositionMs;
   private long elapsedRealtimeUs;
 
   private volatile long durationUs;
@@ -86,22 +92,20 @@
   private volatile long bufferedPositionUs;
 
   public ExoPlayerImplInternal(Handler eventHandler, boolean playWhenReady,
-      boolean[] rendererEnabledFlags, int minBufferMs, int minRebufferMs) {
+      int[] selectedTrackIndices, int minBufferMs, int minRebufferMs) {
     this.eventHandler = eventHandler;
     this.playWhenReady = playWhenReady;
-    this.rendererEnabledFlags = new boolean[rendererEnabledFlags.length];
     this.minBufferUs = minBufferMs * 1000L;
     this.minRebufferUs = minRebufferMs * 1000L;
-    for (int i = 0; i < rendererEnabledFlags.length; i++) {
-      this.rendererEnabledFlags[i] = rendererEnabledFlags[i];
-    }
-
+    this.selectedTrackIndices = Arrays.copyOf(selectedTrackIndices, selectedTrackIndices.length);
     this.state = ExoPlayer.STATE_IDLE;
     this.durationUs = TrackRenderer.UNKNOWN_TIME_US;
     this.bufferedPositionUs = TrackRenderer.UNKNOWN_TIME_US;
 
     standaloneMediaClock = new StandaloneMediaClock();
-    enabledRenderers = new ArrayList<>(rendererEnabledFlags.length);
+    pendingSeekCount = new AtomicInteger();
+    enabledRenderers = new ArrayList<>(selectedTrackIndices.length);
+    trackFormats = new MediaFormat[selectedTrackIndices.length][];
     // Note: The documentation for Process.THREAD_PRIORITY_AUDIO that states "Applications can
     // not normally change to this priority" is incorrect.
     internalPlaybackThread = new PriorityHandlerThread(getClass().getSimpleName() + ":Handler",
@@ -115,7 +119,7 @@ public Looper getPlaybackLooper() {
   }
 
   public long getCurrentPosition() {
-    return positionUs / 1000;
+    return pendingSeekCount.get() > 0 ? lastSeekPositionMs : (positionUs / 1000);
   }
 
   public long getBufferedPosition() {
@@ -137,15 +141,19 @@ public void setPlayWhenReady(boolean playWhenReady) {
   }
 
   public void seekTo(long positionMs) {
-    handler.obtainMessage(MSG_SEEK_TO, positionMs).sendToTarget();
+    lastSeekPositionMs = positionMs;
+    pendingSeekCount.incrementAndGet();
+    handler.obtainMessage(MSG_SEEK_TO, Util.getTopInt(positionMs),
+        Util.getBottomInt(positionMs)).sendToTarget();
   }
 
   public void stop() {
     handler.sendEmptyMessage(MSG_STOP);
   }
 
-  public void setRendererEnabled(int index, boolean enabled) {
-    handler.obtainMessage(MSG_SET_RENDERER_ENABLED, index, enabled ? 1 : 0).sendToTarget();
+  public void setRendererSelectedTrack(int rendererIndex, int trackIndex) {
+    handler.obtainMessage(MSG_SET_RENDERER_SELECTED_TRACK, rendererIndex, trackIndex)
+        .sendToTarget();
   }
 
   public void sendMessage(ExoPlayerComponent target, int messageType, Object message) {
@@ -206,7 +214,7 @@ public boolean handleMessage(Message msg) {
           return true;
         }
         case MSG_SEEK_TO: {
-          seekToInternal((Long) msg.obj);
+          seekToInternal(Util.getLong(msg.arg1, msg.arg2));
           return true;
         }
         case MSG_STOP: {
@@ -221,8 +229,8 @@ public boolean handleMessage(Message msg) {
           sendMessageInternal(msg.arg1, msg.obj);
           return true;
         }
-        case MSG_SET_RENDERER_ENABLED: {
-          setRendererEnabledInternal(msg.arg1, msg.arg2 != 0);
+        case MSG_SET_RENDERER_SELECTED_TRACK: {
+          setRendererSelectedTrackInternal(msg.arg1, msg.arg2);
           return true;
         }
         default:
@@ -251,6 +259,7 @@ private void setState(int state) {
   private void prepareInternal(TrackRenderer[] renderers) throws ExoPlaybackException {
     resetInternal();
     this.renderers = renderers;
+    Arrays.fill(trackFormats, null);
     for (int i = 0; i < renderers.length; i++) {
       MediaClock mediaClock = renderers[i].getMediaClock();
       if (mediaClock != null) {
@@ -286,11 +295,15 @@ private void incrementalPrepareInternal() throws ExoPlaybackException {
     long durationUs = 0;
     boolean allRenderersEnded = true;
     boolean allRenderersReadyOrEnded = true;
-    boolean[] rendererHasMediaFlags = new boolean[renderers.length];
     for (int rendererIndex = 0; rendererIndex < renderers.length; rendererIndex++) {
       TrackRenderer renderer = renderers[rendererIndex];
-      rendererHasMediaFlags[rendererIndex] = renderer.getState() == TrackRenderer.STATE_PREPARED;
-      if (rendererHasMediaFlags[rendererIndex]) {
+      int rendererTrackCount = renderer.getTrackCount();
+      MediaFormat[] rendererTrackFormats = new MediaFormat[rendererTrackCount];
+      for (int trackIndex = 0; trackIndex < rendererTrackCount; trackIndex++) {
+        rendererTrackFormats[trackIndex] = renderer.getFormat(trackIndex);
+      }
+      trackFormats[rendererIndex] = rendererTrackFormats;
+      if (rendererTrackCount > 0) {
         if (durationUs == TrackRenderer.UNKNOWN_TIME_US) {
           // We've already encountered a track for which the duration is unknown, so the media
           // duration is unknown regardless of the duration of this track.
@@ -304,8 +317,9 @@ private void incrementalPrepareInternal() throws ExoPlaybackException {
             durationUs = Math.max(durationUs, trackDurationUs);
           }
         }
-        if (rendererEnabledFlags[rendererIndex]) {
-          renderer.enable(positionUs, false);
+        int trackIndex = selectedTrackIndices[rendererIndex];
+        if (0 <= trackIndex && trackIndex < rendererTrackFormats.length) {
+          renderer.enable(trackIndex, positionUs, false);
           enabledRenderers.add(renderer);
           allRenderersEnded = allRenderersEnded && renderer.isEnded();
           allRenderersReadyOrEnded = allRenderersReadyOrEnded && rendererReadyOrEnded(renderer);
@@ -323,8 +337,8 @@ private void incrementalPrepareInternal() throws ExoPlaybackException {
     }
 
     // Fire an event indicating that the player has been prepared, passing the initial state and
-    // renderer media flags.
-    eventHandler.obtainMessage(MSG_PREPARED, state, 0, rendererHasMediaFlags).sendToTarget();
+    // renderer track information.
+    eventHandler.obtainMessage(MSG_PREPARED, state, 0, trackFormats).sendToTarget();
 
     // Start the renderers if required, and schedule the first piece of work.
     if (playWhenReady && state == ExoPlayer.STATE_READY) {
@@ -482,20 +496,29 @@ private void scheduleNextOperation(int operationType, long thisOperationStartTim
   }
 
   private void seekToInternal(long positionMs) throws ExoPlaybackException {
-    rebuffering = false;
-    positionUs = positionMs * 1000L;
-    standaloneMediaClock.stop();
-    standaloneMediaClock.setPositionUs(positionUs);
-    if (state == ExoPlayer.STATE_IDLE || state == ExoPlayer.STATE_PREPARING) {
-      return;
-    }
-    for (int i = 0; i < enabledRenderers.size(); i++) {
-      TrackRenderer renderer = enabledRenderers.get(i);
-      ensureStopped(renderer);
-      renderer.seekTo(positionUs);
+    try {
+      if (positionMs == (positionUs / 1000)) {
+        // Seek is to the current position. Do nothing.
+        return;
+      }
+
+      rebuffering = false;
+      positionUs = positionMs * 1000;
+      standaloneMediaClock.stop();
+      standaloneMediaClock.setPositionUs(positionUs);
+      if (state == ExoPlayer.STATE_IDLE || state == ExoPlayer.STATE_PREPARING) {
+        return;
+      }
+      for (int i = 0; i < enabledRenderers.size(); i++) {
+        TrackRenderer renderer = enabledRenderers.get(i);
+        ensureStopped(renderer);
+        renderer.seekTo(positionUs);
+      }
+      setState(ExoPlayer.STATE_BUFFERING);
+      handler.sendEmptyMessage(MSG_DO_SOME_WORK);
+    } finally {
+      pendingSeekCount.decrementAndGet();
     }
-    setState(ExoPlayer.STATE_BUFFERING);
-    handler.sendEmptyMessage(MSG_DO_SOME_WORK);
   }
 
   private void stopInternal() {
@@ -564,55 +587,66 @@ private void release(TrackRenderer renderer) {
       @SuppressWarnings("unchecked")
       Pair<ExoPlayerComponent, Object> targetAndMessage = (Pair<ExoPlayerComponent, Object>) obj;
       targetAndMessage.first.handleMessage(what, targetAndMessage.second);
+      if (state != ExoPlayer.STATE_IDLE && state != ExoPlayer.STATE_PREPARING) {
+        // The message may have caused something to change that now requires us to do work.
+        handler.sendEmptyMessage(MSG_DO_SOME_WORK);
+      }
     } finally {
       synchronized (this) {
         customMessagesProcessed++;
         notifyAll();
       }
     }
-    if (state != ExoPlayer.STATE_IDLE && state != ExoPlayer.STATE_PREPARING) {
-      // The message may have caused something to change that now requires us to do work.
-      handler.sendEmptyMessage(MSG_DO_SOME_WORK);
-    }
   }
 
-  private void setRendererEnabledInternal(int rendererIndex, boolean enabled)
+  private void setRendererSelectedTrackInternal(int rendererIndex, int trackIndex)
       throws ExoPlaybackException {
-    if (rendererEnabledFlags[rendererIndex] == enabled) {
+    if (selectedTrackIndices[rendererIndex] == trackIndex) {
       return;
     }
 
-    rendererEnabledFlags[rendererIndex] = enabled;
+    selectedTrackIndices[rendererIndex] = trackIndex;
     if (state == ExoPlayer.STATE_IDLE || state == ExoPlayer.STATE_PREPARING) {
       return;
     }
 
     TrackRenderer renderer = renderers[rendererIndex];
     int rendererState = renderer.getState();
-    if (rendererState != TrackRenderer.STATE_PREPARED &&
-        rendererState != TrackRenderer.STATE_ENABLED &&
-        rendererState != TrackRenderer.STATE_STARTED) {
+    if (rendererState == TrackRenderer.STATE_UNPREPARED
+        || rendererState == TrackRenderer.STATE_RELEASED
+        || renderer.getTrackCount() == 0) {
       return;
     }
 
-    if (enabled) {
-      boolean playing = playWhenReady && state == ExoPlayer.STATE_READY;
-      renderer.enable(positionUs, playing);
-      enabledRenderers.add(renderer);
-      if (playing) {
-        renderer.start();
-      }
-      handler.sendEmptyMessage(MSG_DO_SOME_WORK);
-    } else {
-      if (renderer == rendererMediaClockSource) {
+    boolean isEnabled = rendererState == TrackRenderer.STATE_ENABLED
+        || rendererState == TrackRenderer.STATE_STARTED;
+    boolean shouldEnable = 0 <= trackIndex && trackIndex < trackFormats[rendererIndex].length;
+
+    if (isEnabled) {
+      // The renderer is currently enabled. We need to disable it, so that we can either re-enable
+      // it with the newly selected track (if shouldEnable is true) or because we want to leave it
+      // disabled (if shouldEnable is false).
+      if (!shouldEnable && renderer == rendererMediaClockSource) {
         // We've been using rendererMediaClockSource to advance the current position, but it's being
-        // disabled. Sync standaloneMediaClock so that it can take over timing responsibilities.
+        // disabled and won't be re-enabled. Sync standaloneMediaClock so that it can take over
+        // timing responsibilities.
         standaloneMediaClock.setPositionUs(rendererMediaClock.getPositionUs());
       }
       ensureStopped(renderer);
       enabledRenderers.remove(renderer);
       renderer.disable();
     }
+
+    if (shouldEnable) {
+      // Re-enable the renderer with the newly selected track.
+      boolean playing = playWhenReady && state == ExoPlayer.STATE_READY;
+      renderer.enable(trackIndex, positionUs, playing);
+      enabledRenderers.add(renderer);
+      if (playing) {
+        renderer.start();
+      }
+      handler.sendEmptyMessage(MSG_DO_SOME_WORK);
+    }
   }
 
   private void ensureStopped(TrackRenderer renderer) throws ExoPlaybackException {
diff --git a/library/src/main/java/com/google/android/exoplayer/ExoPlayerLibraryInfo.java b/library/src/main/java/com/google/android/exoplayer/ExoPlayerLibraryInfo.java
index 1d3ae0c6be..f746fd76c8 100644
--- a/library/src/main/java/com/google/android/exoplayer/ExoPlayerLibraryInfo.java
+++ b/library/src/main/java/com/google/android/exoplayer/ExoPlayerLibraryInfo.java
@@ -23,7 +23,7 @@
   /**
    * The version of the library, expressed as a string.
    */
-  public static final String VERSION = "1.4.2";
+  public static final String VERSION = "1.5.0";
 
   /**
    * The version of the library, expressed as an integer.
@@ -31,7 +31,7 @@
    * Three digits are used for each component of {@link #VERSION}. For example "1.2.3" has the
    * corresponding integer version 001002003.
    */
-  public static final int VERSION_INT = 001004002;
+  public static final int VERSION_INT = 001005000;
 
   /**
    * Whether the library was compiled with {@link com.google.android.exoplayer.util.Assertions}
diff --git a/library/src/main/java/com/google/android/exoplayer/FrameworkSampleSource.java b/library/src/main/java/com/google/android/exoplayer/FrameworkSampleSource.java
index a319636d52..6c0cf25b7a 100644
--- a/library/src/main/java/com/google/android/exoplayer/FrameworkSampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/FrameworkSampleSource.java
@@ -23,6 +23,7 @@
 import com.google.android.exoplayer.util.MimeTypes;
 import com.google.android.exoplayer.util.Util;
 
+import android.annotation.SuppressLint;
 import android.annotation.TargetApi;
 import android.content.Context;
 import android.media.MediaExtractor;
@@ -30,6 +31,8 @@
 
 import java.io.FileDescriptor;
 import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.ArrayList;
 import java.util.Map;
 import java.util.UUID;
 
@@ -70,7 +73,7 @@
 
   private IOException preparationError;
   private MediaExtractor extractor;
-  private TrackInfo[] trackInfos;
+  private MediaFormat[] trackFormats;
   private boolean prepared;
   private int remainingReleaseCount;
   private int[] trackStates;
@@ -141,13 +144,9 @@ public boolean prepare(long positionUs) {
 
       trackStates = new int[extractor.getTrackCount()];
       pendingDiscontinuities = new boolean[trackStates.length];
-      trackInfos = new TrackInfo[trackStates.length];
+      trackFormats = new MediaFormat[trackStates.length];
       for (int i = 0; i < trackStates.length; i++) {
-        android.media.MediaFormat format = extractor.getTrackFormat(i);
-        long durationUs = format.containsKey(android.media.MediaFormat.KEY_DURATION)
-            ? format.getLong(android.media.MediaFormat.KEY_DURATION) : C.UNKNOWN_TIME_US;
-        String mime = format.getString(android.media.MediaFormat.KEY_MIME);
-        trackInfos[i] = new TrackInfo(mime, durationUs);
+        trackFormats[i] = createMediaFormat(extractor.getTrackFormat(i));
       }
       prepared = true;
     }
@@ -161,9 +160,9 @@ public int getTrackCount() {
   }
 
   @Override
-  public TrackInfo getTrackInfo(int track) {
+  public MediaFormat getFormat(int track) {
     Assertions.checkState(prepared);
-    return trackInfos[track];
+    return trackFormats[track];
   }
 
   @Override
@@ -197,8 +196,7 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
       return NOTHING_READ;
     }
     if (trackStates[track] != TRACK_STATE_FORMAT_SENT) {
-      formatHolder.format = MediaFormat.createFromFrameworkMediaFormatV16(
-          extractor.getTrackFormat(track));
+      formatHolder.format = trackFormats[track];
       formatHolder.drmInitData = Util.SDK_INT >= 18 ? getDrmInitDataV18() : null;
       trackStates[track] = TRACK_STATE_FORMAT_SENT;
       return FORMAT_READ;
@@ -297,4 +295,42 @@ private void seekToUsInternal(long positionUs, boolean force) {
     }
   }
 
+  @SuppressLint("InlinedApi")
+  private static MediaFormat createMediaFormat(android.media.MediaFormat format) {
+    String mimeType = format.getString(android.media.MediaFormat.KEY_MIME);
+    String language = getOptionalStringV16(format, android.media.MediaFormat.KEY_LANGUAGE);
+    int maxInputSize = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_MAX_INPUT_SIZE);
+    int width = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_WIDTH);
+    int height = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_HEIGHT);
+    int rotationDegrees = getOptionalIntegerV16(format, "rotation-degrees");
+    int channelCount = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_CHANNEL_COUNT);
+    int sampleRate = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_SAMPLE_RATE);
+    ArrayList<byte[]> initializationData = new ArrayList<>();
+    for (int i = 0; format.containsKey("csd-" + i); i++) {
+      ByteBuffer buffer = format.getByteBuffer("csd-" + i);
+      byte[] data = new byte[buffer.limit()];
+      buffer.get(data);
+      initializationData.add(data);
+      buffer.flip();
+    }
+    long durationUs = format.containsKey(android.media.MediaFormat.KEY_DURATION)
+        ? format.getLong(android.media.MediaFormat.KEY_DURATION) : C.UNKNOWN_TIME_US;
+    MediaFormat mediaFormat = new MediaFormat(MediaFormat.NO_VALUE, mimeType, MediaFormat.NO_VALUE,
+        maxInputSize, durationUs, width, height, rotationDegrees, MediaFormat.NO_VALUE,
+        channelCount, sampleRate, language, MediaFormat.OFFSET_SAMPLE_RELATIVE, initializationData,
+        false, MediaFormat.NO_VALUE, MediaFormat.NO_VALUE);
+    mediaFormat.setFrameworkFormatV16(format);
+    return mediaFormat;
+  }
+
+  @TargetApi(16)
+  private static final String getOptionalStringV16(android.media.MediaFormat format, String key) {
+    return format.containsKey(key) ? format.getString(key) : null;
+  }
+
+  @TargetApi(16)
+  private static final int getOptionalIntegerV16(android.media.MediaFormat format, String key) {
+    return format.containsKey(key) ? format.getInteger(key) : MediaFormat.NO_VALUE;
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/MediaCodecAudioTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/MediaCodecAudioTrackRenderer.java
index 510313c787..8a9f2881ba 100644
--- a/library/src/main/java/com/google/android/exoplayer/MediaCodecAudioTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/MediaCodecAudioTrackRenderer.java
@@ -16,11 +16,13 @@
 package com.google.android.exoplayer;
 
 import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
+import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.audio.AudioTrack;
 import com.google.android.exoplayer.drm.DrmSessionManager;
 import com.google.android.exoplayer.util.MimeTypes;
 
 import android.annotation.TargetApi;
+import android.media.AudioManager;
 import android.media.MediaCodec;
 import android.media.audiofx.Virtualizer;
 import android.os.Handler;
@@ -70,6 +72,7 @@
   private final EventListener eventListener;
   private final AudioTrack audioTrack;
 
+  private android.media.MediaFormat passthroughMediaFormat;
   private int audioSessionId;
   private long currentPositionUs;
   private boolean allowPositionDiscontinuity;
@@ -87,7 +90,7 @@ public MediaCodecAudioTrackRenderer(SampleSource source) {
    *     content is not required.
    * @param playClearSamplesWithoutKeys Encrypted media may contain clear (un-encrypted) regions.
    *     For example a media file may start with a short clear region so as to allow playback to
-   *     begin in parallel with key acquisision. This parameter specifies whether the renderer is
+   *     begin in parallel with key acquisition. This parameter specifies whether the renderer is
    *     permitted to play clear regions of encrypted media files before {@code drmSessionManager}
    *     has obtained the keys necessary to decrypt encrypted regions of the media.
    */
@@ -113,7 +116,7 @@ public MediaCodecAudioTrackRenderer(SampleSource source, Handler eventHandler,
    *     content is not required.
    * @param playClearSamplesWithoutKeys Encrypted media may contain clear (un-encrypted) regions.
    *     For example a media file may start with a short clear region so as to allow playback to
-   *     begin in parallel with key acquisision. This parameter specifies whether the renderer is
+   *     begin in parallel with key acquisition. This parameter specifies whether the renderer is
    *     permitted to play clear regions of encrypted media files before {@code drmSessionManager}
    *     has obtained the keys necessary to decrypt encrypted regions of the media.
    * @param eventHandler A handler to use when delivering events to {@code eventListener}. May be
@@ -122,32 +125,89 @@ public MediaCodecAudioTrackRenderer(SampleSource source, Handler eventHandler,
    */
   public MediaCodecAudioTrackRenderer(SampleSource source, DrmSessionManager drmSessionManager,
       boolean playClearSamplesWithoutKeys, Handler eventHandler, EventListener eventListener) {
+    this(source, drmSessionManager, playClearSamplesWithoutKeys, eventHandler, eventListener,
+        null);
+  }
+
+  /**
+   * @param source The upstream source from which the renderer obtains samples.
+   * @param drmSessionManager For use with encrypted content. May be null if support for encrypted
+   *     content is not required.
+   * @param playClearSamplesWithoutKeys Encrypted media may contain clear (un-encrypted) regions.
+   *     For example a media file may start with a short clear region so as to allow playback to
+   *     begin in parallel with key acquisition. This parameter specifies whether the renderer is
+   *     permitted to play clear regions of encrypted media files before {@code drmSessionManager}
+   *     has obtained the keys necessary to decrypt encrypted regions of the media.
+   * @param eventHandler A handler to use when delivering events to {@code eventListener}. May be
+   *     null if delivery of events is not required.
+   * @param eventListener A listener of events. May be null if delivery of events is not required.
+   * @param audioCapabilities The audio capabilities for playback on this device. May be null if the
+   *     default capabilities (no encoded audio passthrough support) should be assumed.
+   */
+  public MediaCodecAudioTrackRenderer(SampleSource source, DrmSessionManager drmSessionManager,
+      boolean playClearSamplesWithoutKeys, Handler eventHandler, EventListener eventListener,
+      AudioCapabilities audioCapabilities) {
+    this(source, drmSessionManager, playClearSamplesWithoutKeys, eventHandler, eventListener,
+        audioCapabilities, AudioManager.STREAM_MUSIC);
+  }
+
+  /**
+   * @param source The upstream source from which the renderer obtains samples.
+   * @param drmSessionManager For use with encrypted content. May be null if support for encrypted
+   *     content is not required.
+   * @param playClearSamplesWithoutKeys Encrypted media may contain clear (un-encrypted) regions.
+   *     For example a media file may start with a short clear region so as to allow playback to
+   *     begin in parallel with key acquisition. This parameter specifies whether the renderer is
+   *     permitted to play clear regions of encrypted media files before {@code drmSessionManager}
+   *     has obtained the keys necessary to decrypt encrypted regions of the media.
+   * @param eventHandler A handler to use when delivering events to {@code eventListener}. May be
+   *     null if delivery of events is not required.
+   * @param eventListener A listener of events. May be null if delivery of events is not required.
+   * @param audioCapabilities The audio capabilities for playback on this device. May be null if the
+   *     default capabilities (no encoded audio passthrough support) should be assumed.
+   * @param streamType The type of audio stream for the {@link AudioTrack}.
+   */
+  public MediaCodecAudioTrackRenderer(SampleSource source, DrmSessionManager drmSessionManager,
+      boolean playClearSamplesWithoutKeys, Handler eventHandler, EventListener eventListener,
+      AudioCapabilities audioCapabilities, int streamType) {
     super(source, drmSessionManager, playClearSamplesWithoutKeys, eventHandler, eventListener);
     this.eventListener = eventListener;
     this.audioSessionId = AudioTrack.SESSION_ID_NOT_SET;
-    this.audioTrack = new AudioTrack();
+    this.audioTrack = new AudioTrack(audioCapabilities, streamType);
   }
 
   @Override
   protected DecoderInfo getDecoderInfo(String mimeType, boolean requiresSecureDecoder)
       throws DecoderQueryException {
-    if (MimeTypes.isPassthroughAudio(mimeType)) {
-      return new DecoderInfo(RAW_DECODER_NAME, true);
-    }
-    return super.getDecoderInfo(mimeType, requiresSecureDecoder);
+    return allowPassthrough(mimeType) ? new DecoderInfo(RAW_DECODER_NAME, true)
+        : super.getDecoderInfo(mimeType, requiresSecureDecoder);
+  }
+
+  /**
+   * Returns whether encoded audio passthrough should be used for playing back the input format.
+   * This implementation returns true if the {@link AudioTrack}'s audio capabilities indicate that
+   * passthrough is supported.
+   *
+   * @param mimeType The type of input media.
+   * @return True if passthrough playback should be used. False otherwise.
+   */
+  protected boolean allowPassthrough(String mimeType) {
+    return audioTrack.isPassthroughSupported(mimeType);
   }
 
   @Override
-  protected void configureCodec(MediaCodec codec, String codecName,
+  protected void configureCodec(MediaCodec codec, String codecName, boolean codecIsAdaptive,
       android.media.MediaFormat format, android.media.MediaCrypto crypto) {
-    if (RAW_DECODER_NAME.equals(codecName)) {
+    String mimeType = format.getString(android.media.MediaFormat.KEY_MIME);
+    if (RAW_DECODER_NAME.equals(codecName) && !MimeTypes.AUDIO_RAW.equals(mimeType)) {
       // Override the MIME type used to configure the codec if we are using a passthrough decoder.
-      String mimeType = format.getString(android.media.MediaFormat.KEY_MIME);
       format.setString(android.media.MediaFormat.KEY_MIME, MimeTypes.AUDIO_RAW);
       codec.configure(format, null, crypto, 0);
       format.setString(android.media.MediaFormat.KEY_MIME, mimeType);
+      passthroughMediaFormat = format;
     } else {
       codec.configure(format, null, crypto, 0);
+      passthroughMediaFormat = null;
     }
   }
 
@@ -157,24 +217,24 @@ protected MediaClock getMediaClock() {
   }
 
   @Override
-  protected boolean handlesMimeType(String mimeType) {
-    return MimeTypes.isAudio(mimeType) && super.handlesMimeType(mimeType);
+  protected boolean handlesTrack(MediaFormat mediaFormat) throws DecoderQueryException {
+    // TODO: Use MediaCodecList.findDecoderForFormat on API 23.
+    String mimeType = mediaFormat.mimeType;
+    return MimeTypes.isAudio(mimeType) && (MimeTypes.AUDIO_UNKNOWN.equals(mimeType)
+        || allowPassthrough(mimeType) || MediaCodecUtil.getDecoderInfo(mimeType, false) != null);
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    super.onEnabled(positionUs, joining);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     seekToInternal(positionUs);
   }
 
   @Override
-  protected void onOutputFormatChanged(MediaFormat inputFormat,
-      android.media.MediaFormat outputFormat) {
-    if (MimeTypes.isPassthroughAudio(inputFormat.mimeType)) {
-      audioTrack.reconfigure(inputFormat.getFrameworkMediaFormatV16());
-    } else {
-      audioTrack.reconfigure(outputFormat);
-    }
+  protected void onOutputFormatChanged(android.media.MediaFormat outputFormat) {
+    boolean passthrough = passthroughMediaFormat != null;
+    audioTrack.reconfigure(passthrough ? passthroughMediaFormat : outputFormat, passthrough);
   }
 
   /**
@@ -207,10 +267,7 @@ protected void onStopped() {
 
   @Override
   protected boolean isEnded() {
-    // We've exhausted the output stream, and the AudioTrack has either played all of the data
-    // submitted, or has been fed insufficient data to begin playback.
-    return super.isEnded() && (!audioTrack.hasPendingData()
-        || !audioTrack.hasEnoughDataToBeginPlayback());
+    return super.isEnded() && !audioTrack.hasPendingData();
   }
 
   @Override
@@ -231,7 +288,7 @@ public long getPositionUs() {
   }
 
   @Override
-  protected void onDisabled() {
+  protected void onDisabled() throws ExoPlaybackException {
     audioSessionId = AudioTrack.SESSION_ID_NOT_SET;
     try {
       audioTrack.release();
@@ -308,6 +365,11 @@ protected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, M
     return false;
   }
 
+  @Override
+  protected void onOutputStreamEnded() {
+    audioTrack.handleEndOfStream();
+  }
+
   protected void handleDiscontinuity() {
     // Do nothing
   }
diff --git a/library/src/main/java/com/google/android/exoplayer/MediaCodecTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/MediaCodecTrackRenderer.java
index f54e8947c0..9970758c90 100644
--- a/library/src/main/java/com/google/android/exoplayer/MediaCodecTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/MediaCodecTrackRenderer.java
@@ -16,7 +16,6 @@
 package com.google.android.exoplayer;
 
 import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
 import com.google.android.exoplayer.drm.DrmInitData;
 import com.google.android.exoplayer.drm.DrmSessionManager;
 import com.google.android.exoplayer.util.Assertions;
@@ -31,7 +30,6 @@
 import android.os.Handler;
 import android.os.SystemClock;
 
-import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.List;
@@ -40,7 +38,7 @@
  * An abstract {@link TrackRenderer} that uses {@link MediaCodec} to decode samples for rendering.
  */
 @TargetApi(16)
-public abstract class MediaCodecTrackRenderer extends TrackRenderer {
+public abstract class MediaCodecTrackRenderer extends SampleSourceTrackRenderer {
 
   /**
    * Interface definition for a callback to be notified of {@link MediaCodecTrackRenderer} events.
@@ -183,7 +181,6 @@ private static String buildCustomDiagnosticInfo(int errorCode) {
 
   private final DrmSessionManager drmSessionManager;
   private final boolean playClearSamplesWithoutKeys;
-  private final SampleSourceReader source;
   private final SampleHolder sampleHolder;
   private final MediaFormatHolder formatHolder;
   private final List<Long> decodeOnlyPresentationTimestamps;
@@ -195,7 +192,9 @@ private static String buildCustomDiagnosticInfo(int errorCode) {
   private DrmInitData drmInitData;
   private MediaCodec codec;
   private boolean codecIsAdaptive;
-  private boolean codecNeedsEndOfStreamWorkaround;
+  private boolean codecNeedsEosPropagationWorkaround;
+  private boolean codecNeedsEosFlushWorkaround;
+  private boolean codecReceivedEos;
   private ByteBuffer[] inputBuffers;
   private ByteBuffer[] outputBuffers;
   private long codecHotswapTimeMs;
@@ -207,7 +206,6 @@ private static String buildCustomDiagnosticInfo(int errorCode) {
   private int codecReinitializationState;
   private boolean codecHasQueuedBuffers;
 
-  private int trackIndex;
   private int sourceState;
   private boolean inputStreamEnded;
   private boolean outputStreamEnded;
@@ -229,8 +227,8 @@ private static String buildCustomDiagnosticInfo(int errorCode) {
    */
   public MediaCodecTrackRenderer(SampleSource source, DrmSessionManager drmSessionManager,
       boolean playClearSamplesWithoutKeys, Handler eventHandler, EventListener eventListener) {
+    super(source);
     Assertions.checkState(Util.SDK_INT >= 16);
-    this.source = source.register();
     this.drmSessionManager = drmSessionManager;
     this.playClearSamplesWithoutKeys = playClearSamplesWithoutKeys;
     this.eventHandler = eventHandler;
@@ -245,39 +243,9 @@ public MediaCodecTrackRenderer(SampleSource source, DrmSessionManager drmSession
   }
 
   @Override
-  protected int doPrepare(long positionUs) {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < trackCount; i++) {
-      // TODO: Right now this is getting the mime types of the container format
-      // (e.g. audio/mp4 and video/mp4 for fragmented mp4). It needs to be getting the mime types
-      // of the actual samples (e.g. audio/mp4a-latm and video/avc).
-      if (handlesMimeType(source.getTrackInfo(i).mimeType)) {
-        trackIndex = i;
-        return TrackRenderer.STATE_PREPARED;
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
-  }
-
-  /**
-   * Determines whether a mime type is handled by the renderer.
-   *
-   * @param mimeType The mime type to test.
-   * @return True if the renderer can handle the mime type. False otherwise.
-   */
-  protected boolean handlesMimeType(String mimeType) {
-    return true;
-    // TODO: Uncomment once the TODO above is fixed.
-    // DecoderInfoUtil.getDecoder(mimeType) != null;
-  }
-
-  @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     seekToInternal();
   }
 
@@ -288,6 +256,7 @@ protected void onEnabled(long positionUs, boolean joining) {
    * @param requiresSecureDecoder Whether a secure decoder is needed for decoding {@code mimeType}.
    * @return {@link DecoderInfo} for decoding media in the specified MIME type, or {@code null} if
    *     no suitable decoder is available.
+   * @throws DecoderQueryException Thrown if there was an error querying decoders.
    */
   protected DecoderInfo getDecoderInfo(String mimeType, boolean requiresSecureDecoder)
       throws DecoderQueryException {
@@ -300,10 +269,11 @@ protected DecoderInfo getDecoderInfo(String mimeType, boolean requiresSecureDeco
    *
    * @param codec The {@link MediaCodec} to configure.
    * @param codecName The name of the codec.
+   * @param codecIsAdaptive Whether the codec is adaptive.
    * @param format The format for which the codec is being configured.
    * @param crypto For drm protected playbacks, a {@link MediaCrypto} to use for decryption.
    */
-  protected void configureCodec(MediaCodec codec, String codecName,
+  protected void configureCodec(MediaCodec codec, String codecName, boolean codecIsAdaptive,
       android.media.MediaFormat format, MediaCrypto crypto) {
     codec.configure(format, null, crypto, 0);
   }
@@ -351,27 +321,29 @@ protected final void maybeInitCodec() throws ExoPlaybackException {
           DecoderInitializationException.NO_SUITABLE_DECODER_ERROR));
     }
 
-    String decoderName = decoderInfo.name;
+    String codecName = decoderInfo.name;
     codecIsAdaptive = decoderInfo.adaptive;
-    codecNeedsEndOfStreamWorkaround = codecNeedsEndOfStreamWorkaround(decoderName);
+    codecNeedsEosPropagationWorkaround = codecNeedsEosPropagationWorkaround(codecName);
+    codecNeedsEosFlushWorkaround = codecNeedsEosFlushWorkaround(codecName);
     try {
       long codecInitializingTimestamp = SystemClock.elapsedRealtime();
-      TraceUtil.beginSection("createByCodecName(" + decoderName + ")");
-      codec = MediaCodec.createByCodecName(decoderName);
+      TraceUtil.beginSection("createByCodecName(" + codecName + ")");
+      codec = MediaCodec.createByCodecName(codecName);
       TraceUtil.endSection();
       TraceUtil.beginSection("configureCodec");
-      configureCodec(codec, decoderName, format.getFrameworkMediaFormatV16(), mediaCrypto);
+      configureCodec(codec, codecName, codecIsAdaptive, format.getFrameworkMediaFormatV16(),
+          mediaCrypto);
       TraceUtil.endSection();
       TraceUtil.beginSection("codec.start()");
       codec.start();
       TraceUtil.endSection();
       long codecInitializedTimestamp = SystemClock.elapsedRealtime();
-      notifyDecoderInitialized(decoderName, codecInitializedTimestamp,
+      notifyDecoderInitialized(codecName, codecInitializedTimestamp,
           codecInitializedTimestamp - codecInitializingTimestamp);
       inputBuffers = codec.getInputBuffers();
       outputBuffers = codec.getOutputBuffers();
     } catch (Exception e) {
-      notifyAndThrowDecoderInitError(new DecoderInitializationException(format, e, decoderName));
+      notifyAndThrowDecoderInitError(new DecoderInitializationException(format, e, codecName));
     }
     codecHotswapTimeMs = getState() == TrackRenderer.STATE_STARTED ?
         SystemClock.elapsedRealtime() : -1;
@@ -400,7 +372,7 @@ protected final boolean haveFormat() {
   }
 
   @Override
-  protected void onDisabled() {
+  protected void onDisabled() throws ExoPlaybackException {
     format = null;
     drmInitData = null;
     try {
@@ -412,7 +384,7 @@ protected void onDisabled() {
           openedDrmSession = false;
         }
       } finally {
-        source.disable(trackIndex);
+        super.onDisabled();
       }
     }
   }
@@ -429,7 +401,9 @@ protected void releaseCodec() {
       codecReconfigured = false;
       codecHasQueuedBuffers = false;
       codecIsAdaptive = false;
-      codecNeedsEndOfStreamWorkaround = false;
+      codecNeedsEosPropagationWorkaround = false;
+      codecNeedsEosFlushWorkaround = false;
+      codecReceivedEos = false;
       codecReconfigurationState = RECONFIGURATION_STATE_NONE;
       codecReinitializationState = REINITIALIZATION_STATE_NONE;
       codecCounters.codecReleaseCount++;
@@ -445,24 +419,9 @@ protected void releaseCodec() {
     }
   }
 
-  @Override
-  protected void onReleased() {
-    source.release();
-  }
-
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
-  }
-
-  @Override
-  protected long getBufferedPositionUs() {
-    return source.getBufferedPositionUs();
-  }
-
   @Override
   protected void seekTo(long positionUs) throws ExoPlaybackException {
-    source.seekToUs(positionUs);
+    super.seekTo(positionUs);
     seekToInternal();
   }
 
@@ -484,7 +443,7 @@ protected void onStopped() {
 
   @Override
   protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPlaybackException {
-    sourceState = source.continueBuffering(trackIndex, positionUs)
+    sourceState = continueBufferingSource(positionUs)
         ? (sourceState == SOURCE_STATE_NOT_READY ? SOURCE_STATE_READY : sourceState)
         : SOURCE_STATE_NOT_READY;
     checkForDiscontinuity(positionUs);
@@ -506,7 +465,7 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
   }
 
   private void readFormat(long positionUs) throws ExoPlaybackException {
-    int result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, false);
+    int result = readSource(positionUs, formatHolder, sampleHolder, false);
     if (result == SampleSource.FORMAT_READ) {
       onInputFormatChanged(formatHolder);
     }
@@ -516,7 +475,7 @@ private void checkForDiscontinuity(long positionUs) throws ExoPlaybackException
     if (codec == null) {
       return;
     }
-    int result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, true);
+    int result = readSource(positionUs, formatHolder, sampleHolder, true);
     if (result == SampleSource.DISCONTINUITY_READ) {
       flushCodec();
     }
@@ -529,14 +488,19 @@ private void flushCodec() throws ExoPlaybackException {
     waitingForFirstSyncFrame = true;
     waitingForKeys = false;
     decodeOnlyPresentationTimestamps.clear();
-    // Workaround for framework bugs.
-    // See [Internal: b/8347958], [Internal: b/8578467], [Internal: b/8543366].
-    if (Util.SDK_INT >= 18 && codecReinitializationState == REINITIALIZATION_STATE_NONE) {
-      codec.flush();
-      codecHasQueuedBuffers = false;
-    } else {
+    if (Util.SDK_INT < 18 || (codecNeedsEosFlushWorkaround && codecReceivedEos)) {
+      // Workaround framework bugs. See [Internal: b/8347958, b/8578467, b/8543366, b/23361053].
+      releaseCodec();
+      maybeInitCodec();
+    } else if (codecReinitializationState != REINITIALIZATION_STATE_NONE) {
+      // We're already waiting to release and re-initialize the codec. Since we're now flushing,
+      // there's no need to wait any longer.
       releaseCodec();
       maybeInitCodec();
+    } else {
+      // We can flush and re-use the existing decoder.
+      codec.flush();
+      codecHasQueuedBuffers = false;
     }
     if (codecReconfigured && format != null) {
       // Any reconfiguration data that we send shortly before the flush may be discarded. We
@@ -567,15 +531,16 @@ private boolean feedInputBuffer(long positionUs, boolean firstFeed) throws ExoPl
         return false;
       }
       sampleHolder.data = inputBuffers[inputIndex];
-      sampleHolder.data.clear();
+      sampleHolder.clearData();
     }
 
     if (codecReinitializationState == REINITIALIZATION_STATE_SIGNAL_END_OF_STREAM) {
       // We need to re-initialize the codec. Send an end of stream signal to the existing codec so
       // that it outputs any remaining buffers before we release it.
-      if (codecNeedsEndOfStreamWorkaround) {
+      if (codecNeedsEosPropagationWorkaround) {
         // Do nothing.
       } else {
+        codecReceivedEos = true;
         codec.queueInputBuffer(inputIndex, 0, 0, 0, MediaCodec.BUFFER_FLAG_END_OF_STREAM);
         inputIndex = -1;
       }
@@ -597,7 +562,7 @@ private boolean feedInputBuffer(long positionUs, boolean firstFeed) throws ExoPl
         }
         codecReconfigurationState = RECONFIGURATION_STATE_QUEUE_PENDING;
       }
-      result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, false);
+      result = readSource(positionUs, formatHolder, sampleHolder, false);
       if (firstFeed && sourceState == SOURCE_STATE_READY && result == SampleSource.NOTHING_READ) {
         sourceState = SOURCE_STATE_READY_READ_MAY_FAIL;
       }
@@ -614,7 +579,7 @@ private boolean feedInputBuffer(long positionUs, boolean firstFeed) throws ExoPl
       if (codecReconfigurationState == RECONFIGURATION_STATE_QUEUE_PENDING) {
         // We received two formats in a row. Clear the current buffer of any reconfiguration data
         // associated with the first format.
-        sampleHolder.data.clear();
+        sampleHolder.clearData();
         codecReconfigurationState = RECONFIGURATION_STATE_WRITE_PENDING;
       }
       onInputFormatChanged(formatHolder);
@@ -625,14 +590,19 @@ private boolean feedInputBuffer(long positionUs, boolean firstFeed) throws ExoPl
         // We received a new format immediately before the end of the stream. We need to clear
         // the corresponding reconfiguration data from the current buffer, but re-write it into
         // a subsequent buffer if there are any (e.g. if the user seeks backwards).
-        sampleHolder.data.clear();
+        sampleHolder.clearData();
         codecReconfigurationState = RECONFIGURATION_STATE_WRITE_PENDING;
       }
       inputStreamEnded = true;
+      if (!codecHasQueuedBuffers) {
+        processEndOfStream();
+        return false;
+      }
       try {
-        if (codecNeedsEndOfStreamWorkaround) {
+        if (codecNeedsEosPropagationWorkaround) {
           // Do nothing.
         } else {
+          codecReceivedEos = true;
           codec.queueInputBuffer(inputIndex, 0, 0, 0, MediaCodec.BUFFER_FLAG_END_OF_STREAM);
           inputIndex = -1;
         }
@@ -646,7 +616,7 @@ private boolean feedInputBuffer(long positionUs, boolean firstFeed) throws ExoPl
       // TODO: Find out if it's possible to supply samples prior to the first sync
       // frame for HE-AAC.
       if (!sampleHolder.isSyncFrame()) {
-        sampleHolder.data.clear();
+        sampleHolder.clearData();
         if (codecReconfigurationState == RECONFIGURATION_STATE_QUEUE_PENDING) {
           // The buffer we just cleared contained reconfiguration data. We need to re-write this
           // data into a subsequent buffer (if there is one).
@@ -746,11 +716,20 @@ protected void onInputFormatChanged(MediaFormatHolder formatHolder) throws ExoPl
    * <p>
    * The default implementation is a no-op.
    *
-   * @param inputFormat The format of media input to the codec.
    * @param outputFormat The new output format.
    */
-  protected void onOutputFormatChanged(MediaFormat inputFormat,
-      android.media.MediaFormat outputFormat) {
+  protected void onOutputFormatChanged(android.media.MediaFormat outputFormat) {
+    // Do nothing.
+  }
+
+  /**
+   * Invoked when the output stream ends, meaning that the last output buffer has been processed
+   * and the {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM} flag has been propagated through the
+   * decoder.
+   * <p>
+   * The default implementation is a no-op.
+   */
+  protected void onOutputStreamEnded() {
     // Do nothing.
   }
 
@@ -774,15 +753,6 @@ protected boolean canReconfigureCodec(MediaCodec codec, boolean codecIsAdaptive,
     return false;
   }
 
-  @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
-    try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
-    }
-  }
-
   @Override
   protected boolean isEnded() {
     return outputStreamEnded;
@@ -833,7 +803,7 @@ private boolean drainOutputBuffer(long positionUs, long elapsedRealtimeUs)
     }
 
     if (outputIndex == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {
-      onOutputFormatChanged(format, codec.getOutputFormat());
+      onOutputFormatChanged(codec.getOutputFormat());
       codecCounters.outputFormatChangedCount++;
       return true;
     } else if (outputIndex == MediaCodec.INFO_OUTPUT_BUFFERS_CHANGED) {
@@ -841,7 +811,7 @@ private boolean drainOutputBuffer(long positionUs, long elapsedRealtimeUs)
       codecCounters.outputBuffersChangedCount++;
       return true;
     } else if (outputIndex < 0) {
-      if (codecNeedsEndOfStreamWorkaround && (inputStreamEnded
+      if (codecNeedsEosPropagationWorkaround && (inputStreamEnded
           || codecReinitializationState == REINITIALIZATION_STATE_WAIT_END_OF_STREAM)) {
         processEndOfStream();
         return true;
@@ -890,6 +860,7 @@ private void processEndOfStream() throws ExoPlaybackException {
       maybeInitCodec();
     } else {
       outputStreamEnded = true;
+      onOutputStreamEnded();
     }
   }
 
@@ -939,19 +910,38 @@ private int getDecodeOnlyIndex(long presentationTimeUs) {
   }
 
   /**
-   * Returns whether the decoder is known to handle {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM}
-   * incorrectly on the host device.
+   * Returns whether the decoder is known to handle the propagation of the
+   * {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM} flag incorrectly on the host device.
    * <p>
    * If true is returned, the renderer will work around the issue by approximating end of stream
-   * behavior without involvement of the underlying decoder.
+   * behavior without relying on the flag being propagated through to an output buffer by the
+   * underlying decoder.
    *
    * @param name The name of the decoder.
    * @return True if the decoder is known to handle {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM}
-   *     incorrectly on the host device. False otherwise.
+   *     propagation incorrectly on the host device. False otherwise.
+   */
+  private static boolean codecNeedsEosPropagationWorkaround(String name) {
+    return Util.SDK_INT <= 17
+        && "OMX.rk.video_decoder.avc".equals(name)
+        && ("ht7s3".equals(Util.DEVICE) // Tesco HUDL
+            || "rk30sdk".equals(Util.DEVICE) // Rockchip rk30
+            || "rk31sdk".equals(Util.DEVICE)); // Rockchip rk31
+  }
+
+  /**
+   * Returns whether the decoder is known to behave incorrectly if flushed after receiving an input
+   * buffer with {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM} set.
+   * <p>
+   * If true is returned, the renderer will work around the issue by instantiating a new decoder
+   * when this case occurs.
+   *
+   * @param name The name of the decoder.
+   * @return True if the decoder is known to behave incorrectly if flushed after receiving an input
+   *     buffer with {@link MediaCodec#BUFFER_FLAG_END_OF_STREAM} set. False otherwise.
    */
-  private static boolean codecNeedsEndOfStreamWorkaround(String name) {
-    return Util.SDK_INT <= 17 && "ht7s3".equals(Util.DEVICE) // Tesco HUDL
-        && "OMX.rk.video_decoder.avc".equals(name);
+  private static boolean codecNeedsEosFlushWorkaround(String name) {
+    return Util.SDK_INT <= 23 && "OMX.google.vorbis.decoder".equals(name);
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/MediaCodecUtil.java b/library/src/main/java/com/google/android/exoplayer/MediaCodecUtil.java
index 8cffd8a852..a2bd8f7466 100644
--- a/library/src/main/java/com/google/android/exoplayer/MediaCodecUtil.java
+++ b/library/src/main/java/com/google/android/exoplayer/MediaCodecUtil.java
@@ -28,6 +28,7 @@
 import android.util.Log;
 import android.util.Pair;
 
+import java.io.IOException;
 import java.util.HashMap;
 
 /**
@@ -42,7 +43,7 @@
    * Such failures are not expected in normal operation and are normally temporary (e.g. if the
    * mediaserver process has crashed and is yet to restart).
    */
-  public static class DecoderQueryException extends Exception {
+  public static class DecoderQueryException extends IOException {
 
     private DecoderQueryException(Throwable cause) {
       super("Failed to query underlying media codecs", cause);
@@ -172,18 +173,32 @@ public static synchronized void warmCodec(String mimeType, boolean secure) {
    */
   private static boolean isCodecUsableDecoder(MediaCodecInfo info, String name,
       boolean secureDecodersExplicit) {
-    if (info.isEncoder() || !name.startsWith("OMX.")
-        || (!secureDecodersExplicit && name.endsWith(".secure"))) {
+    if (info.isEncoder() || (!secureDecodersExplicit && name.endsWith(".secure"))) {
       return false;
     }
 
     // Work around an issue where creating a particular MP3 decoder on some devices on platform API
     // version 16 crashes mediaserver.
     if (Util.SDK_INT == 16
+        && "OMX.qcom.audio.decoder.mp3".equals(name)
         && ("dlxu".equals(Util.DEVICE) // HTC Butterfly
             || "protou".equals(Util.DEVICE) // HTC Desire X
-            || "C6602".equals(Util.DEVICE) || "C6603".equals(Util.DEVICE)) // Sony Xperia Z
-        && name.equals("OMX.qcom.audio.decoder.mp3")) {
+            || "C6602".equals(Util.DEVICE) // Sony Xperia Z
+            || "C6603".equals(Util.DEVICE)
+            || "C6606".equals(Util.DEVICE)
+            || "C6616".equals(Util.DEVICE)
+            || "L36h".equals(Util.DEVICE)
+            || "SO-02E".equals(Util.DEVICE))) {
+      return false;
+    }
+
+    // Work around an issue where large timestamps are not propagated correctly.
+    if (Util.SDK_INT == 16
+        && "OMX.qcom.audio.decoder.aac".equals(name)
+        && ("C1504".equals(Util.DEVICE) // Sony Xperia E
+            || "C1505".equals(Util.DEVICE)
+            || "C1604".equals(Util.DEVICE) // Sony Xperia E dual
+            || "C1605".equals(Util.DEVICE))) {
       return false;
     }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/MediaCodecVideoTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/MediaCodecVideoTrackRenderer.java
index 5970c7df63..6cf315bdac 100644
--- a/library/src/main/java/com/google/android/exoplayer/MediaCodecVideoTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/MediaCodecVideoTrackRenderer.java
@@ -15,17 +15,20 @@
  */
 package com.google.android.exoplayer;
 
+import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
 import com.google.android.exoplayer.drm.DrmSessionManager;
 import com.google.android.exoplayer.util.MimeTypes;
 import com.google.android.exoplayer.util.TraceUtil;
 import com.google.android.exoplayer.util.Util;
 
+import android.annotation.SuppressLint;
 import android.annotation.TargetApi;
 import android.media.MediaCodec;
 import android.media.MediaCrypto;
 import android.os.Handler;
 import android.os.SystemClock;
 import android.view.Surface;
+import android.view.TextureView;
 
 import java.nio.ByteBuffer;
 
@@ -59,11 +62,19 @@
      *
      * @param width The video width in pixels.
      * @param height The video height in pixels.
+     * @param unappliedRotationDegrees For videos that require a rotation, this is the clockwise
+     *     rotation in degrees that the application should apply for the video for it to be rendered
+     *     in the correct orientation. This value will always be zero on API levels 21 and above,
+     *     since the renderer will apply all necessary rotations internally. On earlier API levels
+     *     this is not possible. Applications that use {@link TextureView} can apply the rotation by
+     *     calling {@link TextureView#setTransform}. Applications that do not expect to encounter
+     *     rotated videos can safely ignore this parameter.
      * @param pixelWidthHeightRatio The width to height ratio of each pixel. For the normal case
      *     of square pixels this will be equal to 1.0. Different values are indicative of anamorphic
      *     content.
      */
-    void onVideoSizeChanged(int width, int height, float pixelWidthHeightRatio);
+    void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+        float pixelWidthHeightRatio);
 
     /**
      * Invoked when a frame is rendered to a surface for the first time following that surface
@@ -129,12 +140,15 @@
   private long droppedFrameAccumulationStartTimeMs;
   private int droppedFrameCount;
 
+  private int pendingRotationDegrees;
+  private float pendingPixelWidthHeightRatio;
   private int currentWidth;
   private int currentHeight;
+  private int currentUnappliedRotationDegrees;
   private float currentPixelWidthHeightRatio;
-  private float pendingPixelWidthHeightRatio;
   private int lastReportedWidth;
   private int lastReportedHeight;
+  private int lastReportedUnappliedRotationDegrees;
   private float lastReportedPixelWidthHeightRatio;
 
   /**
@@ -256,13 +270,17 @@ public MediaCodecVideoTrackRenderer(SampleSource source, DrmSessionManager drmSe
   }
 
   @Override
-  protected boolean handlesMimeType(String mimeType) {
-    return MimeTypes.isVideo(mimeType) && super.handlesMimeType(mimeType);
+  protected boolean handlesTrack(MediaFormat mediaFormat) throws DecoderQueryException {
+    // TODO: Use MediaCodecList.findDecoderForFormat on API 23.
+    String mimeType = mediaFormat.mimeType;
+    return MimeTypes.isVideo(mimeType) && (MimeTypes.VIDEO_UNKNOWN.equals(mimeType)
+        || MediaCodecUtil.getDecoderInfo(mimeType, false) != null);
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    super.onEnabled(positionUs, joining);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     renderedFirstFrame = false;
     if (joining && allowedJoiningTimeUs > 0) {
       joiningDeadlineUs = SystemClock.elapsedRealtime() * 1000L + allowedJoiningTimeUs;
@@ -314,7 +332,7 @@ protected void onStopped() {
   }
 
   @Override
-  public void onDisabled() {
+  protected void onDisabled() throws ExoPlaybackException {
     currentWidth = -1;
     currentHeight = -1;
     currentPixelWidthHeightRatio = -1;
@@ -361,8 +379,9 @@ protected boolean shouldInitCodec() {
 
   // Override configureCodec to provide the surface.
   @Override
-  protected void configureCodec(MediaCodec codec, String codecName,
+  protected void configureCodec(MediaCodec codec, String codecName, boolean codecIsAdaptive,
       android.media.MediaFormat format, MediaCrypto crypto) {
+    maybeSetMaxInputSize(format, codecIsAdaptive);
     codec.configure(format, surface, crypto, 0);
     codec.setVideoScalingMode(videoScalingMode);
   }
@@ -372,6 +391,8 @@ protected void onInputFormatChanged(MediaFormatHolder holder) throws ExoPlayback
     super.onInputFormatChanged(holder);
     pendingPixelWidthHeightRatio = holder.format.pixelWidthHeightRatio == MediaFormat.NO_VALUE ? 1
         : holder.format.pixelWidthHeightRatio;
+    pendingRotationDegrees = holder.format.rotationDegrees == MediaFormat.NO_VALUE ? 0
+        : holder.format.rotationDegrees;
   }
 
   /**
@@ -382,8 +403,7 @@ protected final boolean haveRenderedFirstFrame() {
   }
 
   @Override
-  protected void onOutputFormatChanged(MediaFormat inputFormat,
-      android.media.MediaFormat outputFormat) {
+  protected void onOutputFormatChanged(android.media.MediaFormat outputFormat) {
     boolean hasCrop = outputFormat.containsKey(KEY_CROP_RIGHT)
         && outputFormat.containsKey(KEY_CROP_LEFT) && outputFormat.containsKey(KEY_CROP_BOTTOM)
         && outputFormat.containsKey(KEY_CROP_TOP);
@@ -394,6 +414,20 @@ protected void onOutputFormatChanged(MediaFormat inputFormat,
         ? outputFormat.getInteger(KEY_CROP_BOTTOM) - outputFormat.getInteger(KEY_CROP_TOP) + 1
         : outputFormat.getInteger(android.media.MediaFormat.KEY_HEIGHT);
     currentPixelWidthHeightRatio = pendingPixelWidthHeightRatio;
+    if (Util.SDK_INT >= 21) {
+      // On API level 21 and above the decoder applies the rotation when rendering to the surface.
+      // Hence currentUnappliedRotation should always be 0. For 90 and 270 degree rotations, we need
+      // to flip the width, height and pixel aspect ratio to reflect the rotation that was applied.
+      if (pendingRotationDegrees == 90 || pendingRotationDegrees == 270) {
+        int rotatedHeight = currentWidth;
+        currentWidth = currentHeight;
+        currentHeight = rotatedHeight;
+        currentPixelWidthHeightRatio = 1 / currentPixelWidthHeightRatio;
+      }
+    } else {
+      // On API level 20 and below the decoder does not apply the rotation.
+      currentUnappliedRotationDegrees = pendingRotationDegrees;
+    }
   }
 
   @Override
@@ -412,6 +446,19 @@ protected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, M
       return true;
     }
 
+    if (!renderedFirstFrame) {
+      if (Util.SDK_INT >= 21) {
+        renderOutputBufferV21(codec, bufferIndex, System.nanoTime());
+      } else {
+        renderOutputBuffer(codec, bufferIndex);
+      }
+      return true;
+    }
+
+    if (getState() != TrackRenderer.STATE_STARTED) {
+      return false;
+    }
+
     // Compute how many microseconds it is until the buffer's presentation time.
     long elapsedSinceStartOfLoopUs = (SystemClock.elapsedRealtime() * 1000) - elapsedRealtimeUs;
     long earlyUs = bufferInfo.presentationTimeUs - positionUs - elapsedSinceStartOfLoopUs;
@@ -436,19 +483,6 @@ protected boolean processOutputBuffer(long positionUs, long elapsedRealtimeUs, M
       return true;
     }
 
-    if (!renderedFirstFrame) {
-      if (Util.SDK_INT >= 21) {
-        renderOutputBufferV21(codec, bufferIndex, System.nanoTime());
-      } else {
-        renderOutputBuffer(codec, bufferIndex);
-      }
-      return true;
-    }
-
-    if (getState() != TrackRenderer.STATE_STARTED) {
-      return false;
-    }
-
     if (Util.SDK_INT >= 21) {
       // Let the underlying framework time the release.
       if (earlyUs < 50000) {
@@ -516,25 +550,52 @@ protected void renderOutputBufferV21(MediaCodec codec, int bufferIndex, long rel
     maybeNotifyDrawnToSurface();
   }
 
+  @SuppressLint("InlinedApi")
+  private void maybeSetMaxInputSize(android.media.MediaFormat format, boolean codecIsAdaptive) {
+    if (!MimeTypes.VIDEO_H264.equals(format.getString(android.media.MediaFormat.KEY_MIME))) {
+      // Only set a max input size for H264 for now.
+      return;
+    }
+    if (format.containsKey(android.media.MediaFormat.KEY_MAX_INPUT_SIZE)) {
+      // Already set. The source of the format may know better, so do nothing.
+      return;
+    }
+    int maxHeight = format.getInteger(android.media.MediaFormat.KEY_HEIGHT);
+    if (codecIsAdaptive && format.containsKey(android.media.MediaFormat.KEY_MAX_HEIGHT)) {
+      maxHeight = Math.max(maxHeight, format.getInteger(android.media.MediaFormat.KEY_MAX_HEIGHT));
+    }
+    int maxWidth = format.getInteger(android.media.MediaFormat.KEY_WIDTH);
+    if (codecIsAdaptive && format.containsKey(android.media.MediaFormat.KEY_MAX_WIDTH)) {
+      maxWidth = Math.max(maxHeight, format.getInteger(android.media.MediaFormat.KEY_MAX_WIDTH));
+    }
+    // H264 requires compression ratio of at least 2, and uses macroblocks.
+    int maxInputSize = ((maxWidth + 15) / 16) * ((maxHeight + 15) / 16) * 192;
+    format.setInteger(android.media.MediaFormat.KEY_MAX_INPUT_SIZE, maxInputSize);
+  }
+
   private void maybeNotifyVideoSizeChanged() {
     if (eventHandler == null || eventListener == null
         || (lastReportedWidth == currentWidth && lastReportedHeight == currentHeight
+        && lastReportedUnappliedRotationDegrees == currentUnappliedRotationDegrees
         && lastReportedPixelWidthHeightRatio == currentPixelWidthHeightRatio)) {
       return;
     }
     // Make final copies to ensure the runnable reports the correct values.
     final int currentWidth = this.currentWidth;
     final int currentHeight = this.currentHeight;
+    final int currentUnappliedRotationDegrees = this.currentUnappliedRotationDegrees;
     final float currentPixelWidthHeightRatio = this.currentPixelWidthHeightRatio;
     eventHandler.post(new Runnable()  {
       @Override
       public void run() {
-        eventListener.onVideoSizeChanged(currentWidth, currentHeight, currentPixelWidthHeightRatio);
+        eventListener.onVideoSizeChanged(currentWidth, currentHeight,
+            currentUnappliedRotationDegrees, currentPixelWidthHeightRatio);
       }
     });
     // Update the last reported values.
     lastReportedWidth = currentWidth;
     lastReportedHeight = currentHeight;
+    lastReportedUnappliedRotationDegrees = currentUnappliedRotationDegrees;
     lastReportedPixelWidthHeightRatio = currentPixelWidthHeightRatio;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/MediaFormat.java b/library/src/main/java/com/google/android/exoplayer/MediaFormat.java
index c1de1160c9..be21897c55 100644
--- a/library/src/main/java/com/google/android/exoplayer/MediaFormat.java
+++ b/library/src/main/java/com/google/android/exoplayer/MediaFormat.java
@@ -15,13 +15,13 @@
  */
 package com.google.android.exoplayer;
 
+import com.google.android.exoplayer.util.Assertions;
 import com.google.android.exoplayer.util.Util;
 
 import android.annotation.SuppressLint;
 import android.annotation.TargetApi;
 
 import java.nio.ByteBuffer;
-import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
@@ -31,156 +31,272 @@
  */
 public final class MediaFormat {
 
-  private static final String KEY_PIXEL_WIDTH_HEIGHT_RATIO =
-      "com.google.android.videos.pixelWidthHeightRatio";
-
   public static final int NO_VALUE = -1;
 
+  /**
+   * A value for {@link #subsampleOffsetUs} to indicate that subsample timestamps are relative to
+   * the timestamps of their parent samples.
+   */
+  public static final long OFFSET_SAMPLE_RELATIVE = Long.MAX_VALUE;
+
+  /**
+   * The identifier for the track represented by the format, or {@link #NO_VALUE} if unknown or not
+   * applicable.
+   */
+  public final int trackId;
+  /**
+   * The mime type of the format.
+   */
   public final String mimeType;
+  /**
+   * The average bandwidth in bits per second, or {@link #NO_VALUE} if unknown or not applicable.
+   */
+  public final int bitrate;
+  /**
+   * The maximum size of a buffer of data (typically one sample) in the format, or {@link #NO_VALUE}
+   * if unknown or not applicable.
+   */
   public final int maxInputSize;
-
+  /**
+   * The duration in microseconds, or {@link C#UNKNOWN_TIME_US} if the duration is unknown, or
+   * {@link C#MATCH_LONGEST_US} if the duration should match the duration of the longest track whose
+   * duration is known.
+   */
   public final long durationUs;
+  /**
+   * Initialization data that must be provided to the decoder. Will not be null, but may be empty
+   * if initialization data is not required.
+   */
+  public final List<byte[]> initializationData;
+  /**
+   * Whether the format represents an adaptive track, meaning that the format of the actual media
+   * data may change (e.g. to adapt to network conditions).
+   */
+  public final boolean adaptive;
+
+  // Video specific.
 
+  /**
+   * The width of the video in pixels, or {@link #NO_VALUE} if unknown or not applicable.
+   */
   public final int width;
+
+  /**
+   * The height of the video in pixels, or {@link #NO_VALUE} if unknown or not applicable.
+   */
   public final int height;
+  /**
+   * For formats that belong to an adaptive video track (either describing the track, or describing
+   * a specific format within it), this is the maximum width of the video in pixels that will be
+   * encountered in the stream. Set to {@link #NO_VALUE} if unknown or not applicable.
+   */
+  public final int maxWidth;
+  /**
+   * For formats that belong to an adaptive video track (either describing the track, or describing
+   * a specific format within it), this is the maximum height of the video in pixels that will be
+   * encountered in the stream. Set to {@link #NO_VALUE} if unknown or not applicable.
+   */
+  public final int maxHeight;
+  /**
+   * The clockwise rotation that should be applied to the video for it to be rendered in the correct
+   * orientation, or {@link #NO_VALUE} if unknown or not applicable. Only 0, 90, 180 and 270 are
+   * supported.
+   */
+  public final int rotationDegrees;
+  /**
+   * The width to height ratio of pixels in the video, or {@link #NO_VALUE} if unknown or not
+   * applicable.
+   */
   public final float pixelWidthHeightRatio;
 
+  // Audio specific.
+
+  /**
+   * The number of audio channels, or {@link #NO_VALUE} if unknown or not applicable.
+   */
   public final int channelCount;
+  /**
+   * The audio sampling rate in Hz, or {@link #NO_VALUE} if unknown or not applicable.
+   */
   public final int sampleRate;
 
-  public final List<byte[]> initializationData;
-
-  private int maxWidth;
-  private int maxHeight;
-
-  // Lazy-initialized hashcode.
-  private int hashCode;
-  // Possibly-lazy-initialized framework media format.
-  private android.media.MediaFormat frameworkMediaFormat;
-
-  @TargetApi(16)
-  public static MediaFormat createFromFrameworkMediaFormatV16(android.media.MediaFormat format) {
-    return new MediaFormat(format);
-  }
+  // Text specific.
 
-  public static MediaFormat createVideoFormat(String mimeType, int maxInputSize, int width,
-      int height, List<byte[]> initializationData) {
-    return createVideoFormat(
-        mimeType, maxInputSize, C.UNKNOWN_TIME_US, width, height, initializationData);
-  }
+  /**
+   * The language of the track, or null if unknown or not applicable.
+   */
+  public final String language;
 
-  public static MediaFormat createVideoFormat(String mimeType, int maxInputSize, long durationUs,
-      int width, int height, List<byte[]> initializationData) {
-    return createVideoFormat(
-        mimeType, maxInputSize, durationUs, width, height, 1, initializationData);
-  }
+  /**
+   * For samples that contain subsamples, this is an offset that should be added to subsample
+   * timestamps. A value of {@link #OFFSET_SAMPLE_RELATIVE} indicates that subsample timestamps are
+   * relative to the timestamps of their parent samples.
+   */
+  public final long subsampleOffsetUs;
 
-  public static MediaFormat createVideoFormat(String mimeType, int maxInputSize, long durationUs,
-      int width, int height, float pixelWidthHeightRatio, List<byte[]> initializationData) {
-    return new MediaFormat(mimeType, maxInputSize, durationUs, width, height, pixelWidthHeightRatio,
-        NO_VALUE, NO_VALUE, initializationData);
-  }
+  // Lazy-initialized hashcode and framework media format.
 
-  public static MediaFormat createAudioFormat(String mimeType, int maxInputSize, int channelCount,
-      int sampleRate, List<byte[]> initializationData) {
-    return createAudioFormat(
-        mimeType, maxInputSize, C.UNKNOWN_TIME_US, channelCount, sampleRate, initializationData);
-  }
+  private int hashCode;
+  private android.media.MediaFormat frameworkMediaFormat;
 
-  public static MediaFormat createAudioFormat(String mimeType, int maxInputSize, long durationUs,
-      int channelCount, int sampleRate, List<byte[]> initializationData) {
-    return new MediaFormat(mimeType, maxInputSize, durationUs, NO_VALUE, NO_VALUE, NO_VALUE,
-        channelCount, sampleRate, initializationData);
+  public static MediaFormat createVideoFormat(int trackId, String mimeType, int bitrate,
+      int maxInputSize, long durationUs, int width, int height, List<byte[]> initializationData) {
+    return createVideoFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, width, height,
+        initializationData, NO_VALUE, NO_VALUE);
   }
 
-  public static MediaFormat createTextFormat(String mimeType) {
-    return createTextFormat(mimeType, C.UNKNOWN_TIME_US);
+  public static MediaFormat createVideoFormat(int trackId, String mimeType, int bitrate,
+      int maxInputSize, long durationUs, int width, int height, List<byte[]> initializationData,
+      int rotationDegrees, float pixelWidthHeightRatio) {
+    return new MediaFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, width, height,
+        rotationDegrees, pixelWidthHeightRatio, NO_VALUE, NO_VALUE, null, OFFSET_SAMPLE_RELATIVE,
+        initializationData, false, NO_VALUE, NO_VALUE);
   }
 
-  public static MediaFormat createTextFormat(String mimeType, long durationUs) {
-    return createFormatForMimeType(mimeType, durationUs);
+  public static MediaFormat createAudioFormat(int trackId, String mimeType, int bitrate,
+      int maxInputSize, long durationUs, int channelCount, int sampleRate,
+      List<byte[]> initializationData, String language) {
+    return new MediaFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, NO_VALUE, NO_VALUE,
+        NO_VALUE, NO_VALUE, channelCount, sampleRate, language, OFFSET_SAMPLE_RELATIVE,
+        initializationData, false, NO_VALUE, NO_VALUE);
   }
 
-  public static MediaFormat createFormatForMimeType(String mimeType) {
-    return createFormatForMimeType(mimeType, C.UNKNOWN_TIME_US);
+  public static MediaFormat createTextFormat(int trackId, String mimeType, int bitrate,
+      long durationUs, String language) {
+    return createTextFormat(trackId, mimeType, bitrate, durationUs, language,
+        OFFSET_SAMPLE_RELATIVE);
   }
 
-  public static MediaFormat createFormatForMimeType(String mimeType, long durationUs) {
-    return new MediaFormat(mimeType, NO_VALUE, durationUs, NO_VALUE, NO_VALUE, NO_VALUE,
-        NO_VALUE, NO_VALUE, null);
+  public static MediaFormat createTextFormat(int trackId, String mimeType, int bitrate,
+      long durationUs, String language, long subsampleOffsetUs) {
+    return new MediaFormat(trackId, mimeType, bitrate, NO_VALUE, durationUs, NO_VALUE, NO_VALUE,
+        NO_VALUE, NO_VALUE, NO_VALUE, NO_VALUE, language, subsampleOffsetUs, null, false, NO_VALUE,
+        NO_VALUE);
   }
 
-  @TargetApi(16)
-  private MediaFormat(android.media.MediaFormat format) {
-    this.frameworkMediaFormat = format;
-    mimeType = format.getString(android.media.MediaFormat.KEY_MIME);
-    maxInputSize = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_MAX_INPUT_SIZE);
-    width = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_WIDTH);
-    height = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_HEIGHT);
-    channelCount = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_CHANNEL_COUNT);
-    sampleRate = getOptionalIntegerV16(format, android.media.MediaFormat.KEY_SAMPLE_RATE);
-    pixelWidthHeightRatio = getOptionalFloatV16(format, KEY_PIXEL_WIDTH_HEIGHT_RATIO);
-    initializationData = new ArrayList<>();
-    for (int i = 0; format.containsKey("csd-" + i); i++) {
-      ByteBuffer buffer = format.getByteBuffer("csd-" + i);
-      byte[] data = new byte[buffer.limit()];
-      buffer.get(data);
-      initializationData.add(data);
-      buffer.flip();
-    }
-    durationUs = format.containsKey(android.media.MediaFormat.KEY_DURATION)
-        ? format.getLong(android.media.MediaFormat.KEY_DURATION) : C.UNKNOWN_TIME_US;
-    maxWidth = NO_VALUE;
-    maxHeight = NO_VALUE;
+  public static MediaFormat createFormatForMimeType(int trackId, String mimeType, int bitrate,
+      long durationUs) {
+    return new MediaFormat(trackId, mimeType, bitrate, NO_VALUE, durationUs, NO_VALUE, NO_VALUE,
+        NO_VALUE, NO_VALUE, NO_VALUE, NO_VALUE, null, OFFSET_SAMPLE_RELATIVE, null, false, NO_VALUE,
+        NO_VALUE);
   }
 
-  private MediaFormat(String mimeType, int maxInputSize, long durationUs, int width, int height,
-      float pixelWidthHeightRatio, int channelCount, int sampleRate,
-      List<byte[]> initializationData) {
-    this.mimeType = mimeType;
+  /* package */ MediaFormat(int trackId, String mimeType, int bitrate, int maxInputSize,
+      long durationUs, int width, int height, int rotationDegrees, float pixelWidthHeightRatio,
+      int channelCount, int sampleRate, String language, long subsampleOffsetUs,
+      List<byte[]> initializationData, boolean adaptive, int maxWidth, int maxHeight) {
+    this.trackId = trackId;
+    this.mimeType = Assertions.checkNotEmpty(mimeType);
+    this.bitrate = bitrate;
     this.maxInputSize = maxInputSize;
     this.durationUs = durationUs;
     this.width = width;
     this.height = height;
+    this.rotationDegrees = rotationDegrees;
     this.pixelWidthHeightRatio = pixelWidthHeightRatio;
     this.channelCount = channelCount;
     this.sampleRate = sampleRate;
+    this.language = language;
+    this.subsampleOffsetUs = subsampleOffsetUs;
     this.initializationData = initializationData == null ? Collections.<byte[]>emptyList()
         : initializationData;
-    maxWidth = NO_VALUE;
-    maxHeight = NO_VALUE;
-  }
-
-  public void setMaxVideoDimensions(int maxWidth, int maxHeight) {
+    this.adaptive = adaptive;
     this.maxWidth = maxWidth;
     this.maxHeight = maxHeight;
-    if (frameworkMediaFormat != null) {
-      maybeSetMaxDimensionsV16(frameworkMediaFormat);
+  }
+
+  public MediaFormat copyWithMaxVideoDimensions(int maxWidth, int maxHeight) {
+    return new MediaFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, width, height,
+        rotationDegrees, pixelWidthHeightRatio, channelCount, sampleRate, language,
+        subsampleOffsetUs, initializationData, adaptive, maxWidth, maxHeight);
+  }
+
+  public MediaFormat copyWithSubsampleOffsetUs(long subsampleOffsetUs) {
+    return new MediaFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, width, height,
+        rotationDegrees, pixelWidthHeightRatio, channelCount, sampleRate, language,
+        subsampleOffsetUs, initializationData, adaptive, maxWidth, maxHeight);
+  }
+
+  public MediaFormat copyWithDurationUs(long durationUs) {
+    return new MediaFormat(trackId, mimeType, bitrate, maxInputSize, durationUs, width, height,
+        rotationDegrees, pixelWidthHeightRatio, channelCount, sampleRate, language,
+        subsampleOffsetUs, initializationData, adaptive, maxWidth, maxHeight);
+  }
+
+  public MediaFormat copyAsAdaptive() {
+    return new MediaFormat(trackId, mimeType, NO_VALUE, NO_VALUE, durationUs, NO_VALUE, NO_VALUE,
+        NO_VALUE, NO_VALUE, NO_VALUE, NO_VALUE, null, OFFSET_SAMPLE_RELATIVE, null, true, maxWidth,
+        maxHeight);
+  }
+
+  /**
+   * @return A {@link MediaFormat} representation of this format.
+   */
+  @SuppressLint("InlinedApi")
+  @TargetApi(16)
+  public final android.media.MediaFormat getFrameworkMediaFormatV16() {
+    if (frameworkMediaFormat == null) {
+      android.media.MediaFormat format = new android.media.MediaFormat();
+      format.setString(android.media.MediaFormat.KEY_MIME, mimeType);
+      maybeSetStringV16(format, android.media.MediaFormat.KEY_LANGUAGE, language);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_INPUT_SIZE, maxInputSize);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_WIDTH, width);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_HEIGHT, height);
+      maybeSetIntegerV16(format, "rotation-degrees", rotationDegrees);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_WIDTH, maxWidth);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_HEIGHT, maxHeight);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_CHANNEL_COUNT, channelCount);
+      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_SAMPLE_RATE, sampleRate);
+      for (int i = 0; i < initializationData.size(); i++) {
+        format.setByteBuffer("csd-" + i, ByteBuffer.wrap(initializationData.get(i)));
+      }
+      if (durationUs != C.UNKNOWN_TIME_US) {
+        format.setLong(android.media.MediaFormat.KEY_DURATION, durationUs);
+      }
+      frameworkMediaFormat = format;
     }
+    return frameworkMediaFormat;
   }
 
-  public int getMaxVideoWidth() {
-    return maxWidth;
+  /**
+   * Sets the framework format returned by {@link #getFrameworkMediaFormatV16()}.
+   *
+   * @deprecated This method only exists for FrameworkSampleSource, which is itself deprecated.
+   * @param format The framework format.
+   */
+  @Deprecated
+  @TargetApi(16)
+  /* package */ final void setFrameworkFormatV16(android.media.MediaFormat format) {
+    frameworkMediaFormat = format;
   }
 
-  public int getMaxVideoHeight() {
-    return maxHeight;
+  @Override
+  public String toString() {
+    return "MediaFormat(" + trackId + ", " + mimeType + ", " + bitrate + ", " + maxInputSize
+        + ", " + width + ", " + height + ", " + rotationDegrees + ", " + pixelWidthHeightRatio
+        + ", " + channelCount + ", " + sampleRate + ", " + language + ", " + durationUs + ", "
+        + adaptive + ", " + maxWidth + ", " + maxHeight + ")";
   }
 
   @Override
   public int hashCode() {
     if (hashCode == 0) {
       int result = 17;
+      result = 31 * result + trackId;
       result = 31 * result + (mimeType == null ? 0 : mimeType.hashCode());
+      result = 31 * result + bitrate;
       result = 31 * result + maxInputSize;
       result = 31 * result + width;
       result = 31 * result + height;
+      result = 31 * result + rotationDegrees;
       result = 31 * result + Float.floatToRawIntBits(pixelWidthHeightRatio);
       result = 31 * result + (int) durationUs;
+      result = 31 * result + (adaptive ? 1231 : 1237);
       result = 31 * result + maxWidth;
       result = 31 * result + maxHeight;
       result = 31 * result + channelCount;
       result = 31 * result + sampleRate;
+      result = 31 * result + (language == null ? 0 : language.hashCode());
       for (int i = 0; i < initializationData.size(); i++) {
         result = 31 * result + Arrays.hashCode(initializationData.get(i));
       }
@@ -197,24 +313,14 @@ public boolean equals(Object obj) {
     if (obj == null || getClass() != obj.getClass()) {
       return false;
     }
-    return equalsInternal((MediaFormat) obj, false);
-  }
-
-  public boolean equals(MediaFormat other, boolean ignoreMaxDimensions) {
-    if (this == other) {
-      return true;
-    }
-    if (other == null) {
-      return false;
-    }
-    return equalsInternal(other, ignoreMaxDimensions);
-  }
-
-  private boolean equalsInternal(MediaFormat other, boolean ignoreMaxDimensions) {
-    if (maxInputSize != other.maxInputSize || width != other.width || height != other.height
+    MediaFormat other = (MediaFormat) obj;
+    if (adaptive != other.adaptive || bitrate != other.bitrate || maxInputSize != other.maxInputSize
+        || width != other.width || height != other.height
+        || rotationDegrees != other.rotationDegrees
         || pixelWidthHeightRatio != other.pixelWidthHeightRatio
-        || (!ignoreMaxDimensions && (maxWidth != other.maxWidth || maxHeight != other.maxHeight))
+        || maxWidth != other.maxWidth || maxHeight != other.maxHeight
         || channelCount != other.channelCount || sampleRate != other.sampleRate
+        || trackId != other.trackId || !Util.areEqual(language, other.language)
         || !Util.areEqual(mimeType, other.mimeType)
         || initializationData.size() != other.initializationData.size()) {
       return false;
@@ -227,44 +333,12 @@ private boolean equalsInternal(MediaFormat other, boolean ignoreMaxDimensions) {
     return true;
   }
 
-  @Override
-  public String toString() {
-    return "MediaFormat(" + mimeType + ", " + maxInputSize + ", " + width + ", " + height + ", "
-        + pixelWidthHeightRatio + ", " + channelCount + ", " + sampleRate + ", " + durationUs + ", "
-        + maxWidth + ", " + maxHeight + ")";
-  }
-
-  /**
-   * @return A {@link MediaFormat} representation of this format.
-   */
   @TargetApi(16)
-  public final android.media.MediaFormat getFrameworkMediaFormatV16() {
-    if (frameworkMediaFormat == null) {
-      android.media.MediaFormat format = new android.media.MediaFormat();
-      format.setString(android.media.MediaFormat.KEY_MIME, mimeType);
-      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_INPUT_SIZE, maxInputSize);
-      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_WIDTH, width);
-      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_HEIGHT, height);
-      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_CHANNEL_COUNT, channelCount);
-      maybeSetIntegerV16(format, android.media.MediaFormat.KEY_SAMPLE_RATE, sampleRate);
-      maybeSetFloatV16(format, KEY_PIXEL_WIDTH_HEIGHT_RATIO, pixelWidthHeightRatio);
-      for (int i = 0; i < initializationData.size(); i++) {
-        format.setByteBuffer("csd-" + i, ByteBuffer.wrap(initializationData.get(i)));
-      }
-      if (durationUs != C.UNKNOWN_TIME_US) {
-        format.setLong(android.media.MediaFormat.KEY_DURATION, durationUs);
-      }
-      maybeSetMaxDimensionsV16(format);
-      frameworkMediaFormat = format;
+  private static final void maybeSetStringV16(android.media.MediaFormat format, String key,
+      String value) {
+    if (value != null) {
+      format.setString(key, value);
     }
-    return frameworkMediaFormat;
-  }
-
-  @SuppressLint("InlinedApi")
-  @TargetApi(16)
-  private final void maybeSetMaxDimensionsV16(android.media.MediaFormat format) {
-    maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_WIDTH, maxWidth);
-    maybeSetIntegerV16(format, android.media.MediaFormat.KEY_MAX_HEIGHT, maxHeight);
   }
 
   @TargetApi(16)
@@ -275,22 +349,4 @@ private static final void maybeSetIntegerV16(android.media.MediaFormat format, S
     }
   }
 
-  @TargetApi(16)
-  private static final void maybeSetFloatV16(android.media.MediaFormat format, String key,
-      float value) {
-    if (value != NO_VALUE) {
-      format.setFloat(key, value);
-    }
-  }
-
-  @TargetApi(16)
-  private static final int getOptionalIntegerV16(android.media.MediaFormat format, String key) {
-    return format.containsKey(key) ? format.getInteger(key) : NO_VALUE;
-  }
-
-  @TargetApi(16)
-  private static final float getOptionalFloatV16(android.media.MediaFormat format, String key) {
-    return format.containsKey(key) ? format.getFloat(key) : NO_VALUE;
-  }
-
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/SampleHolder.java b/library/src/main/java/com/google/android/exoplayer/SampleHolder.java
index 59873e5921..be2c3f6189 100644
--- a/library/src/main/java/com/google/android/exoplayer/SampleHolder.java
+++ b/library/src/main/java/com/google/android/exoplayer/SampleHolder.java
@@ -63,8 +63,8 @@
   private final int bufferReplacementMode;
 
   /**
-   * @param bufferReplacementMode Determines the behavior of {@link #replaceBuffer(int)}. One of
-   *     {@link #BUFFER_REPLACEMENT_MODE_DISABLED}, {@link #BUFFER_REPLACEMENT_MODE_NORMAL} and
+   * @param bufferReplacementMode Determines the behavior of {@link #ensureSpaceForWrite(int)}. One
+   *     of {@link #BUFFER_REPLACEMENT_MODE_DISABLED}, {@link #BUFFER_REPLACEMENT_MODE_NORMAL} and
    *     {@link #BUFFER_REPLACEMENT_MODE_DIRECT}.
    */
   public SampleHolder(int bufferReplacementMode) {
@@ -73,21 +73,39 @@ public SampleHolder(int bufferReplacementMode) {
   }
 
   /**
-   * Attempts to replace {@link #data} with a {@link ByteBuffer} of the specified capacity.
+   * Ensures that {@link #data} is large enough to accommodate a write of a given length at its
+   * current position.
+   * <p>
+   * If the capacity of {@link #data} is sufficient this method does nothing. If the capacity is
+   * insufficient then an attempt is made to replace {@link #data} with a new {@link ByteBuffer}
+   * whose capacity is sufficient. Data up to the current position is copied to the new buffer.
    *
-   * @param capacity The capacity of the replacement buffer, in bytes.
-   * @return True if the buffer was replaced. False otherwise.
+   * @param length The length of the write that must be accommodated, in bytes.
+   * @throws IllegalStateException If there is insufficient capacity to accommodate the write and
+   *     the buffer replacement mode of the holder is {@link #BUFFER_REPLACEMENT_MODE_DISABLED}.
    */
-  public boolean replaceBuffer(int capacity) {
-    switch (bufferReplacementMode) {
-      case BUFFER_REPLACEMENT_MODE_NORMAL:
-        data = ByteBuffer.allocate(capacity);
-        return true;
-      case BUFFER_REPLACEMENT_MODE_DIRECT:
-        data = ByteBuffer.allocateDirect(capacity);
-        return true;
+  public void ensureSpaceForWrite(int length) throws IllegalStateException {
+    if (data == null) {
+      data = createReplacementBuffer(length);
+      return;
     }
-    return false;
+    // Check whether the current buffer is sufficient.
+    int capacity = data.capacity();
+    int position = data.position();
+    int requiredCapacity = position + length;
+    if (capacity >= requiredCapacity) {
+      return;
+    }
+    // Instantiate a new buffer if possible.
+    ByteBuffer newData = createReplacementBuffer(requiredCapacity);
+    // Copy data up to the current position from the old buffer to the new one.
+    if (position > 0) {
+      data.position(0);
+      data.limit(position);
+      newData.put(data);
+    }
+    // Set the new buffer.
+    data = newData;
   }
 
   /**
@@ -120,4 +138,16 @@ public void clearData() {
     }
   }
 
+  private ByteBuffer createReplacementBuffer(int requiredCapacity) {
+    if (bufferReplacementMode == BUFFER_REPLACEMENT_MODE_NORMAL) {
+      return ByteBuffer.allocate(requiredCapacity);
+    } else if (bufferReplacementMode == BUFFER_REPLACEMENT_MODE_DIRECT) {
+      return ByteBuffer.allocateDirect(requiredCapacity);
+    } else {
+      int currentCapacity = data == null ? 0 : data.capacity();
+      throw new IllegalStateException("Buffer too small (" + currentCapacity + " < "
+          + requiredCapacity + ")");
+    }
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/SampleSource.java b/library/src/main/java/com/google/android/exoplayer/SampleSource.java
index 539983d200..0243387c78 100644
--- a/library/src/main/java/com/google/android/exoplayer/SampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/SampleSource.java
@@ -20,9 +20,9 @@
 /**
  * A source of media samples.
  * <p>
- * A {@link SampleSource} may expose one or multiple tracks. The number of tracks and information
- * about each can be queried using {@link SampleSourceReader#getTrackCount()} and
- * {@link SampleSourceReader#getTrackInfo(int)} respectively.
+ * A {@link SampleSource} may expose one or multiple tracks. The number of tracks and each track's
+ * media format can be queried using {@link SampleSourceReader#getTrackCount()} and
+ * {@link SampleSourceReader#getFormat(int)} respectively.
  */
 public interface SampleSource {
 
@@ -66,6 +66,14 @@
    */
   public interface SampleSourceReader {
 
+    /**
+     * If the source is currently having difficulty preparing or loading samples, then this method
+     * throws the underlying error. Otherwise does nothing.
+     *
+     * @throws IOException The underlying error.
+     */
+    public void maybeThrowError() throws IOException;
+
     /**
      * Prepares the source.
      * <p>
@@ -75,56 +83,52 @@
      * success.
      *
      * @param positionUs The player's current playback position.
-     * @return True if the source was prepared successfully, false otherwise.
+     * @return True if the source was prepared, false otherwise.
      */
     public boolean prepare(long positionUs);
 
     /**
      * Returns the number of tracks exposed by the source.
+     * <p>
+     * This method should only be called after the source has been prepared.
      *
      * @return The number of tracks.
      */
     public int getTrackCount();
 
     /**
-     * Returns information about the specified track.
+     * Returns the format of the specified track.
      * <p>
-     * This method should not be called until after the source has been successfully prepared.
+     * Note that whilst the format of a track will remain constant, the format of the actual media
+     * stream may change dynamically. An example of this is where the track is adaptive
+     * (i.e. @link {@link MediaFormat#adaptive} is true). Hence the track formats returned through
+     * this method should not be used to configure decoders. Decoder configuration should be
+     * performed using the formats obtained when reading the media stream through calls to
+     * {@link #readData(int, long, MediaFormatHolder, SampleHolder, boolean)}.
+     * <p>
+     * This method should only be called after the source has been prepared.
      *
-     * @return Information about the specified track.
+     * @param track The track index.
+     * @return The format of the specified track.
      */
-    public TrackInfo getTrackInfo(int track);
+    public MediaFormat getFormat(int track);
 
     /**
      * Enable the specified track. This allows the track's format and samples to be read from
      * {@link #readData(int, long, MediaFormatHolder, SampleHolder, boolean)}.
      * <p>
-     * This method should not be called until after the source has been successfully prepared.
+     * This method should only be called after the source has been prepared, and when the specified
+     * track is disabled.
      *
      * @param track The track to enable.
      * @param positionUs The player's current playback position.
      */
     public void enable(int track, long positionUs);
 
-    /**
-     * Disable the specified track.
-     * <p>
-     * This method should not be called until after the source has been successfully prepared.
-     *
-     * @param track The track to disable.
-     */
-    public void disable(int track);
-
-    /**
-     * If the source is currently having difficulty preparing or loading samples, then this method
-     * throws the underlying error. Otherwise does nothing.
-     *
-     * @throws IOException The underlying error.
-     */
-    public void maybeThrowError() throws IOException;
-
     /**
      * Indicates to the source that it should still be buffering data for the specified track.
+     * <p>
+     * This method should only be called when the specified track is enabled.
      *
      * @param track The track to continue buffering.
      * @param positionUs The current playback position.
@@ -136,7 +140,7 @@
     /**
      * Attempts to read either a sample, a new format or or a discontinuity from the source.
      * <p>
-     * This method should not be called until after the source has been successfully prepared.
+     * This method should only be called when the specified track is enabled.
      * <p>
      * Note that where multiple tracks are enabled, {@link #NOTHING_READ} may be returned if the
      * next piece of data to be read from the {@link SampleSource} corresponds to a different track
@@ -160,7 +164,7 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
     /**
      * Seeks to the specified time in microseconds.
      * <p>
-     * This method should not be called until after the source has been successfully prepared.
+     * This method should only be called when at least one track is enabled.
      *
      * @param positionUs The seek position in microseconds.
      */
@@ -169,7 +173,7 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
     /**
      * Returns an estimate of the position up to which data is buffered.
      * <p>
-     * This method should not be called until after the source has been successfully prepared.
+     * This method should only be called when at least one track is enabled.
      *
      * @return An estimate of the absolute position in microseconds up to which data is buffered,
      *     or {@link TrackRenderer#END_OF_TRACK_US} if data is buffered to the end of the stream,
@@ -177,6 +181,15 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
      */
     public long getBufferedPositionUs();
 
+    /**
+     * Disable the specified track.
+     * <p>
+     * This method should only be called when the specified track is enabled.
+     *
+     * @param track The track to disable.
+     */
+    public void disable(int track);
+
     /**
      * Releases the {@link SampleSourceReader}.
      * <p>
diff --git a/library/src/main/java/com/google/android/exoplayer/SampleSourceTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/SampleSourceTrackRenderer.java
new file mode 100644
index 0000000000..8673d774cd
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/SampleSourceTrackRenderer.java
@@ -0,0 +1,193 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer;
+
+import com.google.android.exoplayer.MediaCodecUtil.DecoderQueryException;
+import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+
+import java.io.IOException;
+import java.util.Arrays;
+
+/**
+ * Base class for {@link TrackRenderer} implementations that render samples obtained from a
+ * {@link SampleSource}.
+ */
+public abstract class SampleSourceTrackRenderer extends TrackRenderer {
+
+  private final SampleSourceReader[] sources;
+
+  private int[] handledSourceIndices;
+  private int[] handledSourceTrackIndices;
+
+  private SampleSourceReader enabledSource;
+  private int enabledSourceTrackIndex;
+
+  private long durationUs;
+
+  /**
+   * @param sources One or more upstream sources from which the renderer can obtain samples.
+   */
+  public SampleSourceTrackRenderer(SampleSource... sources) {
+    this.sources = new SampleSourceReader[sources.length];
+    for (int i = 0; i < sources.length; i++) {
+      this.sources[i] = sources[i].register();
+    }
+  }
+
+  @Override
+  protected boolean doPrepare(long positionUs) throws ExoPlaybackException {
+    boolean allSourcesPrepared = true;
+    for (int i = 0; i < sources.length; i++) {
+      allSourcesPrepared &= sources[i].prepare(positionUs);
+    }
+    if (!allSourcesPrepared) {
+      return false;
+    }
+    // The sources are all prepared.
+    int totalSourceTrackCount = 0;
+    for (int i = 0; i < sources.length; i++) {
+      totalSourceTrackCount += sources[i].getTrackCount();
+    }
+    long durationUs = 0;
+    int handledTrackCount = 0;
+    int[] handledSourceIndices = new int[totalSourceTrackCount];
+    int[] handledTrackIndices = new int[totalSourceTrackCount];
+    int sourceCount = sources.length;
+    for (int sourceIndex = 0; sourceIndex < sourceCount; sourceIndex++) {
+      SampleSourceReader source = sources[sourceIndex];
+      int sourceTrackCount = source.getTrackCount();
+      for (int trackIndex = 0; trackIndex < sourceTrackCount; trackIndex++) {
+        MediaFormat format = source.getFormat(trackIndex);
+        boolean handlesTrack;
+        try {
+          handlesTrack = handlesTrack(format);
+        } catch (DecoderQueryException e) {
+          throw new ExoPlaybackException(e);
+        }
+        if (handlesTrack) {
+          handledSourceIndices[handledTrackCount] = sourceIndex;
+          handledTrackIndices[handledTrackCount] = trackIndex;
+          handledTrackCount++;
+          if (durationUs == TrackRenderer.UNKNOWN_TIME_US) {
+            // We've already encountered a track for which the duration is unknown, so the media
+            // duration is unknown regardless of the duration of this track.
+          } else {
+            long trackDurationUs = format.durationUs;
+            if (trackDurationUs == TrackRenderer.UNKNOWN_TIME_US) {
+              durationUs = TrackRenderer.UNKNOWN_TIME_US;
+            } else if (trackDurationUs == TrackRenderer.MATCH_LONGEST_US) {
+              // Do nothing.
+            } else {
+              durationUs = Math.max(durationUs, trackDurationUs);
+            }
+          }
+        }
+      }
+    }
+    this.durationUs = durationUs;
+    this.handledSourceIndices = Arrays.copyOf(handledSourceIndices, handledTrackCount);
+    this.handledSourceTrackIndices = Arrays.copyOf(handledTrackIndices, handledTrackCount);
+    return true;
+  }
+
+  /**
+   * Returns whether this renderer is capable of handling the provided track.
+   *
+   * @param mediaFormat The format of the track.
+   * @return True if the renderer can handle the track, false otherwise.
+   * @throws DecoderQueryException Thrown if there was an error querying decoders.
+   */
+  protected abstract boolean handlesTrack(MediaFormat mediaFormat) throws DecoderQueryException;
+
+  @Override
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    enabledSource = sources[handledSourceIndices[track]];
+    enabledSourceTrackIndex = handledSourceTrackIndices[track];
+    enabledSource.enable(enabledSourceTrackIndex, positionUs);
+  }
+
+  @Override
+  protected void seekTo(long positionUs) throws ExoPlaybackException {
+    enabledSource.seekToUs(positionUs);
+  }
+
+  @Override
+  protected long getBufferedPositionUs() {
+    return enabledSource.getBufferedPositionUs();
+  }
+
+  @Override
+  protected long getDurationUs() {
+    return durationUs;
+  }
+
+  @Override
+  protected void maybeThrowError() throws ExoPlaybackException {
+    if (enabledSource != null) {
+      maybeThrowError(enabledSource);
+    } else {
+      int sourceCount = sources.length;
+      for (int i = 0; i < sourceCount; i++) {
+        maybeThrowError(sources[i]);
+      }
+    }
+  }
+
+  private void maybeThrowError(SampleSourceReader source) throws ExoPlaybackException {
+    try {
+      source.maybeThrowError();
+    } catch (IOException e) {
+      throw new ExoPlaybackException(e);
+    }
+  }
+
+  @Override
+  protected void onDisabled() throws ExoPlaybackException {
+    enabledSource.disable(enabledSourceTrackIndex);
+    enabledSource = null;
+  }
+
+  @Override
+  protected void onReleased() throws ExoPlaybackException {
+    int sourceCount = sources.length;
+    for (int i = 0; i < sourceCount; i++) {
+      sources[i].release();
+    }
+  }
+
+  protected final boolean continueBufferingSource(long positionUs) {
+    return enabledSource.continueBuffering(enabledSourceTrackIndex, positionUs);
+  }
+
+  protected final int readSource(long positionUs, MediaFormatHolder formatHolder,
+      SampleHolder sampleHolder, boolean onlyReadDiscontinuity) {
+    return enabledSource.readData(enabledSourceTrackIndex, positionUs, formatHolder, sampleHolder,
+        onlyReadDiscontinuity);
+  }
+
+  @Override
+  protected final int getTrackCount() {
+    return handledSourceTrackIndices.length;
+  }
+
+  @Override
+  protected final MediaFormat getFormat(int track) {
+    SampleSourceReader source = sources[handledSourceIndices[track]];
+    return source.getFormat(handledSourceTrackIndices[track]);
+  }
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/SingleSampleSource.java b/library/src/main/java/com/google/android/exoplayer/SingleSampleSource.java
index 36b44ced1c..55fde5057b 100644
--- a/library/src/main/java/com/google/android/exoplayer/SingleSampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/SingleSampleSource.java
@@ -20,6 +20,7 @@
 import com.google.android.exoplayer.upstream.DataSpec;
 import com.google.android.exoplayer.upstream.Loader;
 import com.google.android.exoplayer.upstream.Loader.Loadable;
+import com.google.android.exoplayer.util.Assertions;
 
 import android.net.Uri;
 import android.os.SystemClock;
@@ -43,15 +44,18 @@
    */
   private static final int INITIAL_SAMPLE_SIZE = 1;
 
+  private static final int STATE_SEND_FORMAT = 0;
+  private static final int STATE_SEND_SAMPLE = 1;
+  private static final int STATE_END_OF_STREAM = 2;
+
   private final Uri uri;
   private final DataSource dataSource;
   private final MediaFormat format;
-  private final TrackInfo trackInfo;
   private final int minLoadableRetryCount;
 
+  private int state;
   private byte[] sampleData;
   private int sampleSize;
-  private boolean pendingSample;
 
   private boolean loadingFinished;
   private Loader loader;
@@ -69,7 +73,6 @@ public SingleSampleSource(Uri uri, DataSource dataSource, MediaFormat format,
     this.dataSource = dataSource;
     this.format = format;
     this.minLoadableRetryCount = minLoadableRetryCount;
-    trackInfo = new TrackInfo(format.mimeType, format.durationUs);
     sampleData = new byte[INITIAL_SAMPLE_SIZE];
   }
 
@@ -92,13 +95,13 @@ public int getTrackCount() {
   }
 
   @Override
-  public TrackInfo getTrackInfo(int track) {
-    return trackInfo;
+  public MediaFormat getFormat(int track) {
+    return format;
   }
 
   @Override
   public void enable(int track, long positionUs) {
-    pendingSample = true;
+    state = STATE_SEND_FORMAT;
     clearCurrentLoadableException();
     maybeStartLoading();
   }
@@ -121,25 +124,33 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
       SampleHolder sampleHolder, boolean onlyReadDiscontinuity) {
     if (onlyReadDiscontinuity) {
       return NOTHING_READ;
-    } else if (!pendingSample) {
+    } else if (state == STATE_END_OF_STREAM) {
       return END_OF_STREAM;
-    } else if (!loadingFinished) {
+    } else if (state == STATE_SEND_FORMAT) {
+      formatHolder.format = format;
+      state = STATE_SEND_SAMPLE;
+      return FORMAT_READ;
+    }
+
+    Assertions.checkState(state == STATE_SEND_SAMPLE);
+    if (!loadingFinished) {
       return NOTHING_READ;
     } else {
       sampleHolder.timeUs = 0;
       sampleHolder.size = sampleSize;
       sampleHolder.flags = C.SAMPLE_FLAG_SYNC;
-      if (sampleHolder.data == null || sampleHolder.data.capacity() < sampleSize) {
-        sampleHolder.replaceBuffer(sampleHolder.size);
-      }
+      sampleHolder.ensureSpaceForWrite(sampleHolder.size);
       sampleHolder.data.put(sampleData, 0, sampleSize);
+      state = STATE_END_OF_STREAM;
       return SAMPLE_READ;
     }
   }
 
   @Override
   public void seekToUs(long positionUs) {
-    pendingSample = true;
+    if (state == STATE_END_OF_STREAM) {
+      state = STATE_SEND_SAMPLE;
+    }
   }
 
   @Override
@@ -149,7 +160,7 @@ public long getBufferedPositionUs() {
 
   @Override
   public void disable(int track) {
-    pendingSample = false;
+    state = STATE_END_OF_STREAM;
   }
 
   @Override
@@ -163,7 +174,7 @@ public void release() {
   // Private methods.
 
   private void maybeStartLoading() {
-    if (loadingFinished || !pendingSample || loader.isLoading()) {
+    if (loadingFinished || state == STATE_END_OF_STREAM || loader.isLoading()) {
       return;
     }
     if (currentLoadableException != null) {
diff --git a/library/src/main/java/com/google/android/exoplayer/TimeRange.java b/library/src/main/java/com/google/android/exoplayer/TimeRange.java
index 03bc528749..46db5aa059 100644
--- a/library/src/main/java/com/google/android/exoplayer/TimeRange.java
+++ b/library/src/main/java/com/google/android/exoplayer/TimeRange.java
@@ -15,37 +15,22 @@
  */
 package com.google.android.exoplayer;
 
+import com.google.android.exoplayer.util.Clock;
+
+import android.os.SystemClock;
+
 /**
  * A container to store a start and end time in microseconds.
  */
-public final class TimeRange {
-
-  /**
-   * Represents a range of time whose bounds change in bulk increments rather than smoothly over
-   * time.
-   */
-  public static final int TYPE_SNAPSHOT = 0;
+public interface TimeRange {
 
   /**
-   * The type of this time range.
-   */
-  public final int type;
-
-  private final long startTimeUs;
-  private final long endTimeUs;
-
-  /**
-   * Create a new {@link TimeRange} of the appropriate type.
+   * Whether the range is static, meaning repeated calls to {@link #getCurrentBoundsMs(long[])}
+   * or {@link #getCurrentBoundsUs(long[])} will return identical results.
    *
-   * @param type The type of the TimeRange.
-   * @param startTimeUs The beginning of the TimeRange.
-   * @param endTimeUs The end of the TimeRange.
+   * @return Whether the range is static.
    */
-  public TimeRange(int type, long startTimeUs, long endTimeUs) {
-    this.type = type;
-    this.startTimeUs = startTimeUs;
-    this.endTimeUs = endTimeUs;
-  }
+  public boolean isStatic();
 
   /**
    * Returns the start and end times (in milliseconds) of the TimeRange in the provided array,
@@ -54,12 +39,7 @@ public TimeRange(int type, long startTimeUs, long endTimeUs) {
    * @param out An array to store the start and end times; can be null.
    * @return An array containing the start time (index 0) and end time (index 1) in milliseconds.
    */
-  public long[] getCurrentBoundsMs(long[] out) {
-    out = getCurrentBoundsUs(out);
-    out[0] /= 1000;
-    out[1] /= 1000;
-    return out;
-  }
+  public long[] getCurrentBoundsMs(long[] out);
 
   /**
    * Returns the start and end times (in microseconds) of the TimeRange in the provided array,
@@ -68,35 +48,156 @@ public TimeRange(int type, long startTimeUs, long endTimeUs) {
    * @param out An array to store the start and end times; can be null.
    * @return An array containing the start time (index 0) and end time (index 1) in microseconds.
    */
-  public long[] getCurrentBoundsUs(long[] out) {
-    if (out == null || out.length < 2) {
-      out = new long[2];
+  public long[] getCurrentBoundsUs(long[] out);
+
+  /**
+   * A static {@link TimeRange}.
+   */
+  public static final class StaticTimeRange implements TimeRange {
+
+    private final long startTimeUs;
+    private final long endTimeUs;
+
+    /**
+     * @param startTimeUs The beginning of the range.
+     * @param endTimeUs The end of the range.
+     */
+    public StaticTimeRange(long startTimeUs, long endTimeUs) {
+      this.startTimeUs = startTimeUs;
+      this.endTimeUs = endTimeUs;
+    }
+
+    @Override
+    public boolean isStatic() {
+      return true;
+    }
+
+    @Override
+    public long[] getCurrentBoundsMs(long[] out) {
+      out = getCurrentBoundsUs(out);
+      out[0] /= 1000;
+      out[1] /= 1000;
+      return out;
+    }
+
+    @Override
+    public long[] getCurrentBoundsUs(long[] out) {
+      if (out == null || out.length < 2) {
+        out = new long[2];
+      }
+      out[0] = startTimeUs;
+      out[1] = endTimeUs;
+      return out;
+    }
+
+    @Override
+    public int hashCode() {
+      int result = 17;
+      result = 31 * result + (int) startTimeUs;
+      result = 31 * result + (int) endTimeUs;
+      return result;
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (obj == this) {
+        return true;
+      }
+      if (obj == null || getClass() != obj.getClass()) {
+        return false;
+      }
+      StaticTimeRange other = (StaticTimeRange) obj;
+      return other.startTimeUs == startTimeUs
+          && other.endTimeUs == endTimeUs;
     }
-    out[0] = startTimeUs;
-    out[1] = endTimeUs;
-    return out;
-  }
 
-  @Override
-  public int hashCode() {
-    int hashCode = 0;
-    hashCode |= type << 30;
-    hashCode |= (((startTimeUs + endTimeUs) / 1000) & 0x3FFFFFFF);
-    return hashCode;
   }
 
-  @Override
-  public boolean equals(Object other) {
-    if (other == this) {
-      return true;
+  /**
+   * A dynamic {@link TimeRange}.
+   */
+  public static final class DynamicTimeRange implements TimeRange {
+
+    private final long minStartTimeUs;
+    private final long maxEndTimeUs;
+    private final long elapsedRealtimeAtStartUs;
+    private final long bufferDepthUs;
+    private final Clock systemClock;
+
+    /**
+     * @param minStartTimeUs A lower bound on the beginning of the range.
+     * @param maxEndTimeUs An upper bound on the end of the range.
+     * @param elapsedRealtimeAtStartUs The value of {@link SystemClock#elapsedRealtime()},
+     *     multiplied by 1000, corresponding to a media time of zero.
+     * @param bufferDepthUs The buffer depth of the media, or -1.
+     * @param systemClock A system clock.
+     */
+    public DynamicTimeRange(long minStartTimeUs, long maxEndTimeUs, long elapsedRealtimeAtStartUs,
+        long bufferDepthUs, Clock systemClock) {
+      this.minStartTimeUs = minStartTimeUs;
+      this.maxEndTimeUs = maxEndTimeUs;
+      this.elapsedRealtimeAtStartUs = elapsedRealtimeAtStartUs;
+      this.bufferDepthUs = bufferDepthUs;
+      this.systemClock = systemClock;
     }
-    if (other instanceof TimeRange) {
-      TimeRange otherTimeRange = (TimeRange) other;
-      return (otherTimeRange.type == type) && (otherTimeRange.startTimeUs == startTimeUs)
-          && (otherTimeRange.endTimeUs == endTimeUs);
-    } else {
+
+    @Override
+    public boolean isStatic() {
       return false;
     }
+
+    @Override
+    public long[] getCurrentBoundsMs(long[] out) {
+      out = getCurrentBoundsUs(out);
+      out[0] /= 1000;
+      out[1] /= 1000;
+      return out;
+    }
+
+    @Override
+    public long[] getCurrentBoundsUs(long[] out) {
+      if (out == null || out.length < 2) {
+        out = new long[2];
+      }
+      // Don't allow the end time to be greater than the total elapsed time.
+      long currentEndTimeUs = Math.min(maxEndTimeUs,
+          (systemClock.elapsedRealtime() * 1000) - elapsedRealtimeAtStartUs);
+      long currentStartTimeUs = minStartTimeUs;
+      if (bufferDepthUs != -1) {
+        // Don't allow the start time to be less than the current end time minus the buffer depth.
+        currentStartTimeUs = Math.max(currentStartTimeUs,
+            currentEndTimeUs - bufferDepthUs);
+      }
+      out[0] = currentStartTimeUs;
+      out[1] = currentEndTimeUs;
+      return out;
+    }
+
+    @Override
+    public int hashCode() {
+      int result = 17;
+      result = 31 * result + (int) minStartTimeUs;
+      result = 31 * result + (int) maxEndTimeUs;
+      result = 31 * result + (int) elapsedRealtimeAtStartUs;
+      result = 31 * result + (int) bufferDepthUs;
+      return result;
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (obj == this) {
+        return true;
+      }
+      if (obj == null || getClass() != obj.getClass()) {
+        return false;
+      }
+      DynamicTimeRange other = (DynamicTimeRange) obj;
+      return other.minStartTimeUs == minStartTimeUs
+          && other.maxEndTimeUs == maxEndTimeUs
+          && other.elapsedRealtimeAtStartUs == elapsedRealtimeAtStartUs
+          && other.bufferDepthUs == bufferDepthUs;
+    }
+
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/TrackInfo.java b/library/src/main/java/com/google/android/exoplayer/TrackInfo.java
deleted file mode 100644
index f0ac31ac22..0000000000
--- a/library/src/main/java/com/google/android/exoplayer/TrackInfo.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Copyright (C) 2014 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package com.google.android.exoplayer;
-
-/**
- * Holds high level information about a media track.
- */
-public final class TrackInfo {
-
-  /**
-   * The mime type.
-   */
-  public final String mimeType;
-
-  /**
-   * The duration in microseconds, or {@link C#UNKNOWN_TIME_US} if the duration is unknown, or
-   * {@link C#MATCH_LONGEST_US} if the duration should match the duration of the longest track whose
-   * duration is known.
-   */
-  public final long durationUs;
-
-  /**
-   * @param mimeType The mime type.
-   * @param durationUs The duration in microseconds, or {@link C#UNKNOWN_TIME_US} if the duration
-   *     is unknown, or {@link C#MATCH_LONGEST_US} if the duration should match the duration of the
-   *     longest track whose duration is known.
-   */
-  public TrackInfo(String mimeType, long durationUs) {
-    this.mimeType = mimeType;
-    this.durationUs = durationUs;
-  }
-
-}
diff --git a/library/src/main/java/com/google/android/exoplayer/TrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/TrackRenderer.java
index ffc02caf4e..e32aa16008 100644
--- a/library/src/main/java/com/google/android/exoplayer/TrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/TrackRenderer.java
@@ -32,13 +32,23 @@
 public abstract class TrackRenderer implements ExoPlayerComponent {
 
   /**
-   * The renderer has been released and should not be used.
+   * Represents an unknown time or duration. Equal to {@link C#UNKNOWN_TIME_US}.
    */
-  protected static final int STATE_RELEASED = -2;
+  public static final long UNKNOWN_TIME_US = C.UNKNOWN_TIME_US; // -1
   /**
-   * The renderer should be ignored by the player.
+   * Represents a time or duration that should match the duration of the longest track whose
+   * duration is known. Equal to {@link C#MATCH_LONGEST_US}.
    */
-  protected static final int STATE_IGNORE = -1;
+  public static final long MATCH_LONGEST_US = C.MATCH_LONGEST_US; // -2
+  /**
+   * Represents the time of the end of the track.
+   */
+  public static final long END_OF_TRACK_US = -3;
+
+  /**
+   * The renderer has been released and should not be used.
+   */
+  protected static final int STATE_RELEASED = -1;
   /**
    * The renderer has not yet been prepared.
    */
@@ -64,20 +74,6 @@
    */
   protected static final int STATE_STARTED = 3;
 
-  /**
-   * Represents an unknown time or duration. Equal to {@link C#UNKNOWN_TIME_US}.
-   */
-  public static final long UNKNOWN_TIME_US = C.UNKNOWN_TIME_US; // -1
-  /**
-   * Represents a time or duration that should match the duration of the longest track whose
-   * duration is known. Equal to {@link C#MATCH_LONGEST_US}.
-   */
-  public static final long MATCH_LONGEST_US = C.MATCH_LONGEST_US; // -2
-  /**
-   * Represents the time of the end of the track.
-   */
-  public static final long END_OF_TRACK_US = -3;
-
   private int state;
 
   /**
@@ -110,42 +106,60 @@ protected final int getState() {
    * @throws ExoPlaybackException If an error occurs.
    */
   /* package */ final int prepare(long positionUs) throws ExoPlaybackException {
-    Assertions.checkState(state == TrackRenderer.STATE_UNPREPARED);
-    state = doPrepare(positionUs);
-    Assertions.checkState(state == TrackRenderer.STATE_UNPREPARED ||
-        state == TrackRenderer.STATE_PREPARED ||
-        state == TrackRenderer.STATE_IGNORE);
+    Assertions.checkState(state == STATE_UNPREPARED);
+    state = doPrepare(positionUs) ? STATE_PREPARED : STATE_UNPREPARED;
     return state;
   }
 
   /**
    * Invoked to make progress when the renderer is in the {@link #STATE_UNPREPARED} state. This
-   * method will be called repeatedly until a value other than {@link #STATE_UNPREPARED} is
-   * returned.
+   * method will be called repeatedly until {@code true} is returned.
    * <p>
    * This method should return quickly, and should not block if the renderer is currently unable to
    * make any useful progress.
    *
    * @param positionUs The player's current playback position.
-   * @return The new state of the renderer. One of {@link #STATE_UNPREPARED},
-   *     {@link #STATE_PREPARED} and {@link #STATE_IGNORE}.
+   * @return True if the renderer is now prepared. False otherwise.
    * @throws ExoPlaybackException If an error occurs.
    */
-  protected abstract int doPrepare(long positionUs) throws ExoPlaybackException;
+  protected abstract boolean doPrepare(long positionUs) throws ExoPlaybackException;
+
+  /**
+   * Returns the number of tracks exposed by the renderer.
+   * <p>
+   * This method may be called when the renderer is in the following states:
+   * {@link #STATE_PREPARED}, {@link #STATE_ENABLED}, {@link #STATE_STARTED}
+   *
+   * @return The number of tracks.
+   */
+  protected abstract int getTrackCount();
+
+  /**
+   * Returns the format of the specified track.
+   * <p>
+   * This method may be called when the renderer is in the following states:
+   * {@link #STATE_PREPARED}, {@link #STATE_ENABLED}, {@link #STATE_STARTED}
+   *
+   * @param track The track index.
+   * @return The format of the specified track.
+   */
+  protected abstract MediaFormat getFormat(int track);
 
   /**
-   * Enable the renderer.
+   * Enable the renderer for a specified track.
    *
+   * @param track The track for which the renderer is being enabled.
    * @param positionUs The player's current position.
    * @param joining Whether this renderer is being enabled to join an ongoing playback. If true
    *     then {@link #start} must be called immediately after this method returns (unless a
    *     {@link ExoPlaybackException} is thrown).
    * @throws ExoPlaybackException If an error occurs.
    */
-  /* package */ final void enable(long positionUs, boolean joining) throws ExoPlaybackException {
-    Assertions.checkState(state == TrackRenderer.STATE_PREPARED);
-    state = TrackRenderer.STATE_ENABLED;
-    onEnabled(positionUs, joining);
+  /* package */ final void enable(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    Assertions.checkState(state == STATE_PREPARED);
+    state = STATE_ENABLED;
+    onEnabled(track, positionUs, joining);
   }
 
   /**
@@ -153,13 +167,15 @@ protected final int getState() {
    * <p>
    * The default implementation is a no-op.
    *
+   * @param track The track for which the renderer is being enabled.
    * @param positionUs The player's current position.
    * @param joining Whether this renderer is being enabled to join an ongoing playback. If true
    *     then {@link #onStarted} is guaranteed to be called immediately after this method returns
    *     (unless a {@link ExoPlaybackException} is thrown).
    * @throws ExoPlaybackException If an error occurs.
    */
-  protected void onEnabled(long positionUs, boolean joining) throws ExoPlaybackException {
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
     // Do nothing.
   }
 
@@ -170,8 +186,8 @@ protected void onEnabled(long positionUs, boolean joining) throws ExoPlaybackExc
    * @throws ExoPlaybackException If an error occurs.
    */
   /* package */ final void start() throws ExoPlaybackException {
-    Assertions.checkState(state == TrackRenderer.STATE_ENABLED);
-    state = TrackRenderer.STATE_STARTED;
+    Assertions.checkState(state == STATE_ENABLED);
+    state = STATE_STARTED;
     onStarted();
   }
 
@@ -192,8 +208,8 @@ protected void onStarted() throws ExoPlaybackException {
    * @throws ExoPlaybackException If an error occurs.
    */
   /* package */ final void stop() throws ExoPlaybackException {
-    Assertions.checkState(state == TrackRenderer.STATE_STARTED);
-    state = TrackRenderer.STATE_ENABLED;
+    Assertions.checkState(state == STATE_STARTED);
+    state = STATE_ENABLED;
     onStopped();
   }
 
@@ -214,8 +230,8 @@ protected void onStopped() throws ExoPlaybackException {
    * @throws ExoPlaybackException If an error occurs.
    */
   /* package */ final void disable() throws ExoPlaybackException {
-    Assertions.checkState(state == TrackRenderer.STATE_ENABLED);
-    state = TrackRenderer.STATE_PREPARED;
+    Assertions.checkState(state == STATE_ENABLED);
+    state = STATE_PREPARED;
     onDisabled();
   }
 
@@ -236,10 +252,10 @@ protected void onDisabled() throws ExoPlaybackException {
    * @throws ExoPlaybackException If an error occurs.
    */
   /* package */ final void release() throws ExoPlaybackException {
-    Assertions.checkState(state != TrackRenderer.STATE_ENABLED
-        && state != TrackRenderer.STATE_STARTED
-        && state != TrackRenderer.STATE_RELEASED);
-    state = TrackRenderer.STATE_RELEASED;
+    Assertions.checkState(state != STATE_ENABLED
+        && state != STATE_STARTED
+        && state != STATE_RELEASED);
+    state = STATE_RELEASED;
     onReleased();
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilities.java b/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilities.java
index 0a56d2d7ed..f470f9ebab 100644
--- a/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilities.java
+++ b/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilities.java
@@ -15,7 +15,13 @@
  */
 package com.google.android.exoplayer.audio;
 
+import android.annotation.SuppressLint;
 import android.annotation.TargetApi;
+import android.content.Context;
+import android.content.Intent;
+import android.content.IntentFilter;
+import android.media.AudioFormat;
+import android.media.AudioManager;
 
 import java.util.Arrays;
 
@@ -25,6 +31,34 @@
 @TargetApi(21)
 public final class AudioCapabilities {
 
+  /**
+   * Default to stereo PCM on SDK < 21 and when HDMI is unplugged.
+   */
+  private static final AudioCapabilities DEFAULT_AUDIO_CAPABILITIES =
+      new AudioCapabilities(new int[] {AudioFormat.ENCODING_PCM_16BIT}, 2);
+
+  /**
+   * Gets the current audio capabilities. Note that to be notified when audio capabilities change,
+   * you can create an instance of {@link AudioCapabilitiesReceiver} and register a listener.
+   *
+   * @param context Context for receiving the initial broadcast.
+   * @return Current audio capabilities for the device.
+   */
+  @SuppressWarnings("InlinedApi")
+  public static AudioCapabilities getCapabilities(Context context) {
+    return getCapabilities(
+        context.registerReceiver(null, new IntentFilter(AudioManager.ACTION_HDMI_AUDIO_PLUG)));
+  }
+
+  @SuppressLint("InlinedApi")
+  /* package */ static AudioCapabilities getCapabilities(Intent intent) {
+    if (intent == null || intent.getIntExtra(AudioManager.EXTRA_AUDIO_PLUG_STATE, 0) == 0) {
+      return DEFAULT_AUDIO_CAPABILITIES;
+    }
+    return new AudioCapabilities(intent.getIntArrayExtra(AudioManager.EXTRA_ENCODINGS),
+        intent.getIntExtra(AudioManager.EXTRA_MAX_CHANNEL_COUNT, 0));
+  }
+
   private final int[] supportedEncodings;
   private final int maxChannelCount;
 
@@ -36,7 +70,7 @@
    *     {@code ENCODING_*} constants.
    * @param maxChannelCount The maximum number of audio channels that can be played simultaneously.
    */
-  public AudioCapabilities(int[] supportedEncodings, int maxChannelCount) {
+  /* package */ AudioCapabilities(int[] supportedEncodings, int maxChannelCount) {
     if (supportedEncodings != null) {
       this.supportedEncodings = Arrays.copyOf(supportedEncodings, supportedEncodings.length);
       Arrays.sort(this.supportedEncodings);
diff --git a/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilitiesReceiver.java b/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilitiesReceiver.java
index 90273e434b..68bae41cf3 100644
--- a/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilitiesReceiver.java
+++ b/library/src/main/java/com/google/android/exoplayer/audio/AudioCapabilitiesReceiver.java
@@ -18,40 +18,42 @@
 import com.google.android.exoplayer.util.Assertions;
 import com.google.android.exoplayer.util.Util;
 
-import android.annotation.TargetApi;
 import android.content.BroadcastReceiver;
 import android.content.Context;
 import android.content.Intent;
 import android.content.IntentFilter;
-import android.media.AudioFormat;
 import android.media.AudioManager;
 
 /**
  * Notifies a listener when the audio playback capabilities change. Call {@link #register} to start
- * receiving notifications, and {@link #unregister} to stop.
+ * (or resume) receiving notifications, and {@link #unregister} to stop.
  */
 public final class AudioCapabilitiesReceiver {
 
-  /** Listener notified when audio capabilities change. */
+  /**
+   * Listener notified when audio capabilities change.
+   */
   public interface Listener {
 
-    /** Called when the audio capabilities change. */
+    /**
+     * Called when the audio capabilities change.
+     *
+     * @param audioCapabilities Current audio capabilities for the device.
+     */
     void onAudioCapabilitiesChanged(AudioCapabilities audioCapabilities);
 
   }
 
-  /** Default to stereo PCM on SDK < 21 and when HDMI is unplugged. */
-  private static final AudioCapabilities DEFAULT_AUDIO_CAPABILITIES =
-      new AudioCapabilities(new int[] {AudioFormat.ENCODING_PCM_16BIT}, 2);
-
   private final Context context;
   private final Listener listener;
   private final BroadcastReceiver receiver;
 
+  /* package */ AudioCapabilities audioCapabilities;
+
   /**
    * Constructs a new audio capabilities receiver.
    *
-   * @param context Application context for registering to receive broadcasts.
+   * @param context Context for registering to receive broadcasts.
    * @param listener Listener to notify when audio capabilities change.
    */
   public AudioCapabilitiesReceiver(Context context, Listener listener) {
@@ -61,48 +63,40 @@ public AudioCapabilitiesReceiver(Context context, Listener listener) {
   }
 
   /**
-   * Registers to notify the listener when audio capabilities change. The listener will immediately
-   * receive the current audio capabilities. It is important to call {@link #unregister} so that
-   * the listener can be garbage collected.
+   * Registers to notify the listener when audio capabilities change. The current capabilities will
+   * be returned. It is important to call {@link #unregister} so that the listener can be garbage
+   * collected.
+   *
+   * @return Current audio capabilities for the device.
    */
-  @TargetApi(21)
-  public void register() {
-    if (receiver != null) {
-      Intent initialStickyIntent =
-          context.registerReceiver(receiver, new IntentFilter(AudioManager.ACTION_HDMI_AUDIO_PLUG));
-      if (initialStickyIntent != null) {
-        receiver.onReceive(context, initialStickyIntent);
-        return;
-      }
-    }
-
-    listener.onAudioCapabilitiesChanged(DEFAULT_AUDIO_CAPABILITIES);
+  @SuppressWarnings("InlinedApi")
+  public AudioCapabilities register() {
+    Intent stickyIntent = receiver == null ? null
+        : context.registerReceiver(receiver, new IntentFilter(AudioManager.ACTION_HDMI_AUDIO_PLUG));
+    audioCapabilities = AudioCapabilities.getCapabilities(stickyIntent);
+    return audioCapabilities;
   }
 
-  /** Unregisters to stop notifying the listener when audio capabilities change. */
+  /**
+   * Unregisters to stop notifying the listener when audio capabilities change.
+   */
   public void unregister() {
     if (receiver != null) {
       context.unregisterReceiver(receiver);
     }
   }
 
-  @TargetApi(21)
   private final class HdmiAudioPlugBroadcastReceiver extends BroadcastReceiver {
 
     @Override
     public void onReceive(Context context, Intent intent) {
-      if (isInitialStickyBroadcast()) {
-        return;
+      if (!isInitialStickyBroadcast()) {
+        AudioCapabilities newAudioCapabilities = AudioCapabilities.getCapabilities(intent);
+        if (!newAudioCapabilities.equals(audioCapabilities)) {
+          audioCapabilities = newAudioCapabilities;
+          listener.onAudioCapabilitiesChanged(newAudioCapabilities);
+        }
       }
-
-      String action = intent.getAction();
-      if (!action.equals(AudioManager.ACTION_HDMI_AUDIO_PLUG)) {
-        return;
-      }
-
-      listener.onAudioCapabilitiesChanged(
-          new AudioCapabilities(intent.getIntArrayExtra(AudioManager.EXTRA_ENCODINGS),
-              intent.getIntExtra(AudioManager.EXTRA_MAX_CHANNEL_COUNT, 0)));
     }
 
   }
diff --git a/library/src/main/java/com/google/android/exoplayer/audio/AudioTrack.java b/library/src/main/java/com/google/android/exoplayer/audio/AudioTrack.java
index 7addf0bf84..461a3cfdd7 100644
--- a/library/src/main/java/com/google/android/exoplayer/audio/AudioTrack.java
+++ b/library/src/main/java/com/google/android/exoplayer/audio/AudioTrack.java
@@ -27,6 +27,7 @@
 import android.media.AudioTimestamp;
 import android.media.MediaFormat;
 import android.os.ConditionVariable;
+import android.os.SystemClock;
 import android.util.Log;
 
 import java.lang.reflect.Method;
@@ -134,8 +135,10 @@ public InvalidAudioTrackTimestampException(String message) {
    */
   private static final long MAX_LATENCY_US = 5 * C.MICROS_PER_SECOND;
 
-  /** Value for ac3Bitrate before the bitrate has been calculated. */
-  private static final int UNKNOWN_AC3_BITRATE = 0;
+  /**
+   * Value for {@link #passthroughBitrate} before the bitrate has been calculated.
+   */
+  private static final int UNKNOWN_BITRATE = 0;
 
   private static final int START_NOT_SET = 0;
   private static final int START_IN_SYNC = 1;
@@ -162,6 +165,8 @@ public InvalidAudioTrackTimestampException(String message) {
    */
   public static boolean failOnSpuriousAudioTimestamp = false;
 
+  private final AudioCapabilities audioCapabilities;
+  private final int streamType;
   private final ConditionVariable releasingConditionVariable;
   private final long[] playheadOffsets;
   private final AudioTrackUtil audioTrackUtil;
@@ -196,12 +201,27 @@ public InvalidAudioTrackTimestampException(String message) {
   private int temporaryBufferOffset;
   private int temporaryBufferSize;
 
-  private boolean isAc3;
-
-  /** Bitrate measured in kilobits per second, if {@link #isAc3} is true. */
-  private int ac3Bitrate;
+  /**
+   * Bitrate measured in kilobits per second, if {@link #isPassthrough()} returns true.
+   */
+  private int passthroughBitrate;
 
+  /**
+   * Creates an audio track with default audio capabilities (no encoded audio passthrough support).
+   */
   public AudioTrack() {
+    this(null, AudioManager.STREAM_MUSIC);
+  }
+
+  /**
+   * Creates an audio track using the specified audio capabilities and stream type.
+   *
+   * @param audioCapabilities The current audio playback capabilities.
+   * @param streamType The type of audio stream for the underlying {@link android.media.AudioTrack}.
+   */
+  public AudioTrack(AudioCapabilities audioCapabilities, int streamType) {
+    this.audioCapabilities = audioCapabilities;
+    this.streamType = streamType;
     releasingConditionVariable = new ConditionVariable(true);
     if (Util.SDK_INT >= 18) {
       try {
@@ -221,6 +241,15 @@ public AudioTrack() {
     startMediaTimeState = START_NOT_SET;
   }
 
+  /**
+   * Returns whether it is possible to play back input audio in the specified format using encoded
+   * audio passthrough.
+   */
+  public boolean isPassthroughSupported(String mimeType) {
+    return audioCapabilities != null
+        && audioCapabilities.supportsEncoding(getEncodingForMimeType(mimeType));
+  }
+
   /**
    * Returns whether the audio track has been successfully initialized via {@link #initialize} and
    * not yet {@link #reset}.
@@ -301,19 +330,19 @@ public int initialize(int sessionId) throws InitializationException {
     releasingConditionVariable.block();
 
     if (sessionId == SESSION_ID_NOT_SET) {
-      audioTrack = new android.media.AudioTrack(AudioManager.STREAM_MUSIC, sampleRate,
-          channelConfig, encoding, bufferSize, android.media.AudioTrack.MODE_STREAM);
+      audioTrack = new android.media.AudioTrack(streamType, sampleRate, channelConfig, encoding,
+          bufferSize, android.media.AudioTrack.MODE_STREAM);
     } else {
       // Re-attach to the same audio session.
-      audioTrack = new android.media.AudioTrack(AudioManager.STREAM_MUSIC, sampleRate,
-          channelConfig, encoding, bufferSize, android.media.AudioTrack.MODE_STREAM, sessionId);
+      audioTrack = new android.media.AudioTrack(streamType, sampleRate, channelConfig, encoding,
+          bufferSize, android.media.AudioTrack.MODE_STREAM, sessionId);
     }
     checkAudioTrackInitialized();
 
     sessionId = audioTrack.getAudioSessionId();
     if (enablePreV21AudioSessionWorkaround) {
       if (Util.SDK_INT < 21) {
-        // The workaround creates an audio track with a one byte buffer on the same session, and
+        // The workaround creates an audio track with a two byte buffer on the same session, and
         // does not release it until this object is released, which keeps the session active.
         if (keepSessionIdAudioTrack != null
             && sessionId != keepSessionIdAudioTrack.getAudioSessionId()) {
@@ -324,15 +353,14 @@ public int initialize(int sessionId) throws InitializationException {
           int channelConfig = AudioFormat.CHANNEL_OUT_MONO;
           int encoding = AudioFormat.ENCODING_PCM_16BIT;
           int bufferSize = 2; // Use a two byte buffer, as it is not actually used for playback.
-          keepSessionIdAudioTrack = new android.media.AudioTrack(AudioManager.STREAM_MUSIC,
-              sampleRate, channelConfig, encoding, bufferSize, android.media.AudioTrack.MODE_STATIC,
-              sessionId);
+          keepSessionIdAudioTrack = new android.media.AudioTrack(streamType, sampleRate,
+              channelConfig, encoding, bufferSize, android.media.AudioTrack.MODE_STATIC, sessionId);
         }
       }
     }
 
-    audioTrackUtil.reconfigure(audioTrack, isAc3);
-    setVolume(volume);
+    audioTrackUtil.reconfigure(audioTrack, isPassthrough());
+    setAudioTrackVolume();
 
     return sessionId;
   }
@@ -340,19 +368,23 @@ public int initialize(int sessionId) throws InitializationException {
   /**
    * Reconfigures the audio track to play back media in {@code format}, inferring a buffer size from
    * the format.
+   *
+   * @param format Specifies the channel count and sample rate to play back.
+   * @param passthrough Whether to play back using a passthrough encoding.
    */
-  public void reconfigure(MediaFormat format) {
-    reconfigure(format, 0);
+  public void reconfigure(MediaFormat format, boolean passthrough) {
+    reconfigure(format, passthrough, 0);
   }
 
   /**
    * Reconfigures the audio track to play back media in {@code format}.
    *
    * @param format Specifies the channel count and sample rate to play back.
+   * @param passthrough Whether to playback using a passthrough encoding.
    * @param specifiedBufferSize A specific size for the playback buffer in bytes, or 0 to use a
    *     size inferred from the format.
    */
-  public void reconfigure(MediaFormat format, int specifiedBufferSize) {
+  public void reconfigure(MediaFormat format, boolean passthrough, int specifiedBufferSize) {
     int channelCount = format.getInteger(MediaFormat.KEY_CHANNEL_COUNT);
     int channelConfig;
     switch (channelCount) {
@@ -371,16 +403,12 @@ public void reconfigure(MediaFormat format, int specifiedBufferSize) {
       default:
         throw new IllegalArgumentException("Unsupported channel count: " + channelCount);
     }
-
     int sampleRate = format.getInteger(MediaFormat.KEY_SAMPLE_RATE);
     String mimeType = format.getString(MediaFormat.KEY_MIME);
-
-    // TODO: Does channelConfig determine channelCount?
-    int encoding = MimeTypes.getEncodingForMimeType(mimeType);
-    boolean isAc3 = encoding == C.ENCODING_AC3 || encoding == C.ENCODING_E_AC3;
+    int encoding = passthrough ? getEncodingForMimeType(mimeType) : AudioFormat.ENCODING_PCM_16BIT;
     if (isInitialized() && this.sampleRate == sampleRate && this.channelConfig == channelConfig
-        && !this.isAc3 && !isAc3) {
-      // We already have an existing audio track with the correct sample rate and channel config.
+        && this.encoding == encoding) {
+      // We already have an audio track with the correct sample rate, encoding and channel config.
       return;
     }
 
@@ -389,8 +417,7 @@ public void reconfigure(MediaFormat format, int specifiedBufferSize) {
     this.encoding = encoding;
     this.sampleRate = sampleRate;
     this.channelConfig = channelConfig;
-    this.isAc3 = isAc3;
-    ac3Bitrate = UNKNOWN_AC3_BITRATE; // Calculated on receiving the first buffer if isAc3 is true.
+    passthroughBitrate = UNKNOWN_BITRATE;
     frameSize = 2 * channelCount; // 2 bytes per 16 bit sample * number of channels.
     minBufferSize = android.media.AudioTrack.getMinBufferSize(sampleRate, channelConfig, encoding);
     Assertions.checkState(minBufferSize != android.media.AudioTrack.ERROR_BAD_VALUE);
@@ -446,7 +473,7 @@ public int handleBuffer(ByteBuffer buffer, int offset, int size, long presentati
     }
 
     // Workarounds for issues with AC-3 passthrough AudioTracks on API versions 21/22:
-    if (Util.SDK_INT <= 22 && isAc3) {
+    if (Util.SDK_INT <= 22 && isPassthrough()) {
       // An AC-3 audio track continues to play data written while it is paused. Stop writing so its
       // buffer empties. See [Internal: b/18899620].
       if (audioTrack.getPlayState() == android.media.AudioTrack.PLAYSTATE_PAUSED) {
@@ -464,8 +491,8 @@ public int handleBuffer(ByteBuffer buffer, int offset, int size, long presentati
 
     int result = 0;
     if (temporaryBufferSize == 0) {
-      if (isAc3 && ac3Bitrate == UNKNOWN_AC3_BITRATE) {
-        ac3Bitrate = Ac3Util.getBitrate(size, sampleRate);
+      if (isPassthrough() && passthroughBitrate == UNKNOWN_BITRATE) {
+        passthroughBitrate = Ac3Util.getBitrate(size, sampleRate);
       }
 
       // This is the first time we've seen this {@code buffer}.
@@ -536,6 +563,16 @@ public int handleBuffer(ByteBuffer buffer, int offset, int size, long presentati
     return result;
   }
 
+  /**
+   * Ensures that the last data passed to {@link #handleBuffer(ByteBuffer, int, int, long)} is
+   * played out in full.
+   */
+  public void handleEndOfStream() {
+    if (isInitialized()) {
+      audioTrackUtil.handleEndOfStream(bytesToFrames(submittedBytes));
+    }
+  }
+
   @TargetApi(21)
   private static int writeNonBlockingV21(
       android.media.AudioTrack audioTrack, ByteBuffer buffer, int size) {
@@ -549,32 +586,31 @@ public boolean hasPendingData() {
             || audioTrackUtil.overrideHasPendingData());
   }
 
-  /** Returns whether enough data has been supplied via {@link #handleBuffer} to begin playback. */
-  public boolean hasEnoughDataToBeginPlayback() {
-    // The value of minBufferSize can be slightly less than what's actually required for playback
-    // to start, hence the multiplication factor.
-    return submittedBytes > (minBufferSize * 3) / 2;
-  }
-
   /** Sets the playback volume. */
   public void setVolume(float volume) {
-    this.volume = volume;
-    if (isInitialized()) {
-      if (Util.SDK_INT >= 21) {
-        setVolumeV21(audioTrack, volume);
-      } else {
-        setVolumeV3(audioTrack, volume);
-      }
+    if (this.volume != volume) {
+      this.volume = volume;
+      setAudioTrackVolume();
+    }
+  }
+
+  private void setAudioTrackVolume() {
+    if (!isInitialized()) {
+      // Do nothing.
+    } else if (Util.SDK_INT >= 21) {
+      setAudioTrackVolumeV21(audioTrack, volume);
+    } else {
+      setAudioTrackVolumeV3(audioTrack, volume);
     }
   }
 
   @TargetApi(21)
-  private static void setVolumeV21(android.media.AudioTrack audioTrack, float volume) {
+  private static void setAudioTrackVolumeV21(android.media.AudioTrack audioTrack, float volume) {
     audioTrack.setVolume(volume);
   }
 
   @SuppressWarnings("deprecation")
-  private static void setVolumeV3(android.media.AudioTrack audioTrack, float volume) {
+  private static void setAudioTrackVolumeV3(android.media.AudioTrack audioTrack, float volume) {
     audioTrack.setStereoVolume(volume, volume);
   }
 
@@ -582,7 +618,7 @@ private static void setVolumeV3(android.media.AudioTrack audioTrack, float volum
   public void pause() {
     if (isInitialized()) {
       resetSyncParams();
-      audioTrack.pause();
+      audioTrackUtil.pause();
     }
   }
 
@@ -611,6 +647,7 @@ public void reset() {
         @Override
         public void run() {
           try {
+            toRelease.flush();
             toRelease.release();
           } finally {
             releasingConditionVariable.open();
@@ -672,9 +709,10 @@ private void maybeSampleSyncParams() {
       }
     }
 
-    // Don't sample the timestamp and latency if this is an AC-3 passthrough AudioTrack, as the
-    // returned values cause audio/video synchronization to be incorrect.
-    if (!isAc3 && systemClockUs - lastTimestampSampleTimeUs >= MIN_TIMESTAMP_SAMPLE_INTERVAL_US) {
+    // Don't sample the timestamp and latency if this is a passthrough AudioTrack, as the returned
+    // values cause audio/video synchronization to be incorrect.
+    if (!isPassthrough()
+        && systemClockUs - lastTimestampSampleTimeUs >= MIN_TIMESTAMP_SAMPLE_INTERVAL_US) {
       audioTimestampSet = audioTrackUtil.updateTimestamp();
       if (audioTimestampSet) {
         // Perform sanity checks on the timestamp.
@@ -754,9 +792,9 @@ private void checkAudioTrackInitialized() throws InitializationException {
   }
 
   private long bytesToFrames(long byteCount) {
-    if (isAc3) {
-      return
-          ac3Bitrate == UNKNOWN_AC3_BITRATE ? 0L : byteCount * 8 * sampleRate / (1000 * ac3Bitrate);
+    if (isPassthrough()) {
+      return passthroughBitrate == UNKNOWN_BITRATE
+          ? 0L : byteCount * 8 * sampleRate / (1000 * passthroughBitrate);
     } else {
       return byteCount / frameSize;
     }
@@ -779,6 +817,20 @@ private void resetSyncParams() {
     lastTimestampSampleTimeUs = 0;
   }
 
+  private boolean isPassthrough() {
+    return encoding == C.ENCODING_AC3 || encoding == C.ENCODING_E_AC3;
+  }
+
+  private static int getEncodingForMimeType(String mimeType) {
+    if (MimeTypes.AUDIO_AC3.equals(mimeType)) {
+      return C.ENCODING_AC3;
+    }
+    if (MimeTypes.AUDIO_EC3.equals(mimeType)) {
+      return C.ENCODING_E_AC3;
+    }
+    return AudioFormat.ENCODING_INVALID;
+  }
+
   /**
    * Wraps an {@link android.media.AudioTrack} to expose useful utility methods.
    */
@@ -791,6 +843,10 @@ private void resetSyncParams() {
     private long rawPlaybackHeadWrapCount;
     private long passthroughWorkaroundPauseOffset;
 
+    private long stopTimestampUs;
+    private long stopPlaybackHeadPosition;
+    private long endPlaybackHeadPosition;
+
     /**
      * Reconfigures the audio track utility helper to use the specified {@code audioTrack}.
      *
@@ -800,6 +856,7 @@ private void resetSyncParams() {
     public void reconfigure(android.media.AudioTrack audioTrack, boolean isPassthrough) {
       this.audioTrack = audioTrack;
       this.isPassthrough = isPassthrough;
+      stopTimestampUs = -1;
       lastRawPlaybackHeadPosition = 0;
       rawPlaybackHeadWrapCount = 0;
       passthroughWorkaroundPauseOffset = 0;
@@ -822,6 +879,32 @@ public boolean overrideHasPendingData() {
           && audioTrack.getPlaybackHeadPosition() == 0;
     }
 
+    /**
+     * Stops the audio track in a way that ensures media written to it is played out in full, and
+     * that {@link #getPlaybackHeadPosition()} and {@link #getPlaybackHeadPositionUs()} continue to
+     * increment as the remaining media is played out.
+     *
+     * @param submittedFrames The total number of frames that have been submitted.
+     */
+    public void handleEndOfStream(long submittedFrames) {
+      stopPlaybackHeadPosition = getPlaybackHeadPosition();
+      stopTimestampUs = SystemClock.elapsedRealtime() * 1000;
+      endPlaybackHeadPosition = submittedFrames;
+      audioTrack.stop();
+    }
+
+    /**
+     * Pauses the audio track unless the end of the stream has been handled, in which case calling
+     * this method does nothing.
+     */
+    public void pause() {
+      if (stopTimestampUs != -1) {
+        // We don't want to knock the audio track back into the paused state.
+        return;
+      }
+      audioTrack.pause();
+    }
+
     /**
      * {@link android.media.AudioTrack#getPlaybackHeadPosition()} returns a value intended to be
      * interpreted as an unsigned 32 bit integer, which also wraps around periodically. This method
@@ -832,18 +915,25 @@ public boolean overrideHasPendingData() {
      *     expressed as a long.
      */
     public long getPlaybackHeadPosition() {
+      if (stopTimestampUs != -1) {
+        // Simulate the playback head position up to the total number of frames submitted.
+        long elapsedTimeSinceStopUs = (SystemClock.elapsedRealtime() * 1000) - stopTimestampUs;
+        long framesSinceStop = (elapsedTimeSinceStopUs * sampleRate) / C.MICROS_PER_SECOND;
+        return Math.min(endPlaybackHeadPosition, stopPlaybackHeadPosition + framesSinceStop);
+      }
+
+      int state = audioTrack.getPlayState();
+      if (state == android.media.AudioTrack.PLAYSTATE_STOPPED) {
+        // The audio track hasn't been started.
+        return 0;
+      }
+
       long rawPlaybackHeadPosition = 0xFFFFFFFFL & audioTrack.getPlaybackHeadPosition();
       if (Util.SDK_INT <= 22 && isPassthrough) {
-        // Work around issues with passthrough/direct AudioTracks on platform API versions 21/22:
-        // - After resetting, the new AudioTrack's playback position continues to increase for a
-        //   short time from the old AudioTrack's position, while in the PLAYSTATE_STOPPED state.
-        // - The playback head position jumps back to zero on paused passthrough/direct audio
-        //   tracks. See [Internal: b/19187573].
-        if (audioTrack.getPlayState() == android.media.AudioTrack.PLAYSTATE_STOPPED) {
-          // Prevent detecting a wrapped position.
-          lastRawPlaybackHeadPosition = rawPlaybackHeadPosition;
-        } else if (audioTrack.getPlayState() == android.media.AudioTrack.PLAYSTATE_PAUSED
-            && rawPlaybackHeadPosition == 0) {
+        // Work around an issue with passthrough/direct AudioTracks on platform API versions 21/22
+        // where the playback head position jumps back to zero on paused passthrough/direct audio
+        // tracks. See [Internal: b/19187573].
+        if (state == android.media.AudioTrack.PLAYSTATE_PAUSED && rawPlaybackHeadPosition == 0) {
           passthroughWorkaroundPauseOffset = lastRawPlaybackHeadPosition;
         }
         rawPlaybackHeadPosition += passthroughWorkaroundPauseOffset;
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/BaseChunkSampleSourceEventListener.java b/library/src/main/java/com/google/android/exoplayer/chunk/BaseChunkSampleSourceEventListener.java
index 9b27d4c560..9bf75da420 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/BaseChunkSampleSourceEventListener.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/BaseChunkSampleSourceEventListener.java
@@ -42,7 +42,7 @@
    *     load is for initialization data.
    */
   void onLoadStarted(int sourceId, long length, int type, int trigger, Format format,
-      int mediaStartTimeMs, int mediaEndTimeMs);
+      long mediaStartTimeMs, long mediaEndTimeMs);
 
   /**
    * Invoked when the current load operation completes.
@@ -61,7 +61,7 @@ void onLoadStarted(int sourceId, long length, int type, int trigger, Format form
    * @param loadDurationMs Amount of time taken to load the data.
    */
    void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Format format,
-       int mediaStartTimeMs, int mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs);
+       long mediaStartTimeMs, long mediaEndTimeMs, long elapsedRealtimeMs, long loadDurationMs);
 
   /**
    * Invoked when the current upstream load operation is canceled.
@@ -87,7 +87,7 @@ void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Form
    * @param mediaStartTimeMs The media time of the start of the discarded data.
    * @param mediaEndTimeMs The media time of the end of the discarded data.
    */
-  void onUpstreamDiscarded(int sourceId, int mediaStartTimeMs, int mediaEndTimeMs);
+  void onUpstreamDiscarded(int sourceId, long mediaStartTimeMs, long mediaEndTimeMs);
 
   /**
    * Invoked when the downstream format changes (i.e. when the format being supplied to the
@@ -99,6 +99,6 @@ void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger, Form
    *     {@link ChunkSource}.
    * @param mediaTimeMs The media time at which the change occurred.
    */
-  void onDownstreamFormatChanged(int sourceId, Format format, int trigger, int mediaTimeMs);
+  void onDownstreamFormatChanged(int sourceId, Format format, int trigger, long mediaTimeMs);
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/BaseMediaChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/BaseMediaChunk.java
index 04f8a084cd..b86a2f8fe2 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/BaseMediaChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/BaseMediaChunk.java
@@ -46,16 +46,15 @@
    * @param startTimeUs The start time of the media contained by the chunk, in microseconds.
    * @param endTimeUs The end time of the media contained by the chunk, in microseconds.
    * @param chunkIndex The index of the chunk.
-   * @param isLastChunk True if this is the last chunk in the media. False otherwise.
    * @param isMediaFormatFinal True if {@link #getMediaFormat()} and {@link #getDrmInitData()} can
    *     be called at any time to obtain the media format and drm initialization data. False if
    *     these methods are only guaranteed to return correct data after the first sample data has
    *     been output from the chunk.
+   * @param parentId Identifier for a parent from which this chunk originates.
    */
   public BaseMediaChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
-      long startTimeUs, long endTimeUs, int chunkIndex, boolean isLastChunk,
-      boolean isMediaFormatFinal) {
-    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex, isLastChunk);
+      long startTimeUs, long endTimeUs, int chunkIndex, boolean isMediaFormatFinal, int parentId) {
+    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex, parentId);
     this.isMediaFormatFinal = isMediaFormatFinal;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/Chunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/Chunk.java
index e42c2331fd..db6996c4d8 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/Chunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/Chunk.java
@@ -75,6 +75,10 @@
    * Implementations may define custom {@link #trigger} codes greater than or equal to this value.
    */
   public static final int TRIGGER_CUSTOM_BASE = 10000;
+  /**
+   * Value of {@link #parentId} if no parent id need be specified.
+   */
+  public static final int NO_PARENT_ID = -1;
 
   /**
    * The type of the chunk. For reporting only.
@@ -93,6 +97,10 @@
    * The {@link DataSpec} that defines the data to be loaded.
    */
   public final DataSpec dataSpec;
+  /**
+   * Optional identifier for a parent from which this chunk originates.
+   */
+  public final int parentId;
 
   protected final DataSource dataSource;
 
@@ -105,13 +113,16 @@
    * @param type See {@link #type}.
    * @param trigger See {@link #trigger}.
    * @param format See {@link #format}.
+   * @param parentId See {@link #parentId}.
    */
-  public Chunk(DataSource dataSource, DataSpec dataSpec, int type, int trigger, Format format) {
+  public Chunk(DataSource dataSource, DataSpec dataSpec, int type, int trigger, Format format,
+      int parentId) {
     this.dataSource = Assertions.checkNotNull(dataSource);
     this.dataSpec = Assertions.checkNotNull(dataSpec);
     this.type = type;
     this.trigger = trigger;
     this.format = format;
+    this.parentId = parentId;
   }
 
   /**
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkOperationHolder.java b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkOperationHolder.java
index c59bce9733..1e2087178b 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkOperationHolder.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkOperationHolder.java
@@ -16,8 +16,13 @@
 package com.google.android.exoplayer.chunk;
 
 /**
- * Holds a chunk operation, which consists of a {@link Chunk} to load together with the number of
- * {@link MediaChunk}s that should be retained on the queue.
+ * Holds a chunk operation, which consists of a either:
+ * <ul>
+ * <li>The number of {@link MediaChunk}s that should be retained on the queue ({@link #queueSize})
+ * together with the next {@link Chunk} to load ({@link #chunk}). {@link #chunk} may be null if the
+ * next chunk cannot be provided yet.</li>
+ * <li>A flag indicating that the end of the stream has been reached ({@link #endOfStream}).</li>
+ * </ul>
  */
 public final class ChunkOperationHolder {
 
@@ -31,4 +36,18 @@
    */
   public Chunk chunk;
 
+  /**
+   * Indicates that the end of the stream has been reached.
+   */
+  public boolean endOfStream;
+
+  /**
+   * Clears the holder.
+   */
+  public void clear() {
+    queueSize = 0;
+    chunk = null;
+    endOfStream = false;
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSampleSource.java b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSampleSource.java
index 1e8cdaf9a6..71c5773db1 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSampleSource.java
@@ -22,7 +22,6 @@
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
 import com.google.android.exoplayer.SampleSource.SampleSourceReader;
-import com.google.android.exoplayer.TrackInfo;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.extractor.DefaultTrackOutput;
 import com.google.android.exoplayer.upstream.Loader;
@@ -58,7 +57,7 @@
   private static final int STATE_PREPARED = 2;
   private static final int STATE_ENABLED = 3;
 
-  private static final int NO_RESET_PENDING = -1;
+  private static final long NO_RESET_PENDING = Long.MIN_VALUE;
 
   private final int eventSourceId;
   private final LoadControl loadControl;
@@ -82,6 +81,7 @@
   private Loader loader;
   private boolean loadingFinished;
   private IOException currentLoadableException;
+  private int enabledTrackCount;
   private int currentLoadableExceptionCount;
   private long currentLoadableExceptionTimestamp;
   private long currentLoadStartTimeMs;
@@ -131,8 +131,12 @@ public boolean prepare(long positionUs) {
     Assertions.checkState(state == STATE_INITIALIZED || state == STATE_PREPARED);
     if (state == STATE_PREPARED) {
       return true;
+    } else if (!chunkSource.prepare()) {
+      return false;
+    }
+    if (chunkSource.getTrackCount() > 0) {
+      loader = new Loader("Loader:" + chunkSource.getFormat(0).mimeType);
     }
-    loader = new Loader("Loader:" + chunkSource.getTrackInfo().mimeType);
     state = STATE_PREPARED;
     return true;
   }
@@ -140,22 +144,21 @@ public boolean prepare(long positionUs) {
   @Override
   public int getTrackCount() {
     Assertions.checkState(state == STATE_PREPARED || state == STATE_ENABLED);
-    return 1;
+    return chunkSource.getTrackCount();
   }
 
   @Override
-  public TrackInfo getTrackInfo(int track) {
+  public MediaFormat getFormat(int track) {
     Assertions.checkState(state == STATE_PREPARED || state == STATE_ENABLED);
-    Assertions.checkState(track == 0);
-    return chunkSource.getTrackInfo();
+    return chunkSource.getFormat(track);
   }
 
   @Override
   public void enable(int track, long positionUs) {
     Assertions.checkState(state == STATE_PREPARED);
-    Assertions.checkState(track == 0);
+    Assertions.checkState(enabledTrackCount++ == 0);
     state = STATE_ENABLED;
-    chunkSource.enable();
+    chunkSource.enable(track);
     loadControl.register(this, bufferSizeContribution);
     downstreamFormat = null;
     downstreamMediaFormat = null;
@@ -168,7 +171,7 @@ public void enable(int track, long positionUs) {
   @Override
   public void disable(int track) {
     Assertions.checkState(state == STATE_ENABLED);
-    Assertions.checkState(track == 0);
+    Assertions.checkState(--enabledTrackCount == 0);
     state = STATE_PREPARED;
     try {
       chunkSource.disable(mediaChunks);
@@ -188,7 +191,6 @@ public void disable(int track) {
   @Override
   public boolean continueBuffering(int track, long positionUs) {
     Assertions.checkState(state == STATE_ENABLED);
-    Assertions.checkState(track == 0);
     downstreamPositionUs = positionUs;
     chunkSource.continueBuffering(positionUs);
     updateLoadControl();
@@ -199,7 +201,6 @@ public boolean continueBuffering(int track, long positionUs) {
   public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
       SampleHolder sampleHolder, boolean onlyReadDiscontinuity) {
     Assertions.checkState(state == STATE_ENABLED);
-    Assertions.checkState(track == 0);
     downstreamPositionUs = positionUs;
 
     if (pendingDiscontinuity) {
@@ -218,7 +219,7 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
     boolean haveSamples = !sampleQueue.isEmpty();
     BaseMediaChunk currentChunk = mediaChunks.getFirst();
     while (haveSamples && mediaChunks.size() > 1
-        && mediaChunks.get(1).getFirstSampleIndex() == sampleQueue.getReadIndex()) {
+        && mediaChunks.get(1).getFirstSampleIndex() <= sampleQueue.getReadIndex()) {
       mediaChunks.removeFirst();
       currentChunk = mediaChunks.getFirst();
     }
@@ -231,8 +232,7 @@ public int readData(int track, long positionUs, MediaFormatHolder formatHolder,
 
     if (haveSamples || currentChunk.isMediaFormatFinal) {
       MediaFormat mediaFormat = currentChunk.getMediaFormat();
-      if (!mediaFormat.equals(downstreamMediaFormat, true)) {
-        chunkSource.getMaxVideoDimensions(mediaFormat);
+      if (!mediaFormat.equals(downstreamMediaFormat)) {
         formatHolder.format = mediaFormat;
         formatHolder.drmInitData = currentChunk.getDrmInitData();
         downstreamMediaFormat = mediaFormat;
@@ -325,10 +325,9 @@ public void onLoadCompleted(Loadable loadable) {
     Chunk currentLoadable = currentLoadableHolder.chunk;
     chunkSource.onChunkLoadCompleted(currentLoadable);
     if (isMediaChunk(currentLoadable)) {
-      MediaChunk mediaChunk = (MediaChunk) currentLoadable;
+      BaseMediaChunk mediaChunk = (BaseMediaChunk) currentLoadable;
       notifyLoadCompleted(currentLoadable.bytesLoaded(), mediaChunk.type, mediaChunk.trigger,
           mediaChunk.format, mediaChunk.startTimeUs, mediaChunk.endTimeUs, now, loadDurationMs);
-      loadingFinished = ((BaseMediaChunk) currentLoadable).isLastChunk;
     } else {
       notifyLoadCompleted(currentLoadable.bytesLoaded(), currentLoadable.type,
           currentLoadable.trigger, currentLoadable.format, -1, -1, now, loadDurationMs);
@@ -408,9 +407,7 @@ private void updateLoadControl() {
         || (now - lastPerformedBufferOperation > 2000))) {
       // Perform the evaluation.
       lastPerformedBufferOperation = now;
-      currentLoadableHolder.queueSize = readOnlyMediaChunks.size();
-      chunkSource.getChunkOperation(readOnlyMediaChunks, pendingResetPositionUs,
-          downstreamPositionUs, currentLoadableHolder);
+      doChunkOperation();
       boolean chunksDiscarded = discardUpstreamMediaChunks(currentLoadableHolder.queueSize);
       // Update the next load position as appropriate.
       if (currentLoadableHolder.chunk == null) {
@@ -447,8 +444,7 @@ private long getNextLoadPositionUs() {
     if (isPendingReset()) {
       return pendingResetPositionUs;
     } else {
-      BaseMediaChunk lastMediaChunk = mediaChunks.getLast();
-      return lastMediaChunk.isLastChunk ? -1 : lastMediaChunk.endTimeUs;
+      return loadingFinished ? -1 : mediaChunks.getLast().endTimeUs;
     }
   }
 
@@ -464,9 +460,7 @@ private void resumeFromBackOff() {
 
     Chunk backedOffChunk = currentLoadableHolder.chunk;
     if (!isMediaChunk(backedOffChunk)) {
-      currentLoadableHolder.queueSize = readOnlyMediaChunks.size();
-      chunkSource.getChunkOperation(readOnlyMediaChunks, pendingResetPositionUs,
-          downstreamPositionUs, currentLoadableHolder);
+      doChunkOperation();
       discardUpstreamMediaChunks(currentLoadableHolder.queueSize);
       if (currentLoadableHolder.chunk == backedOffChunk) {
         // Chunk was unchanged. Resume loading.
@@ -491,9 +485,7 @@ private void resumeFromBackOff() {
     // and add it back again afterwards.
     BaseMediaChunk removedChunk = mediaChunks.removeLast();
     Assertions.checkState(backedOffChunk == removedChunk);
-    currentLoadableHolder.queueSize = readOnlyMediaChunks.size();
-    chunkSource.getChunkOperation(readOnlyMediaChunks, pendingResetPositionUs, downstreamPositionUs,
-        currentLoadableHolder);
+    doChunkOperation();
     mediaChunks.add(removedChunk);
 
     if (currentLoadableHolder.chunk == backedOffChunk) {
@@ -533,6 +525,19 @@ private void maybeStartLoading() {
     loader.startLoading(currentLoadable, this);
   }
 
+  /**
+   * Sets up the {@link #currentLoadableHolder}, passes it to the chunk source to cause it to be
+   * updated with the next operation, and updates {@link #loadingFinished} if the end of the stream
+   * is reached.
+   */
+  private void doChunkOperation() {
+    currentLoadableHolder.endOfStream = false;
+    currentLoadableHolder.queueSize = readOnlyMediaChunks.size();
+    chunkSource.getChunkOperation(readOnlyMediaChunks, pendingResetPositionUs, downstreamPositionUs,
+        currentLoadableHolder);
+    loadingFinished = currentLoadableHolder.endOfStream;
+  }
+
   /**
    * Discard upstream media chunks until the queue length is equal to the length specified.
    *
@@ -569,8 +574,8 @@ private long getRetryDelayMillis(long errorCount) {
     return Math.min((errorCount - 1) * 1000, 5000);
   }
 
-  protected final int usToMs(long timeUs) {
-    return (int) (timeUs / 1000);
+  protected final long usToMs(long timeUs) {
+    return timeUs / 1000;
   }
 
   private void notifyLoadStarted(final long length, final int type, final int trigger,
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSource.java b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSource.java
index 1723f201d1..b90fc5bf15 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/ChunkSource.java
@@ -16,7 +16,6 @@
 package com.google.android.exoplayer.chunk;
 
 import com.google.android.exoplayer.MediaFormat;
-import com.google.android.exoplayer.TrackInfo;
 
 import java.io.IOException;
 import java.util.List;
@@ -32,38 +31,55 @@
 public interface ChunkSource {
 
   /**
-   * Gets information about the track for which this instance provides {@link Chunk}s.
+   * If the source is currently having difficulty preparing or providing chunks, then this method
+   * throws the underlying error. Otherwise does nothing.
+   *
+   * @throws IOException The underlying error.
+   */
+  void maybeThrowError() throws IOException;
+
+  /**
+   * Prepares the source.
    * <p>
-   * May be called when the source is disabled or enabled.
+   * The method can be called repeatedly until the return value indicates success.
    *
-   * @return Information about the track.
+   * @return True if the source was prepared, false otherwise.
    */
-  TrackInfo getTrackInfo();
+  boolean prepare();
 
   /**
-   * Adaptive video {@link ChunkSource} implementations must set the maximum video dimensions on
-   * the supplied {@link MediaFormat}. Other implementations do nothing.
+   * Returns the number of tracks exposed by the source.
    * <p>
-   * Only called when the source is enabled.
+   * This method should only be called after the source has been prepared.
    *
-   * @param out The {@link MediaFormat} on which the maximum video dimensions should be set.
+   * @return The number of tracks.
    */
-  void getMaxVideoDimensions(MediaFormat out);
+  int getTrackCount();
 
   /**
-   * Called when the source is enabled.
+   * Gets the format of the specified track.
+   * <p>
+   * This method should only be called after the source has been prepared.
+   *
+   * @param track The track index.
+   * @return The format of the track.
    */
-  void enable();
+  MediaFormat getFormat(int track);
 
   /**
-   * Called when the source is disabled.
+   * Enable the source for the specified track.
+   * <p>
+   * This method should only be called after the source has been prepared, and when the source is
+   * disabled.
    *
-   * @param queue A representation of the currently buffered {@link MediaChunk}s.
+   * @param track The track index.
    */
-  void disable(List<? extends MediaChunk> queue);
+  void enable(int track);
 
   /**
    * Indicates to the source that it should still be checking for updates to the stream.
+   * <p>
+   * This method should only be called when the source is enabled.
    *
    * @param playbackPositionUs The current playback position.
    */
@@ -73,37 +89,28 @@
    * Updates the provided {@link ChunkOperationHolder} to contain the next operation that should
    * be performed by the calling {@link ChunkSampleSource}.
    * <p>
-   * The next operation comprises of a possibly shortened queue length (shortened if the
-   * implementation wishes for the caller to discard {@link MediaChunk}s from the queue), together
-   * with the next {@link Chunk} to load. The next chunk may be a {@link MediaChunk} to be added to
-   * the queue, or another {@link Chunk} type (e.g. to load initialization data), or null if the
-   * source is not able to provide a chunk in its current state.
+   * This method should only be called when the source is enabled.
    *
    * @param queue A representation of the currently buffered {@link MediaChunk}s.
    * @param seekPositionUs If the queue is empty, this parameter must specify the seek position. If
    *     the queue is non-empty then this parameter is ignored.
    * @param playbackPositionUs The current playback position.
-   * @param out A holder for the next operation, whose {@link ChunkOperationHolder#queueSize} is
-   *     initially equal to the length of the queue, and whose {@link ChunkOperationHolder#chunk} is
-   *     initially equal to null or a {@link Chunk} previously supplied by the {@link ChunkSource}
-   *     that the caller has not yet finished loading. In the latter case the chunk can either be
-   *     replaced or left unchanged. Note that leaving the chunk unchanged is both preferred and
-   *     more efficient than replacing it with a new but identical chunk.
+   * @param out A holder for the next operation, whose {@link ChunkOperationHolder#endOfStream} is
+   *     initially set to false, whose {@link ChunkOperationHolder#queueSize} is initially equal to
+   *     the length of the queue, and whose {@link ChunkOperationHolder#chunk} is initially equal to
+   *     null or a {@link Chunk} previously supplied by the {@link ChunkSource} that the caller has
+   *     not yet finished loading. In the latter case the chunk can either be replaced or left
+   *     unchanged. Note that leaving the chunk unchanged is both preferred and more efficient than
+   *     replacing it with a new but identical chunk.
    */
   void getChunkOperation(List<? extends MediaChunk> queue, long seekPositionUs,
       long playbackPositionUs, ChunkOperationHolder out);
 
-  /**
-   * If the source is currently having difficulty providing chunks, then this method throws the
-   * underlying error. Otherwise does nothing.
-   *
-   * @throws IOException The underlying error.
-   */
-  void maybeThrowError() throws IOException;
-
   /**
    * Invoked when the {@link ChunkSampleSource} has finished loading a chunk obtained from this
    * source.
+   * <p>
+   * This method should only be called when the source is enabled.
    *
    * @param chunk The chunk whose load has been completed.
    */
@@ -112,10 +119,21 @@ void getChunkOperation(List<? extends MediaChunk> queue, long seekPositionUs,
   /**
    * Invoked when the {@link ChunkSampleSource} encounters an error loading a chunk obtained from
    * this source.
+   * <p>
+   * This method should only be called when the source is enabled.
    *
    * @param chunk The chunk whose load encountered the error.
    * @param e The error.
    */
   void onChunkLoadError(Chunk chunk, Exception e);
 
+  /**
+   * Disables the source.
+   * <p>
+   * This method should only be called when the source is enabled.
+   *
+   * @param queue A representation of the currently buffered {@link MediaChunk}s.
+   */
+  void disable(List<? extends MediaChunk> queue);
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/ContainerMediaChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/ContainerMediaChunk.java
index d147ce2e64..162bcba1cb 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/ContainerMediaChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/ContainerMediaChunk.java
@@ -36,6 +36,8 @@
 
   private final ChunkExtractorWrapper extractorWrapper;
   private final long sampleOffsetUs;
+  private final int adaptiveMaxWidth;
+  private final int adaptiveMaxHeight;
 
   private MediaFormat mediaFormat;
   private DrmInitData drmInitData;
@@ -51,25 +53,34 @@
    * @param startTimeUs The start time of the media contained by the chunk, in microseconds.
    * @param endTimeUs The end time of the media contained by the chunk, in microseconds.
    * @param chunkIndex The index of the chunk.
-   * @param isLastChunk True if this is the last chunk in the media. False otherwise.
    * @param sampleOffsetUs An offset to add to the sample timestamps parsed by the extractor.
    * @param extractorWrapper A wrapped extractor to use for parsing the data.
    * @param mediaFormat The {@link MediaFormat} of the chunk, if known. May be null if the data is
    *     known to define its own format.
+   * @param adaptiveMaxWidth If this chunk contains video and is part of an adaptive playback, this
+   *     is the maximum width of the video in pixels that will be encountered during the playback.
+   *     {@link MediaFormat#NO_VALUE} otherwise.
+   * @param adaptiveMaxHeight If this chunk contains video and is part of an adaptive playback, this
+   *     is the maximum height of the video in pixels that will be encountered during the playback.
+   *     {@link MediaFormat#NO_VALUE} otherwise.
    * @param drmInitData The {@link DrmInitData} for the chunk. Null if the media is not drm
    *     protected. May also be null if the data is known to define its own initialization data.
    * @param isMediaFormatFinal True if {@code mediaFormat} and {@code drmInitData} are known to be
    *     correct and final. False if the data may define its own format or initialization data.
+   * @param parentId Identifier for a parent from which this chunk originates.
    */
   public ContainerMediaChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
-      long startTimeUs, long endTimeUs, int chunkIndex, boolean isLastChunk, long sampleOffsetUs,
-      ChunkExtractorWrapper extractorWrapper, MediaFormat mediaFormat, DrmInitData drmInitData,
-      boolean isMediaFormatFinal) {
-    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex, isLastChunk,
-        isMediaFormatFinal);
+      long startTimeUs, long endTimeUs, int chunkIndex, long sampleOffsetUs,
+      ChunkExtractorWrapper extractorWrapper, MediaFormat mediaFormat, int adaptiveMaxWidth,
+      int adaptiveMaxHeight, DrmInitData drmInitData, boolean isMediaFormatFinal, int parentId) {
+    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex,
+        isMediaFormatFinal, parentId);
     this.extractorWrapper = extractorWrapper;
     this.sampleOffsetUs = sampleOffsetUs;
-    this.mediaFormat = mediaFormat;
+    this.adaptiveMaxWidth = adaptiveMaxWidth;
+    this.adaptiveMaxHeight = adaptiveMaxHeight;
+    this.mediaFormat = getAdjustedMediaFormat(mediaFormat, sampleOffsetUs, adaptiveMaxWidth,
+        adaptiveMaxHeight);
     this.drmInitData = drmInitData;
   }
 
@@ -102,7 +113,8 @@ public final void drmInitData(DrmInitData drmInitData) {
 
   @Override
   public final void format(MediaFormat mediaFormat) {
-    this.mediaFormat = mediaFormat;
+    this.mediaFormat = getAdjustedMediaFormat(mediaFormat, sampleOffsetUs, adaptiveMaxWidth,
+        adaptiveMaxHeight);
   }
 
   @Override
@@ -160,4 +172,20 @@ public final void load() throws IOException, InterruptedException {
     }
   }
 
+  // Private methods.
+
+  private static MediaFormat getAdjustedMediaFormat(MediaFormat format, long sampleOffsetUs,
+      int adaptiveMaxWidth, int adaptiveMaxHeight) {
+    if (format == null) {
+      return null;
+    }
+    if (sampleOffsetUs != 0 && format.subsampleOffsetUs != MediaFormat.OFFSET_SAMPLE_RELATIVE) {
+      format = format.copyWithSubsampleOffsetUs(format.subsampleOffsetUs + sampleOffsetUs);
+    }
+    if (adaptiveMaxWidth != MediaFormat.NO_VALUE || adaptiveMaxHeight != MediaFormat.NO_VALUE) {
+      format = format.copyWithMaxVideoDimensions(adaptiveMaxWidth, adaptiveMaxHeight);
+    }
+    return format;
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/DataChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/DataChunk.java
index ed0331f120..985fc233df 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/DataChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/DataChunk.java
@@ -43,11 +43,12 @@
    * @param type See {@link #type}.
    * @param trigger See {@link #trigger}.
    * @param format See {@link #format}.
+   * @param parentId Identifier for a parent from which this chunk originates.
    * @param data An optional recycled array that can be used as a holder for the data.
    */
   public DataChunk(DataSource dataSource, DataSpec dataSpec, int type, int trigger, Format format,
-      byte[] data) {
-    super(dataSource, dataSpec, type, trigger, format);
+      int parentId, byte[] data) {
+    super(dataSource, dataSpec, type, trigger, format, parentId);
     this.data = data;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/Format.java b/library/src/main/java/com/google/android/exoplayer/chunk/Format.java
index 0c2f404426..0c9df38712 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/Format.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/Format.java
@@ -69,7 +69,7 @@ public int compare(Format a, Format b) {
   /**
    * The number of audio channels, or -1 if unknown or not applicable.
    */
-  public final int numChannels;
+  public final int audioChannels;
 
   /**
    * The audio sampling rate in Hz, or -1 if unknown or not applicable.
@@ -131,20 +131,20 @@ public Format(String id, String mimeType, int width, int height, float frameRate
    * @param height The height of the video in pixels, or -1 if unknown or not applicable.
    * @param frameRate The frame rate of the video in frames per second, or -1 if unknown or not
    *     applicable.
-   * @param numChannels The number of audio channels, or -1 if unknown or not applicable.
+   * @param audioChannels The number of audio channels, or -1 if unknown or not applicable.
    * @param audioSamplingRate The audio sampling rate in Hz, or -1 if unknown or not applicable.
    * @param bitrate The average bandwidth of the format in bits per second.
    * @param language The language of the format.
    * @param codecs The codecs used to decode the format.
    */
-  public Format(String id, String mimeType, int width, int height, float frameRate, int numChannels,
-      int audioSamplingRate, int bitrate, String language, String codecs) {
+  public Format(String id, String mimeType, int width, int height, float frameRate,
+      int audioChannels, int audioSamplingRate, int bitrate, String language, String codecs) {
     this.id = Assertions.checkNotNull(id);
     this.mimeType = mimeType;
     this.width = width;
     this.height = height;
     this.frameRate = frameRate;
-    this.numChannels = numChannels;
+    this.audioChannels = audioChannels;
     this.audioSamplingRate = audioSamplingRate;
     this.bitrate = bitrate;
     this.language = language;
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/InitializationChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/InitializationChunk.java
index dd6c68c749..2a953a185f 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/InitializationChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/InitializationChunk.java
@@ -46,6 +46,11 @@
   private volatile int bytesLoaded;
   private volatile boolean loadCanceled;
 
+  public InitializationChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
+      ChunkExtractorWrapper extractorWrapper) {
+    this(dataSource, dataSpec, trigger, format, extractorWrapper, Chunk.NO_PARENT_ID);
+  }
+
   /**
    * Constructor for a chunk of media samples.
    *
@@ -54,10 +59,11 @@
    * @param trigger The reason for this chunk being selected.
    * @param format The format of the stream to which this chunk belongs.
    * @param extractorWrapper A wrapped extractor to use for parsing the initialization data.
+   * @param parentId Identifier for a parent from which this chunk originates.
    */
   public InitializationChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
-      ChunkExtractorWrapper extractorWrapper) {
-    super(dataSource, dataSpec, Chunk.TYPE_MEDIA_INITIALIZATION, trigger, format);
+      ChunkExtractorWrapper extractorWrapper, int parentId) {
+    super(dataSource, dataSpec, Chunk.TYPE_MEDIA_INITIALIZATION, trigger, format, parentId);
     this.extractorWrapper = extractorWrapper;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/MediaChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/MediaChunk.java
index f7d3812a7a..02167d3838 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/MediaChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/MediaChunk.java
@@ -36,10 +36,12 @@
    * The chunk index.
    */
   public final int chunkIndex;
-  /**
-   * True if this is the last chunk in the media. False otherwise.
-   */
-  public final boolean isLastChunk;
+
+  public MediaChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
+      long startTimeUs, long endTimeUs, int chunkIndex) {
+    this(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex,
+        Chunk.NO_PARENT_ID);
+  }
 
   /**
    * @param dataSource A {@link DataSource} for loading the data.
@@ -49,16 +51,15 @@
    * @param startTimeUs The start time of the media contained by the chunk, in microseconds.
    * @param endTimeUs The end time of the media contained by the chunk, in microseconds.
    * @param chunkIndex The index of the chunk.
-   * @param isLastChunk True if this is the last chunk in the media. False otherwise.
+   * @param parentId Identifier for a parent from which this chunk originates.
    */
   public MediaChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
-      long startTimeUs, long endTimeUs, int chunkIndex, boolean isLastChunk) {
-    super(dataSource, dataSpec, Chunk.TYPE_MEDIA, trigger, format);
+      long startTimeUs, long endTimeUs, int chunkIndex, int parentId) {
+    super(dataSource, dataSpec, Chunk.TYPE_MEDIA, trigger, format, parentId);
     Assertions.checkNotNull(format);
     this.startTimeUs = startTimeUs;
     this.endTimeUs = endTimeUs;
     this.chunkIndex = chunkIndex;
-    this.isLastChunk = isLastChunk;
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/MultiTrackChunkSource.java b/library/src/main/java/com/google/android/exoplayer/chunk/MultiTrackChunkSource.java
deleted file mode 100644
index c612dca454..0000000000
--- a/library/src/main/java/com/google/android/exoplayer/chunk/MultiTrackChunkSource.java
+++ /dev/null
@@ -1,125 +0,0 @@
-/*
- * Copyright (C) 2014 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package com.google.android.exoplayer.chunk;
-
-import com.google.android.exoplayer.ExoPlaybackException;
-import com.google.android.exoplayer.ExoPlayer.ExoPlayerComponent;
-import com.google.android.exoplayer.MediaFormat;
-import com.google.android.exoplayer.TrackInfo;
-import com.google.android.exoplayer.util.Assertions;
-
-import java.io.IOException;
-import java.util.List;
-
-/**
- * A {@link ChunkSource} providing the ability to switch between multiple other {@link ChunkSource}
- * instances.
- */
-public final class MultiTrackChunkSource implements ChunkSource, ExoPlayerComponent {
-
-  /**
-   * A message to indicate a source selection. Source selection can only be performed when the
-   * source is disabled.
-   */
-  public static final int MSG_SELECT_TRACK = 1;
-
-  private final ChunkSource[] allSources;
-
-  private ChunkSource selectedSource;
-  private boolean enabled;
-
-  public MultiTrackChunkSource(ChunkSource... sources) {
-    this.allSources = sources;
-    this.selectedSource = sources[0];
-  }
-
-  public MultiTrackChunkSource(List<ChunkSource> sources) {
-    this(toChunkSourceArray(sources));
-  }
-
-  /**
-   * Gets the number of tracks that this source can switch between. May be called safely from any
-   * thread.
-   *
-   * @return The number of tracks.
-   */
-  public int getTrackCount() {
-    return allSources.length;
-  }
-
-  @Override
-  public TrackInfo getTrackInfo() {
-    return selectedSource.getTrackInfo();
-  }
-
-  @Override
-  public void enable() {
-    selectedSource.enable();
-    enabled = true;
-  }
-
-  @Override
-  public void disable(List<? extends MediaChunk> queue) {
-    selectedSource.disable(queue);
-    enabled = false;
-  }
-
-  @Override
-  public void continueBuffering(long playbackPositionUs) {
-    selectedSource.continueBuffering(playbackPositionUs);
-  }
-
-  @Override
-  public void getChunkOperation(List<? extends MediaChunk> queue, long seekPositionUs,
-      long playbackPositionUs, ChunkOperationHolder out) {
-    selectedSource.getChunkOperation(queue, seekPositionUs, playbackPositionUs, out);
-  }
-
-  @Override
-  public void maybeThrowError() throws IOException {
-    selectedSource.maybeThrowError();
-  }
-
-  @Override
-  public void getMaxVideoDimensions(MediaFormat out) {
-    selectedSource.getMaxVideoDimensions(out);
-  }
-
-  @Override
-  public void handleMessage(int what, Object msg) throws ExoPlaybackException {
-    Assertions.checkState(!enabled);
-    if (what == MSG_SELECT_TRACK) {
-      selectedSource = allSources[(Integer) msg];
-    }
-  }
-
-  @Override
-  public void onChunkLoadCompleted(Chunk chunk) {
-    selectedSource.onChunkLoadCompleted(chunk);
-  }
-
-  @Override
-  public void onChunkLoadError(Chunk chunk, Exception e) {
-    selectedSource.onChunkLoadError(chunk, e);
-  }
-
-  private static ChunkSource[] toChunkSourceArray(List<ChunkSource> sources) {
-    ChunkSource[] chunkSourceArray = new ChunkSource[sources.size()];
-    sources.toArray(chunkSourceArray);
-    return chunkSourceArray;
-  }
-
-}
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleChunkSource.java b/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleChunkSource.java
index 12f7689099..c8662cc12c 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleChunkSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleChunkSource.java
@@ -17,7 +17,6 @@
 
 import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.MediaFormat;
-import com.google.android.exoplayer.TrackInfo;
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.upstream.DataSpec;
 
@@ -36,7 +35,6 @@
   private final Format format;
   private final long durationUs;
   private final MediaFormat mediaFormat;
-  private final TrackInfo trackInfo;
 
   /**
    * @param dataSource A {@link DataSource} suitable for loading the sample data.
@@ -54,21 +52,25 @@ public SingleSampleChunkSource(DataSource dataSource, DataSpec dataSpec, Format
     this.format = format;
     this.durationUs = durationUs;
     this.mediaFormat = mediaFormat;
-    trackInfo = new TrackInfo(format.mimeType, durationUs);
   }
 
   @Override
-  public TrackInfo getTrackInfo() {
-    return trackInfo;
+  public boolean prepare() {
+    return true;
   }
 
   @Override
-  public void getMaxVideoDimensions(MediaFormat out) {
-    // Do nothing.
+  public int getTrackCount() {
+    return 1;
+  }
+
+  @Override
+  public MediaFormat getFormat(int track) {
+    return mediaFormat;
   }
 
   @Override
-  public void enable() {
+  public void enable(int track) {
     // Do nothing.
   }
 
@@ -82,6 +84,7 @@ public void getChunkOperation(List<? extends MediaChunk> queue, long seekPositio
       long playbackPositionUs, ChunkOperationHolder out) {
     if (!queue.isEmpty()) {
       // We've already provided the single sample.
+      out.endOfStream = true;
       return;
     }
     out.chunk = initChunk();
@@ -109,7 +112,7 @@ public void onChunkLoadError(Chunk chunk, Exception e) {
 
   private SingleSampleMediaChunk initChunk() {
     return new SingleSampleMediaChunk(dataSource, dataSpec, Chunk.TRIGGER_UNSPECIFIED, format, 0,
-        durationUs, 0, true, mediaFormat, null, null);
+        durationUs, 0, mediaFormat, null, Chunk.NO_PARENT_ID);
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleMediaChunk.java b/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleMediaChunk.java
index de2c7067cc..d8d35acdc7 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleMediaChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/SingleSampleMediaChunk.java
@@ -20,7 +20,6 @@
 import com.google.android.exoplayer.drm.DrmInitData;
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.upstream.DataSpec;
-import com.google.android.exoplayer.util.ParsableByteArray;
 import com.google.android.exoplayer.util.Util;
 
 import java.io.IOException;
@@ -32,9 +31,6 @@
 
   private final MediaFormat sampleFormat;
   private final DrmInitData sampleDrmInitData;
-  private final byte[] headerData;
-
-  private boolean writtenHeader;
 
   private volatile int bytesLoaded;
   private volatile boolean loadCanceled;
@@ -47,22 +43,18 @@
    * @param startTimeUs The start time of the media contained by the chunk, in microseconds.
    * @param endTimeUs The end time of the media contained by the chunk, in microseconds.
    * @param chunkIndex The index of the chunk.
-   * @param isLastChunk True if this is the last chunk in the media. False otherwise.
    * @param sampleFormat The format of the sample.
    * @param sampleDrmInitData The {@link DrmInitData} for the sample. Null if the sample is not drm
    *     protected.
-   * @param headerData Custom header data for the sample. May be null. If set, the header data is
-   *     prepended to the sample data. It is not reflected in the values returned by
-   *     {@link #bytesLoaded()}.
+   * @param parentId Identifier for a parent from which this chunk originates.
    */
   public SingleSampleMediaChunk(DataSource dataSource, DataSpec dataSpec, int trigger,
-      Format format, long startTimeUs, long endTimeUs, int chunkIndex, boolean isLastChunk,
-      MediaFormat sampleFormat, DrmInitData sampleDrmInitData, byte[] headerData) {
-    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex, isLastChunk,
-        true);
+      Format format, long startTimeUs, long endTimeUs, int chunkIndex, MediaFormat sampleFormat,
+      DrmInitData sampleDrmInitData, int parentId) {
+    super(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs, chunkIndex, true,
+        parentId);
     this.sampleFormat = sampleFormat;
     this.sampleDrmInitData = sampleDrmInitData;
-    this.headerData = headerData;
   }
 
   @Override
@@ -95,13 +87,6 @@ public boolean isLoadCanceled() {
   @SuppressWarnings("NonAtomicVolatileUpdate")
   @Override
   public void load() throws IOException, InterruptedException {
-    if (!writtenHeader) {
-      if (headerData != null) {
-        getOutput().sampleData(new ParsableByteArray(headerData), headerData.length);
-      }
-      writtenHeader = true;
-    }
-
     DataSpec loadDataSpec = Util.getRemainderDataSpec(dataSpec, bytesLoaded);
     try {
       // Create and open the input.
@@ -113,9 +98,6 @@ public void load() throws IOException, InterruptedException {
         result = getOutput().sampleData(dataSource, Integer.MAX_VALUE, true);
       }
       int sampleSize = bytesLoaded;
-      if (headerData != null) {
-        sampleSize += headerData.length;
-      }
       getOutput().sampleMetadata(startTimeUs, C.SAMPLE_FLAG_SYNC, sampleSize, 0, null);
     } finally {
       dataSource.close();
diff --git a/library/src/main/java/com/google/android/exoplayer/chunk/VideoFormatSelectorUtil.java b/library/src/main/java/com/google/android/exoplayer/chunk/VideoFormatSelectorUtil.java
index 0866382fc7..5dcf6878fe 100644
--- a/library/src/main/java/com/google/android/exoplayer/chunk/VideoFormatSelectorUtil.java
+++ b/library/src/main/java/com/google/android/exoplayer/chunk/VideoFormatSelectorUtil.java
@@ -50,7 +50,7 @@
    *     mime types.
    * @param filterHdFormats True to filter HD formats. False otherwise.
    * @return An array holding the indices of the selected formats.
-   * @throws DecoderQueryException
+   * @throws DecoderQueryException Thrown if there was an error querying decoders.
    */
   public static int[] selectVideoFormatsForDefaultDisplay(Context context,
       List<? extends FormatWrapper> formatWrappers, String[] allowedContainerMimeTypes,
@@ -125,7 +125,7 @@
     // unnecessarily high resolution given the size at which the video will be displayed within the
     // viewport.
     for (int i = selectedIndexList.size() - 1; i >= 0; i--) {
-      Format format = formatWrappers.get(i).getFormat();
+      Format format = formatWrappers.get(selectedIndexList.get(i)).getFormat();
       if (format.width > 0 && format.height > 0
           && format.width * format.height > maxVideoPixelsToRetain) {
         selectedIndexList.remove(i);
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/DashChunkSource.java b/library/src/main/java/com/google/android/exoplayer/dash/DashChunkSource.java
index b4b0279052..1f72d1218c 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/DashChunkSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/DashChunkSource.java
@@ -19,8 +19,8 @@
 import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.TimeRange;
-import com.google.android.exoplayer.TrackInfo;
-import com.google.android.exoplayer.TrackRenderer;
+import com.google.android.exoplayer.TimeRange.DynamicTimeRange;
+import com.google.android.exoplayer.TimeRange.StaticTimeRange;
 import com.google.android.exoplayer.chunk.Chunk;
 import com.google.android.exoplayer.chunk.ChunkExtractorWrapper;
 import com.google.android.exoplayer.chunk.ChunkOperationHolder;
@@ -33,6 +33,7 @@
 import com.google.android.exoplayer.chunk.InitializationChunk;
 import com.google.android.exoplayer.chunk.MediaChunk;
 import com.google.android.exoplayer.chunk.SingleSampleMediaChunk;
+import com.google.android.exoplayer.dash.DashTrackSelector.Output;
 import com.google.android.exoplayer.dash.mpd.AdaptationSet;
 import com.google.android.exoplayer.dash.mpd.ContentProtection;
 import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
@@ -41,7 +42,6 @@
 import com.google.android.exoplayer.dash.mpd.Representation;
 import com.google.android.exoplayer.drm.DrmInitData;
 import com.google.android.exoplayer.extractor.ChunkIndex;
-import com.google.android.exoplayer.extractor.Extractor;
 import com.google.android.exoplayer.extractor.mp4.FragmentedMp4Extractor;
 import com.google.android.exoplayer.extractor.webm.WebmExtractor;
 import com.google.android.exoplayer.upstream.DataSource;
@@ -52,8 +52,12 @@
 import com.google.android.exoplayer.util.SystemClock;
 
 import android.os.Handler;
+import android.text.TextUtils;
+import android.util.Log;
+import android.util.SparseArray;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
@@ -62,9 +66,17 @@
 /**
  * An {@link ChunkSource} for DASH streams.
  * <p>
- * This implementation currently supports fMP4, webm, and webvtt.
+ * This implementation currently supports fMP4, webm, webvtt and ttml.
+ * <p>
+ * This implementation makes the following assumptions about multi-period manifests:
+ * <ol>
+ * <li>that new periods will contain the same representations as previous periods (i.e. no new or
+ * missing representations) and</li>
+ * <li>that representations are contiguous across multiple periods</li>
+ * </ol>
  */
-public class DashChunkSource implements ChunkSource {
+// TODO: handle cases where the above assumption are false
+public class DashChunkSource implements ChunkSource, Output {
 
   /**
    * Interface definition for a callback to be notified of {@link DashChunkSource} events.
@@ -74,9 +86,9 @@
     /**
      * Invoked when the available seek range of the stream has changed.
      *
-     * @param seekRange The range which specifies available content that can be seeked to.
+     * @param availableRange The range which specifies available content that can be seeked to.
      */
-    public void onSeekRangeChanged(TimeRange seekRange);
+    public void onAvailableRangeChanged(TimeRange availableRange);
 
   }
 
@@ -91,41 +103,29 @@ public NoAdaptationSetException(String message) {
 
   }
 
-  /**
-   * Specifies that we should process all tracks.
-   */
-  public static final int USE_ALL_TRACKS = -1;
+  private static final String TAG = "DashChunkSource";
 
   private final Handler eventHandler;
   private final EventListener eventListener;
 
-  private final TrackInfo trackInfo;
   private final DataSource dataSource;
-  private final FormatEvaluator formatEvaluator;
+  private final FormatEvaluator adaptiveFormatEvaluator;
   private final Evaluation evaluation;
+  private final ManifestFetcher<MediaPresentationDescription> manifestFetcher;
+  private final DashTrackSelector trackSelector;
+  private final ArrayList<ExposedTrack> tracks;
+  private final SparseArray<PeriodHolder> periodHolders;
   private final Clock systemClock;
-  private final StringBuilder headerBuilder;
   private final long liveEdgeLatencyUs;
   private final long elapsedRealtimeOffsetUs;
-  private final int maxWidth;
-  private final int maxHeight;
-
-  private final Format[] formats;
-  private final HashMap<String, RepresentationHolder> representationHolders;
-
-  private final ManifestFetcher<MediaPresentationDescription> manifestFetcher;
-  private final int adaptationSetIndex;
-  private final int[] representationIndices;
+  private final long[] availableRangeValues;
+  private final boolean live;
 
   private MediaPresentationDescription currentManifest;
-  private boolean finishedCurrentManifest;
-
-  private DrmInitData drmInitData;
-  private TimeRange seekRange;
-  private long[] seekRangeValues;
-  private int firstAvailableSegmentNum;
-  private int lastAvailableSegmentNum;
-
+  private ExposedTrack enabledTrack;
+  private int nextPeriodHolderIndex;
+  private TimeRange availableRange;
+  private boolean prepareCalled;
   private boolean startAtLiveEdge;
   private boolean lastChunkWasInitialization;
   private IOException fatalError;
@@ -134,41 +134,49 @@ public NoAdaptationSetException(String message) {
    * Lightweight constructor to use for fixed duration content.
    *
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
+   * @param durationMs The duration of the content.
+   * @param adaptationSetType The type of the adaptation set to which the representations belong.
+   *     One of {@link AdaptationSet#TYPE_AUDIO}, {@link AdaptationSet#TYPE_VIDEO} and
+   *     {@link AdaptationSet#TYPE_TEXT}.
    * @param representations The representations to be considered by the source.
    */
-  public DashChunkSource(DataSource dataSource, FormatEvaluator formatEvaluator,
-      Representation... representations) {
-    this(buildManifest(Arrays.asList(representations)), 0, null, dataSource, formatEvaluator);
+  public DashChunkSource(DataSource dataSource, FormatEvaluator adaptiveFormatEvaluator,
+      long durationMs, int adaptationSetType, Representation... representations) {
+    this(dataSource, adaptiveFormatEvaluator, durationMs, adaptationSetType,
+        Arrays.asList(representations));
   }
 
   /**
    * Lightweight constructor to use for fixed duration content.
    *
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
+   * @param durationMs The duration of the content.
+   * @param adaptationSetType The type of the adaptation set to which the representations belong.
+   *     One of {@link AdaptationSet#TYPE_AUDIO}, {@link AdaptationSet#TYPE_VIDEO} and
+   *     {@link AdaptationSet#TYPE_TEXT}.
    * @param representations The representations to be considered by the source.
    */
-  public DashChunkSource(DataSource dataSource, FormatEvaluator formatEvaluator,
-      List<Representation> representations) {
-    this(buildManifest(representations), 0, null, dataSource, formatEvaluator);
+  public DashChunkSource(DataSource dataSource, FormatEvaluator adaptiveFormatEvaluator,
+      long durationMs, int adaptationSetType, List<Representation> representations) {
+    this(buildManifest(durationMs, adaptationSetType, representations),
+        DefaultDashTrackSelector.newVideoInstance(null, false, false), dataSource,
+        adaptiveFormatEvaluator);
   }
 
   /**
    * Constructor to use for fixed duration content.
    *
    * @param manifest The manifest.
-   * @param adaptationSetIndex The index of the adaptation set that should be used.
-   * @param representationIndices The indices of the representations within the adaptations set
-   *     that should be used. May be null if all representations within the adaptation set should
-   *     be considered.
+   * @param trackSelector Selects tracks from manifest periods to be exposed by this source.
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
    */
-  public DashChunkSource(MediaPresentationDescription manifest, int adaptationSetIndex,
-      int[] representationIndices, DataSource dataSource, FormatEvaluator formatEvaluator) {
-    this(null, manifest, adaptationSetIndex, representationIndices, dataSource, formatEvaluator,
-        new SystemClock(), 0, 0, false, null, null);
+  public DashChunkSource(MediaPresentationDescription manifest, DashTrackSelector trackSelector,
+      DataSource dataSource, FormatEvaluator adaptiveFormatEvaluator) {
+    this(null, manifest, trackSelector, dataSource, adaptiveFormatEvaluator, new SystemClock(), 0,
+        0, false, null, null);
   }
 
   /**
@@ -179,12 +187,9 @@ public DashChunkSource(MediaPresentationDescription manifest, int adaptationSetI
    *
    * @param manifestFetcher A fetcher for the manifest, which must have already successfully
    *     completed an initial load.
-   * @param adaptationSetIndex The index of the adaptation set that should be used.
-   * @param representationIndices The indices of the representations within the adaptations set
-   *     that should be used. May be null if all representations within the adaptation set should
-   *     be considered.
+   * @param trackSelector Selects tracks from manifest periods to be exposed by this source.
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
    * @param liveEdgeLatencyMs For live streams, the number of milliseconds that the playback should
    *     lag behind the "live edge" (i.e. the end of the most recently defined media in the
    *     manifest). Choosing a small value will minimize latency introduced by the player, however
@@ -198,11 +203,11 @@ public DashChunkSource(MediaPresentationDescription manifest, int adaptationSetI
    * @param eventListener A listener of events. May be null if delivery of events is not required.
    */
   public DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFetcher,
-      int adaptationSetIndex, int[] representationIndices, DataSource dataSource,
-      FormatEvaluator formatEvaluator, long liveEdgeLatencyMs, long elapsedRealtimeOffsetMs,
+      DashTrackSelector trackSelector, DataSource dataSource,
+      FormatEvaluator adaptiveFormatEvaluator, long liveEdgeLatencyMs, long elapsedRealtimeOffsetMs,
       Handler eventHandler, EventListener eventListener) {
-    this(manifestFetcher, manifestFetcher.getManifest(), adaptationSetIndex, representationIndices,
-        dataSource, formatEvaluator, new SystemClock(), liveEdgeLatencyMs * 1000,
+    this(manifestFetcher, manifestFetcher.getManifest(), trackSelector,
+        dataSource, adaptiveFormatEvaluator, new SystemClock(), liveEdgeLatencyMs * 1000,
         elapsedRealtimeOffsetMs * 1000, true, eventHandler, eventListener);
   }
 
@@ -211,12 +216,9 @@ public DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFet
    *
    * @param manifestFetcher A fetcher for the manifest, which must have already successfully
    *     completed an initial load.
-   * @param adaptationSetIndex The index of the adaptation set that should be used.
-   * @param representationIndices The indices of the representations within the adaptations set
-   *     that should be used. May be null if all representations within the adaptation set should
-   *     be considered.
+   * @param trackSelector Selects tracks from manifest periods to be exposed by this source.
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
    * @param liveEdgeLatencyMs For live streams, the number of milliseconds that the playback should
    *     lag behind the "live edge" (i.e. the end of the most recently defined media in the
    *     manifest). Choosing a small value will minimize latency introduced by the player, however
@@ -232,25 +234,24 @@ public DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFet
    * @param eventListener A listener of events. May be null if delivery of events is not required.
    */
   public DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFetcher,
-      int adaptationSetIndex, int[] representationIndices, DataSource dataSource,
-      FormatEvaluator formatEvaluator, long liveEdgeLatencyMs, long elapsedRealtimeOffsetMs,
+      DashTrackSelector trackSelector, DataSource dataSource,
+      FormatEvaluator adaptiveFormatEvaluator, long liveEdgeLatencyMs, long elapsedRealtimeOffsetMs,
       boolean startAtLiveEdge, Handler eventHandler, EventListener eventListener) {
-    this(manifestFetcher, manifestFetcher.getManifest(), adaptationSetIndex, representationIndices,
-        dataSource, formatEvaluator, new SystemClock(), liveEdgeLatencyMs * 1000,
+    this(manifestFetcher, manifestFetcher.getManifest(), trackSelector,
+        dataSource, adaptiveFormatEvaluator, new SystemClock(), liveEdgeLatencyMs * 1000,
         elapsedRealtimeOffsetMs * 1000, startAtLiveEdge, eventHandler, eventListener);
   }
 
   /* package */ DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFetcher,
-      MediaPresentationDescription initialManifest, int adaptationSetIndex,
-      int[] representationIndices, DataSource dataSource, FormatEvaluator formatEvaluator,
+      MediaPresentationDescription initialManifest, DashTrackSelector trackSelector,
+      DataSource dataSource, FormatEvaluator adaptiveFormatEvaluator,
       Clock systemClock, long liveEdgeLatencyUs, long elapsedRealtimeOffsetUs,
       boolean startAtLiveEdge, Handler eventHandler, EventListener eventListener) {
     this.manifestFetcher = manifestFetcher;
     this.currentManifest = initialManifest;
-    this.adaptationSetIndex = adaptationSetIndex;
-    this.representationIndices = representationIndices;
+    this.trackSelector = trackSelector;
     this.dataSource = dataSource;
-    this.formatEvaluator = formatEvaluator;
+    this.adaptiveFormatEvaluator = adaptiveFormatEvaluator;
     this.systemClock = systemClock;
     this.liveEdgeLatencyUs = liveEdgeLatencyUs;
     this.elapsedRealtimeOffsetUs = elapsedRealtimeOffsetUs;
@@ -258,77 +259,58 @@ public DashChunkSource(ManifestFetcher<MediaPresentationDescription> manifestFet
     this.eventHandler = eventHandler;
     this.eventListener = eventListener;
     this.evaluation = new Evaluation();
-    this.headerBuilder = new StringBuilder();
-    this.seekRangeValues = new long[2];
-
-    drmInitData = getDrmInitData(currentManifest, adaptationSetIndex);
-    Representation[] representations = getFilteredRepresentations(currentManifest,
-        adaptationSetIndex, representationIndices);
-    long periodDurationUs = (representations[0].periodDurationMs == TrackRenderer.UNKNOWN_TIME_US)
-        ? TrackRenderer.UNKNOWN_TIME_US : representations[0].periodDurationMs * 1000;
-    this.trackInfo = new TrackInfo(representations[0].format.mimeType, periodDurationUs);
-
-    this.formats = new Format[representations.length];
-    this.representationHolders = new HashMap<>();
-    int maxWidth = 0;
-    int maxHeight = 0;
-    for (int i = 0; i < representations.length; i++) {
-      formats[i] = representations[i].format;
-      maxWidth = Math.max(formats[i].width, maxWidth);
-      maxHeight = Math.max(formats[i].height, maxHeight);
-      Extractor extractor = mimeTypeIsWebm(formats[i].mimeType) ? new WebmExtractor()
-          : new FragmentedMp4Extractor();
-      representationHolders.put(formats[i].id,
-          new RepresentationHolder(representations[i], new ChunkExtractorWrapper(extractor)));
-    }
-    this.maxWidth = maxWidth;
-    this.maxHeight = maxHeight;
-    Arrays.sort(formats, new DecreasingBandwidthComparator());
+    this.availableRangeValues = new long[2];
+    periodHolders = new SparseArray<>();
+    tracks = new ArrayList<>();
+    live = initialManifest.dynamic;
   }
 
+  // ChunkSource implementation.
+
   @Override
-  public final void getMaxVideoDimensions(MediaFormat out) {
-    if (trackInfo.mimeType.startsWith("video")) {
-      out.setMaxVideoDimensions(maxWidth, maxHeight);
+  public void maybeThrowError() throws IOException {
+    if (fatalError != null) {
+      throw fatalError;
+    } else if (manifestFetcher != null) {
+      manifestFetcher.maybeThrowError();
     }
   }
 
   @Override
-  public final TrackInfo getTrackInfo() {
-    return trackInfo;
+  public boolean prepare() {
+    if (!prepareCalled) {
+      prepareCalled = true;
+      try {
+        trackSelector.selectTracks(currentManifest, 0, this);
+      } catch (IOException e) {
+        fatalError = e;
+      }
+    }
+    return fatalError == null;
   }
 
-  // VisibleForTesting
-  /* package */ TimeRange getSeekRange() {
-    return seekRange;
+  @Override
+  public int getTrackCount() {
+    return tracks.size();
   }
 
   @Override
-  public void enable() {
-    fatalError = null;
-    formatEvaluator.enable();
-    if (manifestFetcher != null) {
-      manifestFetcher.enable();
-    }
-    DashSegmentIndex segmentIndex =
-        representationHolders.get(formats[0].id).representation.getIndex();
-    if (segmentIndex == null) {
-      seekRange = new TimeRange(TimeRange.TYPE_SNAPSHOT, 0, currentManifest.duration * 1000);
-      notifySeekRangeChanged(seekRange);
-    } else {
-      long nowUs = getNowUs();
-      updateAvailableSegmentBounds(segmentIndex, nowUs);
-      updateSeekRange(segmentIndex, nowUs);
-    }
+  public final MediaFormat getFormat(int track) {
+    return tracks.get(track).trackFormat;
   }
 
   @Override
-  public void disable(List<? extends MediaChunk> queue) {
-    formatEvaluator.disable();
+  public void enable(int track) {
+    enabledTrack = tracks.get(track);
+    if (enabledTrack.isAdaptive()) {
+      adaptiveFormatEvaluator.enable();
+    }
     if (manifestFetcher != null) {
-      manifestFetcher.disable();
+      manifestFetcher.enable();
+      processManifest(manifestFetcher.getManifest());
+    } else {
+      processManifest(currentManifest);
     }
-    seekRange = null;
   }
 
   @Override
@@ -339,41 +321,7 @@ public void continueBuffering(long playbackPositionUs) {
 
     MediaPresentationDescription newManifest = manifestFetcher.getManifest();
     if (currentManifest != newManifest && newManifest != null) {
-      Representation[] newRepresentations = DashChunkSource.getFilteredRepresentations(newManifest,
-          adaptationSetIndex, representationIndices);
-      for (Representation representation : newRepresentations) {
-        RepresentationHolder representationHolder =
-            representationHolders.get(representation.format.id);
-        DashSegmentIndex oldIndex = representationHolder.segmentIndex;
-        int oldIndexLastSegmentNum = oldIndex.getLastSegmentNum();
-        long oldIndexEndTimeUs = oldIndex.getTimeUs(oldIndexLastSegmentNum)
-            + oldIndex.getDurationUs(oldIndexLastSegmentNum);
-        DashSegmentIndex newIndex = representation.getIndex();
-        int newIndexFirstSegmentNum = newIndex.getFirstSegmentNum();
-        long newIndexStartTimeUs = newIndex.getTimeUs(newIndexFirstSegmentNum);
-        if (oldIndexEndTimeUs < newIndexStartTimeUs) {
-          // There's a gap between the old manifest and the new one which means we've slipped behind
-          // the live window and can't proceed.
-          fatalError = new BehindLiveWindowException();
-          return;
-        }
-        int segmentNumShift;
-        if (oldIndexEndTimeUs == newIndexStartTimeUs) {
-          // The new manifest continues where the old one ended, with no overlap.
-          segmentNumShift = oldIndex.getLastSegmentNum() + 1 - newIndexFirstSegmentNum;
-        } else {
-          // The new manifest overlaps with the old one.
-          segmentNumShift = oldIndex.getSegmentNum(newIndexStartTimeUs) - newIndexFirstSegmentNum;
-        }
-        representationHolder.segmentNumShift += segmentNumShift;
-        representationHolder.segmentIndex = newIndex;
-      }
-      currentManifest = newManifest;
-      finishedCurrentManifest = false;
-
-      long nowUs = getNowUs();
-      updateAvailableSegmentBounds(newRepresentations[0].getIndex(), nowUs);
-      updateSeekRange(newRepresentations[0].getIndex(), nowUs);
+      processManifest(newManifest);
     }
 
     // TODO: This is a temporary hack to avoid constantly refreshing the MPD in cases where
@@ -385,8 +333,8 @@ public void continueBuffering(long playbackPositionUs) {
       minUpdatePeriod = 5000;
     }
 
-    if (finishedCurrentManifest && (android.os.SystemClock.elapsedRealtime()
-        > manifestFetcher.getManifestLoadStartTimestamp() + minUpdatePeriod)) {
+    if (android.os.SystemClock.elapsedRealtime()
+        > manifestFetcher.getManifestLoadStartTimestamp() + minUpdatePeriod) {
       manifestFetcher.requestRefresh();
     }
   }
@@ -401,8 +349,15 @@ public final void getChunkOperation(List<? extends MediaChunk> queue, long seekP
 
     evaluation.queueSize = queue.size();
     if (evaluation.format == null || !lastChunkWasInitialization) {
-      formatEvaluator.evaluate(queue, playbackPositionUs, formats, evaluation);
+      if (enabledTrack.isAdaptive()) {
+        adaptiveFormatEvaluator.evaluate(queue, playbackPositionUs, enabledTrack.adaptiveFormats,
+            evaluation);
+      } else {
+        evaluation.format = enabledTrack.fixedFormat;
+        evaluation.trigger = Chunk.TRIGGER_MANUAL;
+      }
     }
+
     Format selectedFormat = evaluation.format;
     out.queueSize = evaluation.queueSize;
 
@@ -419,128 +374,136 @@ public final void getChunkOperation(List<? extends MediaChunk> queue, long seekP
     // In all cases where we return before instantiating a new chunk, we want out.chunk to be null.
     out.chunk = null;
 
-    RepresentationHolder representationHolder = representationHolders.get(selectedFormat.id);
-    Representation selectedRepresentation = representationHolder.representation;
-    DashSegmentIndex segmentIndex = representationHolder.segmentIndex;
-    ChunkExtractorWrapper extractorWrapper = representationHolder.extractorWrapper;
-
-    RangedUri pendingInitializationUri = null;
-    RangedUri pendingIndexUri = null;
-
-    if (representationHolder.format == null) {
-      pendingInitializationUri = selectedRepresentation.getInitializationUri();
-    }
-    if (segmentIndex == null) {
-      pendingIndexUri = selectedRepresentation.getIndexUri();
-    }
-
-    if (pendingInitializationUri != null || pendingIndexUri != null) {
-      // We have initialization and/or index requests to make.
-      Chunk initializationChunk = newInitializationChunk(pendingInitializationUri, pendingIndexUri,
-          selectedRepresentation, extractorWrapper, dataSource, evaluation.trigger);
-      lastChunkWasInitialization = true;
-      out.chunk = initializationChunk;
-      return;
-    }
+    boolean startingNewPeriod;
+    PeriodHolder periodHolder;
 
-    int segmentNum;
-    boolean indexUnbounded = segmentIndex.getLastSegmentNum() == DashSegmentIndex.INDEX_UNBOUNDED;
-    if (indexUnbounded) {
-      // Manifests with unbounded indexes aren't updated regularly, so we need to update the
-      // segment bounds before use to ensure that they are accurate to the current time; also if
-      // the bounds have changed, we should update the seek range
-      long nowUs = getNowUs();
-      int oldFirstAvailableSegmentNum = firstAvailableSegmentNum;
-      int oldLastAvailableSegmentNum = lastAvailableSegmentNum;
-      updateAvailableSegmentBounds(segmentIndex, nowUs);
-      if (oldFirstAvailableSegmentNum != firstAvailableSegmentNum
-          || oldLastAvailableSegmentNum != lastAvailableSegmentNum) {
-        updateSeekRange(segmentIndex, nowUs);
-      }
-    }
+    availableRange.getCurrentBoundsUs(availableRangeValues);
     if (queue.isEmpty()) {
-      if (currentManifest.dynamic) {
-        seekRangeValues = seekRange.getCurrentBoundsUs(seekRangeValues);
+      if (live) {
         if (startAtLiveEdge) {
           // We want live streams to start at the live edge instead of the beginning of the
           // manifest
-          startAtLiveEdge = false;
-          seekPositionUs = seekRangeValues[1];
+          seekPositionUs = Math.max(availableRangeValues[0],
+              availableRangeValues[1] - liveEdgeLatencyUs);
         } else {
-          seekPositionUs = Math.max(seekPositionUs, seekRangeValues[0]);
-          seekPositionUs = Math.min(seekPositionUs, seekRangeValues[1]);
+          // we subtract 1 from the upper bound because it's exclusive for that bound
+          seekPositionUs = Math.min(seekPositionUs, availableRangeValues[1] - 1);
+          seekPositionUs = Math.max(seekPositionUs, availableRangeValues[0]);
         }
       }
-      segmentNum = segmentIndex.getSegmentNum(seekPositionUs);
 
-      // if the index is unbounded then the result of getSegmentNum isn't clamped to ensure that
-      // it doesn't exceed the last available segment. Clamp it here.
-      if (indexUnbounded) {
-        segmentNum = Math.min(segmentNum, lastAvailableSegmentNum);
-      }
+      periodHolder = findPeriodHolder(seekPositionUs);
+      startingNewPeriod = true;
     } else {
-      MediaChunk previous = queue.get(out.queueSize - 1);
-      segmentNum = previous.isLastChunk ? -1
-          : previous.chunkIndex + 1 - representationHolder.segmentNumShift;
-    }
+      if (startAtLiveEdge) {
+        // now that we know the player is consuming media chunks (since the queue isn't empty),
+        // set startAtLiveEdge to false so that the user can perform seek operations
+        startAtLiveEdge = false;
+      }
 
-    if (currentManifest.dynamic) {
-      if (segmentNum < firstAvailableSegmentNum) {
+      MediaChunk previous = queue.get(out.queueSize - 1);
+      long nextSegmentStartTimeUs = previous.endTimeUs;
+      if (live && nextSegmentStartTimeUs < availableRangeValues[0]) {
         // This is before the first chunk in the current manifest.
         fatalError = new BehindLiveWindowException();
         return;
-      } else if (segmentNum > lastAvailableSegmentNum) {
+      } else if (currentManifest.dynamic && nextSegmentStartTimeUs >= availableRangeValues[1]) {
         // This chunk is beyond the last chunk in the current manifest. If the index is bounded
-        // we'll need to refresh it. If it's unbounded we just need to wait for a while before
-        // attempting to load the chunk.
-        finishedCurrentManifest = !indexUnbounded;
+        // we'll need to wait until it's refreshed. If it's unbounded we just need to wait for a
+        // while before attempting to load the chunk.
         return;
-      } else if (!indexUnbounded && segmentNum == lastAvailableSegmentNum) {
-        // This is the last chunk in a dynamic bounded manifest. We'll need to refresh the manifest
-        // to obtain the next chunk.
-        finishedCurrentManifest = true;
+      } else if (!currentManifest.dynamic) {
+        // The current manifest isn't dynamic, so check whether we've reached the end of the stream.
+        PeriodHolder lastPeriodHolder = periodHolders.valueAt(periodHolders.size() - 1);
+        if (previous.parentId == lastPeriodHolder.localIndex) {
+          RepresentationHolder representationHolder =
+              lastPeriodHolder.representationHolders.get(previous.format.id);
+          if (representationHolder.isLastSegment(previous.chunkIndex)) {
+            out.endOfStream = true;
+            return;
+          }
+        }
+      }
+
+      startingNewPeriod = false;
+      periodHolder = periodHolders.get(previous.parentId);
+      if (periodHolder == null) {
+        // The previous chunk was from a period that's no longer on the manifest, therefore the
+        // next chunk must be the first one in the first period that's still on the manifest
+        // (note that we can't actually update the segmentNum yet because the new period might
+        // have a different sequence and it's segmentIndex might not have been loaded yet).
+        periodHolder = periodHolders.valueAt(0);
+        startingNewPeriod = true;
+      } else if (!periodHolder.isIndexUnbounded()) {
+        RepresentationHolder representationHolder =
+            periodHolder.representationHolders.get(previous.format.id);
+        if (representationHolder.isLastSegment(previous.chunkIndex)) {
+          // We reached the end of a period. Start the next one.
+          periodHolder = periodHolders.get(previous.parentId + 1);
+          startingNewPeriod = true;
+        }
       }
     }
 
-    if (segmentNum == -1) {
-      // We've reached the end of the stream.
+    RepresentationHolder representationHolder =
+        periodHolder.representationHolders.get(selectedFormat.id);
+    Representation selectedRepresentation = representationHolder.representation;
+
+    RangedUri pendingInitializationUri = null;
+    RangedUri pendingIndexUri = null;
+
+    MediaFormat mediaFormat = representationHolder.mediaFormat;
+    if (mediaFormat == null) {
+      pendingInitializationUri = selectedRepresentation.getInitializationUri();
+    }
+    if (representationHolder.segmentIndex == null) {
+      pendingIndexUri = selectedRepresentation.getIndexUri();
+    }
+
+    if (pendingInitializationUri != null || pendingIndexUri != null) {
+      // We have initialization and/or index requests to make.
+      Chunk initializationChunk = newInitializationChunk(pendingInitializationUri, pendingIndexUri,
+          selectedRepresentation, representationHolder.extractorWrapper, dataSource,
+          periodHolder.localIndex, evaluation.trigger);
+      lastChunkWasInitialization = true;
+      out.chunk = initializationChunk;
       return;
     }
 
-    Chunk nextMediaChunk = newMediaChunk(representationHolder, dataSource, segmentNum,
-        evaluation.trigger);
+    int segmentNum = queue.isEmpty() ? representationHolder.getSegmentNum(seekPositionUs)
+          : startingNewPeriod ? representationHolder.getFirstAvailableSegmentNum()
+          : queue.get(out.queueSize - 1).chunkIndex + 1;
+    Chunk nextMediaChunk = newMediaChunk(periodHolder, representationHolder, dataSource,
+        mediaFormat, segmentNum, evaluation.trigger);
     lastChunkWasInitialization = false;
     out.chunk = nextMediaChunk;
   }
 
-  @Override
-  public void maybeThrowError() throws IOException {
-    if (fatalError != null) {
-      throw fatalError;
-    } else if (manifestFetcher != null) {
-      manifestFetcher.maybeThrowError();
-    }
-  }
-
   @Override
   public void onChunkLoadCompleted(Chunk chunk) {
     if (chunk instanceof InitializationChunk) {
       InitializationChunk initializationChunk = (InitializationChunk) chunk;
       String formatId = initializationChunk.format.id;
-      RepresentationHolder representationHolder = representationHolders.get(formatId);
+      PeriodHolder periodHolder = periodHolders.get(initializationChunk.parentId);
+      if (periodHolder == null) {
+        // period for this initialization chunk may no longer be on the manifest
+        return;
+      }
+
+      RepresentationHolder representationHolder = periodHolder.representationHolders.get(formatId);
       if (initializationChunk.hasFormat()) {
-        representationHolder.format = initializationChunk.getFormat();
+        representationHolder.mediaFormat = initializationChunk.getFormat();
       }
       if (initializationChunk.hasSeekMap()) {
         representationHolder.segmentIndex = new DashWrappingSegmentIndex(
             (ChunkIndex) initializationChunk.getSeekMap(),
-            initializationChunk.dataSpec.uri.toString(),
-            representationHolder.representation.periodStartMs * 1000);
+            initializationChunk.dataSpec.uri.toString());
       }
+
       // The null check avoids overwriting drmInitData obtained from the manifest with drmInitData
       // obtained from the stream, as per DASH IF Interoperability Recommendations V3.0, 7.5.3.
-      if (drmInitData == null && initializationChunk.hasDrmInitData()) {
-        drmInitData = initializationChunk.getDrmInitData();
+      if (periodHolder.drmInitData == null && initializationChunk.hasDrmInitData()) {
+        periodHolder.drmInitData = initializationChunk.getDrmInitData();
       }
     }
   }
@@ -550,66 +513,182 @@ public void onChunkLoadError(Chunk chunk, Exception e) {
     // Do nothing.
   }
 
-  private void updateAvailableSegmentBounds(DashSegmentIndex segmentIndex, long nowUs) {
-    int indexFirstAvailableSegmentNum = segmentIndex.getFirstSegmentNum();
-    int indexLastAvailableSegmentNum = segmentIndex.getLastSegmentNum();
-    if (indexLastAvailableSegmentNum == DashSegmentIndex.INDEX_UNBOUNDED) {
-      // The index is itself unbounded. We need to use the current time to calculate the range of
-      // available segments.
-      long liveEdgeTimestampUs = nowUs - currentManifest.availabilityStartTime * 1000;
-      if (currentManifest.timeShiftBufferDepth != -1) {
-        long bufferDepthUs = currentManifest.timeShiftBufferDepth * 1000;
-        indexFirstAvailableSegmentNum = Math.max(indexFirstAvailableSegmentNum,
-            segmentIndex.getSegmentNum(liveEdgeTimestampUs - bufferDepthUs));
-      }
-      // getSegmentNum(liveEdgeTimestampUs) will not be completed yet, so subtract one to get the
-      // index of the last completed segment.
-      indexLastAvailableSegmentNum = segmentIndex.getSegmentNum(liveEdgeTimestampUs) - 1;
-    }
-    firstAvailableSegmentNum = indexFirstAvailableSegmentNum;
-    lastAvailableSegmentNum = indexLastAvailableSegmentNum;
-  }
-
-  private void updateSeekRange(DashSegmentIndex segmentIndex, long nowUs) {
-    long earliestSeekPosition = segmentIndex.getTimeUs(firstAvailableSegmentNum);
-    long latestSeekPosition = segmentIndex.getTimeUs(lastAvailableSegmentNum)
-        + segmentIndex.getDurationUs(lastAvailableSegmentNum);
-    if (currentManifest.dynamic) {
-      long liveEdgeTimestampUs;
-      if (segmentIndex.getLastSegmentNum() == DashSegmentIndex.INDEX_UNBOUNDED) {
-        liveEdgeTimestampUs = nowUs - currentManifest.availabilityStartTime * 1000;
-      } else {
-        liveEdgeTimestampUs = segmentIndex.getTimeUs(segmentIndex.getLastSegmentNum())
-            + segmentIndex.getDurationUs(segmentIndex.getLastSegmentNum());
-        if (!segmentIndex.isExplicit()) {
-          // Some segments defined by the index may not be available yet. Bound the calculated live
-          // edge based on the elapsed time since the manifest became available.
-          liveEdgeTimestampUs = Math.min(liveEdgeTimestampUs,
-              nowUs - currentManifest.availabilityStartTime * 1000);
-        }
+  @Override
+  public void disable(List<? extends MediaChunk> queue) {
+    if (enabledTrack.isAdaptive()) {
+      adaptiveFormatEvaluator.disable();
+    }
+    if (manifestFetcher != null) {
+      manifestFetcher.disable();
+    }
+    periodHolders.clear();
+    evaluation.format = null;
+    availableRange = null;
+    fatalError = null;
+    enabledTrack = null;
+  }
+
+  // DashTrackSelector.Output implementation.
+
+  @Override
+  public void adaptiveTrack(MediaPresentationDescription manifest, int periodIndex,
+      int adaptationSetIndex, int[] representationIndices) {
+    if (adaptiveFormatEvaluator == null) {
+      Log.w(TAG, "Skipping adaptive track (missing format evaluator)");
+      return;
+    }
+    AdaptationSet adaptationSet = manifest.getPeriod(periodIndex).adaptationSets.get(
+        adaptationSetIndex);
+    int maxWidth = 0;
+    int maxHeight = 0;
+    Format maxHeightRepresentationFormat = null;
+    Format[] representationFormats = new Format[representationIndices.length];
+    for (int i = 0; i < representationFormats.length; i++) {
+      Format format = adaptationSet.representations.get(representationIndices[i]).format;
+      if (maxHeightRepresentationFormat == null || format.height > maxHeight) {
+        maxHeightRepresentationFormat = format;
       }
+      maxWidth = Math.max(maxWidth, format.width);
+      maxHeight = Math.max(maxHeight, format.height);
+      representationFormats[i] = format;
+    }
+    Arrays.sort(representationFormats, new DecreasingBandwidthComparator());
+    long trackDurationUs = live ? C.UNKNOWN_TIME_US : manifest.duration * 1000;
+    String mediaMimeType = getMediaMimeType(maxHeightRepresentationFormat);
+    if (mediaMimeType == null) {
+      Log.w(TAG, "Skipped adaptive track (unknown media mime type)");
+      return;
+    }
+    MediaFormat trackFormat = getTrackFormat(adaptationSet.type, maxHeightRepresentationFormat,
+        mediaMimeType, trackDurationUs);
+    if (trackFormat == null) {
+      Log.w(TAG, "Skipped adaptive track (unknown media format)");
+      return;
+    }
+    tracks.add(new ExposedTrack(trackFormat.copyAsAdaptive(), adaptationSetIndex,
+        representationFormats, maxWidth, maxHeight));
+  }
+
+  @Override
+  public void fixedTrack(MediaPresentationDescription manifest, int periodIndex,
+      int adaptationSetIndex, int representationIndex) {
+    List<AdaptationSet> adaptationSets = manifest.getPeriod(periodIndex).adaptationSets;
+    AdaptationSet adaptationSet = adaptationSets.get(adaptationSetIndex);
+    Format representationFormat = adaptationSet.representations.get(representationIndex).format;
+    String mediaMimeType = getMediaMimeType(representationFormat);
+    if (mediaMimeType == null) {
+      Log.w(TAG, "Skipped track " + representationFormat.id + " (unknown media mime type)");
+      return;
+    }
+    MediaFormat trackFormat = getTrackFormat(adaptationSet.type, representationFormat,
+        mediaMimeType, manifest.dynamic ? C.UNKNOWN_TIME_US : manifest.duration * 1000);
+    if (trackFormat == null) {
+      Log.w(TAG, "Skipped track " + representationFormat.id + " (unknown media format)");
+      return;
+    }
+    tracks.add(new ExposedTrack(trackFormat, adaptationSetIndex, representationFormat));
+  }
+
+  // Private methods.
 
-      // it's possible that the live edge latency actually puts our latest position before
-      // the earliest position in the case of a DVR-like stream that's just starting up, so
-      // in that case just return the earliest position instead
-      latestSeekPosition = Math.max(earliestSeekPosition, liveEdgeTimestampUs - liveEdgeLatencyUs);
+  // Visible for testing.
+  /* package */ TimeRange getAvailableRange() {
+    return availableRange;
+  }
+
+  private static MediaPresentationDescription buildManifest(long durationMs,
+      int adaptationSetType, List<Representation> representations) {
+    AdaptationSet adaptationSet = new AdaptationSet(0, adaptationSetType, representations);
+    Period period = new Period(null, 0, Collections.singletonList(adaptationSet));
+    return new MediaPresentationDescription(-1, durationMs, -1, false, -1, -1, null, null,
+        Collections.singletonList(period));
+  }
+
+  private static MediaFormat getTrackFormat(int adaptationSetType, Format format,
+      String mediaMimeType, long durationUs) {
+    switch (adaptationSetType) {
+      case AdaptationSet.TYPE_VIDEO:
+        return MediaFormat.createVideoFormat(MediaFormat.NO_VALUE, mediaMimeType, format.bitrate,
+            MediaFormat.NO_VALUE, durationUs, format.width, format.height, null);
+      case AdaptationSet.TYPE_AUDIO:
+        return MediaFormat.createAudioFormat(MediaFormat.NO_VALUE, mediaMimeType, format.bitrate,
+            MediaFormat.NO_VALUE, durationUs, format.audioChannels, format.audioSamplingRate, null,
+            format.language);
+      case AdaptationSet.TYPE_TEXT:
+        return MediaFormat.createTextFormat(MediaFormat.NO_VALUE, mediaMimeType, format.bitrate,
+            durationUs, format.language);
+      default:
+        return null;
     }
+  }
 
-    TimeRange newSeekRange = new TimeRange(TimeRange.TYPE_SNAPSHOT, earliestSeekPosition,
-        latestSeekPosition);
-    if (seekRange == null || !seekRange.equals(newSeekRange)) {
-      seekRange = newSeekRange;
-      notifySeekRangeChanged(seekRange);
+  private static String getMediaMimeType(Format format) {
+    String formatMimeType = format.mimeType;
+    if (MimeTypes.isAudio(formatMimeType)) {
+      return getAudioMediaMimeType(format);
+    } else if (MimeTypes.isVideo(formatMimeType)) {
+      return getVideoMediaMimeType(format);
+    } else if (mimeTypeIsRawText(formatMimeType)) {
+      return formatMimeType;
+    } else if (MimeTypes.APPLICATION_MP4.equals(formatMimeType) && "stpp".equals(format.codecs)) {
+      return MimeTypes.APPLICATION_TTML;
+    } else {
+      return null;
+    }
+  }
+
+  private static String getVideoMediaMimeType(Format format) {
+    String codecs = format.codecs;
+    if (TextUtils.isEmpty(codecs)) {
+      Log.w(TAG, "Codecs attribute missing: " + format.id);
+      return MimeTypes.VIDEO_UNKNOWN;
+    } else if (codecs.startsWith("avc1") || codecs.startsWith("avc3")) {
+      return MimeTypes.VIDEO_H264;
+    } else if (codecs.startsWith("hev1") || codecs.startsWith("hvc1")) {
+      return MimeTypes.VIDEO_H265;
+    } else if (codecs.startsWith("vp9")) {
+      return MimeTypes.VIDEO_VP9;
+    } else if (codecs.startsWith("vp8")) {
+      return MimeTypes.VIDEO_VP8;
     }
+    Log.w(TAG, "Failed to parse mime from codecs: " + format.id + ", " + codecs);
+    return MimeTypes.VIDEO_UNKNOWN;
   }
 
-  private static boolean mimeTypeIsWebm(String mimeType) {
-    return mimeType.startsWith(MimeTypes.VIDEO_WEBM) || mimeType.startsWith(MimeTypes.AUDIO_WEBM);
+  private static String getAudioMediaMimeType(Format format) {
+    String codecs = format.codecs;
+    if (TextUtils.isEmpty(codecs)) {
+      Log.w(TAG, "Codecs attribute missing: " + format.id);
+      return MimeTypes.AUDIO_UNKNOWN;
+    } else if (codecs.startsWith("mp4a")) {
+      return MimeTypes.AUDIO_AAC;
+    } else if (codecs.startsWith("ac-3") || codecs.startsWith("dac3")) {
+      return MimeTypes.AUDIO_AC3;
+    } else if (codecs.startsWith("ec-3") || codecs.startsWith("dec3")) {
+      return MimeTypes.AUDIO_EC3;
+    } else if (codecs.startsWith("dtsc") || codecs.startsWith("dtse")) {
+      return MimeTypes.AUDIO_DTS;
+    } else if (codecs.startsWith("dtsh") || codecs.startsWith("dtsl")) {
+      return MimeTypes.AUDIO_DTS_HD;
+    } else if (codecs.startsWith("opus")) {
+      return MimeTypes.AUDIO_OPUS;
+    }
+    Log.w(TAG, "Failed to parse mime from codecs: " + format.id + ", " + codecs);
+    return MimeTypes.AUDIO_UNKNOWN;
+  }
+
+  /* package */ static boolean mimeTypeIsWebm(String mimeType) {
+    return mimeType.startsWith(MimeTypes.VIDEO_WEBM) || mimeType.startsWith(MimeTypes.AUDIO_WEBM)
+        || mimeType.startsWith(MimeTypes.APPLICATION_WEBM);
+  }
+
+  /* package */ static boolean mimeTypeIsRawText(String mimeType) {
+    return MimeTypes.TEXT_VTT.equals(mimeType) || MimeTypes.APPLICATION_TTML.equals(mimeType);
   }
 
   private Chunk newInitializationChunk(RangedUri initializationUri, RangedUri indexUri,
       Representation representation, ChunkExtractorWrapper extractor, DataSource dataSource,
-      int trigger) {
+      int manifestIndex, int trigger) {
     RangedUri requestUri;
     if (initializationUri != null) {
       // It's common for initialization and index data to be stored adjacently. Attempt to merge
@@ -623,48 +702,35 @@ private Chunk newInitializationChunk(RangedUri initializationUri, RangedUri inde
     }
     DataSpec dataSpec = new DataSpec(requestUri.getUri(), requestUri.start, requestUri.length,
         representation.getCacheKey());
-    return new InitializationChunk(dataSource, dataSpec, trigger, representation.format, extractor);
+    return new InitializationChunk(dataSource, dataSpec, trigger, representation.format,
+        extractor, manifestIndex);
   }
 
-  private Chunk newMediaChunk(RepresentationHolder representationHolder, DataSource dataSource,
-      int segmentNum, int trigger) {
+  private Chunk newMediaChunk(PeriodHolder periodHolder, RepresentationHolder representationHolder,
+      DataSource dataSource, MediaFormat mediaFormat, int segmentNum, int trigger) {
     Representation representation = representationHolder.representation;
-    DashSegmentIndex segmentIndex = representationHolder.segmentIndex;
-
-    long startTimeUs = segmentIndex.getTimeUs(segmentNum);
-    long endTimeUs = startTimeUs + segmentIndex.getDurationUs(segmentNum);
-
-    int absoluteSegmentNum = segmentNum + representationHolder.segmentNumShift;
-    boolean isLastSegment = !currentManifest.dynamic
-        && segmentNum == segmentIndex.getLastSegmentNum();
-
-    RangedUri segmentUri = segmentIndex.getSegmentUrl(segmentNum);
+    Format format = representation.format;
+    long startTimeUs = representationHolder.getSegmentStartTimeUs(segmentNum);
+    long endTimeUs = representationHolder.getSegmentEndTimeUs(segmentNum);
+    RangedUri segmentUri = representationHolder.getSegmentUrl(segmentNum);
     DataSpec dataSpec = new DataSpec(segmentUri.getUri(), segmentUri.start, segmentUri.length,
         representation.getCacheKey());
 
-    long sampleOffsetUs = representation.periodStartMs * 1000
-        - representation.presentationTimeOffsetUs;
-    if (representation.format.mimeType.equals(MimeTypes.TEXT_VTT)) {
-      if (representationHolder.vttHeaderOffsetUs != sampleOffsetUs) {
-        // Update the VTT header.
-        headerBuilder.setLength(0);
-        headerBuilder.append(C.WEBVTT_EXO_HEADER).append("=")
-            .append(C.WEBVTT_EXO_HEADER_OFFSET).append(sampleOffsetUs)
-            .append("\n");
-        representationHolder.vttHeader = headerBuilder.toString().getBytes();
-        representationHolder.vttHeaderOffsetUs = sampleOffsetUs;
-      }
-      return new SingleSampleMediaChunk(dataSource, dataSpec, Chunk.TRIGGER_INITIAL,
-          representation.format, startTimeUs, endTimeUs, absoluteSegmentNum, isLastSegment,
-          MediaFormat.createTextFormat(MimeTypes.TEXT_VTT), null, representationHolder.vttHeader);
+    long sampleOffsetUs = periodHolder.startTimeUs - representation.presentationTimeOffsetUs;
+    if (mimeTypeIsRawText(format.mimeType)) {
+      return new SingleSampleMediaChunk(dataSource, dataSpec, Chunk.TRIGGER_INITIAL, format,
+          startTimeUs, endTimeUs, segmentNum, enabledTrack.trackFormat, null,
+          periodHolder.localIndex);
     } else {
-      return new ContainerMediaChunk(dataSource, dataSpec, trigger, representation.format,
-          startTimeUs, endTimeUs, absoluteSegmentNum, isLastSegment, sampleOffsetUs,
-          representationHolder.extractorWrapper, representationHolder.format, drmInitData, true);
+      boolean isMediaFormatFinal = (mediaFormat != null);
+      return new ContainerMediaChunk(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs,
+          segmentNum, sampleOffsetUs, representationHolder.extractorWrapper, mediaFormat,
+          enabledTrack.adaptiveMaxWidth, enabledTrack.adaptiveMaxHeight, periodHolder.drmInitData,
+          isMediaFormatFinal, periodHolder.localIndex);
     }
   }
 
-  private long getNowUs() {
+  private long getNowUnixTimeUs() {
     if (elapsedRealtimeOffsetUs != 0) {
       return (systemClock.elapsedRealtime() * 1000) + elapsedRealtimeOffsetUs;
     } else {
@@ -672,82 +738,374 @@ private long getNowUs() {
     }
   }
 
-  private static Representation[] getFilteredRepresentations(MediaPresentationDescription manifest,
-      int adaptationSetIndex, int[] representationIndices) {
-    AdaptationSet adaptationSet = manifest.periods.get(0).adaptationSets.get(adaptationSetIndex);
-    List<Representation> representations = adaptationSet.representations;
-    if (representationIndices == null) {
-      Representation[] filteredRepresentations = new Representation[representations.size()];
-      representations.toArray(filteredRepresentations);
-      return filteredRepresentations;
-    } else {
-      Representation[] filteredRepresentations = new Representation[representationIndices.length];
-      for (int i = 0; i < representationIndices.length; i++) {
-        filteredRepresentations[i] = representations.get(representationIndices[i]);
+  private PeriodHolder findPeriodHolder(long positionUs) {
+    // if positionUs is before the first period, return the first period
+    if (positionUs < periodHolders.valueAt(0).getAvailableStartTimeUs()) {
+      return periodHolders.valueAt(0);
+    }
+
+    for (int i = 0; i < periodHolders.size() - 1; i++) {
+      PeriodHolder periodHolder = periodHolders.valueAt(i);
+      if (positionUs < periodHolder.getAvailableEndTimeUs()) {
+        return periodHolder;
       }
-      return filteredRepresentations;
     }
+
+    // positionUs is within or after the last period
+    return periodHolders.valueAt(periodHolders.size() - 1);
   }
 
-  private static DrmInitData getDrmInitData(MediaPresentationDescription manifest,
-      int adaptationSetIndex) {
-    AdaptationSet adaptationSet = manifest.periods.get(0).adaptationSets.get(adaptationSetIndex);
-    String drmInitMimeType = mimeTypeIsWebm(adaptationSet.representations.get(0).format.mimeType)
-        ? MimeTypes.VIDEO_WEBM : MimeTypes.VIDEO_MP4;
-    if (adaptationSet.contentProtections.isEmpty()) {
-      return null;
-    } else {
-      DrmInitData.Mapped drmInitData = null;
-      for (ContentProtection contentProtection : adaptationSet.contentProtections) {
-        if (contentProtection.uuid != null && contentProtection.data != null) {
-          if (drmInitData == null) {
-            drmInitData = new DrmInitData.Mapped(drmInitMimeType);
-          }
-          drmInitData.put(contentProtection.uuid, contentProtection.data);
+  private void processManifest(MediaPresentationDescription manifest) {
+    // Remove old periods.
+    Period firstPeriod = manifest.getPeriod(0);
+    while (periodHolders.size() > 0
+        && periodHolders.valueAt(0).startTimeUs < firstPeriod.startMs * 1000) {
+      PeriodHolder periodHolder = periodHolders.valueAt(0);
+      // TODO: Use periodHolders.removeAt(0) if the minimum API level is ever increased to 11.
+      periodHolders.remove(periodHolder.localIndex);
+    }
+
+    // Update existing periods. Only the first and last periods can change.
+    try {
+      int periodHolderCount = periodHolders.size();
+      if (periodHolderCount > 0) {
+        periodHolders.valueAt(0).updatePeriod(manifest, 0, enabledTrack);
+        if (periodHolderCount > 1) {
+          int lastIndex = periodHolderCount - 1;
+          periodHolders.valueAt(lastIndex).updatePeriod(manifest, lastIndex, enabledTrack);
         }
       }
-      return drmInitData;
+    } catch (BehindLiveWindowException e) {
+      fatalError = e;
+      return;
+    }
+
+    // Add new periods.
+    for (int i = periodHolders.size(); i < manifest.getPeriodCount(); i++) {
+      PeriodHolder holder = new PeriodHolder(nextPeriodHolderIndex, manifest, i, enabledTrack);
+      periodHolders.put(nextPeriodHolderIndex, holder);
+      nextPeriodHolderIndex++;
+    }
+
+    // Update the available range.
+    TimeRange newAvailableRange = getAvailableRange(getNowUnixTimeUs());
+    if (availableRange == null || !availableRange.equals(newAvailableRange)) {
+      availableRange = newAvailableRange;
+      notifyAvailableRangeChanged(availableRange);
     }
+
+    currentManifest = manifest;
   }
 
-  private static MediaPresentationDescription buildManifest(List<Representation> representations) {
-    Representation firstRepresentation = representations.get(0);
-    AdaptationSet adaptationSet = new AdaptationSet(0, AdaptationSet.TYPE_UNKNOWN, representations);
-    Period period = new Period(null, firstRepresentation.periodStartMs,
-        firstRepresentation.periodDurationMs, Collections.singletonList(adaptationSet));
-    long duration = firstRepresentation.periodDurationMs - firstRepresentation.periodStartMs;
-    return new MediaPresentationDescription(-1, duration, -1, false, -1, -1, null, null,
-        Collections.singletonList(period));
+  private TimeRange getAvailableRange(long nowUnixTimeUs) {
+    PeriodHolder firstPeriod = periodHolders.valueAt(0);
+    PeriodHolder lastPeriod = periodHolders.valueAt(periodHolders.size() - 1);
+
+    if (!currentManifest.dynamic || lastPeriod.isIndexExplicit()) {
+      return new StaticTimeRange(firstPeriod.getAvailableStartTimeUs(),
+          lastPeriod.getAvailableEndTimeUs());
+    }
+
+    long minStartPositionUs = firstPeriod.getAvailableStartTimeUs();
+    long maxEndPositionUs = lastPeriod.isIndexUnbounded() ? Long.MAX_VALUE
+        : lastPeriod.getAvailableEndTimeUs();
+    long elapsedRealtimeAtZeroUs = (systemClock.elapsedRealtime() * 1000)
+        - (nowUnixTimeUs - (currentManifest.availabilityStartTime * 1000));
+    long timeShiftBufferDepthUs = currentManifest.timeShiftBufferDepth == -1 ? -1
+        : currentManifest.timeShiftBufferDepth * 1000;
+    return new DynamicTimeRange(minStartPositionUs, maxEndPositionUs, elapsedRealtimeAtZeroUs,
+        timeShiftBufferDepthUs, systemClock);
   }
 
-  private void notifySeekRangeChanged(final TimeRange seekRange) {
+  private void notifyAvailableRangeChanged(final TimeRange seekRange) {
     if (eventHandler != null && eventListener != null) {
       eventHandler.post(new Runnable() {
         @Override
         public void run() {
-          eventListener.onSeekRangeChanged(seekRange);
+          eventListener.onAvailableRangeChanged(seekRange);
         }
       });
     }
   }
 
-  private static class RepresentationHolder {
+  // Private classes.
+
+  private static final class ExposedTrack {
+
+    public final MediaFormat trackFormat;
+
+    private final int adaptationSetIndex;
+
+    // Non-adaptive track variables.
+    private final Format fixedFormat;
+
+    // Adaptive track variables.
+    private final Format[] adaptiveFormats;
+    private final int adaptiveMaxWidth;
+    private final int adaptiveMaxHeight;
+
+    public ExposedTrack(MediaFormat trackFormat, int adaptationSetIndex, Format fixedFormat) {
+      this.trackFormat = trackFormat;
+      this.adaptationSetIndex = adaptationSetIndex;
+      this.fixedFormat = fixedFormat;
+      this.adaptiveFormats = null;
+      this.adaptiveMaxWidth = -1;
+      this.adaptiveMaxHeight = -1;
+    }
+
+    public ExposedTrack(MediaFormat trackFormat, int adaptationSetIndex, Format[] adaptiveFormats,
+        int maxWidth, int maxHeight) {
+      this.trackFormat = trackFormat;
+      this.adaptationSetIndex = adaptationSetIndex;
+      this.adaptiveFormats = adaptiveFormats;
+      this.adaptiveMaxWidth = maxWidth;
+      this.adaptiveMaxHeight = maxHeight;
+      this.fixedFormat = null;
+    }
+
+    public boolean isAdaptive() {
+      return adaptiveFormats != null;
+    }
+
+  }
+
+  private static final class RepresentationHolder {
 
-    public final Representation representation;
     public final ChunkExtractorWrapper extractorWrapper;
 
+    public Representation representation;
     public DashSegmentIndex segmentIndex;
-    public MediaFormat format;
+    public MediaFormat mediaFormat;
 
-    public int segmentNumShift;
-    public long vttHeaderOffsetUs;
-    public byte[] vttHeader;
+    private final long periodStartTimeUs;
 
-    public RepresentationHolder(Representation representation,
-        ChunkExtractorWrapper extractorWrapper) {
+    private long periodDurationUs;
+    private int segmentNumShift;
+
+    public RepresentationHolder(long periodStartTimeUs, long periodDurationUs,
+        Representation representation) {
+      this.periodStartTimeUs = periodStartTimeUs;
+      this.periodDurationUs = periodDurationUs;
       this.representation = representation;
-      this.extractorWrapper = extractorWrapper;
-      this.segmentIndex = representation.getIndex();
+      String mimeType = representation.format.mimeType;
+      extractorWrapper = mimeTypeIsRawText(mimeType) ? null : new ChunkExtractorWrapper(
+          mimeTypeIsWebm(mimeType) ? new WebmExtractor() : new FragmentedMp4Extractor());
+      segmentIndex = representation.getIndex();
+    }
+
+    public void updateRepresentation(long newPeriodDurationUs, Representation newRepresentation)
+        throws BehindLiveWindowException{
+      DashSegmentIndex oldIndex = representation.getIndex();
+      DashSegmentIndex newIndex = newRepresentation.getIndex();
+
+      periodDurationUs = newPeriodDurationUs;
+      representation = newRepresentation;
+      if (oldIndex == null) {
+        // Segment numbers cannot shift if the index isn't defined by the manifest.
+        return;
+      }
+
+      segmentIndex = newIndex;
+      if (!oldIndex.isExplicit()) {
+        // Segment numbers cannot shift if the index isn't explicit.
+        return;
+      }
+
+      int oldIndexLastSegmentNum = oldIndex.getLastSegmentNum(periodDurationUs);
+      long oldIndexEndTimeUs = oldIndex.getTimeUs(oldIndexLastSegmentNum)
+          + oldIndex.getDurationUs(oldIndexLastSegmentNum, periodDurationUs);
+      int newIndexFirstSegmentNum = newIndex.getFirstSegmentNum();
+      long newIndexStartTimeUs = newIndex.getTimeUs(newIndexFirstSegmentNum);
+      if (oldIndexEndTimeUs == newIndexStartTimeUs) {
+        // The new index continues where the old one ended, with no overlap.
+        segmentNumShift += oldIndex.getLastSegmentNum(periodDurationUs) + 1
+            - newIndexFirstSegmentNum;
+      } else if (oldIndexEndTimeUs < newIndexStartTimeUs) {
+        // There's a gap between the old index and the new one which means we've slipped behind the
+        // live window and can't proceed.
+        throw new BehindLiveWindowException();
+      } else {
+        // The new index overlaps with the old one.
+        segmentNumShift += oldIndex.getSegmentNum(newIndexStartTimeUs, periodDurationUs)
+            - newIndexFirstSegmentNum;
+      }
+    }
+
+    public int getSegmentNum(long positionUs) {
+      return segmentIndex.getSegmentNum(positionUs - periodStartTimeUs, periodDurationUs)
+          + segmentNumShift;
+    }
+
+    public long getSegmentStartTimeUs(int segmentNum) {
+      return segmentIndex.getTimeUs(segmentNum - segmentNumShift) + periodStartTimeUs;
+    }
+
+    public long getSegmentEndTimeUs(int segmentNum) {
+      return getSegmentStartTimeUs(segmentNum)
+          + segmentIndex.getDurationUs(segmentNum - segmentNumShift, periodDurationUs);
+    }
+
+    public boolean isLastSegment(int segmentNum) {
+      int lastSegmentNum = segmentIndex.getLastSegmentNum(periodDurationUs);
+      return lastSegmentNum == DashSegmentIndex.INDEX_UNBOUNDED ? false
+          : segmentNum == (lastSegmentNum + segmentNumShift);
+    }
+
+    public int getFirstAvailableSegmentNum() {
+      return segmentIndex.getFirstSegmentNum() + segmentNumShift;
+    }
+
+    public RangedUri getSegmentUrl(int segmentNum) {
+      return segmentIndex.getSegmentUrl(segmentNum - segmentNumShift);
+    }
+
+  }
+
+  private static final class PeriodHolder {
+
+    public final int localIndex;
+    public final long startTimeUs;
+    public final HashMap<String, RepresentationHolder> representationHolders;
+
+    private final int[] representationIndices;
+
+    private DrmInitData drmInitData;
+
+    private boolean indexIsUnbounded;
+    private boolean indexIsExplicit;
+    private long availableStartTimeUs;
+    private long availableEndTimeUs;
+
+    public PeriodHolder(int localIndex, MediaPresentationDescription manifest, int manifestIndex,
+        ExposedTrack selectedTrack) {
+      this.localIndex = localIndex;
+
+      Period period = manifest.getPeriod(manifestIndex);
+      long periodDurationUs = getPeriodDurationUs(manifest, manifestIndex);
+      AdaptationSet adaptationSet = period.adaptationSets.get(selectedTrack.adaptationSetIndex);
+      List<Representation> representations = adaptationSet.representations;
+
+      startTimeUs = period.startMs * 1000;
+      drmInitData = getDrmInitData(adaptationSet);
+
+      if (!selectedTrack.isAdaptive()) {
+        representationIndices = new int[] {
+            getRepresentationIndex(representations, selectedTrack.fixedFormat.id)};
+      } else {
+        representationIndices = new int[selectedTrack.adaptiveFormats.length];
+        for (int j = 0; j < selectedTrack.adaptiveFormats.length; j++) {
+          representationIndices[j] = getRepresentationIndex(
+              representations, selectedTrack.adaptiveFormats[j].id);
+        }
+      }
+
+      representationHolders = new HashMap<>();
+      for (int i = 0; i < representationIndices.length; i++) {
+        Representation representation = representations.get(representationIndices[i]);
+        RepresentationHolder representationHolder = new RepresentationHolder(startTimeUs,
+            periodDurationUs, representation);
+        representationHolders.put(representation.format.id, representationHolder);
+      }
+      updateRepresentationIndependentProperties(periodDurationUs,
+          representations.get(representationIndices[0]));
+    }
+
+    public void updatePeriod(MediaPresentationDescription manifest, int manifestIndex,
+        ExposedTrack selectedTrack) throws BehindLiveWindowException {
+      Period period = manifest.getPeriod(manifestIndex);
+      long periodDurationUs = getPeriodDurationUs(manifest, manifestIndex);
+      List<Representation> representations = period.adaptationSets
+          .get(selectedTrack.adaptationSetIndex).representations;
+
+      for (int j = 0; j < representationIndices.length; j++) {
+        Representation representation = representations.get(representationIndices[j]);
+        representationHolders.get(representation.format.id).updateRepresentation(periodDurationUs,
+            representation);
+      }
+      updateRepresentationIndependentProperties(periodDurationUs,
+          representations.get(representationIndices[0]));
+    }
+
+    public long getAvailableStartTimeUs() {
+      return availableStartTimeUs;
+    }
+
+    public long getAvailableEndTimeUs() {
+      if (isIndexUnbounded()) {
+        throw new IllegalStateException("Period has unbounded index");
+      }
+      return availableEndTimeUs;
+    }
+
+    public boolean isIndexUnbounded() {
+      return indexIsUnbounded;
+    }
+
+    public boolean isIndexExplicit() {
+      return indexIsExplicit;
+    }
+
+    // Private methods.
+
+    private void updateRepresentationIndependentProperties(long periodDurationUs,
+        Representation arbitaryRepresentation) {
+      DashSegmentIndex segmentIndex = arbitaryRepresentation.getIndex();
+      if (segmentIndex != null) {
+        int firstSegmentNum = segmentIndex.getFirstSegmentNum();
+        int lastSegmentNum = segmentIndex.getLastSegmentNum(periodDurationUs);
+        indexIsUnbounded = lastSegmentNum == DashSegmentIndex.INDEX_UNBOUNDED;
+        indexIsExplicit = segmentIndex.isExplicit();
+        availableStartTimeUs = startTimeUs + segmentIndex.getTimeUs(firstSegmentNum);
+        if (!indexIsUnbounded) {
+          availableEndTimeUs = startTimeUs + segmentIndex.getTimeUs(lastSegmentNum)
+              + segmentIndex.getDurationUs(lastSegmentNum, periodDurationUs);
+        }
+      } else {
+        indexIsUnbounded = false;
+        indexIsExplicit = true;
+        availableStartTimeUs = startTimeUs;
+        availableEndTimeUs = startTimeUs + periodDurationUs;
+      }
+    }
+
+    private static int getRepresentationIndex(List<Representation> representations,
+        String formatId) {
+      for (int i = 0; i < representations.size(); i++) {
+        Representation representation = representations.get(i);
+        if (formatId.equals(representation.format.id)) {
+          return i;
+        }
+      }
+      throw new IllegalStateException("Missing format id: " + formatId);
+    }
+
+    private static DrmInitData getDrmInitData(AdaptationSet adaptationSet) {
+      String drmInitMimeType = mimeTypeIsWebm(adaptationSet.representations.get(0).format.mimeType)
+          ? MimeTypes.VIDEO_WEBM : MimeTypes.VIDEO_MP4;
+      if (adaptationSet.contentProtections.isEmpty()) {
+        return null;
+      } else {
+        DrmInitData.Mapped drmInitData = null;
+        for (int i = 0; i < adaptationSet.contentProtections.size(); i++) {
+          ContentProtection contentProtection = adaptationSet.contentProtections.get(i);
+          if (contentProtection.uuid != null && contentProtection.data != null) {
+            if (drmInitData == null) {
+              drmInitData = new DrmInitData.Mapped(drmInitMimeType);
+            }
+            drmInitData.put(contentProtection.uuid, contentProtection.data);
+          }
+        }
+        return drmInitData;
+      }
+    }
+
+    private static long getPeriodDurationUs(MediaPresentationDescription manifest, int index) {
+      long durationMs = manifest.getPeriodDuration(index);
+      if (durationMs == -1) {
+        return C.UNKNOWN_TIME_US;
+      } else {
+        return durationMs * 1000;
+      }
     }
 
   }
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/DashSegmentIndex.java b/library/src/main/java/com/google/android/exoplayer/dash/DashSegmentIndex.java
index e922757e13..95de1cd0d9 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/DashSegmentIndex.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/DashSegmentIndex.java
@@ -15,6 +15,7 @@
  */
 package com.google.android.exoplayer.dash;
 
+import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.dash.mpd.RangedUri;
 
 /**
@@ -24,20 +25,22 @@
  */
 public interface DashSegmentIndex {
 
-  public static final int INDEX_UNBOUNDED = -1;
+  int INDEX_UNBOUNDED = -1;
 
   /**
    * Returns the segment number of the segment containing a given media time.
    * <p>
    * If the given media time is outside the range of the index, then the returned segment number is
    * clamped to {@link #getFirstSegmentNum()} (if the given media time is earlier the start of the
-   * first segment) or {@link #getLastSegmentNum()} (if the given media time is later then the end
-   * of the last segment).
+   * first segment) or {@link #getLastSegmentNum(long)} (if the given media time is later then the
+   * end of the last segment).
    *
    * @param timeUs The time in microseconds.
+   * @param periodDurationUs The duration of the enclosing period in microseconds, or
+   *     {@link C#UNKNOWN_TIME_US} if the period's duration is not yet known.
    * @return The segment number of the corresponding segment.
    */
-  int getSegmentNum(long timeUs);
+  int getSegmentNum(long timeUs, long periodDurationUs);
 
   /**
    * Returns the start time of a segment.
@@ -51,9 +54,11 @@
    * Returns the duration of a segment.
    *
    * @param segmentNum The segment number.
+   * @param periodDurationUs The duration of the enclosing period in microseconds, or
+   *     {@link C#UNKNOWN_TIME_US} if the period's duration is not yet known.
    * @return The duration of the segment, in microseconds.
    */
-  long getDurationUs(int segmentNum);
+  long getDurationUs(int segmentNum, long periodDurationUs);
 
   /**
    * Returns a {@link RangedUri} defining the location of a segment.
@@ -73,15 +78,15 @@
   /**
    * Returns the segment number of the last segment, or {@link #INDEX_UNBOUNDED}.
    * <p>
-   * An unbounded index occurs if a live stream manifest uses SegmentTemplate elements without a
-   * SegmentTimeline element. In this case the manifest can be used to derive information about
-   * segments arbitrarily far into the future. This means that the manifest does not need to be
-   * refreshed as frequently (if at all) during playback, however it is necessary for a player to
-   * manually calculate the window of currently available segments.
+   * An unbounded index occurs if a dynamic manifest uses SegmentTemplate elements without a
+   * SegmentTimeline element, and if the period duration is not yet known. In this case the caller
+   * must manually determine the window of currently available segments.
    *
+   * @param periodDurationUs The duration of the enclosing period in microseconds, or
+   *     {@link C#UNKNOWN_TIME_US} if the period's duration is not yet known.
    * @return The segment number of the last segment, or {@link #INDEX_UNBOUNDED}.
    */
-  int getLastSegmentNum();
+  int getLastSegmentNum(long periodDurationUs);
 
   /**
    * Returns true if segments are defined explicitly by the index.
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/DashTrackSelector.java b/library/src/main/java/com/google/android/exoplayer/dash/DashTrackSelector.java
new file mode 100644
index 0000000000..3b7fb6fec1
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/dash/DashTrackSelector.java
@@ -0,0 +1,71 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.dash;
+
+import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
+import com.google.android.exoplayer.dash.mpd.Period;
+
+import java.io.IOException;
+
+/**
+ * Specifies a track selection from a {@link Period} of a media presentation description.
+ */
+public interface DashTrackSelector {
+
+  /**
+   * Defines a selector output.
+   */
+  interface Output {
+
+    /**
+     * Outputs an adaptive track, covering the specified representations in the specified
+     * adaptation set.
+     *
+     * @param manifest The media presentation description being processed.
+     * @param periodIndex The index of the period being processed.
+     * @param adaptationSetIndex The index of the adaptation set within which the representations
+     *     are located.
+     * @param representationIndices The indices of the track within the element.
+     */
+    void adaptiveTrack(MediaPresentationDescription manifest, int periodIndex,
+        int adaptationSetIndex, int[] representationIndices);
+
+    /**
+     * Outputs an fixed track corresponding to the specified representation in the specified
+     * adaptation set.
+     * 
+     * @param manifest The media presentation description being processed.
+     * @param periodIndex The index of the period being processed.
+     * @param adaptationSetIndex The index of the adaptation set within which the track is located.
+     * @param representationIndex The index of the representation within the adaptation set.
+     */
+    void fixedTrack(MediaPresentationDescription manifest, int periodIndex, int adaptationSetIndex,
+        int representationIndex);
+
+  }
+
+  /**
+   * Outputs a track selection for a given period.
+   *
+   * @param manifest the media presentation description to process.
+   * @param periodIndex The index of the period to process.
+   * @param output The output to receive tracks.
+   * @throws IOException If an error occurs processing the period.
+   */
+  void selectTracks(MediaPresentationDescription manifest, int periodIndex, Output output)
+      throws IOException;
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/DashWrappingSegmentIndex.java b/library/src/main/java/com/google/android/exoplayer/dash/DashWrappingSegmentIndex.java
index bcff061458..5542232e08 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/DashWrappingSegmentIndex.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/DashWrappingSegmentIndex.java
@@ -26,17 +26,14 @@
 
   private final ChunkIndex chunkIndex;
   private final String uri;
-  private final long startTimeUs;
 
   /**
    * @param chunkIndex The {@link ChunkIndex} to wrap.
    * @param uri The URI where the data is located.
-   * @param startTimeUs The start time of the index, in microseconds.
    */
-  public DashWrappingSegmentIndex(ChunkIndex chunkIndex, String uri, long startTimeUs) {
+  public DashWrappingSegmentIndex(ChunkIndex chunkIndex, String uri) {
     this.chunkIndex = chunkIndex;
     this.uri = uri;
-    this.startTimeUs = startTimeUs;
   }
 
   @Override
@@ -45,17 +42,17 @@ public int getFirstSegmentNum() {
   }
 
   @Override
-  public int getLastSegmentNum() {
+  public int getLastSegmentNum(long periodDurationUs) {
     return chunkIndex.length - 1;
   }
 
   @Override
   public long getTimeUs(int segmentNum) {
-    return chunkIndex.timesUs[segmentNum] + startTimeUs;
+    return chunkIndex.timesUs[segmentNum];
   }
 
   @Override
-  public long getDurationUs(int segmentNum) {
+  public long getDurationUs(int segmentNum, long periodDurationUs) {
     return chunkIndex.durationsUs[segmentNum];
   }
 
@@ -65,8 +62,8 @@ public RangedUri getSegmentUrl(int segmentNum) {
   }
 
   @Override
-  public int getSegmentNum(long timeUs) {
-    return chunkIndex.getChunkIndex(timeUs - startTimeUs);
+  public int getSegmentNum(long timeUs, long periodDurationUs) {
+    return chunkIndex.getChunkIndex(timeUs);
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/DefaultDashTrackSelector.java b/library/src/main/java/com/google/android/exoplayer/dash/DefaultDashTrackSelector.java
new file mode 100644
index 0000000000..eb6ba09206
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/dash/DefaultDashTrackSelector.java
@@ -0,0 +1,103 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.dash;
+
+import com.google.android.exoplayer.chunk.VideoFormatSelectorUtil;
+import com.google.android.exoplayer.dash.mpd.AdaptationSet;
+import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
+import com.google.android.exoplayer.dash.mpd.Period;
+import com.google.android.exoplayer.util.Util;
+
+import android.content.Context;
+
+import java.io.IOException;
+
+/**
+ * A default {@link DashTrackSelector} implementation.
+ */
+// TODO: Add more configuration options (e.g. ability to disable adaptive track output).
+public final class DefaultDashTrackSelector implements DashTrackSelector {
+
+  private final int adaptationSetType;
+
+  private final Context context;
+  private final boolean filterVideoRepresentations;
+  private final boolean filterProtectedHdContent;
+
+  /**
+   * @param context A context. May be null if {@code filterVideoRepresentations == false}.
+   * @param filterVideoRepresentations Whether video representations should be filtered according to
+   *     the capabilities of the device. It is strongly recommended to set this to {@code true},
+   *     unless the application has already verified that all representations are playable.
+   * @param filterProtectedHdContent Whether video representations that are both drm protected and
+   *     high definition should be filtered when tracks are built. If
+   *     {@code filterVideoRepresentations == false} then this parameter is ignored.
+   */
+  public static DefaultDashTrackSelector newVideoInstance(Context context,
+      boolean filterVideoRepresentations, boolean filterProtectedHdContent) {
+    return new DefaultDashTrackSelector(AdaptationSet.TYPE_VIDEO, context,
+        filterVideoRepresentations, filterProtectedHdContent);
+  }
+
+  public static DefaultDashTrackSelector newAudioInstance() {
+    return new DefaultDashTrackSelector(AdaptationSet.TYPE_AUDIO, null, false, false);
+  }
+
+  public static DefaultDashTrackSelector newTextInstance() {
+    return new DefaultDashTrackSelector(AdaptationSet.TYPE_TEXT, null, false, false);
+  }
+
+  private DefaultDashTrackSelector(int adaptationSetType, Context context,
+      boolean filterVideoRepresentations, boolean filterProtectedHdContent) {
+    this.adaptationSetType = adaptationSetType;
+    this.context = context;
+    this.filterVideoRepresentations = filterVideoRepresentations;
+    this.filterProtectedHdContent = filterProtectedHdContent;
+  }
+
+  @Override
+  public void selectTracks(MediaPresentationDescription manifest, int periodIndex, Output output)
+      throws IOException {
+    Period period = manifest.getPeriod(periodIndex);
+    for (int i = 0; i < period.adaptationSets.size(); i++) {
+      AdaptationSet adaptationSet = period.adaptationSets.get(i);
+      if (adaptationSet.type == adaptationSetType) {
+        if (adaptationSetType == AdaptationSet.TYPE_VIDEO) {
+          int[] representations;
+          if (filterVideoRepresentations) {
+            representations = VideoFormatSelectorUtil.selectVideoFormatsForDefaultDisplay(
+                context, adaptationSet.representations, null,
+                filterProtectedHdContent && adaptationSet.hasContentProtection());
+          } else {
+            representations = Util.firstIntegersArray(adaptationSet.representations.size());
+          }
+          int representationCount = representations.length;
+          if (representationCount > 1) {
+            output.adaptiveTrack(manifest, periodIndex, i, representations);
+          }
+          for (int j = 0; j < representationCount; j++) {
+            output.fixedTrack(manifest, periodIndex, i, representations[j]);
+          }
+        } else {
+          for (int j = 0; j < adaptationSet.representations.size(); j++) {
+            output.fixedTrack(manifest, periodIndex, i, j);
+          }
+        }
+      }
+    }
+  }
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/DashSingleSegmentIndex.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/DashSingleSegmentIndex.java
index 9b8f6b276c..fe8db6ffbd 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/DashSingleSegmentIndex.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/DashSingleSegmentIndex.java
@@ -22,34 +22,28 @@
  */
 /* package */ final class DashSingleSegmentIndex implements DashSegmentIndex {
 
-  private final long startTimeUs;
-  private final long durationUs;
   private final RangedUri uri;
 
   /**
-   * @param startTimeUs The start time of the segment, in microseconds.
-   * @param durationUs The duration of the segment, in microseconds.
    * @param uri A {@link RangedUri} defining the location of the segment data.
    */
-  public DashSingleSegmentIndex(long startTimeUs, long durationUs, RangedUri uri) {
-    this.startTimeUs = startTimeUs;
-    this.durationUs = durationUs;
+  public DashSingleSegmentIndex(RangedUri uri) {
     this.uri = uri;
   }
 
   @Override
-  public int getSegmentNum(long timeUs) {
+  public int getSegmentNum(long timeUs, long periodDurationUs) {
     return 0;
   }
 
   @Override
   public long getTimeUs(int segmentNum) {
-    return startTimeUs;
+    return 0;
   }
 
   @Override
-  public long getDurationUs(int segmentNum) {
-    return durationUs;
+  public long getDurationUs(int segmentNum, long periodDurationUs) {
+    return periodDurationUs;
   }
 
   @Override
@@ -63,7 +57,7 @@ public int getFirstSegmentNum() {
   }
 
   @Override
-  public int getLastSegmentNum() {
+  public int getLastSegmentNum(long periodDurationUs) {
     return 0;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescription.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescription.java
index f3c2cf4ae2..4b0b94754d 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescription.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescription.java
@@ -41,7 +41,7 @@
 
   public final String location;
 
-  public final List<Period> periods;
+  private final List<Period> periods;
 
   public MediaPresentationDescription(long availabilityStartTime, long duration, long minBufferTime,
       boolean dynamic, long minUpdatePeriod, long timeShiftBufferDepth, UtcTimingElement utcTiming,
@@ -54,12 +54,26 @@ public MediaPresentationDescription(long availabilityStartTime, long duration, l
     this.timeShiftBufferDepth = timeShiftBufferDepth;
     this.utcTiming = utcTiming;
     this.location = location;
-    this.periods = Collections.unmodifiableList(periods);
+    this.periods = periods == null ? Collections.<Period>emptyList() : periods;
   }
 
   @Override
-  public String getNextManifestUri() {
+  public final String getNextManifestUri() {
     return location;
   }
 
+  public final int getPeriodCount() {
+    return periods.size();
+  }
+
+  public final Period getPeriod(int index) {
+    return periods.get(index);
+  }
+
+  public final long getPeriodDuration(int index) {
+    return index == periods.size() - 1
+        ? (duration == -1 ? -1 : duration - periods.get(index).startMs)
+        : periods.get(index + 1).startMs - periods.get(index).startMs;
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescriptionParser.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescriptionParser.java
index 0f0c8a5058..517fea235d 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescriptionParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/MediaPresentationDescriptionParser.java
@@ -25,11 +25,13 @@
 import com.google.android.exoplayer.upstream.UriLoadable;
 import com.google.android.exoplayer.util.Assertions;
 import com.google.android.exoplayer.util.MimeTypes;
+import com.google.android.exoplayer.util.ParserUtil;
 import com.google.android.exoplayer.util.UriUtil;
 import com.google.android.exoplayer.util.Util;
 
 import android.text.TextUtils;
 import android.util.Base64;
+import android.util.Pair;
 
 import org.xml.sax.helpers.DefaultHandler;
 import org.xmlpull.v1.XmlPullParser;
@@ -114,18 +116,48 @@ protected MediaPresentationDescription parseMediaPresentationDescription(XmlPull
     String location = null;
 
     List<Period> periods = new ArrayList<>();
+    long nextPeriodStartMs = dynamic ? -1 : 0;
+    boolean seenEarlyAccessPeriod = false;
+    boolean seenFirstBaseUrl = false;
     do {
       xpp.next();
-      if (isStartTag(xpp, "BaseURL")) {
-        baseUrl = parseBaseUrl(xpp, baseUrl);
-      } else if (isStartTag(xpp, "UTCTiming")) {
+      if (ParserUtil.isStartTag(xpp, "BaseURL")) {
+        if (!seenFirstBaseUrl) {
+          baseUrl = parseBaseUrl(xpp, baseUrl);
+          seenFirstBaseUrl = true;
+        }
+      } else if (ParserUtil.isStartTag(xpp, "UTCTiming")) {
         utcTiming = parseUtcTiming(xpp);
-      } else if (isStartTag(xpp, "Period")) {
-        periods.add(parsePeriod(xpp, baseUrl, durationMs));
-      } else if (isStartTag(xpp, "Location")) {
+      } else if (ParserUtil.isStartTag(xpp, "Location")) {
         location = xpp.nextText();
+      } else if (ParserUtil.isStartTag(xpp, "Period") && !seenEarlyAccessPeriod) {
+        Pair<Period, Long> periodWithDurationMs = parsePeriod(xpp, baseUrl, nextPeriodStartMs);
+        Period period = periodWithDurationMs.first;
+        if (period.startMs == -1) {
+          if (dynamic) {
+            // This is an early access period. Ignore it. All subsequent periods must also be
+            // early access.
+            seenEarlyAccessPeriod = true;
+          } else {
+            throw new ParserException("Unable to determine start of period " + periods.size());
+          }
+        } else {
+          long periodDurationMs = periodWithDurationMs.second;
+          nextPeriodStartMs = periodDurationMs == -1 ? -1 : period.startMs + periodDurationMs;
+          periods.add(period);
+        }
       }
-    } while (!isEndTag(xpp, "MPD"));
+    } while (!ParserUtil.isEndTag(xpp, "MPD"));
+
+    if (!dynamic && durationMs == -1) {
+      // The manifest is static and doesn't define a duration. This is unexpected.
+      if (nextPeriodStartMs != -1) {
+        // If we know the end time of the final period, we can use it as the duration.
+        durationMs = nextPeriodStartMs;
+      } else {
+        throw new ParserException("Unable to determine duration of static manifest.");
+      }
+    }
 
     return buildMediaPresentationDescription(availabilityStartTime, durationMs, minBufferTimeMs,
         dynamic, minUpdateTimeMs, timeShiftBufferDepthMs, utcTiming, location, periods);
@@ -149,80 +181,89 @@ protected UtcTimingElement buildUtcTimingElement(String schemeIdUri, String valu
     return new UtcTimingElement(schemeIdUri, value);
   }
 
-  protected Period parsePeriod(XmlPullParser xpp, String baseUrl, long mpdDurationMs)
+  protected Pair<Period, Long> parsePeriod(XmlPullParser xpp, String baseUrl, long defaultStartMs)
       throws XmlPullParserException, IOException {
     String id = xpp.getAttributeValue(null, "id");
-    long startMs = parseDuration(xpp, "start", 0);
-    long durationMs = parseDuration(xpp, "duration", mpdDurationMs);
+    long startMs = parseDuration(xpp, "start", defaultStartMs);
+    long durationMs = parseDuration(xpp, "duration", -1);
     SegmentBase segmentBase = null;
     List<AdaptationSet> adaptationSets = new ArrayList<>();
+    boolean seenFirstBaseUrl = false;
     do {
       xpp.next();
-      if (isStartTag(xpp, "BaseURL")) {
-        baseUrl = parseBaseUrl(xpp, baseUrl);
-      } else if (isStartTag(xpp, "AdaptationSet")) {
-        adaptationSets.add(parseAdaptationSet(xpp, baseUrl, startMs, durationMs,
-            segmentBase));
-      } else if (isStartTag(xpp, "SegmentBase")) {
+      if (ParserUtil.isStartTag(xpp, "BaseURL")) {
+        if (!seenFirstBaseUrl) {
+          baseUrl = parseBaseUrl(xpp, baseUrl);
+          seenFirstBaseUrl = true;
+        }
+      } else if (ParserUtil.isStartTag(xpp, "AdaptationSet")) {
+        adaptationSets.add(parseAdaptationSet(xpp, baseUrl, segmentBase));
+      } else if (ParserUtil.isStartTag(xpp, "SegmentBase")) {
         segmentBase = parseSegmentBase(xpp, baseUrl, null);
-      } else if (isStartTag(xpp, "SegmentList")) {
-        segmentBase = parseSegmentList(xpp, baseUrl, null, durationMs);
-      } else if (isStartTag(xpp, "SegmentTemplate")) {
-        segmentBase = parseSegmentTemplate(xpp, baseUrl, null, durationMs);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentList")) {
+        segmentBase = parseSegmentList(xpp, baseUrl, null);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentTemplate")) {
+        segmentBase = parseSegmentTemplate(xpp, baseUrl, null);
       }
-    } while (!isEndTag(xpp, "Period"));
+    } while (!ParserUtil.isEndTag(xpp, "Period"));
 
-    return buildPeriod(id, startMs, durationMs, adaptationSets);
+    return Pair.create(buildPeriod(id, startMs, adaptationSets), durationMs);
   }
 
-  protected Period buildPeriod(
-      String id, long startMs, long durationMs, List<AdaptationSet> adaptationSets) {
-    return new Period(id, startMs, durationMs, adaptationSets);
+  protected Period buildPeriod(String id, long startMs, List<AdaptationSet> adaptationSets) {
+    return new Period(id, startMs, adaptationSets);
   }
 
   // AdaptationSet parsing.
 
-  protected AdaptationSet parseAdaptationSet(XmlPullParser xpp, String baseUrl, long periodStartMs,
-      long periodDurationMs, SegmentBase segmentBase) throws XmlPullParserException, IOException {
-
+  protected AdaptationSet parseAdaptationSet(XmlPullParser xpp, String baseUrl,
+      SegmentBase segmentBase) throws XmlPullParserException, IOException {
     int id = parseInt(xpp, "id", -1);
+    int contentType = parseContentType(xpp);
+
     String mimeType = xpp.getAttributeValue(null, "mimeType");
+    String codecs = xpp.getAttributeValue(null, "codecs");
+    int width = parseInt(xpp, "width", -1);
+    int height = parseInt(xpp, "height", -1);
+    float frameRate = parseFrameRate(xpp, -1);
+    int audioChannels = -1;
+    int audioSamplingRate = parseInt(xpp, "audioSamplingRate", -1);
     String language = xpp.getAttributeValue(null, "lang");
-    int contentType = parseAdaptationSetType(xpp.getAttributeValue(null, "contentType"));
-    if (contentType == AdaptationSet.TYPE_UNKNOWN) {
-      contentType = parseAdaptationSetTypeFromMimeType(xpp.getAttributeValue(null, "mimeType"));
-    }
 
     ContentProtectionsBuilder contentProtectionsBuilder = new ContentProtectionsBuilder();
     List<Representation> representations = new ArrayList<>();
+    boolean seenFirstBaseUrl = false;
     do {
       xpp.next();
-      if (isStartTag(xpp, "BaseURL")) {
-        baseUrl = parseBaseUrl(xpp, baseUrl);
-      } else if (isStartTag(xpp, "ContentProtection")) {
+      if (ParserUtil.isStartTag(xpp, "BaseURL")) {
+        if (!seenFirstBaseUrl) {
+          baseUrl = parseBaseUrl(xpp, baseUrl);
+          seenFirstBaseUrl = true;
+        }
+      } else if (ParserUtil.isStartTag(xpp, "ContentProtection")) {
         contentProtectionsBuilder.addAdaptationSetProtection(parseContentProtection(xpp));
-      } else if (isStartTag(xpp, "ContentComponent")) {
+      } else if (ParserUtil.isStartTag(xpp, "ContentComponent")) {
         language = checkLanguageConsistency(language, xpp.getAttributeValue(null, "lang"));
-        contentType = checkAdaptationSetTypeConsistency(contentType,
-            parseAdaptationSetType(xpp.getAttributeValue(null, "contentType")));
-      } else if (isStartTag(xpp, "Representation")) {
-        Representation representation = parseRepresentation(xpp, baseUrl, periodStartMs,
-            periodDurationMs, mimeType, language, segmentBase, contentProtectionsBuilder);
+        contentType = checkContentTypeConsistency(contentType, parseContentType(xpp));
+      } else if (ParserUtil.isStartTag(xpp, "Representation")) {
+        Representation representation = parseRepresentation(xpp, baseUrl, mimeType, codecs, width,
+            height, frameRate, audioChannels, audioSamplingRate, language, segmentBase,
+            contentProtectionsBuilder);
         contentProtectionsBuilder.endRepresentation();
-        contentType = checkAdaptationSetTypeConsistency(contentType,
-            parseAdaptationSetTypeFromMimeType(representation.format.mimeType));
+        contentType = checkContentTypeConsistency(contentType, getContentType(representation));
         representations.add(representation);
-      } else if (isStartTag(xpp, "SegmentBase")) {
+      } else if (ParserUtil.isStartTag(xpp, "AudioChannelConfiguration")) {
+        audioChannels = parseAudioChannelConfiguration(xpp);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentBase")) {
         segmentBase = parseSegmentBase(xpp, baseUrl, (SingleSegmentBase) segmentBase);
-      } else if (isStartTag(xpp, "SegmentList")) {
-        segmentBase = parseSegmentList(xpp, baseUrl, (SegmentList) segmentBase, periodDurationMs);
-      } else if (isStartTag(xpp, "SegmentTemplate")) {
-        segmentBase = parseSegmentTemplate(xpp, baseUrl, (SegmentTemplate) segmentBase,
-            periodDurationMs);
-      } else if (isStartTag(xpp)) {
+      } else if (ParserUtil.isStartTag(xpp, "SegmentList")) {
+        segmentBase = parseSegmentList(xpp, baseUrl, (SegmentList) segmentBase);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentTemplate")) {
+        segmentBase = parseSegmentTemplate(xpp, baseUrl, (SegmentTemplate) segmentBase);
+      } else if (ParserUtil.isStartTag(xpp)) {
         parseAdaptationSetChild(xpp);
       }
-    } while (!isEndTag(xpp, "AdaptationSet"));
+    } while (!ParserUtil.isEndTag(xpp, "AdaptationSet"));
 
     return buildAdaptationSet(id, contentType, representations, contentProtectionsBuilder.build());
   }
@@ -232,7 +273,8 @@ protected AdaptationSet buildAdaptationSet(int id, int contentType,
     return new AdaptationSet(id, contentType, representations, contentProtections);
   }
 
-  protected int parseAdaptationSetType(String contentType) {
+  protected int parseContentType(XmlPullParser xpp) {
+    String contentType = xpp.getAttributeValue(null, "contentType");
     return TextUtils.isEmpty(contentType) ? AdaptationSet.TYPE_UNKNOWN
         : MimeTypes.BASE_TYPE_AUDIO.equals(contentType) ? AdaptationSet.TYPE_AUDIO
         : MimeTypes.BASE_TYPE_VIDEO.equals(contentType) ? AdaptationSet.TYPE_VIDEO
@@ -240,12 +282,25 @@ protected int parseAdaptationSetType(String contentType) {
         : AdaptationSet.TYPE_UNKNOWN;
   }
 
-  protected int parseAdaptationSetTypeFromMimeType(String mimeType) {
-    return TextUtils.isEmpty(mimeType) ? AdaptationSet.TYPE_UNKNOWN
-        : MimeTypes.isAudio(mimeType) ? AdaptationSet.TYPE_AUDIO
-        : MimeTypes.isVideo(mimeType) ? AdaptationSet.TYPE_VIDEO
-        : MimeTypes.isText(mimeType) || MimeTypes.isTtml(mimeType) ? AdaptationSet.TYPE_TEXT
-        : AdaptationSet.TYPE_UNKNOWN;
+  protected int getContentType(Representation representation) {
+    String mimeType = representation.format.mimeType;
+    if (TextUtils.isEmpty(mimeType)) {
+      return AdaptationSet.TYPE_UNKNOWN;
+    } else if (MimeTypes.isVideo(mimeType)) {
+      return AdaptationSet.TYPE_VIDEO;
+    } else if (MimeTypes.isAudio(mimeType)) {
+      return AdaptationSet.TYPE_AUDIO;
+    } else if (MimeTypes.isText(mimeType) || MimeTypes.APPLICATION_TTML.equals(mimeType)) {
+      return AdaptationSet.TYPE_TEXT;
+    } else if (MimeTypes.APPLICATION_MP4.equals(mimeType)) {
+      // The representation uses mp4 but does not contain video or audio. Use codecs to determine
+      // whether the container holds text.
+      String codecs = representation.format.codecs;
+      if ("stpp".equals(codecs) || "wvtt".equals(codecs)) {
+        return AdaptationSet.TYPE_TEXT;
+      }
+    }
+    return AdaptationSet.TYPE_UNKNOWN;
   }
 
   /**
@@ -262,14 +317,14 @@ protected ContentProtection parseContentProtection(XmlPullParser xpp)
     do {
       xpp.next();
       // The cenc:pssh element is defined in 23001-7:2015
-      if (isStartTag(xpp, "cenc:pssh") && xpp.next() == XmlPullParser.TEXT) {
+      if (ParserUtil.isStartTag(xpp, "cenc:pssh") && xpp.next() == XmlPullParser.TEXT) {
         psshAtom = Base64.decode(xpp.getText(), Base64.DEFAULT);
         uuid = PsshAtomUtil.parseUuid(psshAtom);
         if (uuid == null) {
           throw new ParserException("Invalid pssh atom in cenc:pssh element");
         }
       }
-    } while (!isEndTag(xpp, "ContentProtection"));
+    } while (!ParserUtil.isEndTag(xpp, "ContentProtection"));
 
     return buildContentProtection(schemeIdUri, uuid, psshAtom);
   }
@@ -293,68 +348,59 @@ protected void parseAdaptationSetChild(XmlPullParser xpp)
   // Representation parsing.
 
   protected Representation parseRepresentation(XmlPullParser xpp, String baseUrl,
-      long periodStartMs, long periodDurationMs, String mimeType, String language,
-      SegmentBase segmentBase, ContentProtectionsBuilder contentProtectionsBuilder)
+      String adaptationSetMimeType, String adaptationSetCodecs, int adaptationSetWidth,
+      int adaptationSetHeight, float adaptationSetFrameRate, int adaptationSetAudioChannels,
+      int adaptationSetAudioSamplingRate, String adaptationSetLanguage, SegmentBase segmentBase,
+      ContentProtectionsBuilder contentProtectionsBuilder)
       throws XmlPullParserException, IOException {
     String id = xpp.getAttributeValue(null, "id");
     int bandwidth = parseInt(xpp, "bandwidth");
-    int audioSamplingRate = parseInt(xpp, "audioSamplingRate");
-    int width = parseInt(xpp, "width");
-    int height = parseInt(xpp, "height");
-
-    float frameRate = -1;
-    String frameRateAttribute = xpp.getAttributeValue(null, "frameRate");
-    if (frameRateAttribute != null) {
-      Matcher frameRateMatcher = FRAME_RATE_PATTERN.matcher(frameRateAttribute);
-      if (frameRateMatcher.matches()) {
-        int numerator = Integer.parseInt(frameRateMatcher.group(1));
-        String denominatorString = frameRateMatcher.group(2);
-        if (!TextUtils.isEmpty(denominatorString)) {
-          frameRate = (float) numerator / Integer.parseInt(denominatorString);
-        } else {
-          frameRate = numerator;
-        }
-      }
-    }
 
-    mimeType = parseString(xpp, "mimeType", mimeType);
-    String codecs = parseString(xpp, "codecs", null);
+    String mimeType = parseString(xpp, "mimeType", adaptationSetMimeType);
+    String codecs = parseString(xpp, "codecs", adaptationSetCodecs);
+    int width = parseInt(xpp, "width", adaptationSetWidth);
+    int height = parseInt(xpp, "height", adaptationSetHeight);
+    float frameRate = parseFrameRate(xpp, adaptationSetFrameRate);
+    int audioChannels = adaptationSetAudioChannels;
+    int audioSamplingRate = parseInt(xpp, "audioSamplingRate", adaptationSetAudioSamplingRate);
+    String language = adaptationSetLanguage;
 
-    int numChannels = -1;
+    boolean seenFirstBaseUrl = false;
     do {
       xpp.next();
-      if (isStartTag(xpp, "BaseURL")) {
-        baseUrl = parseBaseUrl(xpp, baseUrl);
-      } else if (isStartTag(xpp, "AudioChannelConfiguration")) {
-        numChannels = Integer.parseInt(xpp.getAttributeValue(null, "value"));
-      } else if (isStartTag(xpp, "SegmentBase")) {
+      if (ParserUtil.isStartTag(xpp, "BaseURL")) {
+        if (!seenFirstBaseUrl) {
+          baseUrl = parseBaseUrl(xpp, baseUrl);
+          seenFirstBaseUrl = true;
+        }
+      } else if (ParserUtil.isStartTag(xpp, "AudioChannelConfiguration")) {
+        audioChannels = parseAudioChannelConfiguration(xpp);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentBase")) {
         segmentBase = parseSegmentBase(xpp, baseUrl, (SingleSegmentBase) segmentBase);
-      } else if (isStartTag(xpp, "SegmentList")) {
-        segmentBase = parseSegmentList(xpp, baseUrl, (SegmentList) segmentBase, periodDurationMs);
-      } else if (isStartTag(xpp, "SegmentTemplate")) {
-        segmentBase = parseSegmentTemplate(xpp, baseUrl, (SegmentTemplate) segmentBase,
-            periodDurationMs);
-      } else if (isStartTag(xpp, "ContentProtection")) {
+      } else if (ParserUtil.isStartTag(xpp, "SegmentList")) {
+        segmentBase = parseSegmentList(xpp, baseUrl, (SegmentList) segmentBase);
+      } else if (ParserUtil.isStartTag(xpp, "SegmentTemplate")) {
+        segmentBase = parseSegmentTemplate(xpp, baseUrl, (SegmentTemplate) segmentBase);
+      } else if (ParserUtil.isStartTag(xpp, "ContentProtection")) {
         contentProtectionsBuilder.addRepresentationProtection(parseContentProtection(xpp));
       }
-    } while (!isEndTag(xpp, "Representation"));
+    } while (!ParserUtil.isEndTag(xpp, "Representation"));
 
-    Format format = buildFormat(id, mimeType, width, height, frameRate, numChannels,
+    Format format = buildFormat(id, mimeType, width, height, frameRate, audioChannels,
         audioSamplingRate, bandwidth, language, codecs);
-    return buildRepresentation(periodStartMs, periodDurationMs, contentId, -1, format,
+    return buildRepresentation(contentId, -1, format,
         segmentBase != null ? segmentBase : new SingleSegmentBase(baseUrl));
   }
 
   protected Format buildFormat(String id, String mimeType, int width, int height, float frameRate,
-      int numChannels, int audioSamplingRate, int bandwidth, String language, String codecs) {
-    return new Format(id, mimeType, width, height, frameRate, numChannels, audioSamplingRate,
+      int audioChannels, int audioSamplingRate, int bandwidth, String language, String codecs) {
+    return new Format(id, mimeType, width, height, frameRate, audioChannels, audioSamplingRate,
         bandwidth, language, codecs);
   }
 
-  protected Representation buildRepresentation(long periodStartMs, long periodDurationMs,
-      String contentId, int revisionId, Format format, SegmentBase segmentBase) {
-    return Representation.newInstance(periodStartMs, periodDurationMs, contentId, revisionId,
-        format, segmentBase);
+  protected Representation buildRepresentation(String contentId, int revisionId, Format format,
+      SegmentBase segmentBase) {
+    return Representation.newInstance(contentId, revisionId, format, segmentBase);
   }
 
   // SegmentBase, SegmentList and SegmentTemplate parsing.
@@ -378,10 +424,10 @@ protected SingleSegmentBase parseSegmentBase(XmlPullParser xpp, String baseUrl,
     RangedUri initialization = parent != null ? parent.initialization : null;
     do {
       xpp.next();
-      if (isStartTag(xpp, "Initialization")) {
+      if (ParserUtil.isStartTag(xpp, "Initialization")) {
         initialization = parseInitialization(xpp, baseUrl);
       }
-    } while (!isEndTag(xpp, "SegmentBase"));
+    } while (!ParserUtil.isEndTag(xpp, "SegmentBase"));
 
     return buildSingleSegmentBase(initialization, timescale, presentationTimeOffset, baseUrl,
         indexStart, indexLength);
@@ -393,8 +439,8 @@ protected SingleSegmentBase buildSingleSegmentBase(RangedUri initialization, lon
         indexStart, indexLength);
   }
 
-  protected SegmentList parseSegmentList(XmlPullParser xpp, String baseUrl, SegmentList parent,
-      long periodDurationMs) throws XmlPullParserException, IOException {
+  protected SegmentList parseSegmentList(XmlPullParser xpp, String baseUrl, SegmentList parent)
+      throws XmlPullParserException, IOException {
 
     long timescale = parseLong(xpp, "timescale", parent != null ? parent.timescale : 1);
     long presentationTimeOffset = parseLong(xpp, "presentationTimeOffset",
@@ -408,17 +454,17 @@ protected SegmentList parseSegmentList(XmlPullParser xpp, String baseUrl, Segmen
 
     do {
       xpp.next();
-      if (isStartTag(xpp, "Initialization")) {
+      if (ParserUtil.isStartTag(xpp, "Initialization")) {
         initialization = parseInitialization(xpp, baseUrl);
-      } else if (isStartTag(xpp, "SegmentTimeline")) {
+      } else if (ParserUtil.isStartTag(xpp, "SegmentTimeline")) {
         timeline = parseSegmentTimeline(xpp);
-      } else if (isStartTag(xpp, "SegmentURL")) {
+      } else if (ParserUtil.isStartTag(xpp, "SegmentURL")) {
         if (segments == null) {
           segments = new ArrayList<>();
         }
         segments.add(parseSegmentUrl(xpp, baseUrl));
       }
-    } while (!isEndTag(xpp, "SegmentList"));
+    } while (!ParserUtil.isEndTag(xpp, "SegmentList"));
 
     if (parent != null) {
       initialization = initialization != null ? initialization : parent.initialization;
@@ -426,19 +472,19 @@ protected SegmentList parseSegmentList(XmlPullParser xpp, String baseUrl, Segmen
       segments = segments != null ? segments : parent.mediaSegments;
     }
 
-    return buildSegmentList(initialization, timescale, presentationTimeOffset, periodDurationMs,
+    return buildSegmentList(initialization, timescale, presentationTimeOffset,
         startNumber, duration, timeline, segments);
   }
 
   protected SegmentList buildSegmentList(RangedUri initialization, long timescale,
-      long presentationTimeOffset, long periodDurationMs, int startNumber, long duration,
+      long presentationTimeOffset, int startNumber, long duration,
       List<SegmentTimelineElement> timeline, List<RangedUri> segments) {
-    return new SegmentList(initialization, timescale, presentationTimeOffset, periodDurationMs,
+    return new SegmentList(initialization, timescale, presentationTimeOffset,
         startNumber, duration, timeline, segments);
   }
 
   protected SegmentTemplate parseSegmentTemplate(XmlPullParser xpp, String baseUrl,
-      SegmentTemplate parent, long periodDurationMs) throws XmlPullParserException, IOException {
+      SegmentTemplate parent) throws XmlPullParserException, IOException {
 
     long timescale = parseLong(xpp, "timescale", parent != null ? parent.timescale : 1);
     long presentationTimeOffset = parseLong(xpp, "presentationTimeOffset",
@@ -455,27 +501,27 @@ protected SegmentTemplate parseSegmentTemplate(XmlPullParser xpp, String baseUrl
 
     do {
       xpp.next();
-      if (isStartTag(xpp, "Initialization")) {
+      if (ParserUtil.isStartTag(xpp, "Initialization")) {
         initialization = parseInitialization(xpp, baseUrl);
-      } else if (isStartTag(xpp, "SegmentTimeline")) {
+      } else if (ParserUtil.isStartTag(xpp, "SegmentTimeline")) {
         timeline = parseSegmentTimeline(xpp);
       }
-    } while (!isEndTag(xpp, "SegmentTemplate"));
+    } while (!ParserUtil.isEndTag(xpp, "SegmentTemplate"));
 
     if (parent != null) {
       initialization = initialization != null ? initialization : parent.initialization;
       timeline = timeline != null ? timeline : parent.segmentTimeline;
     }
 
-    return buildSegmentTemplate(initialization, timescale, presentationTimeOffset, periodDurationMs,
+    return buildSegmentTemplate(initialization, timescale, presentationTimeOffset,
         startNumber, duration, timeline, initializationTemplate, mediaTemplate, baseUrl);
   }
 
   protected SegmentTemplate buildSegmentTemplate(RangedUri initialization, long timescale,
-      long presentationTimeOffset, long periodDurationMs, int startNumber, long duration,
+      long presentationTimeOffset, int startNumber, long duration,
       List<SegmentTimelineElement> timeline, UrlTemplate initializationTemplate,
       UrlTemplate mediaTemplate, String baseUrl) {
-    return new SegmentTemplate(initialization, timescale, presentationTimeOffset, periodDurationMs,
+    return new SegmentTemplate(initialization, timescale, presentationTimeOffset,
         startNumber, duration, timeline, initializationTemplate, mediaTemplate, baseUrl);
   }
 
@@ -485,7 +531,7 @@ protected SegmentTemplate buildSegmentTemplate(RangedUri initialization, long ti
     long elapsedTime = 0;
     do {
       xpp.next();
-      if (isStartTag(xpp, "S")) {
+      if (ParserUtil.isStartTag(xpp, "S")) {
         elapsedTime = parseLong(xpp, "t", elapsedTime);
         long duration = parseLong(xpp, "d");
         int count = 1 + parseInt(xpp, "r", 0);
@@ -494,7 +540,7 @@ protected SegmentTemplate buildSegmentTemplate(RangedUri initialization, long ti
           elapsedTime += duration;
         }
       }
-    } while (!isEndTag(xpp, "SegmentTimeline"));
+    } while (!ParserUtil.isEndTag(xpp, "SegmentTimeline"));
     return segmentTimeline;
   }
 
@@ -540,6 +586,23 @@ protected RangedUri buildRangedUri(String baseUrl, String urlText, long rangeSta
     return new RangedUri(baseUrl, urlText, rangeStart, rangeLength);
   }
 
+  // AudioChannelConfiguration parsing.
+
+  protected int parseAudioChannelConfiguration(XmlPullParser xpp)
+      throws XmlPullParserException, IOException {
+    int audioChannels;
+    String schemeIdUri = parseString(xpp, "schemeIdUri", null);
+    if ("urn:mpeg:dash:23003:3:audio_channel_configuration:2011".equals(schemeIdUri)) {
+      audioChannels = parseInt(xpp, "value");
+    } else {
+      audioChannels = -1;
+    }
+    do {
+      xpp.next();
+    } while (!ParserUtil.isEndTag(xpp, "AudioChannelConfiguration"));
+    return audioChannels;
+  }
+
   // Utility methods.
 
   /**
@@ -564,8 +627,8 @@ private static String checkLanguageConsistency(String firstLanguage, String seco
   }
 
   /**
-   * Checks two adaptation set types for consistency, returning the consistent type, or throwing an
-   * {@link IllegalStateException} if the types are inconsistent.
+   * Checks two adaptation set content types for consistency, returning the consistent type, or
+   * throwing an {@link IllegalStateException} if the types are inconsistent.
    * <p>
    * Two types are consistent if they are equal, or if one is {@link AdaptationSet#TYPE_UNKNOWN}.
    * Where one of the types is {@link AdaptationSet#TYPE_UNKNOWN}, the other is returned.
@@ -574,7 +637,7 @@ private static String checkLanguageConsistency(String firstLanguage, String seco
    * @param secondType The second type.
    * @return The consistent type.
    */
-  private static int checkAdaptationSetTypeConsistency(int firstType, int secondType) {
+  private static int checkContentTypeConsistency(int firstType, int secondType) {
     if (firstType == AdaptationSet.TYPE_UNKNOWN) {
       return secondType;
     } else if (secondType == AdaptationSet.TYPE_UNKNOWN) {
@@ -585,17 +648,22 @@ private static int checkAdaptationSetTypeConsistency(int firstType, int secondTy
     }
   }
 
-  protected static boolean isEndTag(XmlPullParser xpp, String name) throws XmlPullParserException {
-    return xpp.getEventType() == XmlPullParser.END_TAG && name.equals(xpp.getName());
-  }
-
-  protected static boolean isStartTag(XmlPullParser xpp, String name)
-      throws XmlPullParserException {
-    return xpp.getEventType() == XmlPullParser.START_TAG && name.equals(xpp.getName());
-  }
-
-  protected static boolean isStartTag(XmlPullParser xpp) throws XmlPullParserException {
-    return xpp.getEventType() == XmlPullParser.START_TAG;
+  protected static float parseFrameRate(XmlPullParser xpp, float defaultValue) {
+    float frameRate = defaultValue;
+    String frameRateAttribute = xpp.getAttributeValue(null, "frameRate");
+    if (frameRateAttribute != null) {
+      Matcher frameRateMatcher = FRAME_RATE_PATTERN.matcher(frameRateAttribute);
+      if (frameRateMatcher.matches()) {
+        int numerator = Integer.parseInt(frameRateMatcher.group(1));
+        String denominatorString = frameRateMatcher.group(2);
+        if (!TextUtils.isEmpty(denominatorString)) {
+          frameRate = (float) numerator / Integer.parseInt(denominatorString);
+        } else {
+          frameRate = numerator;
+        }
+      }
+    }
+    return frameRate;
   }
 
   protected static long parseDuration(XmlPullParser xpp, String name, long defaultValue) {
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/Period.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/Period.java
index c1cc738661..f8398fdd3e 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/Period.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/Period.java
@@ -33,11 +33,6 @@
    */
   public final long startMs;
 
-  /**
-   * The duration of the period in milliseconds, or -1 if the duration is unknown.
-   */
-  public final long durationMs;
-
   /**
    * The adaptation sets belonging to the period.
    */
@@ -46,13 +41,11 @@
   /**
    * @param id The period identifier. May be null.
    * @param start The start time of the period in milliseconds.
-   * @param duration The duration of the period in milliseconds, or -1 if the duration is unknown.
    * @param adaptationSets The adaptation sets belonging to the period.
    */
-  public Period(String id, long start, long duration, List<AdaptationSet> adaptationSets) {
+  public Period(String id, long start, List<AdaptationSet> adaptationSets) {
     this.id = id;
     this.startMs = start;
-    this.durationMs = duration;
     this.adaptationSets = Collections.unmodifiableList(adaptationSets);
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/Representation.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/Representation.java
index 54c0d6913a..8c8778f3e2 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/Representation.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/Representation.java
@@ -35,7 +35,6 @@
    * {@link #contentId}, which should uniquely identify that video.
    */
   public final String contentId;
-
   /**
    * Identifies the revision of the content.
    * <p>
@@ -45,22 +44,10 @@
    * timestamp at which the media was encoded is often a suitable.
    */
   public final long revisionId;
-
   /**
    * The format of the representation.
    */
   public final Format format;
-
-  /**
-   * The start time of the enclosing period in milliseconds since the epoch.
-   */
-  public final long periodStartMs;
-
-  /**
-   * The duration of the enclosing period in milliseconds.
-   */
-  public final long periodDurationMs;
-
   /**
    * The offset of the presentation timestamps in the media stream relative to media time.
    */
@@ -71,33 +58,28 @@
   /**
    * Constructs a new instance.
    *
-   * @param periodStartMs The start time of the enclosing period in milliseconds.
-   * @param periodDurationMs The duration of the enclosing period in milliseconds, or -1 if the
-   *     duration is unknown.
    * @param contentId Identifies the piece of content to which this representation belongs.
    * @param revisionId Identifies the revision of the content.
    * @param format The format of the representation.
    * @param segmentBase A segment base element for the representation.
    * @return The constructed instance.
    */
-  public static Representation newInstance(long periodStartMs, long periodDurationMs,
-      String contentId, long revisionId, Format format, SegmentBase segmentBase) {
+  public static Representation newInstance(String contentId, long revisionId, Format format,
+      SegmentBase segmentBase) {
     if (segmentBase instanceof SingleSegmentBase) {
-      return new SingleSegmentRepresentation(periodStartMs, periodDurationMs, contentId, revisionId,
-          format, (SingleSegmentBase) segmentBase, -1);
+      return new SingleSegmentRepresentation(contentId, revisionId, format,
+          (SingleSegmentBase) segmentBase, -1);
     } else if (segmentBase instanceof MultiSegmentBase) {
-      return new MultiSegmentRepresentation(periodStartMs, periodDurationMs, contentId, revisionId,
-          format, (MultiSegmentBase) segmentBase);
+      return new MultiSegmentRepresentation(contentId, revisionId, format,
+          (MultiSegmentBase) segmentBase);
     } else {
       throw new IllegalArgumentException("segmentBase must be of type SingleSegmentBase or "
           + "MultiSegmentBase");
     }
   }
 
-  private Representation(long periodStartMs, long periodDurationMs, String contentId,
-      long revisionId, Format format, SegmentBase segmentBase) {
-    this.periodStartMs = periodStartMs;
-    this.periodDurationMs = periodDurationMs;
+  private Representation(String contentId, long revisionId, Format format,
+      SegmentBase segmentBase) {
     this.contentId = contentId;
     this.revisionId = revisionId;
     this.format = format;
@@ -165,9 +147,6 @@ public String getCacheKey() {
     private final DashSingleSegmentIndex segmentIndex;
 
     /**
-     * @param periodStartMs The start time of the enclosing period in milliseconds.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds, or -1 if the
-     *     duration is unknown.
      * @param contentId Identifies the piece of content to which this representation belongs.
      * @param revisionId Identifies the revision of the content.
      * @param format The format of the representation.
@@ -178,37 +157,34 @@ public String getCacheKey() {
      * @param indexEnd The offset of the last byte of index data.
      * @param contentLength The content length, or -1 if unknown.
      */
-    public static SingleSegmentRepresentation newInstance(long periodStartMs, long periodDurationMs,
-        String contentId, long revisionId, Format format, String uri, long initializationStart,
-        long initializationEnd, long indexStart, long indexEnd, long contentLength) {
+    public static SingleSegmentRepresentation newInstance(String contentId, long revisionId,
+        Format format, String uri, long initializationStart, long initializationEnd,
+        long indexStart, long indexEnd, long contentLength) {
       RangedUri rangedUri = new RangedUri(uri, null, initializationStart,
           initializationEnd - initializationStart + 1);
       SingleSegmentBase segmentBase = new SingleSegmentBase(rangedUri, 1, 0, uri, indexStart,
           indexEnd - indexStart + 1);
-      return new SingleSegmentRepresentation(periodStartMs, periodDurationMs, contentId, revisionId,
+      return new SingleSegmentRepresentation(contentId, revisionId,
           format, segmentBase, contentLength);
     }
 
     /**
-     * @param periodStartMs The start time of the enclosing period in milliseconds.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds, or -1 if the
-     *     duration is unknown.
      * @param contentId Identifies the piece of content to which this representation belongs.
      * @param revisionId Identifies the revision of the content.
      * @param format The format of the representation.
      * @param segmentBase The segment base underlying the representation.
      * @param contentLength The content length, or -1 if unknown.
      */
-    public SingleSegmentRepresentation(long periodStartMs, long periodDurationMs, String contentId,
-        long revisionId, Format format, SingleSegmentBase segmentBase, long contentLength) {
-      super(periodStartMs, periodDurationMs, contentId, revisionId, format, segmentBase);
+    public SingleSegmentRepresentation(String contentId, long revisionId, Format format,
+        SingleSegmentBase segmentBase, long contentLength) {
+      super(contentId, revisionId, format, segmentBase);
       this.uri = Uri.parse(segmentBase.uri);
       this.indexUri = segmentBase.getIndex();
       this.contentLength = contentLength;
       // If we have an index uri then the index is defined externally, and we shouldn't return one
       // directly. If we don't, then we can't do better than an index defining a single segment.
-      segmentIndex = indexUri != null ? null : new DashSingleSegmentIndex(periodStartMs * 1000,
-          periodDurationMs * 1000, new RangedUri(segmentBase.uri, null, 0, -1));
+      segmentIndex = indexUri != null ? null
+          : new DashSingleSegmentIndex(new RangedUri(segmentBase.uri, null, 0, contentLength));
     }
 
     @Override
@@ -232,17 +208,14 @@ public DashSegmentIndex getIndex() {
     private final MultiSegmentBase segmentBase;
 
     /**
-     * @param periodStartMs The start time of the enclosing period in milliseconds.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds, or -1 if the
-     *     duration is unknown.
      * @param contentId Identifies the piece of content to which this representation belongs.
      * @param revisionId Identifies the revision of the content.
      * @param format The format of the representation.
      * @param segmentBase The segment base underlying the representation.
      */
-    public MultiSegmentRepresentation(long periodStartMs, long periodDurationMs, String contentId,
-        long revisionId, Format format, MultiSegmentBase segmentBase) {
-      super(periodStartMs, periodDurationMs, contentId, revisionId, format, segmentBase);
+    public MultiSegmentRepresentation(String contentId, long revisionId, Format format,
+        MultiSegmentBase segmentBase) {
+      super(contentId, revisionId, format, segmentBase);
       this.segmentBase = segmentBase;
     }
 
@@ -264,18 +237,18 @@ public RangedUri getSegmentUrl(int segmentIndex) {
     }
 
     @Override
-    public int getSegmentNum(long timeUs) {
-      return segmentBase.getSegmentNum(timeUs - periodStartMs * 1000);
+    public int getSegmentNum(long timeUs, long periodDurationUs) {
+      return segmentBase.getSegmentNum(timeUs, periodDurationUs);
     }
 
     @Override
     public long getTimeUs(int segmentIndex) {
-      return segmentBase.getSegmentTimeUs(segmentIndex) + periodStartMs * 1000;
+      return segmentBase.getSegmentTimeUs(segmentIndex);
     }
 
     @Override
-    public long getDurationUs(int segmentIndex) {
-      return segmentBase.getSegmentDurationUs(segmentIndex);
+    public long getDurationUs(int segmentIndex, long periodDurationUs) {
+      return segmentBase.getSegmentDurationUs(segmentIndex, periodDurationUs);
     }
 
     @Override
@@ -284,8 +257,8 @@ public int getFirstSegmentNum() {
     }
 
     @Override
-    public int getLastSegmentNum() {
-      return segmentBase.getLastSegmentNum();
+    public int getLastSegmentNum(long periodDurationUs) {
+      return segmentBase.getLastSegmentNum(periodDurationUs);
     }
 
     @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/dash/mpd/SegmentBase.java b/library/src/main/java/com/google/android/exoplayer/dash/mpd/SegmentBase.java
index 6d55a01393..f770f304ba 100644
--- a/library/src/main/java/com/google/android/exoplayer/dash/mpd/SegmentBase.java
+++ b/library/src/main/java/com/google/android/exoplayer/dash/mpd/SegmentBase.java
@@ -112,7 +112,6 @@ public RangedUri getIndex() {
    */
   public abstract static class MultiSegmentBase extends SegmentBase {
 
-    /* package */ final long periodDurationMs;
     /* package */ final int startNumber;
     /* package */ final long duration;
     /* package */ final List<SegmentTimelineElement> segmentTimeline;
@@ -123,7 +122,6 @@ public RangedUri getIndex() {
      * @param timescale The timescale in units per second.
      * @param presentationTimeOffset The presentation time offset. The value in seconds is the
      *     division of this value and {@code timescale}.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds.
      * @param startNumber The sequence number of the first segment.
      * @param duration The duration of each segment in the case of fixed duration segments. The
      *     value in seconds is the division of this value and {@code timescale}. If
@@ -133,22 +131,20 @@ public RangedUri getIndex() {
      *     parameter.
      */
     public MultiSegmentBase(RangedUri initialization, long timescale, long presentationTimeOffset,
-        long periodDurationMs, int startNumber, long duration,
-        List<SegmentTimelineElement> segmentTimeline) {
+        int startNumber, long duration, List<SegmentTimelineElement> segmentTimeline) {
       super(initialization, timescale, presentationTimeOffset);
-      this.periodDurationMs = periodDurationMs;
       this.startNumber = startNumber;
       this.duration = duration;
       this.segmentTimeline = segmentTimeline;
     }
 
     /**
-     * @see DashSegmentIndex#getSegmentNum(long)
+     * @see DashSegmentIndex#getSegmentNum(long, long)
      */
-    public int getSegmentNum(long timeUs) {
+    public int getSegmentNum(long timeUs, long periodDurationUs) {
       final int firstSegmentNum = getFirstSegmentNum();
       int lowIndex = firstSegmentNum;
-      int highIndex = getLastSegmentNum();
+      int highIndex = getLastSegmentNum(periodDurationUs);
       if (segmentTimeline == null) {
         // All segments are of equal duration (with the possible exception of the last one).
         long durationUs = (duration * C.MICROS_PER_SECOND) / timescale;
@@ -175,15 +171,15 @@ public int getSegmentNum(long timeUs) {
     }
 
     /**
-     * @see DashSegmentIndex#getDurationUs(int)
+     * @see DashSegmentIndex#getDurationUs(int, long)
      */
-    public final long getSegmentDurationUs(int sequenceNumber) {
+    public final long getSegmentDurationUs(int sequenceNumber, long periodDurationUs) {
       if (segmentTimeline != null) {
         long duration = segmentTimeline.get(sequenceNumber - startNumber).duration;
         return (duration * C.MICROS_PER_SECOND) / timescale;
       } else {
-        return sequenceNumber == getLastSegmentNum()
-            ? ((periodDurationMs * 1000) - getSegmentTimeUs(sequenceNumber))
+        return sequenceNumber == getLastSegmentNum(periodDurationUs)
+            ? (periodDurationUs - getSegmentTimeUs(sequenceNumber))
             : ((duration * C.MICROS_PER_SECOND) / timescale);
       }
     }
@@ -218,9 +214,9 @@ public int getFirstSegmentNum() {
     }
 
     /**
-     * @see DashSegmentIndex#getLastSegmentNum()
+     * @see DashSegmentIndex#getLastSegmentNum(long)
      */
-    public abstract int getLastSegmentNum();
+    public abstract int getLastSegmentNum(long periodDurationUs);
 
     /**
      * @see DashSegmentIndex#isExplicit()
@@ -244,7 +240,6 @@ public boolean isExplicit() {
      * @param timescale The timescale in units per second.
      * @param presentationTimeOffset The presentation time offset. The value in seconds is the
      *     division of this value and {@code timescale}.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds.
      * @param startNumber The sequence number of the first segment.
      * @param duration The duration of each segment in the case of fixed duration segments. The
      *     value in seconds is the division of this value and {@code timescale}. If
@@ -255,10 +250,10 @@ public boolean isExplicit() {
      * @param mediaSegments A list of {@link RangedUri}s indicating the locations of the segments.
      */
     public SegmentList(RangedUri initialization, long timescale, long presentationTimeOffset,
-        long periodDurationMs, int startNumber, long duration,
-        List<SegmentTimelineElement> segmentTimeline, List<RangedUri> mediaSegments) {
-      super(initialization, timescale, presentationTimeOffset, periodDurationMs, startNumber,
-          duration, segmentTimeline);
+        int startNumber, long duration, List<SegmentTimelineElement> segmentTimeline,
+        List<RangedUri> mediaSegments) {
+      super(initialization, timescale, presentationTimeOffset, startNumber, duration,
+          segmentTimeline);
       this.mediaSegments = mediaSegments;
     }
 
@@ -268,7 +263,7 @@ public RangedUri getSegmentUrl(Representation representation, int sequenceNumber
     }
 
     @Override
-    public int getLastSegmentNum() {
+    public int getLastSegmentNum(long periodDurationUs) {
       return startNumber + mediaSegments.size() - 1;
     }
 
@@ -296,7 +291,6 @@ public boolean isExplicit() {
      * @param timescale The timescale in units per second.
      * @param presentationTimeOffset The presentation time offset. The value in seconds is the
      *     division of this value and {@code timescale}.
-     * @param periodDurationMs The duration of the enclosing period in milliseconds.
      * @param startNumber The sequence number of the first segment.
      * @param duration The duration of each segment in the case of fixed duration segments. The
      *     value in seconds is the division of this value and {@code timescale}. If
@@ -311,10 +305,9 @@ public boolean isExplicit() {
      * @param baseUrl A url to use as the base for relative urls generated by the templates.
      */
     public SegmentTemplate(RangedUri initialization, long timescale, long presentationTimeOffset,
-        long periodDurationMs, int startNumber, long duration,
-        List<SegmentTimelineElement> segmentTimeline, UrlTemplate initializationTemplate,
-        UrlTemplate mediaTemplate, String baseUrl) {
-      super(initialization, timescale, presentationTimeOffset, periodDurationMs, startNumber,
+        int startNumber, long duration, List<SegmentTimelineElement> segmentTimeline,
+        UrlTemplate initializationTemplate, UrlTemplate mediaTemplate, String baseUrl) {
+      super(initialization, timescale, presentationTimeOffset, startNumber,
           duration, segmentTimeline);
       this.initializationTemplate = initializationTemplate;
       this.mediaTemplate = mediaTemplate;
@@ -346,14 +339,14 @@ public RangedUri getSegmentUrl(Representation representation, int sequenceNumber
     }
 
     @Override
-    public int getLastSegmentNum() {
+    public int getLastSegmentNum(long periodDurationUs) {
       if (segmentTimeline != null) {
         return segmentTimeline.size() + startNumber - 1;
-      } else if (periodDurationMs == -1) {
+      } else if (periodDurationUs == C.UNKNOWN_TIME_US) {
         return DashSegmentIndex.INDEX_UNBOUNDED;
       } else {
-        long durationMs = (duration * 1000) / timescale;
-        return startNumber + (int) Util.ceilDivide(periodDurationMs, durationMs) - 1;
+        long durationUs = (duration * C.MICROS_PER_SECOND) / timescale;
+        return startNumber + (int) Util.ceilDivide(periodDurationUs, durationUs) - 1;
       }
     }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/drm/StreamingDrmSessionManager.java b/library/src/main/java/com/google/android/exoplayer/drm/StreamingDrmSessionManager.java
index 519a2b6987..6e42cea28d 100644
--- a/library/src/main/java/com/google/android/exoplayer/drm/StreamingDrmSessionManager.java
+++ b/library/src/main/java/com/google/android/exoplayer/drm/StreamingDrmSessionManager.java
@@ -50,6 +50,11 @@
    */
   public interface EventListener {
 
+    /**
+     * Invoked each time keys are loaded.
+     */
+    void onDrmKeysLoaded();
+
     /**
      * Invoked when a drm error occurs.
      *
@@ -259,7 +264,7 @@ public final void setPropertyByteArray(String key, byte[] value) {
   }
 
   @Override
-  public final void open(DrmInitData drmInitData) {
+  public void open(DrmInitData drmInitData) {
     if (++openCount != 1) {
       return;
     }
@@ -290,7 +295,7 @@ public final void open(DrmInitData drmInitData) {
   }
 
   @Override
-  public final void close() {
+  public void close() {
     if (--openCount != 0) {
       return;
     }
@@ -386,6 +391,14 @@ private void onKeyResponse(Object response) {
     try {
       mediaDrm.provideKeyResponse(sessionId, (byte[]) response);
       state = STATE_OPENED_WITH_KEYS;
+      if (eventHandler != null && eventListener != null) {
+        eventHandler.post(new Runnable() {
+          @Override
+          public void run() {
+            eventListener.onDrmKeysLoaded();
+          }
+        });
+      }
     } catch (Exception e) {
       onKeysError(e);
     }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ExtractorSampleSource.java b/library/src/main/java/com/google/android/exoplayer/extractor/ExtractorSampleSource.java
index 639c992b65..8f0bc4977b 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ExtractorSampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ExtractorSampleSource.java
@@ -22,7 +22,6 @@
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
 import com.google.android.exoplayer.SampleSource.SampleSourceReader;
-import com.google.android.exoplayer.TrackInfo;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.drm.DrmInitData;
 import com.google.android.exoplayer.upstream.Allocator;
@@ -93,7 +92,7 @@ public UnrecognizedInputFormatException(Extractor[] extractors) {
   public static final int DEFAULT_MIN_LOADABLE_RETRY_COUNT_LIVE = 6;
 
   private static final int MIN_RETRY_COUNT_DEFAULT_FOR_MEDIA = -1;
-  private static final int NO_RESET_PENDING = -1;
+  private static final long NO_RESET_PENDING = Long.MIN_VALUE;
 
   /**
    * Default extractor classes in priority order. They are referred to indirectly so that it is
@@ -163,7 +162,7 @@ public UnrecognizedInputFormatException(Extractor[] extractors) {
 
   private boolean prepared;
   private int enabledTrackCount;
-  private TrackInfo[] trackInfos;
+  private MediaFormat[] mediaFormats;
   private long maxTrackDurationUs;
   private boolean[] pendingMediaFormat;
   private boolean[] pendingDiscontinuities;
@@ -292,11 +291,11 @@ public boolean prepare(long positionUs) {
       trackEnabledStates = new boolean[trackCount];
       pendingDiscontinuities = new boolean[trackCount];
       pendingMediaFormat = new boolean[trackCount];
-      trackInfos = new TrackInfo[trackCount];
+      mediaFormats = new MediaFormat[trackCount];
       maxTrackDurationUs = C.UNKNOWN_TIME_US;
       for (int i = 0; i < trackCount; i++) {
         MediaFormat format = sampleQueues.valueAt(i).getFormat();
-        trackInfos[i] = new TrackInfo(format.mimeType, format.durationUs);
+        mediaFormats[i] = format;
         if (format.durationUs != C.UNKNOWN_TIME_US && format.durationUs > maxTrackDurationUs) {
           maxTrackDurationUs = format.durationUs;
         }
@@ -314,9 +313,9 @@ public int getTrackCount() {
   }
 
   @Override
-  public TrackInfo getTrackInfo(int track) {
+  public MediaFormat getFormat(int track) {
     Assertions.checkState(prepared);
-    return trackInfos[track];
+    return mediaFormats[track];
   }
 
   @Override
@@ -326,10 +325,14 @@ public void enable(int track, long positionUs) {
     enabledTrackCount++;
     trackEnabledStates[track] = true;
     pendingMediaFormat[track] = true;
+    pendingDiscontinuities[track] = false;
     if (enabledTrackCount == 1) {
-      seekToUs(positionUs);
+      // Treat all enables in non-seekable media as being from t=0.
+      positionUs = !seekMap.isSeekable() ? 0 : positionUs;
+      downstreamPositionUs = positionUs;
+      lastSeekPositionUs = positionUs;
+      restartFrom(positionUs);
     }
-    pendingDiscontinuities[track] = false;
   }
 
   @Override
@@ -431,10 +434,8 @@ public void maybeThrowError() throws IOException {
   public void seekToUs(long positionUs) {
     Assertions.checkState(prepared);
     Assertions.checkState(enabledTrackCount > 0);
-    if (!seekMap.isSeekable()) {
-      // Treat all seeks into non-seekable media as seeks to the start.
-      positionUs = 0;
-    }
+    // Treat all seeks into non-seekable media as being to t=0.
+    positionUs = !seekMap.isSeekable() ? 0 : positionUs;
 
     long currentPositionUs = isPendingReset() ? pendingResetPositionUs : downstreamPositionUs;
     downstreamPositionUs = positionUs;
@@ -573,11 +574,11 @@ private void maybeStartLoading() {
             sampleQueues.valueAt(i).clear();
           }
           loadable = createLoadableFromStart();
-        } else if (!seekMap.isSeekable()) {
-          // We're playing a non-seekable stream. Assume it's live, and therefore that the data at
-          // the uri is a continuously shifting window of the latest available media. For this case
-          // there's no way to continue loading from where a previous load finished, and hence it's
-          // necessary to load from the start whenever commencing a new load.
+        } else if (!seekMap.isSeekable() && maxTrackDurationUs == C.UNKNOWN_TIME_US) {
+          // We're playing a non-seekable stream with unknown duration. Assume it's live, and
+          // therefore that the data at the uri is a continuously shifting window of the latest
+          // available media. For this case there's no way to continue loading from where a previous
+          // load finished, so it's necessary to load from the start whenever commencing a new load.
           for (int i = 0; i < sampleQueues.size(); i++) {
             sampleQueues.valueAt(i).clear();
           }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/RollingSampleBuffer.java b/library/src/main/java/com/google/android/exoplayer/extractor/RollingSampleBuffer.java
index c6cdb8b1c4..4a349494b7 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/RollingSampleBuffer.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/RollingSampleBuffer.java
@@ -186,12 +186,8 @@ public boolean readSample(SampleHolder sampleHolder) {
       readEncryptionData(sampleHolder, extrasHolder);
     }
     // Write the sample data into the holder.
-    if (sampleHolder.data == null || sampleHolder.data.capacity() < sampleHolder.size) {
-      sampleHolder.replaceBuffer(sampleHolder.size);
-    }
-    if (sampleHolder.data != null) {
-      readData(extrasHolder.offset, sampleHolder.data, sampleHolder.size);
-    }
+    sampleHolder.ensureSpaceForWrite(sampleHolder.size);
+    readData(extrasHolder.offset, sampleHolder.data, sampleHolder.size);
     // Advance the read head.
     long nextOffset = infoQueue.moveToNextSample();
     dropDownstreamTo(nextOffset);
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp3/Mp3Extractor.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp3/Mp3Extractor.java
index 269030ca04..bbc717fd9e 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp3/Mp3Extractor.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp3/Mp3Extractor.java
@@ -48,6 +48,7 @@
   private static final int INFO_HEADER = Util.getIntegerCodeForString("Info");
   private static final int VBRI_HEADER = Util.getIntegerCodeForString("VBRI");
 
+  private final long forcedFirstSampleTimestampUs;
   private final BufferingInput inputBuffer;
   private final ParsableByteArray scratch;
   private final MpegAudioHeader synchronizedHeader;
@@ -63,28 +64,46 @@
   private int samplesRead;
   private int sampleBytesRemaining;
 
-  /** Constructs a new {@link Mp3Extractor}. */
+  /**
+   * Constructs a new {@link Mp3Extractor}.
+   */
   public Mp3Extractor() {
+    this(-1);
+  }
+
+  /**
+   * Constructs a new {@link Mp3Extractor}.
+   *
+   * @param forcedFirstSampleTimestampUs A timestamp to force for the first sample, or -1 if forcing
+   *     is not required.
+   */
+  public Mp3Extractor(long forcedFirstSampleTimestampUs) {
+    this.forcedFirstSampleTimestampUs = forcedFirstSampleTimestampUs;
     inputBuffer = new BufferingInput(MpegAudioHeader.MAX_FRAME_SIZE_BYTES * 3);
     scratch = new ParsableByteArray(4);
     synchronizedHeader = new MpegAudioHeader();
+    basisTimeUs = -1;
   }
 
   @Override
   public boolean sniff(ExtractorInput input) throws IOException, InterruptedException {
     ParsableByteArray scratch = new ParsableByteArray(4);
     int startPosition = 0;
-    input.peekFully(scratch.data, 0, 3);
-    if (scratch.readUnsignedInt24() == ID3_TAG) {
+    while (true) {
+      input.peekFully(scratch.data, 0, 3);
+      scratch.setPosition(0);
+      if (scratch.readUnsignedInt24() != ID3_TAG) {
+        break;
+      }
       input.advancePeekPosition(3);
       input.peekFully(scratch.data, 0, 4);
       int headerLength = ((scratch.data[0] & 0x7F) << 21) | ((scratch.data[1] & 0x7F) << 14)
           | ((scratch.data[2] & 0x7F) << 7) | (scratch.data[3] & 0x7F);
       input.advancePeekPosition(headerLength);
-      startPosition = 3 + 3 + 4 + headerLength;
-    } else {
-      input.resetPeekPosition();
+      startPosition += 3 + 3 + 4 + headerLength;
     }
+    input.resetPeekPosition();
+    input.advancePeekPosition(startPosition);
 
     // Try to find four consecutive valid MPEG audio frames.
     int headerPosition = startPosition;
@@ -160,6 +179,10 @@ private int readSample(ExtractorInput extractorInput) throws IOException, Interr
       }
       if (basisTimeUs == -1) {
         basisTimeUs = seeker.getTimeUs(getPosition(extractorInput, inputBuffer));
+        if (forcedFirstSampleTimestampUs != -1) {
+          long embeddedFirstSampleTimestampUs = seeker.getTimeUs(0);
+          basisTimeUs += forcedFirstSampleTimestampUs - embeddedFirstSampleTimestampUs;
+        }
       }
       sampleBytesRemaining = synchronizedHeader.frameSize;
     }
@@ -187,7 +210,9 @@ private int readSample(ExtractorInput extractorInput) throws IOException, Interr
     return RESULT_CONTINUE;
   }
 
-  /** Attempts to read an MPEG audio header at the current offset, resynchronizing if necessary. */
+  /**
+   * Attempts to read an MPEG audio header at the current offset, resynchronizing if necessary.
+   */
   private long maybeResynchronize(ExtractorInput extractorInput)
       throws IOException, InterruptedException {
     inputBuffer.mark();
@@ -238,9 +263,12 @@ private long synchronize(ExtractorInput extractorInput) throws IOException, Inte
 
     // Skip any ID3 header at the start of the file.
     if (startPosition == 0) {
-      inputBuffer.read(extractorInput, scratch.data, 0, 3);
-      scratch.setPosition(0);
-      if (scratch.readUnsignedInt24() == ID3_TAG) {
+      while (true) {
+        inputBuffer.read(extractorInput, scratch.data, 0, 3);
+        scratch.setPosition(0);
+        if (scratch.readUnsignedInt24() != ID3_TAG) {
+          break;
+        }
         extractorInput.skipFully(3);
         extractorInput.readFully(scratch.data, 0, 4);
         int headerLength = ((scratch.data[0] & 0x7F) << 21) | ((scratch.data[1] & 0x7F) << 14)
@@ -248,9 +276,8 @@ private long synchronize(ExtractorInput extractorInput) throws IOException, Inte
         extractorInput.skipFully(headerLength);
         inputBuffer.reset();
         startPosition = getPosition(extractorInput, inputBuffer);
-      } else {
-        inputBuffer.returnToMark();
       }
+      inputBuffer.returnToMark();
     }
 
     // Try to find four consecutive valid MPEG audio frames.
@@ -305,9 +332,10 @@ private long synchronize(ExtractorInput extractorInput) throws IOException, Inte
     if (seeker == null) {
       setupSeeker(extractorInput, headerPosition);
       extractorOutput.seekMap(seeker);
-      trackOutput.format(MediaFormat.createAudioFormat(synchronizedHeader.mimeType,
-          MpegAudioHeader.MAX_FRAME_SIZE_BYTES, seeker.getDurationUs(), synchronizedHeader.channels,
-          synchronizedHeader.sampleRate, null));
+      trackOutput.format(MediaFormat.createAudioFormat(MediaFormat.NO_VALUE,
+          synchronizedHeader.mimeType, MediaFormat.NO_VALUE, MpegAudioHeader.MAX_FRAME_SIZE_BYTES,
+          seeker.getDurationUs(), synchronizedHeader.channels, synchronizedHeader.sampleRate, null,
+          null));
     }
 
     return headerPosition;
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp3/XingSeeker.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp3/XingSeeker.java
index b6d2e9c966..7de38898c5 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp3/XingSeeker.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp3/XingSeeker.java
@@ -45,23 +45,18 @@ public static XingSeeker create(MpegAudioHeader mpegAudioHeader, ParsableByteArr
     long firstFramePosition = position + mpegAudioHeader.frameSize;
 
     int flags = frame.readInt();
-    // Frame count, size and table of contents are required to use this header.
-    if ((flags & 0x07) != 0x07) {
+    int frameCount;
+    if ((flags & 0x01) != 0x01 || (frameCount = frame.readUnsignedIntToInt()) == 0) {
+      // If the frame count is missing/invalid, the header can't be used to determine the duration.
       return null;
     }
-
-    // Read frame count, as (flags & 1) == 1.
-    int frameCount = frame.readUnsignedIntToInt();
-    if (frameCount == 0) {
-      return null;
+    long durationUs = Util.scaleLargeTimestamp(frameCount, samplesPerFrame * 1000000L, sampleRate);
+    if ((flags & 0x06) != 0x06) {
+      // If the size in bytes or table of contents is missing, the stream is not seekable.
+      return new XingSeeker(inputLength, firstFramePosition, durationUs);
     }
-    long durationUs =
-        Util.scaleLargeTimestamp(frameCount, samplesPerFrame * 1000000L, sampleRate);
 
-    // Read size in bytes, as (flags & 2) == 2.
     long sizeBytes = frame.readUnsignedIntToInt();
-
-    // Read table-of-contents as (flags & 4) == 4.
     frame.skipBytes(1);
     long[] tableOfContents = new long[99];
     for (int i = 0; i < 99; i++) {
@@ -71,18 +66,24 @@ public static XingSeeker create(MpegAudioHeader mpegAudioHeader, ParsableByteArr
     // TODO: Handle encoder delay and padding in 3 bytes offset by xingBase + 213 bytes:
     // delay = (frame.readUnsignedByte() << 4) + (frame.readUnsignedByte() >> 4);
     // padding = ((frame.readUnsignedByte() & 0x0F) << 8) + frame.readUnsignedByte();
-    return new XingSeeker(tableOfContents, firstFramePosition, sizeBytes, durationUs, inputLength);
+    return new XingSeeker(inputLength, firstFramePosition, durationUs, tableOfContents, sizeBytes);
   }
 
-  /** Entries are in the range [0, 255], but are stored as long integers for convenience. */
+  /**
+   * Entries are in the range [0, 255], but are stored as long integers for convenience.
+   */
   private final long[] tableOfContents;
   private final long firstFramePosition;
   private final long sizeBytes;
   private final long durationUs;
   private final long inputLength;
 
-  private XingSeeker(long[] tableOfContents, long firstFramePosition, long sizeBytes,
-      long durationUs, long inputLength) {
+  private XingSeeker(long inputLength, long firstFramePosition, long durationUs) {
+    this(inputLength, firstFramePosition, durationUs, null, 0);
+  }
+
+  private XingSeeker(long inputLength, long firstFramePosition, long durationUs,
+      long[] tableOfContents, long sizeBytes) {
     this.tableOfContents = tableOfContents;
     this.firstFramePosition = firstFramePosition;
     this.sizeBytes = sizeBytes;
@@ -92,11 +93,14 @@ private XingSeeker(long[] tableOfContents, long firstFramePosition, long sizeByt
 
   @Override
   public boolean isSeekable() {
-    return true;
+    return tableOfContents != null;
   }
 
   @Override
   public long getPosition(long timeUs) {
+    if (!isSeekable()) {
+      return firstFramePosition;
+    }
     float percent = timeUs * 100f / durationUs;
     float fx;
     if (percent <= 0f) {
@@ -119,14 +123,17 @@ public long getPosition(long timeUs) {
       fx = fa + (fb - fa) * (percent - a);
     }
 
-    long position = (long) ((1f / 256) * fx * sizeBytes) + firstFramePosition;
+    long position = (long) ((1.0 / 256) * fx * sizeBytes) + firstFramePosition;
     return inputLength != C.LENGTH_UNBOUNDED ? Math.min(position, inputLength - 1) : position;
   }
 
   @Override
   public long getTimeUs(long position) {
-    long offsetByte = 256 * (position - firstFramePosition) / sizeBytes;
-    int previousIndex = Util.binarySearchFloor(tableOfContents, offsetByte, true, false);
+    if (!isSeekable()) {
+      return 0L;
+    }
+    double offsetByte = 256.0 * (position - firstFramePosition) / sizeBytes;
+    int previousIndex = Util.binarySearchFloor(tableOfContents, (long) offsetByte, true, false);
     long previousTime = getTimeUsForTocIndex(previousIndex);
     if (previousIndex == 98) {
       return previousTime;
@@ -136,8 +143,8 @@ public long getTimeUs(long position) {
     long previousByte = previousIndex == -1 ? 0 : tableOfContents[previousIndex];
     long nextByte = tableOfContents[previousIndex + 1];
     long nextTime = getTimeUsForTocIndex(previousIndex + 1);
-    long timeOffset =
-        (nextTime - previousTime) * (offsetByte - previousByte) / (nextByte - previousByte);
+    long timeOffset = nextByte == previousByte ? 0 : (long) ((nextTime - previousTime)
+        * (offsetByte - previousByte) / (nextByte - previousByte));
     return previousTime + timeOffset;
   }
 
@@ -146,7 +153,9 @@ public long getDurationUs() {
     return durationUs;
   }
 
-  /** Returns the time in microseconds corresponding to an index in the table of contents. */
+  /**
+   * Returns the time in microseconds corresponding to an index in the table of contents.
+   */
   private long getTimeUsForTocIndex(int tocIndex) {
     return durationUs * (tocIndex + 1) / 100;
   }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Atom.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Atom.java
index 0ff25da170..e0b74bb2f9 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Atom.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Atom.java
@@ -57,6 +57,11 @@
   public static final int TYPE_dac3 = Util.getIntegerCodeForString("dac3");
   public static final int TYPE_ec_3 = Util.getIntegerCodeForString("ec-3");
   public static final int TYPE_dec3 = Util.getIntegerCodeForString("dec3");
+  public static final int TYPE_dtsc = Util.getIntegerCodeForString("dtsc");
+  public static final int TYPE_dtsh = Util.getIntegerCodeForString("dtsh");
+  public static final int TYPE_dtsl = Util.getIntegerCodeForString("dtsl");
+  public static final int TYPE_dtse = Util.getIntegerCodeForString("dtse");
+  public static final int TYPE_ddts = Util.getIntegerCodeForString("ddts");
   public static final int TYPE_tfdt = Util.getIntegerCodeForString("tfdt");
   public static final int TYPE_tfhd = Util.getIntegerCodeForString("tfhd");
   public static final int TYPE_trex = Util.getIntegerCodeForString("trex");
@@ -102,6 +107,7 @@
   public static final int TYPE_stco = Util.getIntegerCodeForString("stco");
   public static final int TYPE_co64 = Util.getIntegerCodeForString("co64");
   public static final int TYPE_tx3g = Util.getIntegerCodeForString("tx3g");
+  public static final int TYPE_stpp = Util.getIntegerCodeForString("stpp");
 
   public final int type;
 
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/AtomParsers.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/AtomParsers.java
index 06395188ac..7028cf5159 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/AtomParsers.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/AtomParsers.java
@@ -22,6 +22,7 @@
 import com.google.android.exoplayer.util.CodecSpecificDataUtil;
 import com.google.android.exoplayer.util.MimeTypes;
 import com.google.android.exoplayer.util.NalUnitUtil;
+import com.google.android.exoplayer.util.ParsableBitArray;
 import com.google.android.exoplayer.util.ParsableByteArray;
 import com.google.android.exoplayer.util.Util;
 
@@ -44,14 +45,13 @@
   public static Track parseTrak(Atom.ContainerAtom trak, Atom.LeafAtom mvhd) {
     Atom.ContainerAtom mdia = trak.getContainerAtomOfType(Atom.TYPE_mdia);
     int trackType = parseHdlr(mdia.getLeafAtomOfType(Atom.TYPE_hdlr).data);
-    if (trackType != Track.TYPE_AUDIO && trackType != Track.TYPE_VIDEO
-        && trackType != Track.TYPE_TEXT && trackType != Track.TYPE_SUBTITLE) {
+    if (trackType != Track.TYPE_soun && trackType != Track.TYPE_vide && trackType != Track.TYPE_text
+        && trackType != Track.TYPE_sbtl && trackType != Track.TYPE_subt) {
       return null;
     }
 
-    Pair<Integer, Long> header = parseTkhd(trak.getLeafAtomOfType(Atom.TYPE_tkhd).data);
-    int id = header.first;
-    long duration = header.second;
+    TkhdData tkhdData = parseTkhd(trak.getLeafAtomOfType(Atom.TYPE_tkhd).data);
+    long duration = tkhdData.duration;
     long movieTimescale = parseMvhd(mvhd.data);
     long durationUs;
     if (duration == -1) {
@@ -62,10 +62,11 @@ public static Track parseTrak(Atom.ContainerAtom trak, Atom.LeafAtom mvhd) {
     Atom.ContainerAtom stbl = mdia.getContainerAtomOfType(Atom.TYPE_minf)
         .getContainerAtomOfType(Atom.TYPE_stbl);
 
-    long mediaTimescale = parseMdhd(mdia.getLeafAtomOfType(Atom.TYPE_mdhd).data);
-    StsdDataHolder stsdData = parseStsd(stbl.getLeafAtomOfType(Atom.TYPE_stsd).data, durationUs);
+    Pair<Long, String> mdhdData = parseMdhd(mdia.getLeafAtomOfType(Atom.TYPE_mdhd).data);
+    StsdData stsdData = parseStsd(stbl.getLeafAtomOfType(Atom.TYPE_stsd).data, tkhdData.id,
+        durationUs, tkhdData.rotationDegrees, mdhdData.second);
     return stsdData.mediaFormat == null ? null
-        : new Track(id, trackType, mediaTimescale, durationUs, stsdData.mediaFormat,
+        : new Track(tkhdData.id, trackType, mdhdData.first, durationUs, stsdData.mediaFormat,
             stsdData.trackEncryptionBoxes, stsdData.nalUnitLengthFieldLength);
   }
 
@@ -266,19 +267,17 @@ private static long parseMvhd(ParsableByteArray mvhd) {
   /**
    * Parses a tkhd atom (defined in 14496-12).
    *
-   * @return A {@link Pair} consisting of the track id and duration (in the timescale indicated in
-   *     the movie header box). The duration is set to -1 if the duration is unspecified.
+   * @return An object containing the parsed data.
    */
-  private static Pair<Integer, Long> parseTkhd(ParsableByteArray tkhd) {
+  private static TkhdData parseTkhd(ParsableByteArray tkhd) {
     tkhd.setPosition(Atom.HEADER_SIZE);
     int fullAtom = tkhd.readInt();
     int version = Atom.parseFullAtomVersion(fullAtom);
 
     tkhd.skipBytes(version == 0 ? 8 : 16);
-
     int trackId = tkhd.readInt();
-    tkhd.skipBytes(4);
 
+    tkhd.skipBytes(4);
     boolean durationUnknown = true;
     int durationPosition = tkhd.getPosition();
     int durationByteCount = version == 0 ? 4 : 8;
@@ -296,7 +295,27 @@ private static long parseMvhd(ParsableByteArray mvhd) {
       duration = version == 0 ? tkhd.readUnsignedInt() : tkhd.readUnsignedLongToLong();
     }
 
-    return Pair.create(trackId, duration);
+    tkhd.skipBytes(16);
+    int a00 = tkhd.readInt();
+    int a01 = tkhd.readInt();
+    tkhd.skipBytes(4);
+    int a10 = tkhd.readInt();
+    int a11 = tkhd.readInt();
+
+    int rotationDegrees;
+    int fixedOne = 65536;
+    if (a00 == 0 && a01 == fixedOne && a10 == -fixedOne && a11 == 0) {
+      rotationDegrees = 90;
+    } else if (a00 == 0 && a01 == -fixedOne && a10 == fixedOne && a11 == 0) {
+      rotationDegrees = 270;
+    } else if (a00 == -fixedOne && a01 == 0 && a10 == 0 && a11 == -fixedOne) {
+      rotationDegrees = 180;
+    } else {
+      // Only 0, 90, 180 and 270 are supported. Treat anything else as 0.
+      rotationDegrees = 0;
+    }
+
+    return new TkhdData(trackId, duration, rotationDegrees);
   }
 
   /**
@@ -314,21 +333,38 @@ private static int parseHdlr(ParsableByteArray hdlr) {
    * Parses an mdhd atom (defined in 14496-12).
    *
    * @param mdhd The mdhd atom to parse.
-   * @return The media timescale, defined as the number of time units that pass in one second.
+   * @return A pair consisting of the media timescale defined as the number of time units that pass
+   *     in one second, and the language code.
    */
-  private static long parseMdhd(ParsableByteArray mdhd) {
+  private static Pair<Long, String> parseMdhd(ParsableByteArray mdhd) {
     mdhd.setPosition(Atom.HEADER_SIZE);
     int fullAtom = mdhd.readInt();
     int version = Atom.parseFullAtomVersion(fullAtom);
-
     mdhd.skipBytes(version == 0 ? 8 : 16);
-    return mdhd.readUnsignedInt();
+    long timescale = mdhd.readUnsignedInt();
+    mdhd.skipBytes(version == 0 ? 4 : 8);
+    int languageCode = mdhd.readUnsignedShort();
+    String language = "" + (char) (((languageCode >> 10) & 0x1F) + 0x60)
+        + (char) (((languageCode >> 5) & 0x1F) + 0x60)
+        + (char) (((languageCode) & 0x1F) + 0x60);
+    return Pair.create(timescale, language);
   }
 
-  private static StsdDataHolder parseStsd(ParsableByteArray stsd, long durationUs) {
+  /**
+   * Parses a stsd atom (defined in 14496-12).
+   *
+   * @param stsd The stsd atom to parse.
+   * @param trackId The track's identifier in its container.
+   * @param durationUs The duration of the track in microseconds.
+   * @param rotationDegrees The rotation of the track in degrees.
+   * @param language The language of the track.
+   * @return An object containing the parsed data.
+   */
+  private static StsdData parseStsd(ParsableByteArray stsd, int trackId, long durationUs,
+      int rotationDegrees, String language) {
     stsd.setPosition(Atom.FULL_HEADER_SIZE);
     int numberOfEntries = stsd.readInt();
-    StsdDataHolder holder = new StsdDataHolder(numberOfEntries);
+    StsdData out = new StsdData(numberOfEntries);
     for (int i = 0; i < numberOfEntries; i++) {
       int childStartPosition = stsd.getPosition();
       int childAtomSize = stsd.readInt();
@@ -338,28 +374,37 @@ private static StsdDataHolder parseStsd(ParsableByteArray stsd, long durationUs)
           || childAtomType == Atom.TYPE_encv || childAtomType == Atom.TYPE_mp4v
           || childAtomType == Atom.TYPE_hvc1 || childAtomType == Atom.TYPE_hev1
           || childAtomType == Atom.TYPE_s263) {
-        parseVideoSampleEntry(stsd, childStartPosition, childAtomSize, durationUs, holder, i);
+        parseVideoSampleEntry(stsd, childStartPosition, childAtomSize, trackId, durationUs,
+            rotationDegrees, out, i);
       } else if (childAtomType == Atom.TYPE_mp4a || childAtomType == Atom.TYPE_enca
-          || childAtomType == Atom.TYPE_ac_3) {
-        parseAudioSampleEntry(stsd, childAtomType, childStartPosition, childAtomSize, durationUs,
-            holder, i);
+          || childAtomType == Atom.TYPE_ac_3 || childAtomType == Atom.TYPE_ec_3
+          || childAtomType == Atom.TYPE_dtsc || childAtomType == Atom.TYPE_dtse
+          || childAtomType == Atom.TYPE_dtsh || childAtomType == Atom.TYPE_dtsl) {
+        parseAudioSampleEntry(stsd, childAtomType, childStartPosition, childAtomSize, trackId,
+            durationUs, language, out, i);
       } else if (childAtomType == Atom.TYPE_TTML) {
-        holder.mediaFormat = MediaFormat.createTextFormat(MimeTypes.APPLICATION_TTML, durationUs);
+        out.mediaFormat = MediaFormat.createTextFormat(trackId, MimeTypes.APPLICATION_TTML,
+            MediaFormat.NO_VALUE, durationUs, language);
       } else if (childAtomType == Atom.TYPE_tx3g) {
-        holder.mediaFormat = MediaFormat.createTextFormat(MimeTypes.APPLICATION_TX3G, durationUs);
+        out.mediaFormat = MediaFormat.createTextFormat(trackId, MimeTypes.APPLICATION_TX3G,
+            MediaFormat.NO_VALUE, durationUs, language);
+      } else if (childAtomType == Atom.TYPE_stpp) {
+        out.mediaFormat = MediaFormat.createTextFormat(trackId, MimeTypes.APPLICATION_TTML,
+            MediaFormat.NO_VALUE, durationUs, language, 0 /* subsample timing is absolute */);
       }
       stsd.setPosition(childStartPosition + childAtomSize);
     }
-    return holder;
+    return out;
   }
 
   private static void parseVideoSampleEntry(ParsableByteArray parent, int position, int size,
-      long durationUs, StsdDataHolder out, int entryIndex) {
+      int trackId, long durationUs, int rotationDegrees, StsdData out, int entryIndex) {
     parent.setPosition(position + Atom.HEADER_SIZE);
 
     parent.skipBytes(24);
     int width = parent.readUnsignedShort();
     int height = parent.readUnsignedShort();
+    boolean pixelWidthHeightRatioFromPasp = false;
     float pixelWidthHeightRatio = 1;
     parent.skipBytes(50);
 
@@ -379,9 +424,12 @@ private static void parseVideoSampleEntry(ParsableByteArray parent, int position
       if (childAtomType == Atom.TYPE_avcC) {
         Assertions.checkState(mimeType == null);
         mimeType = MimeTypes.VIDEO_H264;
-        Pair<List<byte[]>, Integer> avcCData = parseAvcCFromParent(parent, childStartPosition);
-        initializationData = avcCData.first;
-        out.nalUnitLengthFieldLength = avcCData.second;
+        AvcCData avcCData = parseAvcCFromParent(parent, childStartPosition);
+        initializationData = avcCData.initializationData;
+        out.nalUnitLengthFieldLength = avcCData.nalUnitLengthFieldLength;
+        if (!pixelWidthHeightRatioFromPasp) {
+          pixelWidthHeightRatio = avcCData.pixelWidthAspectRatio;
+        }
       } else if (childAtomType == Atom.TYPE_hvcC) {
         Assertions.checkState(mimeType == null);
         mimeType = MimeTypes.VIDEO_H265;
@@ -402,6 +450,7 @@ private static void parseVideoSampleEntry(ParsableByteArray parent, int position
             parseSinfFromParent(parent, childStartPosition, childAtomSize);
       } else if (childAtomType == Atom.TYPE_pasp) {
         pixelWidthHeightRatio = parsePaspFromParent(parent, childStartPosition);
+        pixelWidthHeightRatioFromPasp = true;
       }
       childPosition += childAtomSize;
     }
@@ -411,12 +460,12 @@ private static void parseVideoSampleEntry(ParsableByteArray parent, int position
       return;
     }
 
-    out.mediaFormat = MediaFormat.createVideoFormat(mimeType, MediaFormat.NO_VALUE, durationUs,
-        width, height, pixelWidthHeightRatio, initializationData);
+    out.mediaFormat = MediaFormat.createVideoFormat(trackId, mimeType, MediaFormat.NO_VALUE,
+        MediaFormat.NO_VALUE, durationUs, width, height, initializationData, rotationDegrees,
+        pixelWidthHeightRatio);
   }
 
-  private static Pair<List<byte[]>, Integer> parseAvcCFromParent(ParsableByteArray parent,
-      int position) {
+  private static AvcCData parseAvcCFromParent(ParsableByteArray parent, int position) {
     parent.setPosition(position + Atom.HEADER_SIZE + 4);
     // Start of the AVCDecoderConfigurationRecord (defined in 14496-15)
     int nalUnitLengthFieldLength = (parent.readUnsignedByte() & 0x3) + 1;
@@ -424,8 +473,7 @@ private static void parseVideoSampleEntry(ParsableByteArray parent, int position
       throw new IllegalStateException();
     }
     List<byte[]> initializationData = new ArrayList<>();
-    // TODO: We should try and parse these using CodecSpecificDataUtil.parseSpsNalUnit, and
-    // expose the AVC profile and level somewhere useful; Most likely in MediaFormat.
+    float pixelWidthAspectRatio = 1;
     int numSequenceParameterSets = parent.readUnsignedByte() & 0x1F;
     for (int j = 0; j < numSequenceParameterSets; j++) {
       initializationData.add(NalUnitUtil.parseChildNalUnit(parent));
@@ -434,7 +482,17 @@ private static void parseVideoSampleEntry(ParsableByteArray parent, int position
     for (int j = 0; j < numPictureParameterSets; j++) {
       initializationData.add(NalUnitUtil.parseChildNalUnit(parent));
     }
-    return Pair.create(initializationData, nalUnitLengthFieldLength);
+
+    if (numSequenceParameterSets > 0) {
+      // Parse the first sequence parameter set to obtain pixelWidthAspectRatio.
+      ParsableBitArray spsDataBitArray = new ParsableBitArray(initializationData.get(0));
+      // Skip the NAL header consisting of the nalUnitLengthField and the type (1 byte).
+      spsDataBitArray.setPosition(8 * (nalUnitLengthFieldLength + 1));
+      pixelWidthAspectRatio = CodecSpecificDataUtil.parseSpsNalUnit(spsDataBitArray)
+          .pixelWidthAspectRatio;
+    }
+
+    return new AvcCData(initializationData, nalUnitLengthFieldLength, pixelWidthAspectRatio);
   }
 
   private static Pair<List<byte[]>, Integer> parseHvcCFromParent(ParsableByteArray parent,
@@ -532,7 +590,7 @@ private static TrackEncryptionBox parseSchiFromParent(ParsableByteArray parent,
   }
 
   private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType, int position,
-      int size, long durationUs, StsdDataHolder out, int entryIndex) {
+      int size, int trackId, long durationUs, String language, StsdData out, int entryIndex) {
     parent.setPosition(position + Atom.HEADER_SIZE);
     parent.skipBytes(16);
     int channelCount = parent.readUnsignedShort();
@@ -546,6 +604,10 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
       mimeType = MimeTypes.AUDIO_AC3;
     } else if (atomType == Atom.TYPE_ec_3) {
       mimeType = MimeTypes.AUDIO_EC3;
+    } else if (atomType == Atom.TYPE_dtsc || atomType == Atom.TYPE_dtse) {
+      mimeType = MimeTypes.AUDIO_DTS;
+    } else if (atomType == Atom.TYPE_dtsh || atomType == Atom.TYPE_dtsl) {
+      mimeType = MimeTypes.AUDIO_DTS_HD;
     }
 
     byte[] initializationData = null;
@@ -578,11 +640,17 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
         // TODO: Choose the right AC-3 track based on the contents of dac3/dec3.
         // TODO: Add support for encryption (by setting out.trackEncryptionBoxes).
         parent.setPosition(Atom.HEADER_SIZE + childStartPosition);
-        out.mediaFormat = Ac3Util.parseAnnexFAc3Format(parent);
+        out.mediaFormat = Ac3Util.parseAnnexFAc3Format(parent, trackId, durationUs, language);
         return;
-      } else if  (atomType == Atom.TYPE_ec_3 && childAtomType == Atom.TYPE_dec3) {
+      } else if (atomType == Atom.TYPE_ec_3 && childAtomType == Atom.TYPE_dec3) {
         parent.setPosition(Atom.HEADER_SIZE + childStartPosition);
-        out.mediaFormat = Ac3Util.parseAnnexFEAc3Format(parent);
+        out.mediaFormat = Ac3Util.parseAnnexFEAc3Format(parent, trackId, durationUs, language);
+        return;
+      } else if ((atomType == Atom.TYPE_dtsc || atomType == Atom.TYPE_dtse
+          || atomType == Atom.TYPE_dtsh || atomType == Atom.TYPE_dtsl)
+          && childAtomType == Atom.TYPE_ddts) {
+        out.mediaFormat = MediaFormat.createAudioFormat(trackId, mimeType, MediaFormat.NO_VALUE,
+            MediaFormat.NO_VALUE, durationUs, channelCount, sampleRate, null, language);
         return;
       }
       childPosition += childAtomSize;
@@ -593,9 +661,10 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
       return;
     }
 
-    out.mediaFormat = MediaFormat.createAudioFormat(mimeType, sampleSize, durationUs, channelCount,
-        sampleRate,
-        initializationData == null ? null : Collections.singletonList(initializationData));
+    out.mediaFormat = MediaFormat.createAudioFormat(trackId, mimeType, MediaFormat.NO_VALUE,
+        sampleSize, durationUs, channelCount, sampleRate,
+        initializationData == null ? null : Collections.singletonList(initializationData),
+        language);
   }
 
   /** Returns codec-specific initialization data contained in an esds box. */
@@ -633,7 +702,6 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
     switch (objectTypeIndication) {
       case 0x6B:
         mimeType = MimeTypes.AUDIO_MPEG;
-        // Don't extract codec-specific data for MPEG audio tracks, as it is not needed.
         return Pair.create(mimeType, null);
       case 0x20:
         mimeType = MimeTypes.VIDEO_MP4V;
@@ -645,6 +713,9 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
         mimeType = MimeTypes.VIDEO_H265;
         break;
       case 0x40:
+      case 0x66:
+      case 0x67:
+      case 0x68:
         mimeType = MimeTypes.AUDIO_AAC;
         break;
       case 0xA5:
@@ -653,6 +724,14 @@ private static void parseAudioSampleEntry(ParsableByteArray parent, int atomType
       case 0xA6:
         mimeType = MimeTypes.AUDIO_EC3;
         break;
+      case 0xA9:
+      case 0xAC:
+        mimeType = MimeTypes.AUDIO_DTS;
+        return Pair.create(mimeType, null);
+      case 0xAA:
+      case 0xAB:
+        mimeType = MimeTypes.AUDIO_DTS_HD;
+        return Pair.create(mimeType, null);
       default:
         mimeType = null;
         break;
@@ -678,21 +757,56 @@ private AtomParsers() {
     // Prevent instantiation.
   }
 
+  /**
+   * Holds data parsed from a tkhd atom.
+   */
+  private static final class TkhdData {
+
+    private final int id;
+    private final long duration;
+    private final int rotationDegrees;
+
+    public TkhdData(int id, long duration, int rotationDegrees) {
+      this.id = id;
+      this.duration = duration;
+      this.rotationDegrees = rotationDegrees;
+    }
+
+  }
+
   /**
    * Holds data parsed from an stsd atom and its children.
    */
-  private static final class StsdDataHolder {
+  private static final class StsdData {
 
     public final TrackEncryptionBox[] trackEncryptionBoxes;
 
     public MediaFormat mediaFormat;
     public int nalUnitLengthFieldLength;
 
-    public StsdDataHolder(int numberOfEntries) {
+    public StsdData(int numberOfEntries) {
       trackEncryptionBoxes = new TrackEncryptionBox[numberOfEntries];
       nalUnitLengthFieldLength = -1;
     }
 
   }
 
+  /**
+   * Holds data parsed from an AvcC atom.
+   */
+  private static final class AvcCData {
+
+    public final List<byte[]> initializationData;
+    public final int nalUnitLengthFieldLength;
+    public final float pixelWidthAspectRatio;
+
+    public AvcCData(List<byte[]> initializationData, int nalUnitLengthFieldLength,
+        float pixelWidthAspectRatio) {
+      this.initializationData = initializationData;
+      this.nalUnitLengthFieldLength = nalUnitLengthFieldLength;
+      this.pixelWidthAspectRatio = pixelWidthAspectRatio;
+    }
+
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/FragmentedMp4Extractor.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/FragmentedMp4Extractor.java
index 9307f8446d..291b167971 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/FragmentedMp4Extractor.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/FragmentedMp4Extractor.java
@@ -474,7 +474,7 @@ private static void parseTrun(Track track, DefaultSampleValues defaultSampleValu
 
     long timescale = track.timescale;
     long cumulativeTime = decodeTime;
-    boolean workaroundEveryVideoFrameIsSyncFrame = track.type == Track.TYPE_VIDEO
+    boolean workaroundEveryVideoFrameIsSyncFrame = track.type == Track.TYPE_vide
         && ((workaroundFlags & WORKAROUND_EVERY_VIDEO_FRAME_IS_SYNC_FRAME)
         == WORKAROUND_EVERY_VIDEO_FRAME_IS_SYNC_FRAME);
     for (int i = 0; i < sampleCount; i++) {
@@ -495,7 +495,7 @@ private static void parseTrun(Track track, DefaultSampleValues defaultSampleValu
       } else {
         sampleCompositionTimeOffsetTable[i] = 0;
       }
-      sampleDecodingTimeTable[i] = (cumulativeTime * 1000) / timescale;
+      sampleDecodingTimeTable[i] = Util.scaleLargeTimestamp(cumulativeTime, 1000, timescale);
       sampleSizeTable[i] = sampleSize;
       sampleIsSyncFrameTable[i] = ((sampleFlags >> 16) & 0x1) == 0
           && (!workaroundEveryVideoFrameIsSyncFrame || i == 0);
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Sniffer.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Sniffer.java
index ece82e5beb..96878b82d9 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Sniffer.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Sniffer.java
@@ -102,13 +102,9 @@ private static boolean sniffInternal(ExtractorInput input, int searchLength, boo
         atomSize = buffer.readLong();
       }
       // Check the atom size is large enough to include its header.
-      if (atomSize < headerSize || atomSize > Integer.MAX_VALUE) {
+      if (atomSize < headerSize) {
         return false;
       }
-      // Stop searching if reading this atom would exceed the search limit.
-      if (bytesSearched + atomSize > bytesToSearch) {
-        break;
-      }
       int atomDataSize = (int) atomSize - headerSize;
       if (atomType == Atom.TYPE_ftyp) {
         if (atomDataSize < 8) {
@@ -126,10 +122,18 @@ private static boolean sniffInternal(ExtractorInput input, int searchLength, boo
             break;
           }
         }
+        // There is only one ftyp box, so reject the file if the file type in this box was invalid.
+        if (!foundGoodFileType) {
+          return false;
+        }
       } else if (atomType == Atom.TYPE_moof) {
         foundFragment = true;
         break;
       } else if (atomDataSize != 0) {
+        // Stop searching if reading this atom would exceed the search limit.
+        if (bytesSearched + atomSize >= bytesToSearch) {
+          break;
+        }
         input.advancePeekPosition(atomDataSize);
       }
       bytesSearched += atomSize;
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Track.java b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Track.java
index 6cdcd9568f..bd04be1c64 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Track.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/mp4/Track.java
@@ -24,22 +24,11 @@
  */
 public final class Track {
 
-  /**
-   * Type of a video track.
-   */
-  public static final int TYPE_VIDEO = Util.getIntegerCodeForString("vide");
-  /**
-   * Type of an audio track.
-   */
-  public static final int TYPE_AUDIO = Util.getIntegerCodeForString("soun");
-  /**
-   * Type of a text track.
-   */
-  public static final int TYPE_TEXT = Util.getIntegerCodeForString("text");
-  /**
-   * Type of a subtitle track.
-   */
-  public static final int TYPE_SUBTITLE = Util.getIntegerCodeForString("sbtl");
+  public static final int TYPE_vide = Util.getIntegerCodeForString("vide");
+  public static final int TYPE_soun = Util.getIntegerCodeForString("soun");
+  public static final int TYPE_text = Util.getIntegerCodeForString("text");
+  public static final int TYPE_sbtl = Util.getIntegerCodeForString("sbtl");
+  public static final int TYPE_subt = Util.getIntegerCodeForString("subt");
 
   /**
    * The track identifier.
@@ -47,7 +36,8 @@
   public final int id;
 
   /**
-   * One of {@link #TYPE_VIDEO}, {@link #TYPE_AUDIO}, {@link #TYPE_TEXT} and {@link #TYPE_SUBTITLE}.
+   * One of {@link #TYPE_vide}, {@link #TYPE_soun}, {@link #TYPE_text} and {@link #TYPE_sbtl} and
+   * {@link #TYPE_subt}.
    */
   public final int type;
 
@@ -62,7 +52,7 @@
   public final long durationUs;
 
   /**
-   * The format if {@link #type} is {@link #TYPE_VIDEO} or {@link #TYPE_AUDIO}. Null otherwise.
+   * The media format.
    */
   public final MediaFormat mediaFormat;
 
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/Ac3Reader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/Ac3Reader.java
index 5c98a680e8..baa4687450 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/Ac3Reader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/Ac3Reader.java
@@ -155,7 +155,8 @@ private void parseHeader() {
     sampleSize = Ac3Util.parseFrameSize(headerScratchBits);
     if (mediaFormat == null) {
       headerScratchBits.setPosition(0);
-      mediaFormat = Ac3Util.parseFrameAc3Format(headerScratchBits);
+      mediaFormat = Ac3Util.parseFrameAc3Format(headerScratchBits, MediaFormat.NO_VALUE,
+          C.UNKNOWN_TIME_US, null);
       output.format(mediaFormat);
       bitrate = Ac3Util.getBitrate(sampleSize, mediaFormat.sampleRate);
     }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsExtractor.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsExtractor.java
index fd72242216..24b578b028 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsExtractor.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsExtractor.java
@@ -20,6 +20,7 @@
 import com.google.android.exoplayer.extractor.ExtractorOutput;
 import com.google.android.exoplayer.extractor.PositionHolder;
 import com.google.android.exoplayer.extractor.SeekMap;
+import com.google.android.exoplayer.util.ParsableBitArray;
 import com.google.android.exoplayer.util.ParsableByteArray;
 import com.google.android.exoplayer.util.Util;
 
@@ -32,6 +33,12 @@
 public final class AdtsExtractor implements Extractor {
 
   private static final int MAX_PACKET_SIZE = 200;
+  private static final int ID3_TAG = Util.getIntegerCodeForString("ID3");
+  /**
+   * The maximum number of bytes to search when sniffing, excluding the header, before giving up.
+   * Frame sizes are represented by 13-bit fields, so expect a valid frame in the first 8192 bytes.
+   */
+  private static final int MAX_SNIFF_BYTES = 8 * 1024;
 
   private final long firstSampleTimestampUs;
   private final ParsableByteArray packetBuffer;
@@ -52,20 +59,53 @@ public AdtsExtractor(long firstSampleTimestampUs) {
 
   @Override
   public boolean sniff(ExtractorInput input) throws IOException, InterruptedException {
+    // Skip any ID3 headers.
     ParsableByteArray scratch = new ParsableByteArray(10);
-    input.peekFully(scratch.data, 0, 10);
-    int value = scratch.readUnsignedInt24();
-    if (value != Util.getIntegerCodeForString("ID3")) {
-      value = value >> 8;
-    } else {
+    ParsableBitArray scratchBits = new ParsableBitArray(scratch.data);
+    int startPosition = 0;
+    while (true) {
+      input.peekFully(scratch.data, 0, 10);
+      scratch.setPosition(0);
+      if (scratch.readUnsignedInt24() != ID3_TAG) {
+        break;
+      }
       int length = (scratch.data[6] & 0x7F) << 21 | ((scratch.data[7] & 0x7F) << 14)
           | ((scratch.data[8] & 0x7F) << 7) | (scratch.data[9] & 0x7F);
+      startPosition += 10 + length;
       input.advancePeekPosition(length);
+    }
+    input.resetPeekPosition();
+    input.advancePeekPosition(startPosition);
+
+    // Try to find four or more consecutive AAC audio frames, exceeding the MPEG TS packet size.
+    int headerPosition = startPosition;
+    int validFramesSize = 0;
+    int validFramesCount = 0;
+    while (true) {
       input.peekFully(scratch.data, 0, 2);
       scratch.setPosition(0);
-      value = scratch.readUnsignedShort();
+      int syncBytes = scratch.readUnsignedShort();
+      if ((syncBytes & 0xFFF6) != 0xFFF0) {
+        validFramesCount = 0;
+        validFramesSize = 0;
+        input.resetPeekPosition();
+        if (++headerPosition - startPosition >= MAX_SNIFF_BYTES) {
+          return false;
+        }
+        input.advancePeekPosition(headerPosition);
+      } else {
+        if (++validFramesCount >= 4 && validFramesSize > 188) {
+          return true;
+        }
+
+        // Skip the frame.
+        input.peekFully(scratch.data, 0, 4);
+        scratchBits.setPosition(14);
+        int frameSize = scratchBits.readBits(13);
+        input.advancePeekPosition(frameSize - 6);
+        validFramesSize += frameSize;
+      }
     }
-    return (value & 0xFFF6) == 0xFFF0;
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsReader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsReader.java
index 5f360d4664..cbdc58872a 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsReader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/AdtsReader.java
@@ -170,9 +170,10 @@ private void parseHeader() {
       Pair<Integer, Integer> audioParams = CodecSpecificDataUtil.parseAacAudioSpecificConfig(
           audioSpecificConfig);
 
-      MediaFormat mediaFormat = MediaFormat.createAudioFormat(MimeTypes.AUDIO_AAC,
-          MediaFormat.NO_VALUE, audioParams.second, audioParams.first,
-          Collections.singletonList(audioSpecificConfig));
+      MediaFormat mediaFormat = MediaFormat.createAudioFormat(MediaFormat.NO_VALUE,
+          MimeTypes.AUDIO_AAC, MediaFormat.NO_VALUE, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US,
+          audioParams.second, audioParams.first, Collections.singletonList(audioSpecificConfig),
+          null);
       frameDurationUs = (C.MICROS_PER_SECOND * 1024L) / mediaFormat.sampleRate;
       output.format(mediaFormat);
       hasOutputFormat = true;
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/H264Reader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/H264Reader.java
index 731254dbde..848e40b29d 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/H264Reader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/H264Reader.java
@@ -18,13 +18,13 @@
 import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.extractor.TrackOutput;
+import com.google.android.exoplayer.util.CodecSpecificDataUtil;
+import com.google.android.exoplayer.util.CodecSpecificDataUtil.SpsData;
 import com.google.android.exoplayer.util.MimeTypes;
 import com.google.android.exoplayer.util.NalUnitUtil;
 import com.google.android.exoplayer.util.ParsableBitArray;
 import com.google.android.exoplayer.util.ParsableByteArray;
 
-import android.util.Log;
-
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -34,8 +34,6 @@
  */
 /* package */ final class H264Reader extends ElementaryStreamReader {
 
-  private static final String TAG = "H264Reader";
-
   private static final int FRAME_TYPE_I = 2;
   private static final int FRAME_TYPE_ALL_I = 7;
 
@@ -205,121 +203,20 @@ private void parseMediaFormat(NalUnitTargetBuffer sps, NalUnitTargetBuffer pps)
     initializationData.add(spsData);
     initializationData.add(ppsData);
 
-    // Unescape and then parse the SPS unit.
+    // Unescape and parse the SPS unit.
     NalUnitUtil.unescapeStream(sps.nalData, sps.nalLength);
     ParsableBitArray bitArray = new ParsableBitArray(sps.nalData);
     bitArray.skipBits(32); // NAL header
-    int profileIdc = bitArray.readBits(8);
-    bitArray.skipBits(16); // constraint bits (6), reserved (2) and level_idc (8)
-    bitArray.readUnsignedExpGolombCodedInt(); // seq_parameter_set_id
-
-    int chromaFormatIdc = 1; // Default is 4:2:0
-    if (profileIdc == 100 || profileIdc == 110 || profileIdc == 122 || profileIdc == 244
-        || profileIdc == 44 || profileIdc == 83 || profileIdc == 86 || profileIdc == 118
-        || profileIdc == 128 || profileIdc == 138) {
-      chromaFormatIdc = bitArray.readUnsignedExpGolombCodedInt();
-      if (chromaFormatIdc == 3) {
-        bitArray.skipBits(1); // separate_colour_plane_flag
-      }
-      bitArray.readUnsignedExpGolombCodedInt(); // bit_depth_luma_minus8
-      bitArray.readUnsignedExpGolombCodedInt(); // bit_depth_chroma_minus8
-      bitArray.skipBits(1); // qpprime_y_zero_transform_bypass_flag
-      boolean seqScalingMatrixPresentFlag = bitArray.readBit();
-      if (seqScalingMatrixPresentFlag) {
-        int limit = (chromaFormatIdc != 3) ? 8 : 12;
-        for (int i = 0; i < limit; i++) {
-          boolean seqScalingListPresentFlag = bitArray.readBit();
-          if (seqScalingListPresentFlag) {
-            skipScalingList(bitArray, i < 6 ? 16 : 64);
-          }
-        }
-      }
-    }
-
-    bitArray.readUnsignedExpGolombCodedInt(); // log2_max_frame_num_minus4
-    long picOrderCntType = bitArray.readUnsignedExpGolombCodedInt();
-    if (picOrderCntType == 0) {
-      bitArray.readUnsignedExpGolombCodedInt(); // log2_max_pic_order_cnt_lsb_minus4
-    } else if (picOrderCntType == 1) {
-      bitArray.skipBits(1); // delta_pic_order_always_zero_flag
-      bitArray.readSignedExpGolombCodedInt(); // offset_for_non_ref_pic
-      bitArray.readSignedExpGolombCodedInt(); // offset_for_top_to_bottom_field
-      long numRefFramesInPicOrderCntCycle = bitArray.readUnsignedExpGolombCodedInt();
-      for (int i = 0; i < numRefFramesInPicOrderCntCycle; i++) {
-        bitArray.readUnsignedExpGolombCodedInt(); // offset_for_ref_frame[i]
-      }
-    }
-    bitArray.readUnsignedExpGolombCodedInt(); // max_num_ref_frames
-    bitArray.skipBits(1); // gaps_in_frame_num_value_allowed_flag
-
-    int picWidthInMbs = bitArray.readUnsignedExpGolombCodedInt() + 1;
-    int picHeightInMapUnits = bitArray.readUnsignedExpGolombCodedInt() + 1;
-    boolean frameMbsOnlyFlag = bitArray.readBit();
-    int frameHeightInMbs = (2 - (frameMbsOnlyFlag ? 1 : 0)) * picHeightInMapUnits;
-    if (!frameMbsOnlyFlag) {
-      bitArray.skipBits(1); // mb_adaptive_frame_field_flag
-    }
-
-    bitArray.skipBits(1); // direct_8x8_inference_flag
-    int frameWidth = picWidthInMbs * 16;
-    int frameHeight = frameHeightInMbs * 16;
-    boolean frameCroppingFlag = bitArray.readBit();
-    if (frameCroppingFlag) {
-      int frameCropLeftOffset = bitArray.readUnsignedExpGolombCodedInt();
-      int frameCropRightOffset = bitArray.readUnsignedExpGolombCodedInt();
-      int frameCropTopOffset = bitArray.readUnsignedExpGolombCodedInt();
-      int frameCropBottomOffset = bitArray.readUnsignedExpGolombCodedInt();
-      int cropUnitX, cropUnitY;
-      if (chromaFormatIdc == 0) {
-        cropUnitX = 1;
-        cropUnitY = 2 - (frameMbsOnlyFlag ? 1 : 0);
-      } else {
-        int subWidthC = (chromaFormatIdc == 3) ? 1 : 2;
-        int subHeightC = (chromaFormatIdc == 1) ? 2 : 1;
-        cropUnitX = subWidthC;
-        cropUnitY = subHeightC * (2 - (frameMbsOnlyFlag ? 1 : 0));
-      }
-      frameWidth -= (frameCropLeftOffset + frameCropRightOffset) * cropUnitX;
-      frameHeight -= (frameCropTopOffset + frameCropBottomOffset) * cropUnitY;
-    }
-
-    float pixelWidthHeightRatio = 1;
-    boolean vuiParametersPresentFlag = bitArray.readBit();
-    if (vuiParametersPresentFlag) {
-      boolean aspectRatioInfoPresentFlag = bitArray.readBit();
-      if (aspectRatioInfoPresentFlag) {
-        int aspectRatioIdc = bitArray.readBits(8);
-        if (aspectRatioIdc == NalUnitUtil.EXTENDED_SAR) {
-          int sarWidth = bitArray.readBits(16);
-          int sarHeight = bitArray.readBits(16);
-          if (sarWidth != 0 && sarHeight != 0) {
-            pixelWidthHeightRatio = (float) sarWidth / sarHeight;
-          }
-        } else if (aspectRatioIdc < NalUnitUtil.ASPECT_RATIO_IDC_VALUES.length) {
-          pixelWidthHeightRatio = NalUnitUtil.ASPECT_RATIO_IDC_VALUES[aspectRatioIdc];
-        } else {
-          Log.w(TAG, "Unexpected aspect_ratio_idc value: " + aspectRatioIdc);
-        }
-      }
-    }
+    SpsData parsedSpsData = CodecSpecificDataUtil.parseSpsNalUnit(bitArray);
 
-    output.format(MediaFormat.createVideoFormat(MimeTypes.VIDEO_H264, MediaFormat.NO_VALUE,
-        C.UNKNOWN_TIME_US, frameWidth, frameHeight, pixelWidthHeightRatio, initializationData));
+    // Construct and output the format.
+    output.format(MediaFormat.createVideoFormat(MediaFormat.NO_VALUE, MimeTypes.VIDEO_H264,
+        MediaFormat.NO_VALUE, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US, parsedSpsData.width,
+        parsedSpsData.height, initializationData, MediaFormat.NO_VALUE,
+        parsedSpsData.pixelWidthAspectRatio));
     hasOutputFormat = true;
   }
 
-  private void skipScalingList(ParsableBitArray bitArray, int size) {
-    int lastScale = 8;
-    int nextScale = 8;
-    for (int i = 0; i < size; i++) {
-      if (nextScale != 0) {
-        int deltaScale = bitArray.readSignedExpGolombCodedInt();
-        nextScale = (lastScale + deltaScale + 256) % 256;
-      }
-      lastScale = (nextScale == 0) ? lastScale : nextScale;
-    }
-  }
-
   /**
    * A buffer specifically for IFR units that can be used to parse the IFR's slice type.
    */
@@ -369,7 +266,7 @@ public void startNalUnit(int nalUnitType) {
     }
 
     /**
-     * Invoked to pass stream data. The data passed should not include 4 byte NAL unit prefixes.
+     * Invoked to pass stream data. The data passed should not include the 3 byte start code.
      *
      * @param data Holds the data being passed.
      * @param offset The offset of the data in {@code data}.
@@ -387,6 +284,7 @@ public void appendToNalUnit(byte[] data, int offset, int limit) {
       ifrLength += readLength;
 
       scratchSliceType.reset(ifrData, ifrLength);
+      scratchSliceType.skipBits(8);
       // first_mb_in_slice
       int len = scratchSliceType.peekExpGolombCodedNumLength();
       if ((len == -1) || (len > scratchSliceType.bitsLeft())) {
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/H265Reader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/H265Reader.java
index 7a2dd8c454..0927ffa3b4 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/H265Reader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/H265Reader.java
@@ -37,10 +37,6 @@
   // nal_unit_type values from H.265/HEVC (2014) Table 7-1.
   private static final int RASL_R = 9;
   private static final int BLA_W_LP = 16;
-  private static final int BLA_W_RADL = 17;
-  private static final int BLA_N_LP = 18;
-  private static final int IDR_W_RADL = 19;
-  private static final int IDR_N_LP = 20;
   private static final int CRA_NUT = 21;
   private static final int VPS_NUT = 32;
   private static final int SPS_NUT = 33;
@@ -59,14 +55,9 @@
   private final NalUnitTargetBuffer pps;
   private final NalUnitTargetBuffer prefixSei;
   private final NalUnitTargetBuffer suffixSei; // TODO: Are both needed?
-  private boolean foundFirstSample;
+  private final SampleReader sampleReader;
   private long totalBytesWritten;
 
-  // Per sample state that gets reset at the start of each sample.
-  private boolean isKeyframe;
-  private long samplePosition;
-  private long sampleTimeUs;
-
   // Scratch variables to avoid allocations.
   private final ParsableByteArray seiWrapper;
 
@@ -79,6 +70,7 @@ public H265Reader(TrackOutput output, SeiReader seiReader) {
     pps = new NalUnitTargetBuffer(PPS_NUT, 128);
     prefixSei = new NalUnitTargetBuffer(PREFIX_SEI_NUT, 128);
     suffixSei = new NalUnitTargetBuffer(SUFFIX_SEI_NUT, 128);
+    sampleReader = new SampleReader(output);
     seiWrapper = new ParsableByteArray();
   }
 
@@ -91,7 +83,7 @@ public void seek() {
     pps.reset();
     prefixSei.reset();
     suffixSei.reset();
-    foundFirstSample = false;
+    sampleReader.reset();
     totalBytesWritten = 0;
   }
 
@@ -108,44 +100,31 @@ public void consume(ParsableByteArray data, long pesTimeUs, boolean startOfPacke
 
       // Scan the appended data, processing NAL units as they are encountered
       while (offset < limit) {
-        int nextNalUnitOffset = NalUnitUtil.findNalUnit(dataArray, offset, limit, prefixFlags);
-        if (nextNalUnitOffset < limit) {
+        int nalUnitOffset = NalUnitUtil.findNalUnit(dataArray, offset, limit, prefixFlags);
+        if (nalUnitOffset < limit) {
           // We've seen the start of a NAL unit.
 
           // This is the length to the start of the unit. It may be negative if the NAL unit
           // actually started in previously consumed data.
-          int lengthToNalUnit = nextNalUnitOffset - offset;
+          int lengthToNalUnit = nalUnitOffset - offset;
           if (lengthToNalUnit > 0) {
-            feedNalUnitTargetBuffersData(dataArray, offset, nextNalUnitOffset);
-          }
-
-          int nalUnitType = NalUnitUtil.getH265NalUnitType(dataArray, nextNalUnitOffset);
-          int bytesWrittenPastNalUnit = limit - nextNalUnitOffset;
-          if (isFirstSliceSegmentInPic(dataArray, nextNalUnitOffset)) {
-            if (foundFirstSample) {
-              if (isKeyframe && !hasOutputFormat && vps.isCompleted() && sps.isCompleted()
-                  && pps.isCompleted()) {
-                parseMediaFormat(vps, sps, pps);
-              }
-              int flags = isKeyframe ? C.SAMPLE_FLAG_SYNC : 0;
-              int size = (int) (totalBytesWritten - samplePosition) - bytesWrittenPastNalUnit;
-              output.sampleMetadata(sampleTimeUs, flags, size, bytesWrittenPastNalUnit, null);
-            }
-            foundFirstSample = true;
-            samplePosition = totalBytesWritten - bytesWrittenPastNalUnit;
-            sampleTimeUs = pesTimeUs;
-            isKeyframe = isRandomAccessPoint(nalUnitType);
+            nalUnitData(dataArray, offset, nalUnitOffset);
           }
-
-          // If the length to the start of the unit is negative then we wrote too many bytes to the
-          // NAL buffers. Discard the excess bytes when notifying that the unit has ended.
-          feedNalUnitTargetEnd(pesTimeUs, lengthToNalUnit < 0 ? -lengthToNalUnit : 0);
-          // Notify the start of the next NAL unit.
-          feedNalUnitTargetBuffersStart(nalUnitType);
+          int bytesWrittenPastPosition = limit - nalUnitOffset;
+          long absolutePosition = totalBytesWritten - bytesWrittenPastPosition;
+          // Indicate the end of the previous NAL unit. If the length to the start of the next unit
+          // is negative then we wrote too many bytes to the NAL buffers. Discard the excess bytes
+          // when notifying that the unit has ended.
+          nalUnitEnd(absolutePosition, bytesWrittenPastPosition,
+              lengthToNalUnit < 0 ? -lengthToNalUnit : 0, pesTimeUs);
+
+          // Indicate the start of the next NAL unit.
+          int nalUnitType = NalUnitUtil.getH265NalUnitType(dataArray, nalUnitOffset);
+          startNalUnit(absolutePosition, bytesWrittenPastPosition, nalUnitType);
           // Continue scanning the data.
-          offset = nextNalUnitOffset + 3;
+          offset = nalUnitOffset + 3;
         } else {
-          feedNalUnitTargetBuffersData(dataArray, offset, limit);
+          nalUnitData(dataArray, offset, limit);
           offset = limit;
         }
       }
@@ -157,7 +136,7 @@ public void packetFinished() {
     // Do nothing.
   }
 
-  private void feedNalUnitTargetBuffersStart(int nalUnitType) {
+  private void startNalUnit(long position, int offset, int nalUnitType) {
     if (!hasOutputFormat) {
       vps.startNalUnit(nalUnitType);
       sps.startNalUnit(nalUnitType);
@@ -165,10 +144,13 @@ private void feedNalUnitTargetBuffersStart(int nalUnitType) {
     }
     prefixSei.startNalUnit(nalUnitType);
     suffixSei.startNalUnit(nalUnitType);
+    sampleReader.startNalUnit(position, offset, nalUnitType);
   }
 
-  private void feedNalUnitTargetBuffersData(byte[] dataArray, int offset, int limit) {
-    if (!hasOutputFormat) {
+  private void nalUnitData(byte[] dataArray, int offset, int limit) {
+    if (hasOutputFormat) {
+      sampleReader.readNalUnitData(dataArray, offset, limit);
+    } else {
       vps.appendToNalUnit(dataArray, offset, limit);
       sps.appendToNalUnit(dataArray, offset, limit);
       pps.appendToNalUnit(dataArray, offset, limit);
@@ -177,10 +159,17 @@ private void feedNalUnitTargetBuffersData(byte[] dataArray, int offset, int limi
     suffixSei.appendToNalUnit(dataArray, offset, limit);
   }
 
-  private void feedNalUnitTargetEnd(long pesTimeUs, int discardPadding) {
-    vps.endNalUnit(discardPadding);
-    sps.endNalUnit(discardPadding);
-    pps.endNalUnit(discardPadding);
+  private void nalUnitEnd(long position, int offset, int discardPadding, long pesTimeUs) {
+    if (hasOutputFormat) {
+      sampleReader.endNalUnit(position, offset, pesTimeUs);
+    } else {
+      vps.endNalUnit(discardPadding);
+      sps.endNalUnit(discardPadding);
+      pps.endNalUnit(discardPadding);
+      if (vps.isCompleted() && sps.isCompleted() && pps.isCompleted()) {
+        parseMediaFormat(vps, sps, pps);
+      }
+    }
     if (prefixSei.endNalUnit(discardPadding)) {
       int unescapedLength = NalUnitUtil.unescapeStream(prefixSei.nalData, prefixSei.nalLength);
       seiWrapper.reset(prefixSei.nalData, unescapedLength);
@@ -271,7 +260,7 @@ private void parseMediaFormat(NalUnitTargetBuffer vps, NalUnitTargetBuffer sps,
     bitArray.skipBits(2); // amp_enabled_flag (1), sample_adaptive_offset_enabled_flag (1)
     if (bitArray.readBit()) { // pcm_enabled_flag
       // pcm_sample_bit_depth_luma_minus1 (4), pcm_sample_bit_depth_chroma_minus1 (4)
-      bitArray.skipBits(4);
+      bitArray.skipBits(8);
       bitArray.readUnsignedExpGolombCodedInt(); // log2_min_pcm_luma_coding_block_size_minus3
       bitArray.readUnsignedExpGolombCodedInt(); // log2_diff_max_min_pcm_luma_coding_block_size
       bitArray.skipBits(1); // pcm_loop_filter_disabled_flag
@@ -305,9 +294,10 @@ private void parseMediaFormat(NalUnitTargetBuffer vps, NalUnitTargetBuffer sps,
       }
     }
 
-    output.format(MediaFormat.createVideoFormat(MimeTypes.VIDEO_H265, MediaFormat.NO_VALUE,
-        C.UNKNOWN_TIME_US, picWidthInLumaSamples, picHeightInLumaSamples, pixelWidthHeightRatio,
-        Collections.singletonList(csd)));
+    output.format(MediaFormat.createVideoFormat(MediaFormat.NO_VALUE, MimeTypes.VIDEO_H265,
+        MediaFormat.NO_VALUE, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US, picWidthInLumaSamples,
+        picHeightInLumaSamples, Collections.singletonList(csd), MediaFormat.NO_VALUE,
+        pixelWidthHeightRatio));
     hasOutputFormat = true;
   }
 
@@ -319,7 +309,7 @@ private void skipScalingList(ParsableBitArray bitArray) {
           // scaling_list_pred_matrix_id_delta[sizeId][matrixId]
           bitArray.readUnsignedExpGolombCodedInt();
         } else {
-          int coefNum = Math.min(64, 1 << (4 + sizeId << 1));
+          int coefNum = Math.min(64, 1 << (4 + (sizeId << 1)));
           if (sizeId > 1) {
             // scaling_list_dc_coef_minus8[sizeId - 2][matrixId]
             bitArray.readSignedExpGolombCodedInt();
@@ -373,30 +363,85 @@ private static void skipShortTermRefPicSets(ParsableBitArray bitArray) {
     }
   }
 
-  /**
-   * Returns whether the NAL unit is a random access point.
-   */
-  private static boolean isRandomAccessPoint(int nalUnitType) {
-    return nalUnitType == BLA_W_LP || nalUnitType == BLA_W_RADL || nalUnitType == BLA_N_LP
-        || nalUnitType == IDR_W_RADL || nalUnitType == IDR_N_LP || nalUnitType == CRA_NUT;
-  }
+  private static final class SampleReader {
 
-  /**
-   * Returns whether the NAL unit in {@code data} starting at {@code offset} contains the first
-   * slice in a picture.
-   *
-   * @param data The data to read.
-   * @param offset The start offset of a NAL unit. Must lie between {@code -3} (inclusive) and
-   *     {@code data.length - 3} (exclusive).
-   * @return Whether the NAL unit contains the first slice in a picture.
-   */
-  public static boolean isFirstSliceSegmentInPic(byte[] data, int offset) {
-    int nalUnitType = NalUnitUtil.getH265NalUnitType(data, offset);
-    // Check the flag in NAL units that contain a slice_segment_layer_rbsp RBSP.
-    if ((nalUnitType <= RASL_R) || (nalUnitType >= BLA_W_LP && nalUnitType <= CRA_NUT)) {
-      return (data[offset + 5] & 0x80) != 0;
+    /**
+     * Offset in bytes of the first_slice_segment_in_pic_flag in a NAL unit containing a
+     * slice_segment_layer_rbsp.
+     */
+    private static final int FIRST_SLICE_FLAG_OFFSET = 2;
+
+    private final TrackOutput output;
+
+    // Per NAL unit state. A sample consists of one or more NAL units.
+    private long nalUnitStartPosition;
+    private boolean nalUnitHasKeyframeData;
+    private int nalUnitBytesRead;
+    private boolean lookingForFirstSliceFlag;
+    private boolean firstSliceFlag;
+
+    // Per sample state that gets reset at the start of each sample.
+    private boolean readingSample;
+    private long samplePosition;
+    private long sampleTimeUs;
+    private boolean sampleIsKeyframe;
+
+    public SampleReader(TrackOutput output) {
+      this.output = output;
     }
-    return false;
+
+    public void reset() {
+      lookingForFirstSliceFlag = false;
+      firstSliceFlag = false;
+      readingSample = false;
+    }
+
+    public void startNalUnit(long position, int offset, int nalUnitType) {
+      firstSliceFlag = false;
+      nalUnitBytesRead = 0;
+      nalUnitStartPosition = position;
+      // Flush the previous sample when reading a non-VCL NAL unit.
+      if (nalUnitType >= VPS_NUT && readingSample) {
+        outputSample(offset);
+        readingSample = false;
+      }
+      // Look for the flag if this NAL unit contains a slice_segment_layer_rbsp.
+      nalUnitHasKeyframeData = (nalUnitType >= BLA_W_LP && nalUnitType <= CRA_NUT);
+      lookingForFirstSliceFlag = nalUnitHasKeyframeData || nalUnitType <= RASL_R;
+    }
+
+    public void readNalUnitData(byte[] data, int offset, int limit) {
+      if (lookingForFirstSliceFlag) {
+        int headerOffset = offset + FIRST_SLICE_FLAG_OFFSET - nalUnitBytesRead;
+        if (headerOffset < limit) {
+          firstSliceFlag = (data[headerOffset] & 0x80) != 0;
+          lookingForFirstSliceFlag = false;
+        } else {
+          nalUnitBytesRead += limit - offset;
+        }
+      }
+    }
+
+    public void endNalUnit(long position, int offset, long timeUs) {
+      if (firstSliceFlag) {
+        // If the NAL unit ending is the start of a new sample, output the previous one.
+        if (readingSample) {
+          int nalUnitLength = (int) (position - nalUnitStartPosition);
+          outputSample(offset + nalUnitLength);
+        }
+        samplePosition = nalUnitStartPosition;
+        sampleTimeUs = timeUs;
+        readingSample = true;
+        sampleIsKeyframe = nalUnitHasKeyframeData;
+      }
+    }
+
+    private void outputSample(int offset) {
+      int flags = sampleIsKeyframe ? C.SAMPLE_FLAG_SYNC : 0;
+      int size = (int) (nalUnitStartPosition - samplePosition);
+      output.sampleMetadata(sampleTimeUs, flags, size, offset, null);
+    }
+
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/Id3Reader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/Id3Reader.java
index 4e778820a5..553aae6499 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/Id3Reader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/Id3Reader.java
@@ -35,7 +35,8 @@
 
   public Id3Reader(TrackOutput output) {
     super(output);
-    output.format(MediaFormat.createTextFormat(MimeTypes.APPLICATION_ID3));
+    output.format(MediaFormat.createFormatForMimeType(MediaFormat.NO_VALUE,
+        MimeTypes.APPLICATION_ID3, MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US));
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/MpegAudioReader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/MpegAudioReader.java
index 5ce86b7d63..8e268e53fe 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/MpegAudioReader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/MpegAudioReader.java
@@ -160,9 +160,9 @@ private void readHeaderRemainder(ParsableByteArray source) {
     frameSize = header.frameSize;
     if (!hasOutputFormat) {
       frameDurationUs = (C.MICROS_PER_SECOND * header.samplesPerFrame) / header.sampleRate;
-      MediaFormat mediaFormat = MediaFormat.createAudioFormat(header.mimeType,
-          MpegAudioHeader.MAX_FRAME_SIZE_BYTES, C.UNKNOWN_TIME_US, header.channels,
-          header.sampleRate, null);
+      MediaFormat mediaFormat = MediaFormat.createAudioFormat(MediaFormat.NO_VALUE, header.mimeType,
+          MediaFormat.NO_VALUE, MpegAudioHeader.MAX_FRAME_SIZE_BYTES, C.UNKNOWN_TIME_US,
+          header.channels, header.sampleRate, null, null);
       output.format(mediaFormat);
       hasOutputFormat = true;
     }
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/PtsTimestampAdjuster.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/PtsTimestampAdjuster.java
new file mode 100644
index 0000000000..59d96eb003
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/PtsTimestampAdjuster.java
@@ -0,0 +1,79 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.extractor.ts;
+
+import com.google.android.exoplayer.C;
+
+/**
+ * Scales and adjusts MPEG-2 TS presentation timestamps, taking into account an initial offset and
+ * timestamp rollover.
+ */
+public final class PtsTimestampAdjuster {
+
+  /**
+   * The value one greater than the largest representable (33 bit) presentation timestamp.
+   */
+  private static final long MAX_PTS_PLUS_ONE = 0x200000000L;
+
+  private final long firstSampleTimestampUs;
+
+  private long timestampOffsetUs;
+  private long lastPts;
+
+  /**
+   * @param firstSampleTimestampUs The desired result of the first call to
+   *     {@link #adjustTimestamp(long)}.
+   */
+  public PtsTimestampAdjuster(long firstSampleTimestampUs) {
+    this.firstSampleTimestampUs = firstSampleTimestampUs;
+    lastPts = Long.MIN_VALUE;
+  }
+
+  /**
+   * Resets the instance to its initial state.
+   */
+  public void reset() {
+    lastPts = Long.MIN_VALUE;
+  }
+
+  /**
+   * Scales and adjusts an MPEG-2 TS presentation timestamp.
+   *
+   * @param pts The unscaled MPEG-2 TS presentation timestamp.
+   * @return The adjusted timestamp in microseconds.
+   */
+  public long adjustTimestamp(long pts) {
+    if (lastPts != Long.MIN_VALUE) {
+      // The wrap count for the current PTS may be closestWrapCount or (closestWrapCount - 1),
+      // and we need to snap to the one closest to lastPts.
+      long closestWrapCount = (lastPts + (MAX_PTS_PLUS_ONE / 2)) / MAX_PTS_PLUS_ONE;
+      long ptsWrapBelow = pts + (MAX_PTS_PLUS_ONE * (closestWrapCount - 1));
+      long ptsWrapAbove = pts + (MAX_PTS_PLUS_ONE * closestWrapCount);
+      pts = Math.abs(ptsWrapBelow - lastPts) < Math.abs(ptsWrapAbove - lastPts)
+          ? ptsWrapBelow : ptsWrapAbove;
+    }
+    // Calculate the corresponding timestamp.
+    long timeUs = (pts * C.MICROS_PER_SECOND) / 90000;
+    // If we haven't done the initial timestamp adjustment, do it now.
+    if (lastPts == Long.MIN_VALUE) {
+      timestampOffsetUs = firstSampleTimestampUs - timeUs;
+    }
+    // Record the adjusted PTS to adjust for wraparound next time.
+    lastPts = pts;
+    return timeUs + timestampOffsetUs;
+  }
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/SeiReader.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/SeiReader.java
index ac1aaef4a2..81378d1685 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/SeiReader.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/SeiReader.java
@@ -32,7 +32,8 @@
 
   public SeiReader(TrackOutput output) {
     super(output);
-    output.format(MediaFormat.createTextFormat(MimeTypes.APPLICATION_EIA608));
+    output.format(MediaFormat.createTextFormat(MediaFormat.NO_VALUE, MimeTypes.APPLICATION_EIA608,
+        MediaFormat.NO_VALUE, C.UNKNOWN_TIME_US, null));
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/ts/TsExtractor.java b/library/src/main/java/com/google/android/exoplayer/extractor/ts/TsExtractor.java
index 2d196d5cb9..5b553838ec 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/ts/TsExtractor.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/ts/TsExtractor.java
@@ -15,8 +15,6 @@
  */
 package com.google.android.exoplayer.extractor.ts;
 
-import com.google.android.exoplayer.C;
-import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.extractor.Extractor;
 import com.google.android.exoplayer.extractor.ExtractorInput;
 import com.google.android.exoplayer.extractor.ExtractorOutput;
@@ -52,45 +50,33 @@
   private static final int TS_STREAM_TYPE_ID3 = 0x15;
   private static final int TS_STREAM_TYPE_EIA608 = 0x100; // 0xFF + 1
 
-  private static final long MAX_PTS = 0x1FFFFFFFFL;
-
+  private final PtsTimestampAdjuster ptsTimestampAdjuster;
   private final ParsableByteArray tsPacketBuffer;
   private final ParsableBitArray tsScratch;
   private final boolean idrKeyframesOnly;
-  private final long firstSampleTimestampUs;
   /* package */ final SparseBooleanArray streamTypes;
-  /* package */ final SparseBooleanArray allowedPassthroughStreamTypes;
   /* package */ final SparseArray<TsPayloadReader> tsPayloadReaders; // Indexed by pid
 
   // Accessed only by the loading thread.
   private ExtractorOutput output;
-  private long timestampOffsetUs;
-  private long lastPts;
   /* package */ Id3Reader id3Reader;
 
   public TsExtractor() {
-    this(0);
-  }
-
-  public TsExtractor(long firstSampleTimestampUs) {
-    this(firstSampleTimestampUs, null);
+    this(new PtsTimestampAdjuster(0));
   }
 
-  public TsExtractor(long firstSampleTimestampUs, AudioCapabilities audioCapabilities) {
-    this(firstSampleTimestampUs, audioCapabilities, true);
+  public TsExtractor(PtsTimestampAdjuster ptsTimestampAdjuster) {
+    this(ptsTimestampAdjuster, true);
   }
 
-  public TsExtractor(long firstSampleTimestampUs, AudioCapabilities audioCapabilities,
-      boolean idrKeyframesOnly) {
-    this.firstSampleTimestampUs = firstSampleTimestampUs;
+  public TsExtractor(PtsTimestampAdjuster ptsTimestampAdjuster, boolean idrKeyframesOnly) {
     this.idrKeyframesOnly = idrKeyframesOnly;
     tsScratch = new ParsableBitArray(new byte[3]);
     tsPacketBuffer = new ParsableByteArray(TS_PACKET_SIZE);
     streamTypes = new SparseBooleanArray();
-    allowedPassthroughStreamTypes = getPassthroughStreamTypes(audioCapabilities);
     tsPayloadReaders = new SparseArray<>();
     tsPayloadReaders.put(TS_PAT_PID, new PatReader());
-    lastPts = Long.MIN_VALUE;
+    this.ptsTimestampAdjuster = ptsTimestampAdjuster;
   }
 
   // Extractor implementation.
@@ -116,8 +102,7 @@ public void init(ExtractorOutput output) {
 
   @Override
   public void seek() {
-    timestampOffsetUs = 0;
-    lastPts = Long.MIN_VALUE;
+    ptsTimestampAdjuster.reset();
     for (int i = 0; i < tsPayloadReaders.size(); i++) {
       tsPayloadReaders.valueAt(i).seek();
     }
@@ -168,51 +153,6 @@ public int read(ExtractorInput input, PositionHolder seekPosition)
 
   // Internals.
 
-  /**
-   * Adjusts a PTS value to the corresponding time in microseconds, accounting for PTS wraparound.
-   *
-   * @param pts The raw PTS value.
-   * @return The corresponding time in microseconds.
-   */
-  /* package */ long ptsToTimeUs(long pts) {
-    if (lastPts != Long.MIN_VALUE) {
-      // The wrap count for the current PTS may be closestWrapCount or (closestWrapCount - 1),
-      // and we need to snap to the one closest to lastPts.
-      long closestWrapCount = (lastPts + (MAX_PTS / 2)) / MAX_PTS;
-      long ptsWrapBelow = pts + (MAX_PTS * (closestWrapCount - 1));
-      long ptsWrapAbove = pts + (MAX_PTS * closestWrapCount);
-      pts = Math.abs(ptsWrapBelow - lastPts) < Math.abs(ptsWrapAbove - lastPts)
-          ? ptsWrapBelow : ptsWrapAbove;
-    }
-    // Calculate the corresponding timestamp.
-    long timeUs = (pts * C.MICROS_PER_SECOND) / 90000;
-    // If we haven't done the initial timestamp adjustment, do it now.
-    if (lastPts == Long.MIN_VALUE) {
-      timestampOffsetUs = firstSampleTimestampUs - timeUs;
-    }
-    // Record the adjusted PTS to adjust for wraparound next time.
-    lastPts = pts;
-    return timeUs + timestampOffsetUs;
-  }
-
-  /**
-   * Returns a sparse boolean array of stream types that can be played back based on
-   * {@code audioCapabilities}.
-   */
-  private static SparseBooleanArray getPassthroughStreamTypes(AudioCapabilities audioCapabilities) {
-    SparseBooleanArray streamTypes = new SparseBooleanArray();
-    if (audioCapabilities != null) {
-      if (audioCapabilities.supportsEncoding(C.ENCODING_AC3)) {
-        streamTypes.put(TS_STREAM_TYPE_ATSC_AC3, true);
-      }
-      if (audioCapabilities.supportsEncoding(C.ENCODING_E_AC3)) {
-        // TODO: Uncomment when Ac3Reader supports enhanced AC-3.
-        // streamTypes.put(TS_STREAM_TYPE_ATSC_E_AC3, true);
-      }
-    }
-    return streamTypes;
-  }
-
   /**
    * Parses TS packet payload data.
    */
@@ -365,9 +305,6 @@ public void consume(ParsableByteArray data, boolean payloadUnitStartIndicator,
             break;
           case TS_STREAM_TYPE_ATSC_E_AC3:
           case TS_STREAM_TYPE_ATSC_AC3:
-            if (!allowedPassthroughStreamTypes.get(streamType)) {
-              continue;
-            }
             pesPayloadReader = new Ac3Reader(output.track(streamType));
             break;
           case TS_STREAM_TYPE_H264:
@@ -405,7 +342,8 @@ public void consume(ParsableByteArray data, boolean payloadUnitStartIndicator,
     private static final int STATE_READING_BODY = 3;
 
     private static final int HEADER_SIZE = 9;
-    private static final int MAX_HEADER_EXTENSION_SIZE = 5;
+    private static final int MAX_HEADER_EXTENSION_SIZE = 10;
+    private static final int PES_SCRATCH_SIZE = 10; // max(HEADER_SIZE, MAX_HEADER_EXTENSION_SIZE)
 
     private final ParsableBitArray pesScratch;
     private final ElementaryStreamReader pesPayloadReader;
@@ -415,13 +353,15 @@ public void consume(ParsableByteArray data, boolean payloadUnitStartIndicator,
     private boolean bodyStarted;
 
     private boolean ptsFlag;
+    private boolean dtsFlag;
+    private boolean seenFirstDts;
     private int extendedHeaderLength;
     private int payloadSize;
     private long timeUs;
 
     public PesReader(ElementaryStreamReader pesPayloadReader) {
       this.pesPayloadReader = pesPayloadReader;
-      pesScratch = new ParsableBitArray(new byte[HEADER_SIZE]);
+      pesScratch = new ParsableBitArray(new byte[PES_SCRATCH_SIZE]);
       state = STATE_FINDING_HEADER;
     }
 
@@ -430,6 +370,7 @@ public void seek() {
       state = STATE_FINDING_HEADER;
       bytesRead = 0;
       bodyStarted = false;
+      seenFirstDts = false;
       pesPayloadReader.seek();
     }
 
@@ -547,9 +488,10 @@ private boolean parseHeader() {
       // data_alignment_indicator (1), copyright (1), original_or_copy (1)
       pesScratch.skipBits(8);
       ptsFlag = pesScratch.readBit();
-      // DTS_flag (1), ESCR_flag (1), ES_rate_flag (1), DSM_trick_mode_flag (1),
+      dtsFlag = pesScratch.readBit();
+      // ESCR_flag (1), ES_rate_flag (1), DSM_trick_mode_flag (1),
       // additional_copy_info_flag (1), PES_CRC_flag (1), PES_extension_flag (1)
-      pesScratch.skipBits(7);
+      pesScratch.skipBits(6);
       extendedHeaderLength = pesScratch.readBits(8);
 
       if (packetLength == 0) {
@@ -572,7 +514,23 @@ private void parseHeaderExtension() {
         pesScratch.skipBits(1); // marker_bit
         pts |= pesScratch.readBits(15);
         pesScratch.skipBits(1); // marker_bit
-        timeUs = ptsToTimeUs(pts);
+        if (!seenFirstDts && dtsFlag) {
+          pesScratch.skipBits(4); // '0011'
+          long dts = (long) pesScratch.readBits(3) << 30;
+          pesScratch.skipBits(1); // marker_bit
+          dts |= pesScratch.readBits(15) << 15;
+          pesScratch.skipBits(1); // marker_bit
+          dts |= pesScratch.readBits(15);
+          pesScratch.skipBits(1); // marker_bit
+          // Subsequent PES packets may have earlier presentation timestamps than this one, but they
+          // should all be greater than or equal to this packet's decode timestamp. We feed the
+          // decode timestamp to the adjuster here so that in the case that this is the first to be
+          // fed, the adjuster will be able to compute an offset to apply such that the adjusted
+          // presentation timestamps of all future packets are non-negative.
+          ptsTimestampAdjuster.adjustTimestamp(dts);
+          seenFirstDts = true;
+        }
+        timeUs = ptsTimestampAdjuster.adjustTimestamp(pts);
       }
     }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/extractor/webm/WebmExtractor.java b/library/src/main/java/com/google/android/exoplayer/extractor/webm/WebmExtractor.java
index 29687aefe3..771fe1e90b 100644
--- a/library/src/main/java/com/google/android/exoplayer/extractor/webm/WebmExtractor.java
+++ b/library/src/main/java/com/google/android/exoplayer/extractor/webm/WebmExtractor.java
@@ -34,13 +34,16 @@
 import com.google.android.exoplayer.util.Util;
 
 import android.util.Pair;
+import android.util.SparseArray;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
+import java.nio.ByteOrder;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
+import java.util.Locale;
 
 /**
  * An extractor to facilitate data retrieval from the WebM container format.
@@ -57,10 +60,6 @@
   private static final int BLOCK_STATE_HEADER = 1;
   private static final int BLOCK_STATE_DATA = 2;
 
-  private static final int CUES_STATE_NOT_BUILT = 0;
-  private static final int CUES_STATE_BUILDING = 1;
-  private static final int CUES_STATE_BUILT = 2;
-
   private static final String DOC_TYPE_WEBM = "webm";
   private static final String DOC_TYPE_MATROSKA = "matroska";
   private static final String CODEC_ID_VP8 = "V_VP8";
@@ -75,12 +74,16 @@
   private static final String CODEC_ID_AAC = "A_AAC";
   private static final String CODEC_ID_MP3 = "A_MPEG/L3";
   private static final String CODEC_ID_AC3 = "A_AC3";
+  private static final String CODEC_ID_DTS = "A_DTS";
+  private static final String CODEC_ID_DTS_EXPRESS = "A_DTS/EXPRESS";
+  private static final String CODEC_ID_DTS_LOSSLESS = "A_DTS/LOSSLESS";
+  private static final String CODEC_ID_SUBRIP = "S_TEXT/UTF8";
+
   private static final int VORBIS_MAX_INPUT_SIZE = 8192;
   private static final int OPUS_MAX_INPUT_SIZE = 5760;
   private static final int MP3_MAX_INPUT_SIZE = 4096;
   private static final int ENCRYPTION_IV_SIZE = 8;
   private static final int TRACK_TYPE_AUDIO = 2;
-  private static final int TRACK_TYPE_VIDEO = 1;
   private static final int UNKNOWN = -1;
 
   private static final int ID_EBML = 0x1A45DFA3;
@@ -101,6 +104,7 @@
   private static final int ID_SIMPLE_BLOCK = 0xA3;
   private static final int ID_BLOCK_GROUP = 0xA0;
   private static final int ID_BLOCK = 0xA1;
+  private static final int ID_BLOCK_DURATION = 0x9B;
   private static final int ID_REFERENCE_BLOCK = 0xFB;
   private static final int ID_TRACKS = 0x1654AE6B;
   private static final int ID_TRACK_ENTRY = 0xAE;
@@ -134,14 +138,42 @@
   private static final int ID_CUE_TIME = 0xB3;
   private static final int ID_CUE_TRACK_POSITIONS = 0xB7;
   private static final int ID_CUE_CLUSTER_POSITION = 0xF1;
+  private static final int ID_LANGUAGE = 0x22B59C;
 
   private static final int LACING_NONE = 0;
   private static final int LACING_XIPH = 1;
   private static final int LACING_FIXED_SIZE = 2;
   private static final int LACING_EBML = 3;
 
+  /**
+   * A template for the prefix that must be added to each subrip sample. The 12 byte end timecode
+   * starting at {@link #SUBRIP_PREFIX_END_TIMECODE_OFFSET} is set to a dummy value, and must be
+   * replaced with the duration of the subtitle.
+   * <p>
+   * Equivalent to the UTF-8 string: "1\n00:00:00,000 --> 00:00:00,000\n".
+   */
+  private static final byte[] SUBRIP_PREFIX = new byte[] {49, 10, 48, 48, 58, 48, 48, 58, 48, 48,
+      44, 48, 48, 48, 32, 45, 45, 62, 32, 48, 48, 58, 48, 48, 58, 48, 48, 44, 48, 48, 48, 10};
+  /**
+   * A special end timecode indicating that a subtitle should be displayed until the next subtitle,
+   * or until the end of the media in the case of the last subtitle.
+   * <p>
+   * Equivalent to the UTF-8 string: "            ".
+   */
+  private static final byte[] SUBRIP_TIMECODE_EMPTY =
+      new byte[] {32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32};
+  /**
+   * The byte offset of the end timecode in {@link #SUBRIP_PREFIX}.
+   */
+  private static final int SUBRIP_PREFIX_END_TIMECODE_OFFSET = 19;
+  /**
+   * The length in bytes of a timecode in a subrip prefix.
+   */
+  private static final int SUBRIP_TIMECODE_LENGTH = 12;
+
   private final EbmlReader reader;
   private final VarintReader varintReader;
+  private final SparseArray<Track> tracks;
 
   // Temporary arrays.
   private final ParsableByteArray nalStartCode;
@@ -150,6 +182,7 @@
   private final ParsableByteArray vorbisNumPageSamples;
   private final ParsableByteArray seekEntryIdBytes;
   private final ParsableByteArray sampleStrippedBytes;
+  private final ParsableByteArray subripSample;
 
   private long segmentContentPosition = UNKNOWN;
   private long segmentContentSize = UNKNOWN;
@@ -157,11 +190,12 @@
   private long durationTimecode = C.UNKNOWN_TIME_US;
   private long durationUs = C.UNKNOWN_TIME_US;
 
-  private TrackFormat trackFormat;  // Used to store the last seen track.
-  private TrackFormat audioTrackFormat;
-  private TrackFormat videoTrackFormat;
+  // The track corresponding to the current TrackEntry element, or null.
+  private Track currentTrack;
 
+  // Whether drm init data has been sent to the output.
   private boolean sentDrmInitData;
+  private boolean sentSeekMap;
 
   // Master seek entry related elements.
   private int seekEntryId;
@@ -171,7 +205,6 @@
   private boolean seekForCues;
   private long cuesContentPosition = UNKNOWN;
   private long seekPositionAfterBuildingCues = UNKNOWN;
-  private int cuesState = CUES_STATE_NOT_BUILT;
   private long clusterTimecodeUs = UNKNOWN;
   private LongArray cueTimesUs;
   private LongArray cueClusterPositions;
@@ -180,13 +213,13 @@
   // Block reading state.
   private int blockState;
   private long blockTimeUs;
+  private long blockDurationUs;
   private int blockLacingSampleIndex;
   private int blockLacingSampleCount;
   private int[] blockLacingSampleSizes;
   private int blockTrackNumber;
   private int blockTrackNumberLength;
   private int blockFlags;
-  private byte[] blockEncryptionKeyId;
 
   // Sample reading state.
   private int sampleBytesRead;
@@ -207,12 +240,14 @@ public WebmExtractor() {
     this.reader = reader;
     this.reader.init(new InnerEbmlReaderOutput());
     varintReader = new VarintReader();
+    tracks = new SparseArray<>();
     scratch = new ParsableByteArray(4);
     vorbisNumPageSamples = new ParsableByteArray(ByteBuffer.allocate(4).putInt(-1).array());
     seekEntryIdBytes = new ParsableByteArray(4);
     nalStartCode = new ParsableByteArray(NalUnitUtil.NAL_START_CODE);
     nalLength = new ParsableByteArray(4);
     sampleStrippedBytes = new ParsableByteArray();
+    subripSample = new ParsableByteArray();
   }
 
   @Override
@@ -275,6 +310,7 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
       case ID_SEEK_POSITION:
       case ID_TIMECODE_SCALE:
       case ID_TIME_CODE:
+      case ID_BLOCK_DURATION:
       case ID_PIXEL_WIDTH:
       case ID_PIXEL_HEIGHT:
       case ID_TRACK_NUMBER:
@@ -294,6 +330,7 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         return EbmlReader.TYPE_UNSIGNED_INT;
       case ID_DOC_TYPE:
       case ID_CODEC_ID:
+      case ID_LANGUAGE:
         return EbmlReader.TYPE_STRING;
       case ID_SEEK_ID:
       case ID_CONTENT_COMPRESSION_SETTINGS:
@@ -332,7 +369,7 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         seenClusterPositionForCurrentCuePoint = false;
         return;
       case ID_CLUSTER:
-        if (cuesState == CUES_STATE_NOT_BUILT) {
+        if (!sentSeekMap) {
           // We need to build cues before parsing the cluster.
           if (cuesContentPosition != UNKNOWN) {
             // We know where the Cues element is located. Seek to request it.
@@ -341,7 +378,7 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
             // We don't know where the Cues element is located. It's most likely omitted. Allow
             // playback, but disable seeking.
             extractorOutput.seekMap(SeekMap.UNSEEKABLE);
-            cuesState = CUES_STATE_BUILT;
+            sentSeekMap = true;
           }
         }
         return;
@@ -352,10 +389,10 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         // TODO: check and fail if more than one content encoding is present.
         return;
       case ID_CONTENT_ENCRYPTION:
-        trackFormat.hasContentEncryption = true;
+        currentTrack.hasContentEncryption = true;
         return;
       case ID_TRACK_ENTRY:
-        trackFormat = new TrackFormat();
+        currentTrack = new Track();
         return;
       default:
         return;
@@ -382,9 +419,9 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         }
         return;
       case ID_CUES:
-        if (cuesState != CUES_STATE_BUILT) {
+        if (!sentSeekMap) {
           extractorOutput.seekMap(buildSeekMap());
-          cuesState = CUES_STATE_BUILT;
+          sentSeekMap = true;
         } else {
           // We have already built the cues. Ignore.
         }
@@ -398,53 +435,37 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         if (!sampleSeenReferenceBlock) {
           blockFlags |= C.SAMPLE_FLAG_SYNC;
         }
-        outputSampleMetadata(
-            (audioTrackFormat != null && blockTrackNumber == audioTrackFormat.number)
-                ? audioTrackFormat.trackOutput : videoTrackFormat.trackOutput, blockTimeUs);
+        commitSampleToOutput(tracks.get(blockTrackNumber), blockTimeUs);
         blockState = BLOCK_STATE_START;
         return;
       case ID_CONTENT_ENCODING:
-        if (trackFormat.hasContentEncryption) {
-          if (trackFormat.encryptionKeyId == null) {
+        if (currentTrack.hasContentEncryption) {
+          if (currentTrack.encryptionKeyId == null) {
             throw new ParserException("Encrypted Track found but ContentEncKeyID was not found");
           }
           if (!sentDrmInitData) {
             extractorOutput.drmInitData(
-                new DrmInitData.Universal(MimeTypes.VIDEO_WEBM, trackFormat.encryptionKeyId));
+                new DrmInitData.Universal(MimeTypes.VIDEO_WEBM, currentTrack.encryptionKeyId));
             sentDrmInitData = true;
           }
         }
         return;
       case ID_CONTENT_ENCODINGS:
-        if (trackFormat.hasContentEncryption && trackFormat.sampleStrippedBytes != null) {
+        if (currentTrack.hasContentEncryption && currentTrack.sampleStrippedBytes != null) {
           throw new ParserException("Combining encryption and compression is not supported");
         }
         return;
       case ID_TRACK_ENTRY:
-        if (trackFormat.number == UNKNOWN || trackFormat.type == UNKNOWN) {
-          throw new ParserException("Mandatory element TrackNumber or TrackType not found");
-        }
-        if ((trackFormat.type == TRACK_TYPE_AUDIO && audioTrackFormat != null)
-            || (trackFormat.type == TRACK_TYPE_VIDEO && videoTrackFormat != null)) {
-          // There is more than 1 audio/video track. Ignore everything but the first.
-          trackFormat = null;
-          return;
-        }
-        if (trackFormat.type == TRACK_TYPE_AUDIO && isCodecSupported(trackFormat.codecId)) {
-          audioTrackFormat = trackFormat;
-          audioTrackFormat.trackOutput = extractorOutput.track(audioTrackFormat.number);
-          audioTrackFormat.trackOutput.format(audioTrackFormat.getMediaFormat(durationUs));
-        } else if (trackFormat.type == TRACK_TYPE_VIDEO && isCodecSupported(trackFormat.codecId)) {
-          videoTrackFormat = trackFormat;
-          videoTrackFormat.trackOutput = extractorOutput.track(videoTrackFormat.number);
-          videoTrackFormat.trackOutput.format(videoTrackFormat.getMediaFormat(durationUs));
+        if (tracks.get(currentTrack.number) == null && isCodecSupported(currentTrack.codecId)) {
+          currentTrack.initializeOutput(extractorOutput, currentTrack.number, durationUs);
+          tracks.put(currentTrack.number, currentTrack);
         } else {
-          // Unsupported track type. Do nothing.
+          // We've seen this track entry before, or the codec is unsupported. Do nothing.
         }
-        trackFormat = null;
+        currentTrack = null;
         return;
       case ID_TRACKS:
-        if (videoTrackFormat == null && audioTrackFormat == null) {
+        if (tracks.size() == 0) {
           throw new ParserException("No valid tracks were found");
         }
         extractorOutput.endTracks();
@@ -477,28 +498,28 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         timecodeScale = value;
         return;
       case ID_PIXEL_WIDTH:
-        trackFormat.pixelWidth = (int) value;
+        currentTrack.width = (int) value;
         return;
       case ID_PIXEL_HEIGHT:
-        trackFormat.pixelHeight = (int) value;
+        currentTrack.height = (int) value;
         return;
       case ID_TRACK_NUMBER:
-        trackFormat.number = (int) value;
+        currentTrack.number = (int) value;
         return;
       case ID_TRACK_TYPE:
-        trackFormat.type = (int) value;
+        currentTrack.type = (int) value;
         return;
       case ID_DEFAULT_DURATION:
-        trackFormat.defaultSampleDurationNs = (int) value;
+        currentTrack.defaultSampleDurationNs = (int) value;
         break;
       case ID_CODEC_DELAY:
-        trackFormat.codecDelayNs = value;
+        currentTrack.codecDelayNs = value;
         return;
       case ID_SEEK_PRE_ROLL:
-        trackFormat.seekPreRollNs = value;
+        currentTrack.seekPreRollNs = value;
         return;
       case ID_CHANNELS:
-        trackFormat.channelCount = (int) value;
+        currentTrack.channelCount = (int) value;
         return;
       case ID_REFERENCE_BLOCK:
         sampleSeenReferenceBlock = true;
@@ -548,6 +569,9 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
       case ID_TIME_CODE:
         clusterTimecodeUs = scaleTimecodeToUs(value);
         return;
+      case ID_BLOCK_DURATION:
+        blockDurationUs = scaleTimecodeToUs(value);
+        return;
       default:
         return;
     }
@@ -559,7 +583,7 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         durationTimecode = (long) value;
         return;
       case ID_SAMPLING_FREQUENCY:
-        trackFormat.sampleRate = (int) value;
+        currentTrack.sampleRate = (int) value;
         return;
       default:
         return;
@@ -575,7 +599,10 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         }
         return;
       case ID_CODEC_ID:
-        trackFormat.codecId = value;
+        currentTrack.codecId = value;
+        return;
+      case ID_LANGUAGE:
+        currentTrack.language = value;
         return;
       default:
         return;
@@ -592,17 +619,17 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         seekEntryId = (int) seekEntryIdBytes.readUnsignedInt();
         return;
       case ID_CODEC_PRIVATE:
-        trackFormat.codecPrivate = new byte[contentSize];
-        input.readFully(trackFormat.codecPrivate, 0, contentSize);
+        currentTrack.codecPrivate = new byte[contentSize];
+        input.readFully(currentTrack.codecPrivate, 0, contentSize);
         return;
       case ID_CONTENT_COMPRESSION_SETTINGS:
         // This extractor only supports header stripping, so the payload is the stripped bytes.
-        trackFormat.sampleStrippedBytes = new byte[contentSize];
-        input.readFully(trackFormat.sampleStrippedBytes, 0, contentSize);
+        currentTrack.sampleStrippedBytes = new byte[contentSize];
+        input.readFully(currentTrack.sampleStrippedBytes, 0, contentSize);
         return;
       case ID_CONTENT_ENCRYPTION_KEY_ID:
-        trackFormat.encryptionKeyId = new byte[contentSize];
-        input.readFully(trackFormat.encryptionKeyId, 0, contentSize);
+        currentTrack.encryptionKeyId = new byte[contentSize];
+        input.readFully(currentTrack.encryptionKeyId, 0, contentSize);
         return;
       case ID_SIMPLE_BLOCK:
       case ID_BLOCK:
@@ -614,28 +641,20 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         if (blockState == BLOCK_STATE_START) {
           blockTrackNumber = (int) varintReader.readUnsignedVarint(input, false, true);
           blockTrackNumberLength = varintReader.getLastLength();
+          blockDurationUs = UNKNOWN;
           blockState = BLOCK_STATE_HEADER;
           scratch.reset();
         }
 
-        // Ignore the block if the track number equals neither the audio track nor the video track.
-        if ((audioTrackFormat != null && videoTrackFormat != null
-                && audioTrackFormat.number != blockTrackNumber
-                && videoTrackFormat.number != blockTrackNumber)
-            || (audioTrackFormat != null && videoTrackFormat == null
-                && audioTrackFormat.number != blockTrackNumber)
-            || (audioTrackFormat == null && videoTrackFormat != null
-                && videoTrackFormat.number != blockTrackNumber)) {
+        Track track = tracks.get(blockTrackNumber);
+
+        // Ignore the block if we don't know about the track to which it belongs.
+        if (track == null) {
           input.skipFully(contentSize - blockTrackNumberLength);
           blockState = BLOCK_STATE_START;
           return;
         }
 
-        TrackFormat sampleTrackFormat =
-            (audioTrackFormat != null && blockTrackNumber == audioTrackFormat.number)
-                ? audioTrackFormat : videoTrackFormat;
-        TrackOutput trackOutput = sampleTrackFormat.trackOutput;
-
         if (blockState == BLOCK_STATE_HEADER) {
           // Read the relative timecode (2 bytes) and flags (1 byte).
           readScratch(input, 3);
@@ -720,10 +739,10 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
           int timecode = (scratch.data[0] << 8) | (scratch.data[1] & 0xFF);
           blockTimeUs = clusterTimecodeUs + scaleTimecodeToUs(timecode);
           boolean isInvisible = (scratch.data[2] & 0x08) == 0x08;
-          boolean isKeyframe = (id == ID_SIMPLE_BLOCK && (scratch.data[2] & 0x80) == 0x80);
+          boolean isKeyframe = track.type == TRACK_TYPE_AUDIO
+              || (id == ID_SIMPLE_BLOCK && (scratch.data[2] & 0x80) == 0x80);
           blockFlags = (isKeyframe ? C.SAMPLE_FLAG_SYNC : 0)
               | (isInvisible ? C.SAMPLE_FLAG_DECODE_ONLY : 0);
-          blockEncryptionKeyId = sampleTrackFormat.encryptionKeyId;
           blockState = BLOCK_STATE_DATA;
           blockLacingSampleIndex = 0;
         }
@@ -731,18 +750,17 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
         if (id == ID_SIMPLE_BLOCK) {
           // For SimpleBlock, we have metadata for each sample here.
           while (blockLacingSampleIndex < blockLacingSampleCount) {
-            writeSampleData(input, trackOutput, sampleTrackFormat,
-                blockLacingSampleSizes[blockLacingSampleIndex]);
+            writeSampleData(input, track, blockLacingSampleSizes[blockLacingSampleIndex]);
             long sampleTimeUs = this.blockTimeUs
-                + (blockLacingSampleIndex * sampleTrackFormat.defaultSampleDurationNs) / 1000;
-            outputSampleMetadata(trackOutput, sampleTimeUs);
+                + (blockLacingSampleIndex * track.defaultSampleDurationNs) / 1000;
+            commitSampleToOutput(track, sampleTimeUs);
             blockLacingSampleIndex++;
           }
           blockState = BLOCK_STATE_START;
         } else {
           // For Block, we send the metadata at the end of the BlockGroup element since we'll know
           // if the sample is a keyframe or not only at that point.
-          writeSampleData(input, trackOutput, sampleTrackFormat, blockLacingSampleSizes[0]);
+          writeSampleData(input, track, blockLacingSampleSizes[0]);
         }
 
         return;
@@ -751,8 +769,11 @@ public int read(ExtractorInput input, PositionHolder seekPosition) throws IOExce
     }
   }
 
-  private void outputSampleMetadata(TrackOutput trackOutput, long timeUs) {
-    trackOutput.sampleMetadata(timeUs, blockFlags, sampleBytesWritten, 0, blockEncryptionKeyId);
+  private void commitSampleToOutput(Track track, long timeUs) {
+    if (CODEC_ID_SUBRIP.equals(track.codecId)) {
+      writeSubripSample(track);
+    }
+    track.output.sampleMetadata(timeUs, blockFlags, sampleBytesWritten, 0, track.encryptionKeyId);
     sampleRead = true;
     resetSample();
   }
@@ -782,10 +803,26 @@ private void readScratch(ExtractorInput input, int requiredLength)
     scratch.setLimit(requiredLength);
   }
 
-  private void writeSampleData(ExtractorInput input, TrackOutput output, TrackFormat format,
-      int size) throws IOException, InterruptedException {
+  private void writeSampleData(ExtractorInput input, Track track, int size)
+      throws IOException, InterruptedException {
+    if (CODEC_ID_SUBRIP.equals(track.codecId)) {
+      int sizeWithPrefix = SUBRIP_PREFIX.length + size;
+      if (subripSample.capacity() < sizeWithPrefix) {
+        // Initialize subripSample to contain the required prefix and have space to hold a subtitle
+        // twice as long as this one.
+        subripSample.data = Arrays.copyOf(SUBRIP_PREFIX, sizeWithPrefix + size);
+      }
+      input.readFully(subripSample.data, SUBRIP_PREFIX.length, size);
+      subripSample.setPosition(0);
+      subripSample.setLimit(sizeWithPrefix);
+      // Defer writing the data to the track output. We need to modify the sample data by setting
+      // the correct end timecode, which we might not have yet.
+      return;
+    }
+
+    TrackOutput output = track.output;
     if (!sampleEncodingHandled) {
-      if (format.hasContentEncryption) {
+      if (track.hasContentEncryption) {
         // If the sample is encrypted, read its encryption signal byte and set the IV size.
         // Clear the encrypted flag.
         blockFlags &= ~C.SAMPLE_FLAG_ENCRYPTED;
@@ -801,15 +838,15 @@ private void writeSampleData(ExtractorInput input, TrackOutput output, TrackForm
           sampleBytesWritten++;
           blockFlags |= C.SAMPLE_FLAG_ENCRYPTED;
         }
-      } else if (format.sampleStrippedBytes != null) {
+      } else if (track.sampleStrippedBytes != null) {
         // If the sample has header stripping, prepare to read/output the stripped bytes first.
-        sampleStrippedBytes.reset(format.sampleStrippedBytes, format.sampleStrippedBytes.length);
+        sampleStrippedBytes.reset(track.sampleStrippedBytes, track.sampleStrippedBytes.length);
       }
       sampleEncodingHandled = true;
     }
     size += sampleStrippedBytes.limit();
 
-    if (CODEC_ID_H264.equals(format.codecId) || CODEC_ID_H265.equals(format.codecId)) {
+    if (CODEC_ID_H264.equals(track.codecId) || CODEC_ID_H265.equals(track.codecId)) {
       // TODO: Deduplicate with Mp4Extractor.
 
       // Zero the top three bytes of the array that we'll use to parse nal unit lengths, in case
@@ -818,8 +855,8 @@ private void writeSampleData(ExtractorInput input, TrackOutput output, TrackForm
       nalLengthData[0] = 0;
       nalLengthData[1] = 0;
       nalLengthData[2] = 0;
-      int nalUnitLengthFieldLength = format.nalUnitLengthFieldLength;
-      int nalUnitLengthFieldLengthDiff = 4 - format.nalUnitLengthFieldLength;
+      int nalUnitLengthFieldLength = track.nalUnitLengthFieldLength;
+      int nalUnitLengthFieldLengthDiff = 4 - track.nalUnitLengthFieldLength;
       // NAL units are length delimited, but the decoder requires start code delimited units.
       // Loop until we've written the sample to the track output, replacing length delimiters with
       // start codes as we encounter them.
@@ -846,7 +883,7 @@ private void writeSampleData(ExtractorInput input, TrackOutput output, TrackForm
       }
     }
 
-    if (CODEC_ID_VORBIS.equals(format.codecId)) {
+    if (CODEC_ID_VORBIS.equals(track.codecId)) {
       // Vorbis decoder in android MediaCodec [1] expects the last 4 bytes of the sample to be the
       // number of samples in the current page. This definition holds good only for Ogg and
       // irrelevant for WebM. So we always set this to -1 (the decoder will ignore this value if we
@@ -859,6 +896,33 @@ private void writeSampleData(ExtractorInput input, TrackOutput output, TrackForm
     }
   }
 
+  private void writeSubripSample(Track track) {
+    setSubripSampleEndTimecode(subripSample.data, blockDurationUs);
+    // Note: If we ever want to support DRM protected subtitles then we'll need to output the
+    // appropriate encryption data here.
+    track.output.sampleData(subripSample, subripSample.limit());
+    sampleBytesWritten += subripSample.limit();
+  }
+
+  private static void setSubripSampleEndTimecode(byte[] subripSampleData, long timeUs) {
+    byte[] timeCodeData;
+    if (timeUs == UNKNOWN) {
+      timeCodeData = SUBRIP_TIMECODE_EMPTY;
+    } else {
+      int hours = (int) (timeUs / 3600000000L);
+      timeUs -= (hours * 3600000000L);
+      int minutes = (int) (timeUs / 60000000);
+      timeUs -= (minutes * 60000000);
+      int seconds = (int) (timeUs / 1000000);
+      timeUs -= (seconds * 1000000);
+      int milliseconds = (int) (timeUs / 1000);
+      timeCodeData = String.format(Locale.US, "%02d:%02d:%02d,%03d",
+          hours, minutes, seconds, milliseconds).getBytes();
+    }
+    System.arraycopy(timeCodeData, 0, subripSampleData, SUBRIP_PREFIX_END_TIMECODE_OFFSET,
+        SUBRIP_TIMECODE_LENGTH);
+  }
+
   /**
    * Writes {@code length} bytes of sample data into {@code target} at {@code offset}, consisting of
    * pending {@link #sampleStrippedBytes} and any remaining data read from {@code input}.
@@ -941,13 +1005,12 @@ private boolean maybeSeekForCues(PositionHolder seekPosition, long currentPositi
     if (seekForCues) {
       seekPositionAfterBuildingCues = currentPosition;
       seekPosition.position = cuesContentPosition;
-      cuesState = CUES_STATE_BUILDING;
       seekForCues = false;
       return true;
     }
-    // After parsing Cues, Seek back to original position if available. We will not do this unless
+    // After parsing Cues, seek back to original position if available. We will not do this unless
     // we seeked to get to the Cues in the first place.
-    if (cuesState == CUES_STATE_BUILT && seekPositionAfterBuildingCues != UNKNOWN) {
+    if (sentSeekMap && seekPositionAfterBuildingCues != UNKNOWN) {
       seekPosition.position = seekPositionAfterBuildingCues;
       seekPositionAfterBuildingCues = UNKNOWN;
       return true;
@@ -974,7 +1037,11 @@ private static boolean isCodecSupported(String codecId) {
         || CODEC_ID_VORBIS.equals(codecId)
         || CODEC_ID_AAC.equals(codecId)
         || CODEC_ID_MP3.equals(codecId)
-        || CODEC_ID_AC3.equals(codecId);
+        || CODEC_ID_AC3.equals(codecId)
+        || CODEC_ID_DTS.equals(codecId)
+        || CODEC_ID_DTS_EXPRESS.equals(codecId)
+        || CODEC_ID_DTS_LOSSLESS.equals(codecId)
+        || CODEC_ID_SUBRIP.equals(codecId);
   }
 
   /**
@@ -1036,36 +1103,43 @@ public void binaryElement(int id, int contentsSize, ExtractorInput input)
 
   }
 
-  private static final class TrackFormat {
+  private static final class Track {
 
-    // Common track elements.
+    // Common elements.
     public String codecId;
-    public int number = UNKNOWN;
-    public int type = UNKNOWN;
-    public int defaultSampleDurationNs = UNKNOWN;
+    public int number;
+    public int type;
+    public int defaultSampleDurationNs;
     public boolean hasContentEncryption;
     public byte[] sampleStrippedBytes;
     public byte[] encryptionKeyId;
     public byte[] codecPrivate;
 
-    // Video track related elements.
-    public int pixelWidth = UNKNOWN;
-    public int pixelHeight = UNKNOWN;
-    public int nalUnitLengthFieldLength = UNKNOWN;
+    // Video elements.
+    public int width = MediaFormat.NO_VALUE;
+    public int height = MediaFormat.NO_VALUE;
 
-    // Audio track related elements.
-    public int channelCount = UNKNOWN;
-    public int sampleRate = UNKNOWN;
-    public long codecDelayNs = UNKNOWN;
-    public long seekPreRollNs = UNKNOWN;
+    // Audio elements. Initially set to their default values.
+    public int channelCount = 1;
+    public int sampleRate = 8000;
+    public long codecDelayNs = 0;
+    public long seekPreRollNs = 0;
 
-    public TrackOutput trackOutput;
+    // Text elements.
+    private String language = "eng";
 
-    /** Returns a {@link MediaFormat} built using the information in this instance. */
-    public MediaFormat getMediaFormat(long durationUs) throws ParserException {
+    // Set when the output is initialized. nalUnitLengthFieldLength is only set for H264/H265.
+    public TrackOutput output;
+    public int nalUnitLengthFieldLength;
+
+    /**
+     * Initializes the track with an output.
+     */
+    public void initializeOutput(ExtractorOutput output, int trackId, long durationUs)
+        throws ParserException {
       String mimeType;
+      int maxInputSize = MediaFormat.NO_VALUE;
       List<byte[]> initializationData = null;
-      int maxInputSize = UNKNOWN;
       switch (codecId) {
         case CODEC_ID_VP8:
           mimeType = MimeTypes.VIDEO_VP8;
@@ -1104,33 +1178,52 @@ public MediaFormat getMediaFormat(long durationUs) throws ParserException {
           maxInputSize = OPUS_MAX_INPUT_SIZE;
           initializationData = new ArrayList<>(3);
           initializationData.add(codecPrivate);
-          initializationData.add(ByteBuffer.allocate(Long.SIZE).putLong(codecDelayNs).array());
-          initializationData.add(ByteBuffer.allocate(Long.SIZE).putLong(seekPreRollNs).array());
+          initializationData.add(
+              ByteBuffer.allocate(8).order(ByteOrder.LITTLE_ENDIAN).putLong(codecDelayNs).array());
+          initializationData.add(
+              ByteBuffer.allocate(8).order(ByteOrder.LITTLE_ENDIAN).putLong(seekPreRollNs).array());
           break;
         case CODEC_ID_AAC:
           mimeType = MimeTypes.AUDIO_AAC;
           initializationData = Collections.singletonList(codecPrivate);
           break;
         case CODEC_ID_MP3:
-          maxInputSize = MP3_MAX_INPUT_SIZE;
           mimeType = MimeTypes.AUDIO_MPEG;
+          maxInputSize = MP3_MAX_INPUT_SIZE;
           break;
         case CODEC_ID_AC3:
           mimeType = MimeTypes.AUDIO_AC3;
           break;
+        case CODEC_ID_DTS:
+        case CODEC_ID_DTS_EXPRESS:
+          mimeType = MimeTypes.AUDIO_DTS;
+          break;
+        case CODEC_ID_DTS_LOSSLESS:
+          mimeType = MimeTypes.AUDIO_DTS_HD;
+          break;
+        case CODEC_ID_SUBRIP:
+          mimeType = MimeTypes.APPLICATION_SUBRIP;
+          break;
         default:
           throw new ParserException("Unrecognized codec identifier.");
       }
 
+      MediaFormat format;
       if (MimeTypes.isAudio(mimeType)) {
-        return MediaFormat.createAudioFormat(mimeType, maxInputSize, durationUs, channelCount,
-            sampleRate, initializationData);
+        format = MediaFormat.createAudioFormat(trackId, mimeType, MediaFormat.NO_VALUE,
+            maxInputSize, durationUs, channelCount, sampleRate, initializationData, language);
       } else if (MimeTypes.isVideo(mimeType)) {
-        return MediaFormat.createVideoFormat(mimeType, maxInputSize, durationUs, pixelWidth,
-            pixelHeight, initializationData);
+        format = MediaFormat.createVideoFormat(trackId, mimeType, MediaFormat.NO_VALUE,
+            maxInputSize, durationUs, width, height, initializationData);
+      } else if (MimeTypes.APPLICATION_SUBRIP.equals(mimeType)) {
+        format = MediaFormat.createTextFormat(trackId, mimeType, MediaFormat.NO_VALUE, durationUs,
+            language);
       } else {
         throw new ParserException("Unexpected MIME type.");
       }
+
+      this.output = output.track(number);
+      this.output.format(format);
     }
 
     /**
diff --git a/library/src/main/java/com/google/android/exoplayer/hls/HlsChunkSource.java b/library/src/main/java/com/google/android/exoplayer/hls/HlsChunkSource.java
index 6816f77c20..f70d1900f6 100644
--- a/library/src/main/java/com/google/android/exoplayer/hls/HlsChunkSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/hls/HlsChunkSource.java
@@ -17,13 +17,15 @@
 
 import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.MediaFormat;
-import com.google.android.exoplayer.audio.AudioCapabilities;
 import com.google.android.exoplayer.chunk.BaseChunkSampleSourceEventListener;
 import com.google.android.exoplayer.chunk.Chunk;
+import com.google.android.exoplayer.chunk.ChunkOperationHolder;
 import com.google.android.exoplayer.chunk.DataChunk;
 import com.google.android.exoplayer.chunk.Format;
 import com.google.android.exoplayer.extractor.Extractor;
+import com.google.android.exoplayer.extractor.mp3.Mp3Extractor;
 import com.google.android.exoplayer.extractor.ts.AdtsExtractor;
+import com.google.android.exoplayer.extractor.ts.PtsTimestampAdjuster;
 import com.google.android.exoplayer.extractor.ts.TsExtractor;
 import com.google.android.exoplayer.upstream.BandwidthMeter;
 import com.google.android.exoplayer.upstream.DataSource;
@@ -113,6 +115,7 @@
 
   private static final String TAG = "HlsChunkSource";
   private static final String AAC_FILE_EXTENSION = ".aac";
+  private static final String MP3_FILE_EXTENSION = ".mp3";
   private static final float BANDWIDTH_FRACTION = 0.8f;
 
   private final DataSource dataSource;
@@ -120,11 +123,10 @@
   private final BandwidthMeter bandwidthMeter;
   private final int adaptiveMode;
   private final String baseUri;
-  private final int maxWidth;
-  private final int maxHeight;
+  private final int adaptiveMaxWidth;
+  private final int adaptiveMaxHeight;
   private final long minBufferDurationToSwitchUpUs;
   private final long maxBufferDurationToSwitchDownUs;
-  private final AudioCapabilities audioCapabilities;
 
   // A list of variants considered during playback, ordered by decreasing bandwidth. The following
   // three arrays are of the same length and are ordered in the same way (i.e. variantPlaylists[i],
@@ -140,6 +142,8 @@
   private byte[] scratchSpace;
   private boolean live;
   private long durationUs;
+  private IOException fatalError;
+  private PtsTimestampAdjuster ptsTimestampAdjuster;
 
   private Uri encryptionKeyUri;
   private byte[] encryptionKey;
@@ -147,11 +151,9 @@
   private byte[] encryptionIv;
 
   public HlsChunkSource(DataSource dataSource, String playlistUrl, HlsPlaylist playlist,
-      BandwidthMeter bandwidthMeter, int[] variantIndices, int adaptiveMode,
-      AudioCapabilities audioCapabilities) {
+      BandwidthMeter bandwidthMeter, int[] variantIndices, int adaptiveMode) {
     this(dataSource, playlistUrl, playlist, bandwidthMeter, variantIndices, adaptiveMode,
-        DEFAULT_MIN_BUFFER_TO_SWITCH_UP_MS, DEFAULT_MAX_BUFFER_TO_SWITCH_DOWN_MS,
-        audioCapabilities);
+        DEFAULT_MIN_BUFFER_TO_SWITCH_UP_MS, DEFAULT_MAX_BUFFER_TO_SWITCH_DOWN_MS);
   }
 
   /**
@@ -169,17 +171,13 @@ public HlsChunkSource(DataSource dataSource, String playlistUrl, HlsPlaylist pla
    *     for a switch to a higher quality variant to be considered.
    * @param maxBufferDurationToSwitchDownMs The maximum duration of media that needs to be buffered
    *     for a switch to a lower quality variant to be considered.
-   * @param audioCapabilities The audio capabilities for playback on this device, or {@code null} if
-   *     the default capabilities should be assumed.
    */
   public HlsChunkSource(DataSource dataSource, String playlistUrl, HlsPlaylist playlist,
       BandwidthMeter bandwidthMeter, int[] variantIndices, int adaptiveMode,
-      long minBufferDurationToSwitchUpMs, long maxBufferDurationToSwitchDownMs,
-      AudioCapabilities audioCapabilities) {
+      long minBufferDurationToSwitchUpMs, long maxBufferDurationToSwitchDownMs) {
     this.dataSource = dataSource;
     this.bandwidthMeter = bandwidthMeter;
     this.adaptiveMode = adaptiveMode;
-    this.audioCapabilities = audioCapabilities;
     minBufferDurationToSwitchUpUs = minBufferDurationToSwitchUpMs * 1000;
     maxBufferDurationToSwitchDownUs = maxBufferDurationToSwitchDownMs * 1000;
     baseUri = playlist.baseUri;
@@ -192,8 +190,8 @@ public HlsChunkSource(DataSource dataSource, String playlistUrl, HlsPlaylist pla
       variantBlacklistTimes = new long[1];
       setMediaPlaylist(0, (HlsMediaPlaylist) playlist);
       // We won't be adapting between different variants.
-      maxWidth = -1;
-      maxHeight = -1;
+      adaptiveMaxWidth = MediaFormat.NO_VALUE;
+      adaptiveMaxHeight = MediaFormat.NO_VALUE;
     } else {
       List<Variant> masterPlaylistVariants = ((HlsMasterPlaylist) playlist).variants;
       variants = buildOrderedVariants(masterPlaylistVariants, variantIndices);
@@ -216,48 +214,46 @@ public HlsChunkSource(DataSource dataSource, String playlistUrl, HlsPlaylist pla
       }
       if (variants.length <= 1 || adaptiveMode == ADAPTIVE_MODE_NONE) {
         // We won't be adapting between different variants.
-        this.maxWidth = -1;
-        this.maxHeight = -1;
+        this.adaptiveMaxWidth = MediaFormat.NO_VALUE;
+        this.adaptiveMaxHeight = MediaFormat.NO_VALUE;
       } else {
         // We will be adapting between different variants.
         // TODO: We should allow the default values to be passed through the constructor.
-        this.maxWidth = maxWidth > 0 ? maxWidth : 1920;
-        this.maxHeight = maxHeight > 0 ? maxHeight : 1080;
+        this.adaptiveMaxWidth = maxWidth > 0 ? maxWidth : 1920;
+        this.adaptiveMaxHeight = maxHeight > 0 ? maxHeight : 1080;
       }
     }
   }
 
   public long getDurationUs() {
-    return live ? C.UNKNOWN_TIME_US : durationUs;
+    return durationUs;
   }
 
   /**
-   * Adaptive implementations must set the maximum video dimensions on the supplied
-   * {@link MediaFormat}. Other implementations do nothing.
-   * <p>
-   * Only called when the source is enabled.
+   * If the source is currently having difficulty providing chunks, then this method throws the
+   * underlying error. Otherwise does nothing.
    *
-   * @param out The {@link MediaFormat} on which the maximum video dimensions should be set.
+   * @throws IOException The underlying error.
    */
-  public void getMaxVideoDimensions(MediaFormat out) {
-    if (maxWidth == -1 || maxHeight == -1) {
-      // Not adaptive.
-      return;
+  public void maybeThrowError() throws IOException {
+    if (fatalError != null) {
+      throw fatalError;
     }
-    out.setMaxVideoDimensions(maxWidth, maxHeight);
   }
 
   /**
-   * Returns the next {@link Chunk} that should be loaded.
+   * Updates the provided {@link ChunkOperationHolder} to contain the next operation that should
+   * be performed by the calling {@link HlsSampleSource}.
    *
    * @param previousTsChunk The previously loaded chunk that the next chunk should follow.
    * @param seekPositionUs If there is no previous chunk, this parameter must specify the seek
    *     position. If there is a previous chunk then this parameter is ignored.
    * @param playbackPositionUs The current playback position.
-   * @return The next chunk to load.
+   * @param out The holder to populate with the result. {@link ChunkOperationHolder#queueSize} is
+   *     unused.
    */
-  public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
-      long playbackPositionUs) {
+  public void getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
+      long playbackPositionUs, ChunkOperationHolder out) {
     int nextVariantIndex;
     boolean switchingVariantSpliced;
     if (adaptiveMode == ADAPTIVE_MODE_NONE) {
@@ -273,7 +269,8 @@ public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
     HlsMediaPlaylist mediaPlaylist = variantPlaylists[nextVariantIndex];
     if (mediaPlaylist == null) {
       // We don't have the media playlist for the next variant. Request it now.
-      return newMediaPlaylistChunk(nextVariantIndex);
+      out.chunk = newMediaPlaylistChunk(nextVariantIndex);
+      return;
     }
 
     selectedVariantIndex = nextVariantIndex;
@@ -286,9 +283,15 @@ public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
         chunkMediaSequence = switchingVariantSpliced
             ? previousTsChunk.chunkIndex : previousTsChunk.chunkIndex + 1;
         if (chunkMediaSequence < mediaPlaylist.mediaSequence) {
+          // TODO: Decide what we want to do with: https://github.com/google/ExoPlayer/issues/765
+          // if (allowSkipAhead) {
           // If the chunk is no longer in the playlist. Skip ahead and start again.
           chunkMediaSequence = getLiveStartChunkMediaSequence(nextVariantIndex);
           liveDiscontinuity = true;
+          // } else {
+          //   fatalError = new BehindLiveWindowException();
+          //   return null;
+          // }
         }
       }
     } else {
@@ -304,11 +307,12 @@ public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
 
     int chunkIndex = chunkMediaSequence - mediaPlaylist.mediaSequence;
     if (chunkIndex >= mediaPlaylist.segments.size()) {
-      if (mediaPlaylist.live && shouldRerequestMediaPlaylist(nextVariantIndex)) {
-        return newMediaPlaylistChunk(nextVariantIndex);
-      } else {
-        return null;
+      if (!mediaPlaylist.live) {
+        out.endOfStream = true;
+      } else if (shouldRerequestLiveMediaPlaylist(nextVariantIndex)) {
+        out.chunk = newMediaPlaylistChunk(nextVariantIndex);
       }
+      return;
     }
 
     HlsMediaPlaylist.Segment segment = mediaPlaylist.segments.get(chunkIndex);
@@ -319,8 +323,8 @@ public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
       Uri keyUri = UriUtil.resolveToUri(mediaPlaylist.baseUri, segment.encryptionKeyUri);
       if (!keyUri.equals(encryptionKeyUri)) {
         // Encryption is specified and the key has changed.
-        Chunk toReturn = newEncryptionKeyChunk(keyUri, segment.encryptionIV, selectedVariantIndex);
-        return toReturn;
+        out.chunk = newEncryptionKeyChunk(keyUri, segment.encryptionIV, selectedVariantIndex);
+        return;
       }
       if (!Util.areEqual(segment.encryptionIV, encryptionIvString)) {
         setEncryptionData(keyUri, segment.encryptionIV, encryptionKey);
@@ -347,26 +351,38 @@ public Chunk getChunkOperation(TsChunk previousTsChunk, long seekPositionUs,
       startTimeUs = segment.startTimeUs;
     }
     long endTimeUs = startTimeUs + (long) (segment.durationSecs * C.MICROS_PER_SECOND);
-    boolean isLastChunk = !mediaPlaylist.live && chunkIndex == mediaPlaylist.segments.size() - 1;
     int trigger = Chunk.TRIGGER_UNSPECIFIED;
     Format format = variants[selectedVariantIndex].format;
 
     // Configure the extractor that will read the chunk.
     HlsExtractorWrapper extractorWrapper;
-    if (previousTsChunk == null || segment.discontinuity || !format.equals(previousTsChunk.format)
-        || liveDiscontinuity) {
-      Extractor extractor = chunkUri.getLastPathSegment().endsWith(AAC_FILE_EXTENSION)
-          ? new AdtsExtractor(startTimeUs)
-          : new TsExtractor(startTimeUs, audioCapabilities);
+    if (chunkUri.getLastPathSegment().endsWith(AAC_FILE_EXTENSION)) {
+      Extractor extractor = new AdtsExtractor(startTimeUs);
       extractorWrapper = new HlsExtractorWrapper(trigger, format, startTimeUs, extractor,
-          switchingVariantSpliced);
+          switchingVariantSpliced, adaptiveMaxWidth, adaptiveMaxHeight);
+    } else if (chunkUri.getLastPathSegment().endsWith(MP3_FILE_EXTENSION)) {
+      Extractor extractor = new Mp3Extractor(startTimeUs);
+      extractorWrapper = new HlsExtractorWrapper(trigger, format, startTimeUs, extractor,
+          switchingVariantSpliced, adaptiveMaxWidth, adaptiveMaxHeight);
+    } else if (previousTsChunk == null || segment.discontinuity || liveDiscontinuity
+        || !format.equals(previousTsChunk.format)) {
+      // MPEG-2 TS segments, but we need a new extractor.
+      if (previousTsChunk == null || segment.discontinuity || liveDiscontinuity
+          || ptsTimestampAdjuster == null) {
+        // TODO: Use this for AAC as well, along with the ID3 PRIV priv tag values with owner
+        // identifier com.apple.streaming.transportStreamTimestamp.
+        ptsTimestampAdjuster = new PtsTimestampAdjuster(startTimeUs);
+      }
+      Extractor extractor = new TsExtractor(ptsTimestampAdjuster);
+      extractorWrapper = new HlsExtractorWrapper(trigger, format, startTimeUs, extractor,
+          switchingVariantSpliced, adaptiveMaxWidth, adaptiveMaxHeight);
     } else {
+      // MPEG-2 TS segments, and we need to continue using the same extractor.
       extractorWrapper = previousTsChunk.extractorWrapper;
     }
 
-    return new TsChunk(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs,
-        chunkMediaSequence, isLastChunk, extractorWrapper, encryptionKey,
-        encryptionIv);
+    out.chunk = new TsChunk(dataSource, dataSpec, trigger, format, startTimeUs, endTimeUs,
+        chunkMediaSequence, extractorWrapper, encryptionKey, encryptionIv);
   }
 
   /**
@@ -439,6 +455,10 @@ public boolean onChunkLoadError(Chunk chunk, IOException e) {
     return false;
   }
 
+  public void reset() {
+    fatalError = null;
+  }
+
   private int getNextVariantIndex(TsChunk previousTsChunk, long playbackPositionUs) {
     clearStaleBlacklistedVariants();
     long bitrateEstimate = bandwidthMeter.getBitrateEstimate();
@@ -494,7 +514,7 @@ private int getVariantIndexForBandwidth(long bitrateEstimate) {
     return lowestQualityEnabledVariantIndex;
   }
 
-  private boolean shouldRerequestMediaPlaylist(int nextVariantIndex) {
+  private boolean shouldRerequestLiveMediaPlaylist(int nextVariantIndex) {
     // Don't re-request media playlist more often than one-half of the target duration.
     HlsMediaPlaylist mediaPlaylist = variantPlaylists[nextVariantIndex];
     long timeSinceLastMediaPlaylistLoadMs =
@@ -553,7 +573,7 @@ private void setMediaPlaylist(int variantIndex, HlsMediaPlaylist mediaPlaylist)
     variantLastPlaylistLoadTimesMs[variantIndex] = SystemClock.elapsedRealtime();
     variantPlaylists[variantIndex] = mediaPlaylist;
     live |= mediaPlaylist.live;
-    durationUs = mediaPlaylist.durationUs;
+    durationUs = live ? C.UNKNOWN_TIME_US : mediaPlaylist.durationUs;
   }
 
   /**
@@ -669,7 +689,7 @@ private int getVariantIndex(Format format) {
     public MediaPlaylistChunk(DataSource dataSource, DataSpec dataSpec, byte[] scratchSpace,
         HlsPlaylistParser playlistParser, int variantIndex, String playlistUrl) {
       super(dataSource, dataSpec, Chunk.TYPE_MANIFEST, Chunk.TRIGGER_UNSPECIFIED, null,
-          scratchSpace);
+          Chunk.NO_PARENT_ID, scratchSpace);
       this.variantIndex = variantIndex;
       this.playlistParser = playlistParser;
       this.playlistUrl = playlistUrl;
@@ -696,7 +716,8 @@ public HlsMediaPlaylist getResult() {
 
     public EncryptionKeyChunk(DataSource dataSource, DataSpec dataSpec, byte[] scratchSpace,
         String iv, int variantIndex) {
-      super(dataSource, dataSpec, Chunk.TYPE_DRM, Chunk.TRIGGER_UNSPECIFIED, null, scratchSpace);
+      super(dataSource, dataSpec, Chunk.TYPE_DRM, Chunk.TRIGGER_UNSPECIFIED, null,
+          Chunk.NO_PARENT_ID, scratchSpace);
       this.iv = iv;
       this.variantIndex = variantIndex;
     }
diff --git a/library/src/main/java/com/google/android/exoplayer/hls/HlsExtractorWrapper.java b/library/src/main/java/com/google/android/exoplayer/hls/HlsExtractorWrapper.java
index b1d1a8e10e..cb0b95f0c5 100644
--- a/library/src/main/java/com/google/android/exoplayer/hls/HlsExtractorWrapper.java
+++ b/library/src/main/java/com/google/android/exoplayer/hls/HlsExtractorWrapper.java
@@ -27,6 +27,7 @@
 import com.google.android.exoplayer.extractor.TrackOutput;
 import com.google.android.exoplayer.upstream.Allocator;
 import com.google.android.exoplayer.util.Assertions;
+import com.google.android.exoplayer.util.MimeTypes;
 
 import android.util.SparseArray;
 
@@ -44,7 +45,10 @@
   private final Extractor extractor;
   private final SparseArray<DefaultTrackOutput> sampleQueues;
   private final boolean shouldSpliceIn;
+  private final int adaptiveMaxWidth;
+  private final int adaptiveMaxHeight;
 
+  private MediaFormat[] sampleQueueFormats;
   private Allocator allocator;
 
   private volatile boolean tracksBuilt;
@@ -54,12 +58,14 @@
   private boolean spliceConfigured;
 
   public HlsExtractorWrapper(int trigger, Format format, long startTimeUs, Extractor extractor,
-      boolean shouldSpliceIn) {
+      boolean shouldSpliceIn, int adaptiveMaxWidth, int adaptiveMaxHeight) {
     this.trigger = trigger;
     this.format = format;
     this.startTimeUs = startTimeUs;
     this.extractor = extractor;
     this.shouldSpliceIn = shouldSpliceIn;
+    this.adaptiveMaxWidth = adaptiveMaxWidth;
+    this.adaptiveMaxHeight = adaptiveMaxHeight;
     sampleQueues = new SparseArray<>();
   }
 
@@ -86,6 +92,15 @@ public boolean isPrepared() {
         }
       }
       prepared = true;
+      sampleQueueFormats = new MediaFormat[sampleQueues.size()];
+      for (int i = 0; i < sampleQueueFormats.length; i++) {
+        MediaFormat format = sampleQueues.valueAt(i).getFormat();
+        if (MimeTypes.isVideo(format.mimeType) && (adaptiveMaxWidth != MediaFormat.NO_VALUE
+            || adaptiveMaxHeight != MediaFormat.NO_VALUE)) {
+          format = format.copyWithMaxVideoDimensions(adaptiveMaxWidth, adaptiveMaxHeight);
+        }
+        sampleQueueFormats[i] = format;
+      }
     }
     return prepared;
   }
@@ -169,7 +184,7 @@ public int getTrackCount() {
    */
   public MediaFormat getMediaFormat(int track) {
     Assertions.checkState(isPrepared());
-    return sampleQueues.valueAt(track).getFormat();
+    return sampleQueueFormats[track];
   }
 
   /**
diff --git a/library/src/main/java/com/google/android/exoplayer/hls/HlsPlaylistParser.java b/library/src/main/java/com/google/android/exoplayer/hls/HlsPlaylistParser.java
index 789217bbcc..8db6eb2484 100644
--- a/library/src/main/java/com/google/android/exoplayer/hls/HlsPlaylistParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/hls/HlsPlaylistParser.java
@@ -87,7 +87,7 @@
   private static final Pattern METHOD_ATTR_REGEX =
       Pattern.compile(METHOD_ATTR + "=(" + METHOD_NONE + "|" + METHOD_AES128 + ")");
   private static final Pattern URI_ATTR_REGEX =
-      Pattern.compile(URI_ATTR + "=\"(.+)\"");
+      Pattern.compile(URI_ATTR + "=\"(.+?)\"");
   private static final Pattern IV_ATTR_REGEX =
       Pattern.compile(IV_ATTR + "=([^,.*]+)");
   private static final Pattern TYPE_ATTR_REGEX =
diff --git a/library/src/main/java/com/google/android/exoplayer/hls/HlsSampleSource.java b/library/src/main/java/com/google/android/exoplayer/hls/HlsSampleSource.java
index 30eb9bb0a1..4eaa685e7f 100644
--- a/library/src/main/java/com/google/android/exoplayer/hls/HlsSampleSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/hls/HlsSampleSource.java
@@ -22,14 +22,15 @@
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
 import com.google.android.exoplayer.SampleSource.SampleSourceReader;
-import com.google.android.exoplayer.TrackInfo;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.chunk.BaseChunkSampleSourceEventListener;
 import com.google.android.exoplayer.chunk.Chunk;
+import com.google.android.exoplayer.chunk.ChunkOperationHolder;
 import com.google.android.exoplayer.chunk.Format;
 import com.google.android.exoplayer.upstream.Loader;
 import com.google.android.exoplayer.upstream.Loader.Loadable;
 import com.google.android.exoplayer.util.Assertions;
+import com.google.android.exoplayer.util.MimeTypes;
 
 import android.os.Handler;
 import android.os.SystemClock;
@@ -52,12 +53,13 @@
    */
   public static final int DEFAULT_MIN_LOADABLE_RETRY_COUNT = 3;
 
-  private static final int NO_RESET_PENDING = -1;
+  private static final long NO_RESET_PENDING = Long.MIN_VALUE;
 
   private final HlsChunkSource chunkSource;
   private final LinkedList<HlsExtractorWrapper> extractors;
   private final int minLoadableRetryCount;
   private final int bufferSizeContribution;
+  private final ChunkOperationHolder chunkOperationHolder;
 
   private final int eventSourceId;
   private final LoadControl loadControl;
@@ -71,7 +73,7 @@
   private int enabledTrackCount;
   private boolean[] trackEnabledStates;
   private boolean[] pendingDiscontinuities;
-  private TrackInfo[] trackInfos;
+  private MediaFormat[] trackFormat;
   private MediaFormat[] downstreamMediaFormats;
   private Format downstreamFormat;
 
@@ -114,6 +116,7 @@ public HlsSampleSource(HlsChunkSource chunkSource, LoadControl loadControl,
     this.eventSourceId = eventSourceId;
     this.pendingResetPositionUs = NO_RESET_PENDING;
     extractors = new LinkedList<>();
+    chunkOperationHolder = new ChunkOperationHolder();
   }
 
   @Override
@@ -128,20 +131,30 @@ public boolean prepare(long positionUs) {
       return true;
     }
     if (!extractors.isEmpty()) {
-      // We're not prepared, but we might have loaded what we need.
-      HlsExtractorWrapper extractor = getCurrentExtractor();
-      if (extractor.isPrepared()) {
-        trackCount = extractor.getTrackCount();
-        trackEnabledStates = new boolean[trackCount];
-        pendingDiscontinuities = new boolean[trackCount];
-        downstreamMediaFormats = new MediaFormat[trackCount];
-        trackInfos = new TrackInfo[trackCount];
-        for (int i = 0; i < trackCount; i++) {
-          MediaFormat format = extractor.getMediaFormat(i);
-          trackInfos[i] = new TrackInfo(format.mimeType, chunkSource.getDurationUs());
+      while (true) {
+        // We're not prepared, but we might have loaded what we need.
+        HlsExtractorWrapper extractor = extractors.getFirst();
+        if (extractor.isPrepared()) {
+          trackCount = extractor.getTrackCount();
+          trackEnabledStates = new boolean[trackCount];
+          pendingDiscontinuities = new boolean[trackCount];
+          downstreamMediaFormats = new MediaFormat[trackCount];
+          trackFormat = new MediaFormat[trackCount];
+          long durationUs = chunkSource.getDurationUs();
+          for (int i = 0; i < trackCount; i++) {
+            MediaFormat format = extractor.getMediaFormat(i).copyWithDurationUs(durationUs);
+            if (MimeTypes.isVideo(format.mimeType)) {
+              format = format.copyAsAdaptive();
+            }
+            trackFormat[i] = format;
+          }
+          prepared = true;
+          return true;
+        } else if (extractors.size() > 1) {
+          extractors.removeFirst().clear();
+        } else {
+          break;
         }
-        prepared = true;
-        return true;
       }
     }
     // We're not prepared and we haven't loaded what we need.
@@ -170,9 +183,9 @@ public int getTrackCount() {
   }
 
   @Override
-  public TrackInfo getTrackInfo(int track) {
+  public MediaFormat getFormat(int track) {
     Assertions.checkState(prepared);
-    return trackInfos[track];
+    return trackFormat[track];
   }
 
   @Override
@@ -182,15 +195,26 @@ public void enable(int track, long positionUs) {
     enabledTrackCount++;
     trackEnabledStates[track] = true;
     downstreamMediaFormats[track] = null;
+    pendingDiscontinuities[track] = false;
     downstreamFormat = null;
+    boolean wasLoadControlRegistered = loadControlRegistered;
     if (!loadControlRegistered) {
       loadControl.register(this, bufferSizeContribution);
       loadControlRegistered = true;
     }
     if (enabledTrackCount == 1) {
-      seekToUs(positionUs);
+      lastSeekPositionUs = positionUs;
+      if (wasLoadControlRegistered && downstreamPositionUs == positionUs) {
+        // TODO: Address [Internal: b/21743989] to remove the need for this kind of hack.
+        // This is the first track to be enabled after preparation and the position is the same as
+        // was passed to prepare. In this case we can avoid restarting, which would reload the same
+        // chunks as were loaded during preparation.
+        maybeStartLoading();
+      } else {
+        downstreamPositionUs = positionUs;
+        restartFrom(positionUs);
+      }
     }
-    pendingDiscontinuities[track] = false;
   }
 
   @Override
@@ -200,6 +224,7 @@ public void disable(int track) {
     enabledTrackCount--;
     trackEnabledStates[track] = false;
     if (enabledTrackCount == 0) {
+      chunkSource.reset();
       downstreamPositionUs = Long.MIN_VALUE;
       if (loadControlRegistered) {
         loadControl.unregister(this);
@@ -288,8 +313,7 @@ public int readData(int track, long playbackPositionUs, MediaFormatHolder format
     }
 
     MediaFormat mediaFormat = extractor.getMediaFormat(track);
-    if (mediaFormat != null && !mediaFormat.equals(downstreamMediaFormats[track], true)) {
-      chunkSource.getMaxVideoDimensions(mediaFormat);
+    if (mediaFormat != null && !mediaFormat.equals(downstreamMediaFormats[track])) {
       formatHolder.format = mediaFormat;
       downstreamMediaFormats[track] = mediaFormat;
       return FORMAT_READ;
@@ -312,6 +336,8 @@ public int readData(int track, long playbackPositionUs, MediaFormatHolder format
   public void maybeThrowError() throws IOException {
     if (currentLoadableException != null && currentLoadableExceptionCount > minLoadableRetryCount) {
       throw currentLoadableException;
+    } else if (currentLoadable == null) {
+      chunkSource.maybeThrowError();
     }
   }
 
@@ -345,6 +371,12 @@ public long getBufferedPositionUs() {
       return TrackRenderer.END_OF_TRACK_US;
     } else {
       long largestParsedTimestampUs = extractors.getLast().getLargestParsedTimestampUs();
+      if (extractors.size() > 1) {
+        // When adapting from one format to the next, the penultimate extractor may have the largest
+        // parsed timestamp (e.g. if the last extractor hasn't parsed any timestamps yet).
+        largestParsedTimestampUs = Math.max(largestParsedTimestampUs,
+            extractors.get(extractors.size() - 2).getLargestParsedTimestampUs());
+      }
       return largestParsedTimestampUs == Long.MIN_VALUE ? downstreamPositionUs
           : largestParsedTimestampUs;
     }
@@ -369,7 +401,6 @@ public void onLoadCompleted(Loadable loadable) {
     chunkSource.onChunkLoadCompleted(currentLoadable);
     if (isTsChunk(currentLoadable)) {
       Assertions.checkState(currentLoadable == currentTsLoadable);
-      loadingFinished = currentTsLoadable.isLastChunk;
       previousTsLoadable = currentTsLoadable;
       notifyLoadCompleted(currentLoadable.bytesLoaded(), currentTsLoadable.type,
           currentTsLoadable.trigger, currentTsLoadable.format, currentTsLoadable.startTimeUs,
@@ -507,8 +538,16 @@ private void maybeStartLoading() {
       return;
     }
 
-    Chunk nextLoadable = chunkSource.getChunkOperation(previousTsLoadable, pendingResetPositionUs,
-        downstreamPositionUs);
+    chunkSource.getChunkOperation(previousTsLoadable, pendingResetPositionUs,
+        downstreamPositionUs, chunkOperationHolder);
+    boolean endOfStream = chunkOperationHolder.endOfStream;
+    Chunk nextLoadable = chunkOperationHolder.chunk;
+    chunkOperationHolder.clear();
+
+    if (endOfStream) {
+      loadingFinished = true;
+      return;
+    }
     if (nextLoadable == null) {
       return;
     }
@@ -543,9 +582,8 @@ private long getNextLoadPositionUs() {
     if (isPendingReset()) {
       return pendingResetPositionUs;
     } else {
-      return currentTsLoadable != null
-          ? (currentTsLoadable.isLastChunk ? -1 : currentTsLoadable.endTimeUs)
-          : (previousTsLoadable.isLastChunk ? -1 : previousTsLoadable.endTimeUs);
+      return loadingFinished ? -1
+          : currentTsLoadable != null ? currentTsLoadable.endTimeUs : previousTsLoadable.endTimeUs;
     }
   }
 
@@ -561,8 +599,8 @@ private long getRetryDelayMillis(long errorCount) {
     return Math.min((errorCount - 1) * 1000, 5000);
   }
 
-  /* package */ int usToMs(long timeUs) {
-    return (int) (timeUs / 1000);
+  /* package */ long usToMs(long timeUs) {
+    return timeUs / 1000;
   }
 
   private void notifyLoadStarted(final long length, final int type, final int trigger,
diff --git a/library/src/main/java/com/google/android/exoplayer/hls/TsChunk.java b/library/src/main/java/com/google/android/exoplayer/hls/TsChunk.java
index 56968c5fe7..520046be36 100644
--- a/library/src/main/java/com/google/android/exoplayer/hls/TsChunk.java
+++ b/library/src/main/java/com/google/android/exoplayer/hls/TsChunk.java
@@ -49,16 +49,15 @@
    * @param startTimeUs The start time of the media contained by the chunk, in microseconds.
    * @param endTimeUs The end time of the media contained by the chunk, in microseconds.
    * @param chunkIndex The index of the chunk.
-   * @param isLastChunk True if this is the last chunk in the media. False otherwise.
    * @param extractorWrapper A wrapped extractor to parse samples from the data.
    * @param encryptionKey For AES encryption chunks, the encryption key.
    * @param encryptionIv For AES encryption chunks, the encryption initialization vector.
    */
   public TsChunk(DataSource dataSource, DataSpec dataSpec, int trigger, Format format,
-      long startTimeUs, long endTimeUs, int chunkIndex, boolean isLastChunk,
-      HlsExtractorWrapper extractorWrapper, byte[] encryptionKey, byte[] encryptionIv) {
+      long startTimeUs, long endTimeUs, int chunkIndex, HlsExtractorWrapper extractorWrapper,
+      byte[] encryptionKey, byte[] encryptionIv) {
     super(buildDataSource(dataSource, encryptionKey, encryptionIv), dataSpec, trigger, format,
-        startTimeUs, endTimeUs, chunkIndex, isLastChunk);
+        startTimeUs, endTimeUs, chunkIndex);
     this.extractorWrapper = extractorWrapper;
     // Note: this.dataSource and dataSource may be different.
     this.isEncrypted = this.dataSource instanceof Aes128DataSource;
diff --git a/library/src/main/java/com/google/android/exoplayer/metadata/MetadataTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/metadata/MetadataTrackRenderer.java
index 767214482f..a59519a7e6 100644
--- a/library/src/main/java/com/google/android/exoplayer/metadata/MetadataTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/metadata/MetadataTrackRenderer.java
@@ -16,10 +16,11 @@
 package com.google.android.exoplayer.metadata;
 
 import com.google.android.exoplayer.ExoPlaybackException;
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.MediaFormatHolder;
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+import com.google.android.exoplayer.SampleSourceTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.util.Assertions;
 
@@ -35,7 +36,7 @@
  *
  * @param <T> The type of the metadata.
  */
-public final class MetadataTrackRenderer<T> extends TrackRenderer implements Callback {
+public final class MetadataTrackRenderer<T> extends SampleSourceTrackRenderer implements Callback {
 
   /**
    * An interface for components that process metadata.
@@ -55,16 +56,13 @@
 
   private static final int MSG_INVOKE_RENDERER = 0;
 
-  private final SampleSourceReader source;
   private final MetadataParser<T> metadataParser;
   private final MetadataRenderer<T> metadataRenderer;
   private final Handler metadataHandler;
   private final MediaFormatHolder formatHolder;
   private final SampleHolder sampleHolder;
 
-  private int trackIndex;
   private boolean inputStreamEnded;
-
   private long pendingMetadataTimestamp;
   private T pendingMetadata;
 
@@ -80,7 +78,7 @@
    */
   public MetadataTrackRenderer(SampleSource source, MetadataParser<T> metadataParser,
       MetadataRenderer<T> metadataRenderer, Looper metadataRendererLooper) {
-    this.source = source.register();
+    super(source);
     this.metadataParser = Assertions.checkNotNull(metadataParser);
     this.metadataRenderer = Assertions.checkNotNull(metadataRenderer);
     this.metadataHandler = metadataRendererLooper == null ? null
@@ -90,30 +88,20 @@ public MetadataTrackRenderer(SampleSource source, MetadataParser<T> metadataPars
   }
 
   @Override
-  protected int doPrepare(long positionUs) {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < trackCount; i++) {
-      if (metadataParser.canParse(source.getTrackInfo(i).mimeType)) {
-        trackIndex = i;
-        return TrackRenderer.STATE_PREPARED;
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
+  protected boolean handlesTrack(MediaFormat mediaFormat) {
+    return metadataParser.canParse(mediaFormat.mimeType);
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     seekToInternal();
   }
 
   @Override
   protected void seekTo(long positionUs) throws ExoPlaybackException {
-    source.seekToUs(positionUs);
+    super.seekTo(positionUs);
     seekToInternal();
   }
 
@@ -123,23 +111,21 @@ private void seekToInternal() {
   }
 
   @Override
-  protected void doSomeWork(long positionUs, long elapsedRealtimeUs)
-      throws ExoPlaybackException {
-    source.continueBuffering(trackIndex, positionUs);
-
+  protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPlaybackException {
+    continueBufferingSource(positionUs);
     if (!inputStreamEnded && pendingMetadata == null) {
-        int result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, false);
-        if (result == SampleSource.SAMPLE_READ) {
-          pendingMetadataTimestamp = sampleHolder.timeUs;
-          try {
-            pendingMetadata = metadataParser.parse(sampleHolder.data.array(), sampleHolder.size);
-          } catch (IOException e) {
-            throw new ExoPlaybackException(e);
-          }
-          sampleHolder.data.clear();
-        } else if (result == SampleSource.END_OF_STREAM) {
-          inputStreamEnded = true;
+      sampleHolder.clearData();
+      int result = readSource(positionUs, formatHolder, sampleHolder, false);
+      if (result == SampleSource.SAMPLE_READ) {
+        pendingMetadataTimestamp = sampleHolder.timeUs;
+        try {
+          pendingMetadata = metadataParser.parse(sampleHolder.data.array(), sampleHolder.size);
+        } catch (IOException e) {
+          throw new ExoPlaybackException(e);
         }
+      } else if (result == SampleSource.END_OF_STREAM) {
+        inputStreamEnded = true;
+      }
     }
 
     if (pendingMetadata != null && pendingMetadataTimestamp <= positionUs) {
@@ -149,23 +135,9 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs)
   }
 
   @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
-    try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
-    }
-  }
-
-  @Override
-  protected void onDisabled() {
+  protected void onDisabled() throws ExoPlaybackException {
     pendingMetadata = null;
-    source.disable(trackIndex);
-  }
-
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
+    super.onDisabled();
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/smoothstreaming/DefaultSmoothStreamingTrackSelector.java b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/DefaultSmoothStreamingTrackSelector.java
new file mode 100644
index 0000000000..d87e52b5ed
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/DefaultSmoothStreamingTrackSelector.java
@@ -0,0 +1,69 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.smoothstreaming;
+
+import com.google.android.exoplayer.chunk.VideoFormatSelectorUtil;
+import com.google.android.exoplayer.smoothstreaming.SmoothStreamingManifest.StreamElement;
+
+import android.content.Context;
+
+import java.io.IOException;
+import java.util.Arrays;
+
+/**
+ * A default {@link SmoothStreamingTrackSelector} implementation.
+ */
+// TODO: Add configuration options (e.g. ability to disable adaptive track output, disable format
+// filtering etc).
+public final class DefaultSmoothStreamingTrackSelector implements SmoothStreamingTrackSelector {
+
+  private final Context context;
+  private final int streamElementType;
+
+  /**
+   * @param context A context.
+   * @param streamElementType The type of stream to select. One of {@link StreamElement#TYPE_AUDIO},
+   *     {@link StreamElement#TYPE_VIDEO} and {@link StreamElement#TYPE_TEXT}.
+   */
+  public DefaultSmoothStreamingTrackSelector(Context context, int streamElementType) {
+    this.context = context;
+    this.streamElementType = streamElementType;
+  }
+
+  @Override
+  public void selectTracks(SmoothStreamingManifest manifest, Output output) throws IOException {
+    for (int i = 0; i < manifest.streamElements.length; i++) {
+      if (manifest.streamElements[i].type == streamElementType) {
+        if (streamElementType == StreamElement.TYPE_VIDEO) {
+          int[] trackIndices = VideoFormatSelectorUtil.selectVideoFormatsForDefaultDisplay(
+              context, Arrays.asList(manifest.streamElements[i].tracks), null, false);
+          int trackCount = trackIndices.length;
+          if (trackCount > 1) {
+            output.adaptiveTrack(manifest, i, trackIndices);
+          }
+          for (int j = 0; j < trackCount; j++) {
+            output.fixedTrack(manifest, i, trackIndices[j]);
+          }
+        } else {
+          for (int j = 0; j < manifest.streamElements[i].tracks.length; j++) {
+            output.fixedTrack(manifest, i, j);
+          }
+        }
+      }
+    }
+  }
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingChunkSource.java b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingChunkSource.java
index 9849b3d323..6ccb297804 100644
--- a/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingChunkSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingChunkSource.java
@@ -16,8 +16,8 @@
 package com.google.android.exoplayer.smoothstreaming;
 
 import com.google.android.exoplayer.BehindLiveWindowException;
+import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.MediaFormat;
-import com.google.android.exoplayer.TrackInfo;
 import com.google.android.exoplayer.chunk.Chunk;
 import com.google.android.exoplayer.chunk.ChunkExtractorWrapper;
 import com.google.android.exoplayer.chunk.ChunkOperationHolder;
@@ -37,6 +37,7 @@
 import com.google.android.exoplayer.smoothstreaming.SmoothStreamingManifest.TrackElement;
 import com.google.android.exoplayer.upstream.DataSource;
 import com.google.android.exoplayer.upstream.DataSpec;
+import com.google.android.exoplayer.util.Assertions;
 import com.google.android.exoplayer.util.CodecSpecificDataUtil;
 import com.google.android.exoplayer.util.ManifestFetcher;
 import com.google.android.exoplayer.util.MimeTypes;
@@ -47,6 +48,7 @@
 import android.util.SparseArray;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
@@ -54,31 +56,34 @@
 /**
  * An {@link ChunkSource} for SmoothStreaming.
  */
-public class SmoothStreamingChunkSource implements ChunkSource {
+public class SmoothStreamingChunkSource implements ChunkSource,
+    SmoothStreamingTrackSelector.Output {
 
   private static final int MINIMUM_MANIFEST_REFRESH_PERIOD_MS = 5000;
   private static final int INITIALIZATION_VECTOR_SIZE = 8;
 
-  private final TrackInfo trackInfo;
+  private final SmoothStreamingTrackSelector trackSelector;
   private final DataSource dataSource;
-  private final FormatEvaluator formatEvaluator;
   private final Evaluation evaluation;
   private final long liveEdgeLatencyUs;
-  private final int maxWidth;
-  private final int maxHeight;
+  private final TrackEncryptionBox[] trackEncryptionBoxes;
+  private final ManifestFetcher<SmoothStreamingManifest> manifestFetcher;
+  private final DrmInitData.Mapped drmInitData;
+  private final FormatEvaluator adaptiveFormatEvaluator;
+  private final boolean live;
+
+  // The tracks exposed by this source.
+  private final ArrayList<ExposedTrack> tracks;
 
+  // Mappings from manifest track key.
   private final SparseArray<ChunkExtractorWrapper> extractorWrappers;
   private final SparseArray<MediaFormat> mediaFormats;
-  private final DrmInitData drmInitData;
-  private final Format[] formats;
-
-  private final ManifestFetcher<SmoothStreamingManifest> manifestFetcher;
-  private final int streamElementIndex;
 
+  private boolean prepareCalled;
   private SmoothStreamingManifest currentManifest;
   private int currentManifestChunkOffset;
-  private boolean finishedCurrentManifest;
-
+  private boolean needManifestRefresh;
+  private ExposedTrack enabledTrack;
   private IOException fatalError;
 
   /**
@@ -89,12 +94,9 @@
    *
    * @param manifestFetcher A fetcher for the manifest, which must have already successfully
    *     completed an initial load.
-   * @param streamElementIndex The index of the stream element in the manifest to be provided by
-   *     the source.
-   * @param trackIndices The indices of the tracks within the stream element to be considered by
-   *     the source. May be null if all tracks within the element should be considered.
+   * @param trackSelector Selects tracks from the manifest to be exposed by this source.
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
    * @param liveEdgeLatencyMs For live streams, the number of milliseconds that the playback should
    *     lag behind the "live edge" (i.e. the end of the most recently defined media in the
    *     manifest). Choosing a small value will minimize latency introduced by the player, however
@@ -102,109 +104,96 @@
    *     Hence a small value may increase the probability of rebuffering and playback failures.
    */
   public SmoothStreamingChunkSource(ManifestFetcher<SmoothStreamingManifest> manifestFetcher,
-      int streamElementIndex, int[] trackIndices, DataSource dataSource,
-      FormatEvaluator formatEvaluator, long liveEdgeLatencyMs) {
-    this(manifestFetcher, manifestFetcher.getManifest(), streamElementIndex, trackIndices,
-        dataSource, formatEvaluator, liveEdgeLatencyMs);
+      SmoothStreamingTrackSelector trackSelector, DataSource dataSource,
+      FormatEvaluator adaptiveFormatEvaluator, long liveEdgeLatencyMs) {
+    this(manifestFetcher, manifestFetcher.getManifest(), trackSelector, dataSource,
+        adaptiveFormatEvaluator, liveEdgeLatencyMs);
   }
 
   /**
    * Constructor to use for fixed duration content.
    *
    * @param manifest The manifest parsed from {@code baseUrl + "/Manifest"}.
-   * @param streamElementIndex The index of the stream element in the manifest to be provided by
-   *     the source.
-   * @param trackIndices The indices of the tracks within the stream element to be considered by
-   *     the source. May be null if all tracks within the element should be considered.
+   * @param trackSelector Selects tracks from the manifest to be exposed by this source.
    * @param dataSource A {@link DataSource} suitable for loading the media data.
-   * @param formatEvaluator Selects from the available formats.
+   * @param adaptiveFormatEvaluator For adaptive tracks, selects from the available formats.
    */
-  public SmoothStreamingChunkSource(SmoothStreamingManifest manifest, int streamElementIndex,
-      int[] trackIndices, DataSource dataSource, FormatEvaluator formatEvaluator) {
-    this(null, manifest, streamElementIndex, trackIndices, dataSource, formatEvaluator, 0);
+  public SmoothStreamingChunkSource(SmoothStreamingManifest manifest,
+      SmoothStreamingTrackSelector trackSelector, DataSource dataSource,
+      FormatEvaluator adaptiveFormatEvaluator) {
+    this(null, manifest, trackSelector, dataSource, adaptiveFormatEvaluator, 0);
   }
 
   private SmoothStreamingChunkSource(ManifestFetcher<SmoothStreamingManifest> manifestFetcher,
-      SmoothStreamingManifest initialManifest, int streamElementIndex, int[] trackIndices,
-      DataSource dataSource, FormatEvaluator formatEvaluator, long liveEdgeLatencyMs) {
+      SmoothStreamingManifest initialManifest, SmoothStreamingTrackSelector trackSelector,
+      DataSource dataSource, FormatEvaluator adaptiveFormatEvaluator, long liveEdgeLatencyMs) {
     this.manifestFetcher = manifestFetcher;
-    this.streamElementIndex = streamElementIndex;
     this.currentManifest = initialManifest;
+    this.trackSelector = trackSelector;
     this.dataSource = dataSource;
-    this.formatEvaluator = formatEvaluator;
+    this.adaptiveFormatEvaluator = adaptiveFormatEvaluator;
     this.liveEdgeLatencyUs = liveEdgeLatencyMs * 1000;
-
-    StreamElement streamElement = getElement(initialManifest);
-    trackInfo = new TrackInfo(streamElement.tracks[0].format.mimeType, initialManifest.durationUs);
     evaluation = new Evaluation();
+    tracks = new ArrayList<>();
+    extractorWrappers = new SparseArray<>();
+    mediaFormats = new SparseArray<>();
+    live = initialManifest.isLive;
 
-    TrackEncryptionBox[] trackEncryptionBoxes = null;
     ProtectionElement protectionElement = initialManifest.protectionElement;
     if (protectionElement != null) {
-      byte[] keyId = getKeyId(protectionElement.data);
+      byte[] keyId = getProtectionElementKeyId(protectionElement.data);
       trackEncryptionBoxes = new TrackEncryptionBox[1];
       trackEncryptionBoxes[0] = new TrackEncryptionBox(true, INITIALIZATION_VECTOR_SIZE, keyId);
-      DrmInitData.Mapped drmInitData = new DrmInitData.Mapped(MimeTypes.VIDEO_MP4);
+      drmInitData = new DrmInitData.Mapped(MimeTypes.VIDEO_MP4);
       drmInitData.put(protectionElement.uuid, protectionElement.data);
-      this.drmInitData = drmInitData;
     } else {
+      trackEncryptionBoxes = null;
       drmInitData = null;
     }
+  }
 
-    int trackCount = trackIndices != null ? trackIndices.length : streamElement.tracks.length;
-    formats = new Format[trackCount];
-    extractorWrappers = new SparseArray<>();
-    mediaFormats = new SparseArray<>();
-    int maxWidth = 0;
-    int maxHeight = 0;
-    for (int i = 0; i < trackCount; i++) {
-      int trackIndex = trackIndices != null ? trackIndices[i] : i;
-      formats[i] = streamElement.tracks[trackIndex].format;
-      maxWidth = Math.max(maxWidth, formats[i].width);
-      maxHeight = Math.max(maxHeight, formats[i].height);
-
-      MediaFormat mediaFormat = getMediaFormat(streamElement, trackIndex);
-      int trackType = streamElement.type == StreamElement.TYPE_VIDEO ? Track.TYPE_VIDEO
-          : Track.TYPE_AUDIO;
-      FragmentedMp4Extractor extractor = new FragmentedMp4Extractor(
-          FragmentedMp4Extractor.WORKAROUND_EVERY_VIDEO_FRAME_IS_SYNC_FRAME);
-      extractor.setTrack(new Track(trackIndex, trackType, streamElement.timescale,
-          initialManifest.durationUs, mediaFormat, trackEncryptionBoxes,
-          trackType == Track.TYPE_VIDEO ? 4 : -1));
-      extractorWrappers.put(trackIndex, new ChunkExtractorWrapper(extractor));
-      mediaFormats.put(trackIndex, mediaFormat);
+  // ChunkSource implementation.
+
+  @Override
+  public void maybeThrowError() throws IOException {
+    if (fatalError != null) {
+      throw fatalError;
+    } else {
+      manifestFetcher.maybeThrowError();
     }
-    this.maxWidth = maxWidth;
-    this.maxHeight = maxHeight;
-    Arrays.sort(formats, new DecreasingBandwidthComparator());
   }
 
   @Override
-  public final void getMaxVideoDimensions(MediaFormat out) {
-    if (trackInfo.mimeType.startsWith("video")) {
-      out.setMaxVideoDimensions(maxWidth, maxHeight);
+  public boolean prepare() {
+    if (!prepareCalled) {
+      prepareCalled = true;
+      try {
+        trackSelector.selectTracks(currentManifest, this);
+      } catch (IOException e) {
+        fatalError = e;
+      }
     }
+    return fatalError == null;
   }
 
   @Override
-  public final TrackInfo getTrackInfo() {
-    return trackInfo;
+  public int getTrackCount() {
+    return tracks.size();
   }
 
   @Override
-  public void enable() {
-    fatalError = null;
-    formatEvaluator.enable();
-    if (manifestFetcher != null) {
-      manifestFetcher.enable();
-    }
+  public final MediaFormat getFormat(int track) {
+    return tracks.get(track).trackFormat;
   }
 
   @Override
-  public void disable(List<? extends MediaChunk> queue) {
-    formatEvaluator.disable();
+  public void enable(int track) {
+    enabledTrack = tracks.get(track);
+    if (enabledTrack.isAdaptive()) {
+      adaptiveFormatEvaluator.enable();
+    }
     if (manifestFetcher != null) {
-      manifestFetcher.disable();
+      manifestFetcher.enable();
     }
   }
 
@@ -216,9 +205,9 @@ public void continueBuffering(long playbackPositionUs) {
 
     SmoothStreamingManifest newManifest = manifestFetcher.getManifest();
     if (currentManifest != newManifest && newManifest != null) {
-      StreamElement currentElement = getElement(currentManifest);
+      StreamElement currentElement = currentManifest.streamElements[enabledTrack.elementIndex];
       int currentElementChunkCount = currentElement.chunkCount;
-      StreamElement newElement = getElement(newManifest);
+      StreamElement newElement = newManifest.streamElements[enabledTrack.elementIndex];
       if (currentElementChunkCount == 0 || newElement.chunkCount == 0) {
         // There's no overlap between the old and new elements because at least one is empty.
         currentManifestChunkOffset += currentElementChunkCount;
@@ -235,10 +224,10 @@ public void continueBuffering(long playbackPositionUs) {
         }
       }
       currentManifest = newManifest;
-      finishedCurrentManifest = false;
+      needManifestRefresh = false;
     }
 
-    if (finishedCurrentManifest && (SystemClock.elapsedRealtime()
+    if (needManifestRefresh && (SystemClock.elapsedRealtime()
         > manifestFetcher.getManifestLoadStartTimestamp() + MINIMUM_MANIFEST_REFRESH_PERIOD_MS)) {
       manifestFetcher.requestRefresh();
     }
@@ -253,7 +242,14 @@ public final void getChunkOperation(List<? extends MediaChunk> queue, long seekP
     }
 
     evaluation.queueSize = queue.size();
-    formatEvaluator.evaluate(queue, playbackPositionUs, formats, evaluation);
+    if (enabledTrack.isAdaptive()) {
+      adaptiveFormatEvaluator.evaluate(queue, playbackPositionUs, enabledTrack.adaptiveFormats,
+          evaluation);
+    } else {
+      evaluation.format = enabledTrack.fixedFormat;
+      evaluation.trigger = Chunk.TRIGGER_MANUAL;
+    }
+
     Format selectedFormat = evaluation.format;
     out.queueSize = evaluation.queueSize;
 
@@ -270,42 +266,43 @@ public final void getChunkOperation(List<? extends MediaChunk> queue, long seekP
     // In all cases where we return before instantiating a new chunk, we want out.chunk to be null.
     out.chunk = null;
 
-    StreamElement streamElement = getElement(currentManifest);
+    StreamElement streamElement = currentManifest.streamElements[enabledTrack.elementIndex];
     if (streamElement.chunkCount == 0) {
-      // The manifest is currently empty for this stream.
-      finishedCurrentManifest = true;
+      if (currentManifest.isLive) {
+        needManifestRefresh = true;
+      } else {
+        out.endOfStream = true;
+      }
       return;
     }
 
     int chunkIndex;
     if (queue.isEmpty()) {
-      if (currentManifest.isLive) {
-        seekPositionUs = getLiveSeekPosition();
+      if (live) {
+        seekPositionUs = getLiveSeekPosition(currentManifest, liveEdgeLatencyUs);
       }
       chunkIndex = streamElement.getChunkIndex(seekPositionUs);
     } else {
       MediaChunk previous = queue.get(out.queueSize - 1);
-      chunkIndex = previous.isLastChunk ? -1 : previous.chunkIndex + 1 - currentManifestChunkOffset;
+      chunkIndex = previous.chunkIndex + 1 - currentManifestChunkOffset;
     }
 
-    if (currentManifest.isLive) {
-      if (chunkIndex < 0) {
-        // This is before the first chunk in the current manifest.
-        fatalError = new BehindLiveWindowException();
-        return;
-      } else if (chunkIndex >= streamElement.chunkCount) {
+    if (live && chunkIndex < 0) {
+      // This is before the first chunk in the current manifest.
+      fatalError = new BehindLiveWindowException();
+      return;
+    } else if (currentManifest.isLive) {
+      if (chunkIndex >= streamElement.chunkCount) {
         // This is beyond the last chunk in the current manifest.
-        finishedCurrentManifest = true;
+        needManifestRefresh = true;
         return;
       } else if (chunkIndex == streamElement.chunkCount - 1) {
         // This is the last chunk in the current manifest. Mark the manifest as being finished,
         // but continue to return the final chunk.
-        finishedCurrentManifest = true;
+        needManifestRefresh = true;
       }
-    }
-
-    if (chunkIndex == -1) {
-      // We've reached the end of the stream.
+    } else if (chunkIndex >= streamElement.chunkCount) {
+      out.endOfStream = true;
       return;
     }
 
@@ -315,23 +312,16 @@ public final void getChunkOperation(List<? extends MediaChunk> queue, long seekP
         : chunkStartTimeUs + streamElement.getChunkDurationUs(chunkIndex);
     int currentAbsoluteChunkIndex = chunkIndex + currentManifestChunkOffset;
 
-    int trackIndex = getTrackIndex(selectedFormat);
-    Uri uri = streamElement.buildRequestUri(trackIndex, chunkIndex);
-    Chunk mediaChunk = newMediaChunk(selectedFormat, uri, null, extractorWrappers.get(trackIndex),
-        drmInitData, dataSource, currentAbsoluteChunkIndex, isLastChunk, chunkStartTimeUs,
-        chunkEndTimeUs, evaluation.trigger, mediaFormats.get(trackIndex));
+    int manifestTrackIndex = getManifestTrackIndex(streamElement, selectedFormat);
+    int manifestTrackKey = getManifestTrackKey(enabledTrack.elementIndex, manifestTrackIndex);
+    Uri uri = streamElement.buildRequestUri(manifestTrackIndex, chunkIndex);
+    Chunk mediaChunk = newMediaChunk(selectedFormat, uri, null,
+        extractorWrappers.get(manifestTrackKey), drmInitData, dataSource, currentAbsoluteChunkIndex,
+        chunkStartTimeUs, chunkEndTimeUs, evaluation.trigger, mediaFormats.get(manifestTrackKey),
+        enabledTrack.adaptiveMaxWidth, enabledTrack.adaptiveMaxHeight);
     out.chunk = mediaChunk;
   }
 
-  @Override
-  public void maybeThrowError() throws IOException {
-    if (fatalError != null) {
-      throw fatalError;
-    } else {
-      manifestFetcher.maybeThrowError();
-    }
-  }
-
   @Override
   public void onChunkLoadCompleted(Chunk chunk) {
     // Do nothing.
@@ -342,16 +332,125 @@ public void onChunkLoadError(Chunk chunk, Exception e) {
     // Do nothing.
   }
 
+  @Override
+  public void disable(List<? extends MediaChunk> queue) {
+    if (enabledTrack.isAdaptive()) {
+      adaptiveFormatEvaluator.disable();
+    }
+    if (manifestFetcher != null) {
+      manifestFetcher.disable();
+    }
+    evaluation.format = null;
+    fatalError = null;
+  }
+
+  // SmoothStreamingTrackSelector.Output implementation.
+
+  @Override
+  public void adaptiveTrack(SmoothStreamingManifest manifest, int element, int[] trackIndices) {
+    if (adaptiveFormatEvaluator == null) {
+      // Do nothing.
+      return;
+    }
+    MediaFormat maxHeightMediaFormat = null;
+    StreamElement streamElement = manifest.streamElements[element];
+    int maxWidth = -1;
+    int maxHeight = -1;
+    Format[] formats = new Format[trackIndices.length];
+    for (int i = 0; i < formats.length; i++) {
+      int manifestTrackIndex = trackIndices[i];
+      formats[i] = streamElement.tracks[manifestTrackIndex].format;
+      MediaFormat mediaFormat = initManifestTrack(manifest, element, manifestTrackIndex);
+      if (maxHeightMediaFormat == null || mediaFormat.height > maxHeight) {
+        maxHeightMediaFormat = mediaFormat;
+      }
+      maxWidth = Math.max(maxWidth, mediaFormat.width);
+      maxHeight = Math.max(maxHeight, mediaFormat.height);
+    }
+    Arrays.sort(formats, new DecreasingBandwidthComparator());
+    MediaFormat adaptiveMediaFormat = maxHeightMediaFormat.copyAsAdaptive();
+    tracks.add(new ExposedTrack(adaptiveMediaFormat, element, formats, maxWidth, maxHeight));
+  }
+
+  @Override
+  public void fixedTrack(SmoothStreamingManifest manifest, int element, int trackIndex) {
+    MediaFormat mediaFormat = initManifestTrack(manifest, element, trackIndex);
+    Format format = manifest.streamElements[element].tracks[trackIndex].format;
+    tracks.add(new ExposedTrack(mediaFormat, element, format));
+  }
+
+  // Private methods.
+
+  private MediaFormat initManifestTrack(SmoothStreamingManifest manifest, int elementIndex,
+      int trackIndex) {
+    int manifestTrackKey = getManifestTrackKey(elementIndex, trackIndex);
+    MediaFormat mediaFormat = mediaFormats.get(manifestTrackKey);
+    if (mediaFormat != null) {
+      // Already initialized.
+      return mediaFormat;
+    }
+
+    // Build the media format.
+    long durationUs = live ? C.UNKNOWN_TIME_US : manifest.durationUs;
+    StreamElement element = manifest.streamElements[elementIndex];
+    Format format = element.tracks[trackIndex].format;
+    byte[][] csdArray = element.tracks[trackIndex].csd;
+    int mp4TrackType;
+    switch (element.type) {
+      case StreamElement.TYPE_VIDEO:
+        mediaFormat = MediaFormat.createVideoFormat(MediaFormat.NO_VALUE, format.mimeType,
+            format.bitrate, MediaFormat.NO_VALUE, durationUs, format.width, format.height,
+            Arrays.asList(csdArray));
+        mp4TrackType = Track.TYPE_vide;
+        break;
+      case StreamElement.TYPE_AUDIO:
+        List<byte[]> csd;
+        if (csdArray != null) {
+          csd = Arrays.asList(csdArray);
+        } else {
+          csd = Collections.singletonList(CodecSpecificDataUtil.buildAacAudioSpecificConfig(
+              format.audioSamplingRate, format.audioChannels));
+        }
+        mediaFormat = MediaFormat.createAudioFormat(MediaFormat.NO_VALUE, format.mimeType,
+            format.bitrate, MediaFormat.NO_VALUE, durationUs, format.audioChannels,
+            format.audioSamplingRate, csd, format.language);
+        mp4TrackType = Track.TYPE_soun;
+        break;
+      case StreamElement.TYPE_TEXT:
+        mediaFormat = MediaFormat.createTextFormat(MediaFormat.NO_VALUE, format.mimeType,
+            format.bitrate, durationUs, format.language);
+        mp4TrackType = Track.TYPE_text;
+        break;
+      default:
+        throw new IllegalStateException("Invalid type: " + element.type);
+    }
+
+    // Build the extractor.
+    FragmentedMp4Extractor mp4Extractor = new FragmentedMp4Extractor(
+        FragmentedMp4Extractor.WORKAROUND_EVERY_VIDEO_FRAME_IS_SYNC_FRAME);
+    Track mp4Track = new Track(trackIndex, mp4TrackType, element.timescale, durationUs, mediaFormat,
+        trackEncryptionBoxes, mp4TrackType == Track.TYPE_vide ? 4 : -1);
+    mp4Extractor.setTrack(mp4Track);
+
+    // Store the format and a wrapper around the extractor.
+    mediaFormats.put(manifestTrackKey, mediaFormat);
+    extractorWrappers.put(manifestTrackKey, new ChunkExtractorWrapper(mp4Extractor));
+    return mediaFormat;
+  }
+
   /**
    * For live playbacks, determines the seek position that snaps playback to be
-   * {@link #liveEdgeLatencyUs} behind the live edge of the current manifest
+   * {@code liveEdgeLatencyUs} behind the live edge of the provided manifest.
    *
+   * @param manifest The manifest.
+   * @param liveEdgeLatencyUs The live edge latency, in microseconds.
    * @return The seek position in microseconds.
    */
-  private long getLiveSeekPosition() {
+  private static long getLiveSeekPosition(SmoothStreamingManifest manifest,
+      long liveEdgeLatencyUs) {
     long liveEdgeTimestampUs = Long.MIN_VALUE;
-    for (int i = 0; i < currentManifest.streamElements.length; i++) {
-      StreamElement streamElement = currentManifest.streamElements[i];
+    for (int i = 0; i < manifest.streamElements.length; i++) {
+      StreamElement streamElement = manifest.streamElements[i];
       if (streamElement.chunkCount > 0) {
         long elementLiveEdgeTimestampUs =
             streamElement.getStartTimeUs(streamElement.chunkCount - 1)
@@ -362,12 +461,8 @@ private long getLiveSeekPosition() {
     return liveEdgeTimestampUs - liveEdgeLatencyUs;
   }
 
-  private StreamElement getElement(SmoothStreamingManifest manifest) {
-    return manifest.streamElements[streamElementIndex];
-  }
-
-  private int getTrackIndex(Format format) {
-    TrackElement[] tracks = currentManifest.streamElements[streamElementIndex].tracks;
+  private static int getManifestTrackIndex(StreamElement element, Format format) {
+    TrackElement[] tracks = element.tracks;
     for (int i = 0; i < tracks.length; i++) {
       if (tracks[i].format.equals(format)) {
         return i;
@@ -377,46 +472,25 @@ private int getTrackIndex(Format format) {
     throw new IllegalStateException("Invalid format: " + format);
   }
 
-  private static MediaFormat getMediaFormat(StreamElement streamElement, int trackIndex) {
-    TrackElement trackElement = streamElement.tracks[trackIndex];
-    Format trackFormat = trackElement.format;
-    String mimeType = trackFormat.mimeType;
-    if (streamElement.type == StreamElement.TYPE_VIDEO) {
-      MediaFormat format = MediaFormat.createVideoFormat(mimeType, MediaFormat.NO_VALUE,
-          trackFormat.width, trackFormat.height, Arrays.asList(trackElement.csd));
-      format.setMaxVideoDimensions(streamElement.maxWidth, streamElement.maxHeight);
-      return format;
-    } else if (streamElement.type == StreamElement.TYPE_AUDIO) {
-      List<byte[]> csd;
-      if (trackElement.csd != null) {
-        csd = Arrays.asList(trackElement.csd);
-      } else {
-        csd = Collections.singletonList(CodecSpecificDataUtil.buildAacAudioSpecificConfig(
-            trackFormat.audioSamplingRate, trackFormat.numChannels));
-      }
-      MediaFormat format = MediaFormat.createAudioFormat(mimeType, MediaFormat.NO_VALUE,
-          trackFormat.numChannels, trackFormat.audioSamplingRate, csd);
-      return format;
-    } else if (streamElement.type == StreamElement.TYPE_TEXT) {
-      return MediaFormat.createTextFormat(trackFormat.mimeType);
-    }
-    return null;
-  }
-
   private static MediaChunk newMediaChunk(Format formatInfo, Uri uri, String cacheKey,
       ChunkExtractorWrapper extractorWrapper, DrmInitData drmInitData, DataSource dataSource,
-      int chunkIndex, boolean isLast, long chunkStartTimeUs, long chunkEndTimeUs,
-      int trigger, MediaFormat mediaFormat) {
+      int chunkIndex, long chunkStartTimeUs, long chunkEndTimeUs, int trigger,
+      MediaFormat mediaFormat, int adaptiveMaxWidth, int adaptiveMaxHeight) {
     long offset = 0;
     DataSpec dataSpec = new DataSpec(uri, offset, -1, cacheKey);
     // In SmoothStreaming each chunk contains sample timestamps relative to the start of the chunk.
     // To convert them the absolute timestamps, we need to set sampleOffsetUs to -chunkStartTimeUs.
     return new ContainerMediaChunk(dataSource, dataSpec, trigger, formatInfo, chunkStartTimeUs,
-        chunkEndTimeUs, chunkIndex, isLast, chunkStartTimeUs, extractorWrapper, mediaFormat,
-        drmInitData, true);
+        chunkEndTimeUs, chunkIndex, chunkStartTimeUs, extractorWrapper, mediaFormat,
+        adaptiveMaxWidth, adaptiveMaxHeight, drmInitData, true, Chunk.NO_PARENT_ID);
+  }
+
+  private static int getManifestTrackKey(int elementIndex, int trackIndex) {
+    Assertions.checkState(elementIndex <= 65536 && trackIndex <= 65536);
+    return (elementIndex << 16) | trackIndex;
   }
 
-  private static byte[] getKeyId(byte[] initData) {
+  private static byte[] getProtectionElementKeyId(byte[] initData) {
     StringBuilder initDataStringBuilder = new StringBuilder();
     for (int i = 0; i < initData.length; i += 2) {
       initDataStringBuilder.append((char) initData[i]);
@@ -438,4 +512,45 @@ private static void swap(byte[] data, int firstPosition, int secondPosition) {
     data[secondPosition] = temp;
   }
 
+  // Private classes.
+
+  private static final class ExposedTrack {
+
+    public final MediaFormat trackFormat;
+
+    private final int elementIndex;
+
+    // Non-adaptive track variables.
+    private final Format fixedFormat;
+
+    // Adaptive track variables.
+    private final Format[] adaptiveFormats;
+    private final int adaptiveMaxWidth;
+    private final int adaptiveMaxHeight;
+
+    public ExposedTrack(MediaFormat trackFormat, int elementIndex, Format fixedFormat) {
+      this.trackFormat = trackFormat;
+      this.elementIndex = elementIndex;
+      this.fixedFormat = fixedFormat;
+      this.adaptiveFormats = null;
+      this.adaptiveMaxWidth = MediaFormat.NO_VALUE;
+      this.adaptiveMaxHeight = MediaFormat.NO_VALUE;
+    }
+
+    public ExposedTrack(MediaFormat trackFormat, int elementIndex, Format[] adaptiveFormats,
+        int adaptiveMaxWidth, int adaptiveMaxHeight) {
+      this.trackFormat = trackFormat;
+      this.elementIndex = elementIndex;
+      this.adaptiveFormats = adaptiveFormats;
+      this.adaptiveMaxWidth = adaptiveMaxWidth;
+      this.adaptiveMaxHeight = adaptiveMaxHeight;
+      this.fixedFormat = null;
+    }
+
+    public boolean isAdaptive() {
+      return adaptiveFormats != null;
+    }
+
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingTrackSelector.java b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingTrackSelector.java
new file mode 100644
index 0000000000..d8d549521f
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/smoothstreaming/SmoothStreamingTrackSelector.java
@@ -0,0 +1,59 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.smoothstreaming;
+
+import java.io.IOException;
+
+/**
+ * Specifies a track selection from a {@link SmoothStreamingManifest}.
+ */
+public interface SmoothStreamingTrackSelector {
+
+  /**
+   * Defines a selector output.
+   */
+  interface Output {
+
+    /**
+     * Outputs an adaptive track, covering the specified tracks in the specified element.
+     *
+     * @param manifest The manifest being processed.
+     * @param element The index of the element within which the adaptive tracks are located.
+     * @param tracks The indices of the tracks within the element.
+     */
+    void adaptiveTrack(SmoothStreamingManifest manifest, int element, int[] tracks);
+
+    /**
+     * Outputs a fixed track corresponding to the specified track in the specified element.
+     *
+     * @param manifest The manifest being processed.
+     * @param element The index of the element within which the track is located.
+     * @param track The index of the track within the element.
+     */
+    void fixedTrack(SmoothStreamingManifest manifest, int element, int track);
+
+  }
+
+  /**
+   * Outputs a track selection for a given manifest.
+   *
+   * @param manifest The manifest to process.
+   * @param output The output to receive tracks.
+   * @throws IOException If an error occurs processing the manifest.
+   */
+  void selectTracks(SmoothStreamingManifest manifest, Output output) throws IOException;
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/text/Cue.java b/library/src/main/java/com/google/android/exoplayer/text/Cue.java
index f9476b5a5a..33f37ef608 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/Cue.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/Cue.java
@@ -23,30 +23,117 @@
 public class Cue {
 
   /**
-   * Used by some methods to indicate that no value is set.
+   * An unset position or width.
    */
-  public static final int UNSET_VALUE = -1;
+  public static final float DIMEN_UNSET = Float.MIN_VALUE;
+  /**
+   * An unset anchor or line type value.
+   */
+  public static final int TYPE_UNSET = Integer.MIN_VALUE;
+  /**
+   * Anchors the left (for horizontal positions) or top (for vertical positions) edge of the cue
+   * box.
+   */
+  public static final int ANCHOR_TYPE_START = 0;
+  /**
+   * Anchors the middle of the cue box.
+   */
+  public static final int ANCHOR_TYPE_MIDDLE = 1;
+  /**
+   * Anchors the right (for horizontal positions) or bottom (for vertical positions) edge of the cue
+   * box.
+   */
+  public static final int ANCHOR_TYPE_END = 2;
+  /**
+   * Value for {@link #lineType} when {@link #line} is a fractional position.
+   */
+  public static final int LINE_TYPE_FRACTION = 0;
+  /**
+   * Value for {@link #lineType} when {@link #line} is a line number.
+   */
+  public static final int LINE_TYPE_NUMBER = 1;
 
+  /**
+   * The cue text. Note the {@link CharSequence} may be decorated with styling spans.
+   */
   public final CharSequence text;
-
-  public final int line;
-  public final int position;
-  public final Alignment alignment;
-  public final int size;
+  /**
+   * The alignment of the cue text within the cue box.
+   */
+  public final Alignment textAlignment;
+  /**
+   * The position of the {@link #lineAnchor} of the cue box within the viewport in the direction
+   * orthogonal to the writing direction, or {@link #DIMEN_UNSET}. When set, the interpretation of
+   * the value depends on the value of {@link #lineType}.
+   * <p>
+   * For horizontal text and {@link #lineType} equal to {@link #LINE_TYPE_FRACTION}, this is the
+   * fractional vertical position relative to the top of the viewport.
+   */
+  public final float line;
+  /**
+   * The type of the {@link #line} value.
+   * <p>
+   * {@link #LINE_TYPE_FRACTION} indicates that {@link #line} is a fractional position within the
+   * viewport.
+   * <p>
+   * {@link #LINE_TYPE_NUMBER} indicates that {@link #line} is a line number, where the size of each
+   * line is taken to be the size of the first line of the cue. When {@link #line} is greater than
+   * or equal to 0, lines count from the start of the viewport (the first line is numbered 0). When
+   * {@link #line} is negative, lines count from the end of the viewport (the last line is numbered
+   * -1). For horizontal text the size of the first line of the cue is its height, and the start
+   * and end of the viewport are the top and bottom respectively.
+   */
+  public final int lineType;
+  /**
+   * The cue box anchor positioned by {@link #line}. One of {@link #ANCHOR_TYPE_START},
+   * {@link #ANCHOR_TYPE_MIDDLE}, {@link #ANCHOR_TYPE_END} and {@link #TYPE_UNSET}.
+   * <p>
+   * For the normal case of horizontal text, {@link #ANCHOR_TYPE_START}, {@link #ANCHOR_TYPE_MIDDLE}
+   * and {@link #ANCHOR_TYPE_END} correspond to the top, middle and bottom of the cue box
+   * respectively.
+   */
+  public final int lineAnchor;
+  /**
+   * The fractional position of the {@link #positionAnchor} of the cue box within the viewport in
+   * the direction orthogonal to {@link #line}, or {@link #DIMEN_UNSET}.
+   * <p>
+   * For horizontal text, this is the horizontal position relative to the left of the viewport. Note
+   * that positioning is relative to the left of the viewport even in the case of right-to-left
+   * text.
+   */
+  public final float position;
+  /**
+   * The cue box anchor positioned by {@link #position}. One of {@link #ANCHOR_TYPE_START},
+   * {@link #ANCHOR_TYPE_MIDDLE}, {@link #ANCHOR_TYPE_END} and {@link #TYPE_UNSET}.
+   * <p>
+   * For the normal case of horizontal text, {@link #ANCHOR_TYPE_START}, {@link #ANCHOR_TYPE_MIDDLE}
+   * and {@link #ANCHOR_TYPE_END} correspond to the left, middle and right of the cue box
+   * respectively.
+   */
+  public final int positionAnchor;
+  /**
+   * The size of the cue box in the writing direction specified as a fraction of the viewport size
+   * in that direction, or {@link #DIMEN_UNSET}.
+   */
+  public final float size;
 
   public Cue() {
     this(null);
   }
 
   public Cue(CharSequence text) {
-    this(text, UNSET_VALUE, UNSET_VALUE, null, UNSET_VALUE);
+    this(text, null, DIMEN_UNSET, TYPE_UNSET, TYPE_UNSET, DIMEN_UNSET, TYPE_UNSET, DIMEN_UNSET);
   }
 
-  public Cue(CharSequence text, int line, int position, Alignment alignment, int size) {
+  public Cue(CharSequence text, Alignment textAlignment, float line, int lineType,
+      int lineAnchor, float position, int positionAnchor, float size) {
     this.text = text;
+    this.textAlignment = textAlignment;
     this.line = line;
+    this.lineType = lineType;
+    this.lineAnchor = lineAnchor;
     this.position = position;
-    this.alignment = alignment;
+    this.positionAnchor = positionAnchor;
     this.size = size;
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/text/CuePainter.java b/library/src/main/java/com/google/android/exoplayer/text/CuePainter.java
index bbeee94f51..a86edd376a 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/CuePainter.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/CuePainter.java
@@ -45,18 +45,6 @@
    */
   private static final float INNER_PADDING_RATIO = 0.125f;
 
-  /**
-   * Use the same line height ratio as WebVtt to match the display with the preview.
-   * WebVtt specifies line height as 5.3% of the viewport height.
-   */
-  private static final float LINE_HEIGHT_FRACTION = 0.0533f;
-
-  /**
-   * The default bottom padding to apply when {@link Cue#line} is {@link Cue#UNSET_VALUE}, as a
-   * fraction of the viewport height.
-   */
-  private static final float DEFAULT_BOTTOM_PADDING_FRACTION = 0.08f;
-
   /**
    * Temporary rectangle used for computing line bounds.
    */
@@ -75,13 +63,21 @@
 
   // Previous input variables.
   private CharSequence cueText;
-  private int cuePosition;
-  private Alignment cueAlignment;
+  private Alignment cueTextAlignment;
+  private float cueLine;
+  private int cueLineType;
+  private int cueLineAnchor;
+  private float cuePosition;
+  private int cuePositionAnchor;
+  private float cueSize;
+  private boolean applyEmbeddedStyles;
   private int foregroundColor;
   private int backgroundColor;
   private int windowColor;
   private int edgeColor;
   private int edgeType;
+  private float textSizePx;
+  private float bottomPaddingFraction;
   private int parentLeft;
   private int parentTop;
   private int parentRight;
@@ -125,69 +121,95 @@ public CuePainter(Context context) {
    * which the same parameters are passed.
    *
    * @param cue The cue to draw.
+   * @param applyEmbeddedStyles Whether styling embedded within the cue should be applied.
    * @param style The style to use when drawing the cue text.
-   * @param fontScale The font scale.
+   * @param textSizePx The text size to use when drawing the cue text, in pixels.
+   * @param bottomPaddingFraction The bottom padding fraction to apply when {@link Cue#line} is
+   *     {@link Cue#DIMEN_UNSET}, as a fraction of the viewport height
    * @param canvas The canvas into which to draw.
    * @param cueBoxLeft The left position of the enclosing cue box.
    * @param cueBoxTop The top position of the enclosing cue box.
    * @param cueBoxRight The right position of the enclosing cue box.
    * @param cueBoxBottom The bottom position of the enclosing cue box.
    */
-  public void draw(Cue cue, CaptionStyleCompat style, float fontScale, Canvas canvas,
-      int cueBoxLeft, int cueBoxTop, int cueBoxRight, int cueBoxBottom) {
-    if (TextUtils.isEmpty(cue.text)) {
+  public void draw(Cue cue, boolean applyEmbeddedStyles, CaptionStyleCompat style, float textSizePx,
+      float bottomPaddingFraction, Canvas canvas, int cueBoxLeft, int cueBoxTop, int cueBoxRight,
+      int cueBoxBottom) {
+    CharSequence cueText = cue.text;
+    if (TextUtils.isEmpty(cueText)) {
       // Nothing to draw.
       return;
     }
-
-    if (TextUtils.equals(cueText, cue.text)
-        && cuePosition == cue.position
-        && Util.areEqual(cueAlignment, cue.alignment)
-        && foregroundColor == style.foregroundColor
-        && backgroundColor == style.backgroundColor
-        && windowColor == style.windowColor
-        && edgeType == style.edgeType
-        && edgeColor == style.edgeColor
-        && Util.areEqual(textPaint.getTypeface(), style.typeface)
-        && parentLeft == cueBoxLeft
-        && parentTop == cueBoxTop
-        && parentRight == cueBoxRight
-        && parentBottom == cueBoxBottom) {
+    if (!applyEmbeddedStyles) {
+      // Strip out any embedded styling.
+      cueText = cueText.toString();
+    }
+    if (areCharSequencesEqual(this.cueText, cueText)
+        && Util.areEqual(this.cueTextAlignment, cue.textAlignment)
+        && this.cueLine == cue.line
+        && this.cueLineType == cue.lineType
+        && Util.areEqual(this.cueLineAnchor, cue.lineAnchor)
+        && this.cuePosition == cue.position
+        && Util.areEqual(this.cuePositionAnchor, cue.positionAnchor)
+        && this.cueSize == cue.size
+        && this.applyEmbeddedStyles == applyEmbeddedStyles
+        && this.foregroundColor == style.foregroundColor
+        && this.backgroundColor == style.backgroundColor
+        && this.windowColor == style.windowColor
+        && this.edgeType == style.edgeType
+        && this.edgeColor == style.edgeColor
+        && Util.areEqual(this.textPaint.getTypeface(), style.typeface)
+        && this.textSizePx == textSizePx
+        && this.bottomPaddingFraction == bottomPaddingFraction
+        && this.parentLeft == cueBoxLeft
+        && this.parentTop == cueBoxTop
+        && this.parentRight == cueBoxRight
+        && this.parentBottom == cueBoxBottom) {
       // We can use the cached layout.
       drawLayout(canvas);
       return;
     }
 
-    cueText = cue.text;
-    cuePosition = cue.position;
-    cueAlignment = cue.alignment;
-    foregroundColor = style.foregroundColor;
-    backgroundColor = style.backgroundColor;
-    windowColor = style.windowColor;
-    edgeType = style.edgeType;
-    edgeColor = style.edgeColor;
-    textPaint.setTypeface(style.typeface);
-    parentLeft = cueBoxLeft;
-    parentTop = cueBoxTop;
-    parentRight = cueBoxRight;
-    parentBottom = cueBoxBottom;
+    this.cueText = cueText;
+    this.cueTextAlignment = cue.textAlignment;
+    this.cueLine = cue.line;
+    this.cueLineType = cue.lineType;
+    this.cueLineAnchor = cue.lineAnchor;
+    this.cuePosition = cue.position;
+    this.cuePositionAnchor = cue.positionAnchor;
+    this.cueSize = cue.size;
+    this.applyEmbeddedStyles = applyEmbeddedStyles;
+    this.foregroundColor = style.foregroundColor;
+    this.backgroundColor = style.backgroundColor;
+    this.windowColor = style.windowColor;
+    this.edgeType = style.edgeType;
+    this.edgeColor = style.edgeColor;
+    this.textPaint.setTypeface(style.typeface);
+    this.textSizePx = textSizePx;
+    this.bottomPaddingFraction = bottomPaddingFraction;
+    this.parentLeft = cueBoxLeft;
+    this.parentTop = cueBoxTop;
+    this.parentRight = cueBoxRight;
+    this.parentBottom = cueBoxBottom;
 
     int parentWidth = parentRight - parentLeft;
     int parentHeight = parentBottom - parentTop;
 
-    float textSize = LINE_HEIGHT_FRACTION * parentHeight * fontScale;
-    textPaint.setTextSize(textSize);
-    int textPaddingX = (int) (textSize * INNER_PADDING_RATIO + 0.5f);
+    textPaint.setTextSize(textSizePx);
+    int textPaddingX = (int) (textSizePx * INNER_PADDING_RATIO + 0.5f);
+
     int availableWidth = parentWidth - textPaddingX * 2;
+    if (cueSize != Cue.DIMEN_UNSET) {
+      availableWidth = (int) (availableWidth * cueSize);
+    }
     if (availableWidth <= 0) {
       Log.w(TAG, "Skipped drawing subtitle cue (insufficient space)");
       return;
     }
 
-    Alignment layoutAlignment = cueAlignment == null ? Alignment.ALIGN_CENTER : cueAlignment;
-    textLayout = new StaticLayout(cueText, textPaint, availableWidth, layoutAlignment, spacingMult,
+    Alignment textAlignment = cueTextAlignment == null ? Alignment.ALIGN_CENTER : cueTextAlignment;
+    textLayout = new StaticLayout(cueText, textPaint, availableWidth, textAlignment, spacingMult,
         spacingAdd, true);
-
     int textHeight = textLayout.getHeight();
     int textWidth = 0;
     int lineCount = textLayout.getLineCount();
@@ -196,33 +218,55 @@ public void draw(Cue cue, CaptionStyleCompat style, float fontScale, Canvas canv
     }
     textWidth += textPaddingX * 2;
 
-    int textLeft = (parentWidth - textWidth) / 2;
-    int textRight = textLeft + textWidth;
-    int textTop = parentBottom - textHeight
-        - (int) (parentHeight * DEFAULT_BOTTOM_PADDING_FRACTION);
-    int textBottom = textTop + textHeight;
+    int textLeft;
+    int textRight;
+    if (cuePosition != Cue.DIMEN_UNSET) {
+      int anchorPosition = Math.round(parentWidth * cuePosition) + parentLeft;
+      textLeft = cuePositionAnchor == Cue.ANCHOR_TYPE_END ? anchorPosition - textWidth
+          : cuePositionAnchor == Cue.ANCHOR_TYPE_MIDDLE ? (anchorPosition * 2 - textWidth) / 2
+          : anchorPosition;
+      textLeft = Math.max(textLeft, parentLeft);
+      textRight = Math.min(textLeft + textWidth, parentRight);
+    } else {
+      textLeft = (parentWidth - textWidth) / 2;
+      textRight = textLeft + textWidth;
+    }
 
-    if (cue.position != Cue.UNSET_VALUE) {
-      if (cue.alignment == Alignment.ALIGN_OPPOSITE) {
-        textRight = (parentWidth * cue.position) / 100 + parentLeft;
-        textLeft = Math.max(textRight - textWidth, parentLeft);
+    int textTop;
+    int textBottom;
+    if (cueLine != Cue.DIMEN_UNSET) {
+      int anchorPosition;
+      if (cueLineType == Cue.LINE_TYPE_FRACTION) {
+        anchorPosition = Math.round(parentHeight * cueLine) + parentTop;
       } else {
-        textLeft = (parentWidth * cue.position) / 100 + parentLeft;
-        textRight = Math.min(textLeft + textWidth, parentRight);
+        // cueLineType == Cue.LINE_TYPE_NUMBER
+        int firstLineHeight = textLayout.getLineBottom(0) - textLayout.getLineTop(0);
+        if (cueLine >= 0) {
+          anchorPosition = Math.round(cueLine * firstLineHeight) + parentTop;
+        } else {
+          anchorPosition = Math.round(cueLine * firstLineHeight) + parentBottom;
+        }
       }
-    }
-    if (cue.line != Cue.UNSET_VALUE) {
-      textTop = (parentHeight * cue.line) / 100 + parentTop;
+      textTop = cueLineAnchor == Cue.ANCHOR_TYPE_END ? anchorPosition - textHeight
+          : cueLineAnchor == Cue.ANCHOR_TYPE_MIDDLE ? (anchorPosition * 2 - textHeight) / 2
+          : anchorPosition;
       textBottom = textTop + textHeight;
       if (textBottom > parentBottom) {
         textTop = parentBottom - textHeight;
         textBottom = parentBottom;
+      } else if (textTop < parentTop) {
+        textTop = parentTop;
+        textBottom = parentTop + textHeight;
       }
+    } else {
+      textTop = parentBottom - textHeight - (int) (parentHeight * bottomPaddingFraction);
+      textBottom = textTop + textHeight;
     }
+
     textWidth = textRight - textLeft;
 
     // Update the derived drawing variables.
-    this.textLayout = new StaticLayout(cueText, textPaint, textWidth, layoutAlignment, spacingMult,
+    this.textLayout = new StaticLayout(cueText, textPaint, textWidth, textAlignment, spacingMult,
         spacingAdd, true);
     this.textLeft = textLeft;
     this.textTop = textTop;
@@ -295,4 +339,15 @@ private void drawLayout(Canvas canvas) {
     canvas.restoreToCount(saveCount);
   }
 
+  /**
+   * This method is used instead of {@link TextUtils#equals(CharSequence, CharSequence)} because the
+   * latter only checks the text of each sequence, and does not check for equality of styling that
+   * may be embedded within the {@link CharSequence}s.
+   */
+  private static boolean areCharSequencesEqual(CharSequence first, CharSequence second) {
+    // Some CharSequence implementations don't perform a cheap referential equality check in their
+    // equals methods, so we perform one explicitly here.
+    return first == second || (first != null && first.equals(second));
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/PlayableSubtitle.java b/library/src/main/java/com/google/android/exoplayer/text/PlayableSubtitle.java
new file mode 100644
index 0000000000..9afcf1c9c5
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/text/PlayableSubtitle.java
@@ -0,0 +1,75 @@
+package com.google.android.exoplayer.text;
+
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import java.util.List;
+
+/**
+ * A subtitle that wraps another subtitle, making it playable by adjusting it to be correctly
+ * aligned with the playback timebase.
+ */
+/* package */ final class PlayableSubtitle implements Subtitle {
+
+  /**
+   * The start time of the subtitle.
+   * <p>
+   * May be less than {@code getEventTime(0)}, since a subtitle may begin prior to the time of the
+   * first event.
+   */
+  public final long startTimeUs;
+
+  private final Subtitle subtitle;
+  private final long offsetUs;
+
+  /**
+   * @param subtitle The subtitle to wrap.
+   * @param isRelative True if the wrapped subtitle's timestamps are relative to the start time.
+   *     False if they are absolute.
+   * @param startTimeUs The start time of the subtitle.
+   * @param offsetUs An offset to add to the subtitle timestamps.
+   */
+  public PlayableSubtitle(Subtitle subtitle, boolean isRelative, long startTimeUs, long offsetUs) {
+    this.subtitle = subtitle;
+    this.startTimeUs = startTimeUs;
+    this.offsetUs = (isRelative ? startTimeUs : 0) + offsetUs;
+  }
+
+  @Override
+  public int getEventTimeCount() {
+    return subtitle.getEventTimeCount();
+  }
+
+  @Override
+  public long getEventTime(int index) {
+    return subtitle.getEventTime(index) + offsetUs;
+  }
+
+  @Override
+  public long getLastEventTime() {
+    return subtitle.getLastEventTime() + offsetUs;
+  }
+
+  @Override
+  public int getNextEventTimeIndex(long timeUs) {
+    return subtitle.getNextEventTimeIndex(timeUs - offsetUs);
+  }
+
+  @Override
+  public List<Cue> getCues(long timeUs) {
+    return subtitle.getCues(timeUs - offsetUs);
+  }
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/text/Subtitle.java b/library/src/main/java/com/google/android/exoplayer/text/Subtitle.java
index 2b2e1ad44b..55a99cdf43 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/Subtitle.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/Subtitle.java
@@ -22,16 +22,6 @@
  */
 public interface Subtitle {
 
-  /**
-   * Gets the start time of the subtitle.
-   * <p>
-   * Note that the value returned may be less than {@code getEventTime(0)}, since a subtitle may
-   * begin prior to the time of the first event.
-   *
-   * @return The start time of the subtitle in microseconds.
-   */
-  public long getStartTime();
-
   /**
    * Gets the index of the first event that occurs after a given time (exclusive).
    *
diff --git a/library/src/main/java/com/google/android/exoplayer/text/SubtitleLayout.java b/library/src/main/java/com/google/android/exoplayer/text/SubtitleLayout.java
index 690e7056e7..700a72138c 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/SubtitleLayout.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/SubtitleLayout.java
@@ -16,8 +16,10 @@
 package com.google.android.exoplayer.text;
 
 import android.content.Context;
+import android.content.res.Resources;
 import android.graphics.Canvas;
 import android.util.AttributeSet;
+import android.util.TypedValue;
 import android.view.View;
 
 import java.util.ArrayList;
@@ -28,11 +30,33 @@
  */
 public final class SubtitleLayout extends View {
 
+  /**
+   * The default fractional text size.
+   *
+   * @see #setFractionalTextSize(float, boolean)
+   */
+  public static final float DEFAULT_TEXT_SIZE_FRACTION = 0.0533f;
+
+  /**
+   * The default bottom padding to apply when {@link Cue#line} is {@link Cue#DIMEN_UNSET}, as a
+   * fraction of the viewport height.
+   *
+   * @see #setBottomPaddingFraction(float)
+   */
+  public static final float DEFAULT_BOTTOM_PADDING_FRACTION = 0.08f;
+
+  private static final int FRACTIONAL = 0;
+  private static final int FRACTIONAL_IGNORE_PADDING = 1;
+  private static final int ABSOLUTE = 2;
+
   private final List<CuePainter> painters;
 
   private List<Cue> cues;
-  private float fontScale;
+  private int textSizeType;
+  private float textSize;
+  private boolean applyEmbeddedStyles;
   private CaptionStyleCompat style;
+  private float bottomPaddingFraction;
 
   public SubtitleLayout(Context context) {
     this(context, null);
@@ -41,8 +65,11 @@ public SubtitleLayout(Context context) {
   public SubtitleLayout(Context context, AttributeSet attrs) {
     super(context, attrs);
     painters = new ArrayList<>();
-    fontScale = 1;
+    textSizeType = FRACTIONAL;
+    textSize = DEFAULT_TEXT_SIZE_FRACTION;
+    applyEmbeddedStyles = true;
     style = CaptionStyleCompat.DEFAULT;
+    bottomPaddingFraction = DEFAULT_BOTTOM_PADDING_FRACTION;
   }
 
   /**
@@ -65,21 +92,75 @@ public void setCues(List<Cue> cues) {
   }
 
   /**
-   * Sets the scale of the font.
+   * Set the text size to a given unit and value.
+   * <p>
+   * See {@link TypedValue} for the possible dimension units.
+   *
+   * @param unit The desired dimension unit.
+   * @param size The desired size in the given units.
+   */
+  public void setFixedTextSize(int unit, float size) {
+    Context context = getContext();
+    Resources resources;
+    if (context == null) {
+      resources = Resources.getSystem();
+    } else {
+      resources = context.getResources();
+    }
+    setTextSize(ABSOLUTE, TypedValue.applyDimension(unit, size, resources.getDisplayMetrics()));
+  }
+
+  /**
+   * Sets the text size to be a fraction of the view's remaining height after its top and bottom
+   * padding have been subtracted.
+   * <p>
+   * Equivalent to {@code #setFractionalTextSize(fractionOfHeight, false)}.
+   *
+   * @param fractionOfHeight A fraction between 0 and 1.
+   */
+  public void setFractionalTextSize(float fractionOfHeight) {
+    setFractionalTextSize(fractionOfHeight, false);
+  }
+
+  /**
+   * Sets the text size to be a fraction of the height of this view.
    *
-   * @param fontScale The scale of the font.
+   * @param fractionOfHeight A fraction between 0 and 1.
+   * @param ignorePadding Set to true if {@code fractionOfHeight} should be interpreted as a
+   *     fraction of this view's height ignoring any top and bottom padding. Set to false if
+   *     {@code fractionOfHeight} should be interpreted as a fraction of this view's remaining
+   *     height after the top and bottom padding has been subtracted.
    */
-  public void setFontScale(float fontScale) {
-    if (this.fontScale == fontScale) {
+  public void setFractionalTextSize(float fractionOfHeight, boolean ignorePadding) {
+    setTextSize(ignorePadding ? FRACTIONAL_IGNORE_PADDING : FRACTIONAL, fractionOfHeight);
+  }
+
+  private void setTextSize(int textSizeType, float textSize) {
+    if (this.textSizeType == textSizeType && this.textSize == textSize) {
       return;
     }
-    this.fontScale = fontScale;
+    this.textSizeType = textSizeType;
+    this.textSize = textSize;
     // Invalidate to trigger drawing.
     invalidate();
   }
 
   /**
-   * Configures the view according to the given style.
+   * Sets whether styling embedded within the cues should be applied. Enabled by default.
+   *
+   * @param applyEmbeddedStyles Whether styling embedded within the cues should be applied.
+   */
+  public void setApplyEmbeddedStyles(boolean applyEmbeddedStyles) {
+    if (this.applyEmbeddedStyles == applyEmbeddedStyles) {
+      return;
+    }
+    this.applyEmbeddedStyles = applyEmbeddedStyles;
+    // Invalidate to trigger drawing.
+    invalidate();
+  }
+
+  /**
+   * Sets the caption style.
    *
    * @param style A style for the view.
    */
@@ -92,12 +173,50 @@ public void setStyle(CaptionStyleCompat style) {
     invalidate();
   }
 
+  /**
+   * Sets the bottom padding fraction to apply when {@link Cue#line} is {@link Cue#DIMEN_UNSET},
+   * as a fraction of the view's remaining height after its top and bottom padding have been
+   * subtracted.
+   * <p>
+   * Note that this padding is applied in addition to any standard view padding.
+   *
+   * @param bottomPaddingFraction The bottom padding fraction.
+   */
+  public void setBottomPaddingFraction(float bottomPaddingFraction) {
+    if (this.bottomPaddingFraction == bottomPaddingFraction) {
+      return;
+    }
+    this.bottomPaddingFraction = bottomPaddingFraction;
+    // Invalidate to trigger drawing.
+    invalidate();
+  }
+
   @Override
   public void dispatchDraw(Canvas canvas) {
     int cueCount = (cues == null) ? 0 : cues.size();
+    int rawTop = getTop();
+    int rawBottom = getBottom();
+
+    // Calculate the bounds after padding is taken into account.
+    int left = getLeft() + getPaddingLeft();
+    int top = rawTop + getPaddingTop();
+    int right = getRight() + getPaddingRight();
+    int bottom = rawBottom - getPaddingBottom();
+    if (bottom <= top || right <= left) {
+      // No space to draw subtitles.
+      return;
+    }
+
+    float textSizePx = textSizeType == ABSOLUTE ? textSize
+        : textSize * (textSizeType == FRACTIONAL ? (bottom - top) : (rawBottom - rawTop));
+    if (textSizePx <= 0) {
+      // Text has no height.
+      return;
+    }
+
     for (int i = 0; i < cueCount; i++) {
-      painters.get(i).draw(cues.get(i), style, fontScale, canvas, getLeft(), getTop(), getRight(),
-          getBottom());
+      painters.get(i).draw(cues.get(i), applyEmbeddedStyles, style, textSizePx,
+          bottomPaddingFraction, canvas, left, top, right, bottom);
     }
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/text/SubtitleParser.java b/library/src/main/java/com/google/android/exoplayer/text/SubtitleParser.java
index e041373d6e..d02ac46f42 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/SubtitleParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/SubtitleParser.java
@@ -35,12 +35,9 @@
    * Parses a {@link Subtitle} from the provided {@link InputStream}.
    *
    * @param inputStream The stream from which to parse the subtitle.
-   * @param inputEncoding The encoding of the input stream.
-   * @param startTimeUs The start time of the subtitle.
    * @return A parsed representation of the subtitle.
    * @throws IOException If a problem occurred reading from the stream.
    */
-  public Subtitle parse(InputStream inputStream, String inputEncoding, long startTimeUs)
-      throws IOException;
+  public Subtitle parse(InputStream inputStream) throws IOException;
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/SubtitleParserHelper.java b/library/src/main/java/com/google/android/exoplayer/text/SubtitleParserHelper.java
index 835f66aa51..952ae04b97 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/SubtitleParserHelper.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/SubtitleParserHelper.java
@@ -15,8 +15,10 @@
  */
 package com.google.android.exoplayer.text;
 
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.util.Assertions;
+import com.google.android.exoplayer.util.Util;
 
 import android.media.MediaCodec;
 import android.os.Handler;
@@ -31,15 +33,22 @@
  * Wraps a {@link SubtitleParser}, exposing an interface similar to {@link MediaCodec} for
  * asynchronous parsing of subtitles.
  */
-public final class SubtitleParserHelper implements Handler.Callback {
+/* package */ final class SubtitleParserHelper implements Handler.Callback {
 
-  private final SubtitleParser parser;
+  private static final int MSG_FORMAT = 0;
+  private static final int MSG_SAMPLE = 1;
 
+  private final SubtitleParser parser;
   private final Handler handler;
+
   private SampleHolder sampleHolder;
   private boolean parsing;
-  private Subtitle result;
+  private PlayableSubtitle result;
   private IOException error;
+  private RuntimeException runtimeError;
+
+  private boolean subtitlesAreRelative;
+  private long subtitleOffsetUs;
 
   /**
    * @param looper The {@link Looper} associated with the thread on which parsing should occur.
@@ -59,6 +68,7 @@ public synchronized void flush() {
     parsing = false;
     result = null;
     error = null;
+    runtimeError = null;
   }
 
   /**
@@ -83,6 +93,15 @@ public synchronized SampleHolder getSampleHolder() {
     return sampleHolder;
   }
 
+  /**
+   * Sets the format of subsequent samples.
+   *
+   * @param format The format.
+   */
+  public void setFormat(MediaFormat format) {
+    handler.obtainMessage(MSG_FORMAT, format).sendToTarget();
+  }
+
   /**
    * Start a parsing operation.
    * <p>
@@ -94,7 +113,9 @@ public synchronized void startParseOperation() {
     parsing = true;
     result = null;
     error = null;
-    handler.obtainMessage(0, sampleHolder).sendToTarget();
+    runtimeError = null;
+    handler.obtainMessage(MSG_SAMPLE, Util.getTopInt(sampleHolder.timeUs),
+        Util.getBottomInt(sampleHolder.timeUs), sampleHolder).sendToTarget();
   }
 
   /**
@@ -106,41 +127,65 @@ public synchronized void startParseOperation() {
    * @return The result of the parsing operation, or null.
    * @throws IOException If the parsing operation failed.
    */
-  public synchronized Subtitle getAndClearResult() throws IOException {
+  public synchronized PlayableSubtitle getAndClearResult() throws IOException {
     try {
       if (error != null) {
         throw error;
+      } else if (runtimeError != null) {
+        throw runtimeError;
+      } else {
+        return result;
       }
-      return result;
     } finally {
-      error = null;
       result = null;
+      error = null;
+      runtimeError = null;
     }
   }
 
   @Override
   public boolean handleMessage(Message msg) {
-    Subtitle result;
-    IOException error;
-    SampleHolder holder = (SampleHolder) msg.obj;
+    switch (msg.what) {
+      case MSG_FORMAT:
+        handleFormat((MediaFormat) msg.obj);
+        break;
+      case MSG_SAMPLE:
+        long sampleTimeUs = Util.getLong(msg.arg1, msg.arg2);
+        SampleHolder holder = (SampleHolder) msg.obj;
+        handleSample(sampleTimeUs, holder);
+        break;
+    }
+    return true;
+  }
+
+  private void handleFormat(MediaFormat format) {
+    subtitlesAreRelative = format.subsampleOffsetUs == MediaFormat.OFFSET_SAMPLE_RELATIVE;
+    subtitleOffsetUs = subtitlesAreRelative ? 0 : format.subsampleOffsetUs;
+  }
+
+  private void handleSample(long sampleTimeUs, SampleHolder holder) {
+    Subtitle parsedSubtitle = null;
+    IOException error = null;
+    RuntimeException runtimeError = null;
     try {
       InputStream inputStream = new ByteArrayInputStream(holder.data.array(), 0, holder.size);
-      result = parser.parse(inputStream, null, sampleHolder.timeUs);
-      error = null;
+      parsedSubtitle = parser.parse(inputStream);
     } catch (IOException e) {
-      result = null;
       error = e;
+    } catch (RuntimeException e) {
+      runtimeError = e;
     }
     synchronized (this) {
       if (sampleHolder != holder) {
         // A flush has occurred since this holder was posted. Do nothing.
       } else {
-        this.result = result;
+        this.result = new PlayableSubtitle(parsedSubtitle, subtitlesAreRelative, sampleTimeUs,
+            subtitleOffsetUs);
         this.error = error;
+        this.runtimeError = runtimeError;
         this.parsing = false;
       }
     }
-    return true;
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/TextTrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/text/TextTrackRenderer.java
index dd9b7bd28f..4fa5a4f918 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/TextTrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/TextTrackRenderer.java
@@ -16,10 +16,11 @@
 package com.google.android.exoplayer.text;
 
 import com.google.android.exoplayer.ExoPlaybackException;
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.MediaFormatHolder;
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+import com.google.android.exoplayer.SampleSourceTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.util.Assertions;
 
@@ -58,7 +59,7 @@
  * {@link SubtitleParser#canParse(String)} will be used.
  */
 @TargetApi(16)
-public final class TextTrackRenderer extends TrackRenderer implements Callback {
+public final class TextTrackRenderer extends SampleSourceTrackRenderer implements Callback {
 
   private static final int MSG_UPDATE_OVERLAY = 0;
 
@@ -104,17 +105,13 @@
 
   private final Handler textRendererHandler;
   private final TextRenderer textRenderer;
-  private final SampleSourceReader source;
   private final MediaFormatHolder formatHolder;
   private final SubtitleParser[] subtitleParsers;
 
   private int parserIndex;
-  private int trackIndex;
-
   private boolean inputStreamEnded;
-
-  private Subtitle subtitle;
-  private Subtitle nextSubtitle;
+  private PlayableSubtitle subtitle;
+  private PlayableSubtitle nextSubtitle;
   private SubtitleParserHelper parserHelper;
   private HandlerThread parserThread;
   private int nextSubtitleEventIndex;
@@ -132,7 +129,23 @@
    */
   public TextTrackRenderer(SampleSource source, TextRenderer textRenderer,
       Looper textRendererLooper, SubtitleParser... subtitleParsers) {
-    this.source = source.register();
+    this(new SampleSource[] {source}, textRenderer, textRendererLooper, subtitleParsers);
+  }
+
+  /**
+   * @param sources Sources from which samples containing subtitle data can be read.
+   * @param textRenderer The text renderer.
+   * @param textRendererLooper The looper associated with the thread on which textRenderer should be
+   *     invoked. If the renderer makes use of standard Android UI components, then this should
+   *     normally be the looper associated with the applications' main thread, which can be
+   *     obtained using {@link android.app.Activity#getMainLooper()}. Null may be passed if the
+   *     renderer should be invoked directly on the player's internal rendering thread.
+   * @param subtitleParsers {@link SubtitleParser}s to parse text samples, in order of decreasing
+   *     priority. If omitted, the default parsers will be used.
+   */
+  public TextTrackRenderer(SampleSource[] sources, TextRenderer textRenderer,
+      Looper textRendererLooper, SubtitleParser... subtitleParsers) {
+    super(sources);
     this.textRenderer = Assertions.checkNotNull(textRenderer);
     this.textRendererHandler = textRendererLooper == null ? null
         : new Handler(textRendererLooper, this);
@@ -153,27 +166,15 @@ public TextTrackRenderer(SampleSource source, TextRenderer textRenderer,
   }
 
   @Override
-  protected int doPrepare(long positionUs) {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < subtitleParsers.length; i++) {
-      for (int j = 0; j < trackCount; j++) {
-        if (subtitleParsers[i].canParse(source.getTrackInfo(j).mimeType)) {
-          parserIndex = i;
-          trackIndex = j;
-          return TrackRenderer.STATE_PREPARED;
-        }
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
+  protected boolean handlesTrack(MediaFormat mediaFormat) {
+    return getParserIndex(mediaFormat) != -1;
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
+    parserIndex = getParserIndex(getFormat(track));
     parserThread = new HandlerThread("textParser");
     parserThread.start();
     parserHelper = new SubtitleParserHelper(parserThread.getLooper(), subtitleParsers[parserIndex]);
@@ -181,8 +182,8 @@ protected void onEnabled(long positionUs, boolean joining) {
   }
 
   @Override
-  protected void seekTo(long positionUs) {
-    source.seekToUs(positionUs);
+  protected void seekTo(long positionUs) throws ExoPlaybackException {
+    super.seekTo(positionUs);
     seekToInternal();
   }
 
@@ -196,8 +197,7 @@ private void seekToInternal() {
 
   @Override
   protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPlaybackException {
-    source.continueBuffering(trackIndex, positionUs);
-
+    continueBufferingSource(positionUs);
     if (nextSubtitle == null) {
       try {
         nextSubtitle = parserHelper.getAndClearResult();
@@ -223,8 +223,7 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
       }
     }
 
-    if (subtitleNextEventTimeUs == Long.MAX_VALUE && nextSubtitle != null
-        && nextSubtitle.getStartTime() <= positionUs) {
+    if (nextSubtitle != null && nextSubtitle.startTimeUs <= positionUs) {
       // Advance to the next subtitle. Sync the next event index and trigger an update.
       subtitle = nextSubtitle;
       nextSubtitle = null;
@@ -241,8 +240,10 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
       // Try and read the next subtitle from the source.
       SampleHolder sampleHolder = parserHelper.getSampleHolder();
       sampleHolder.clearData();
-      int result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, false);
-      if (result == SampleSource.SAMPLE_READ) {
+      int result = readSource(positionUs, formatHolder, sampleHolder, false);
+      if (result == SampleSource.FORMAT_READ) {
+        parserHelper.setFormat(formatHolder.format);
+      } else if (result == SampleSource.SAMPLE_READ) {
         parserHelper.startParseOperation();
       } else if (result == SampleSource.END_OF_STREAM) {
         inputStreamEnded = true;
@@ -251,33 +252,14 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
   }
 
   @Override
-  protected void onDisabled() {
+  protected void onDisabled() throws ExoPlaybackException {
     subtitle = null;
     nextSubtitle = null;
     parserThread.quit();
     parserThread = null;
     parserHelper = null;
     clearTextRenderer();
-    source.disable(trackIndex);
-  }
-
-  @Override
-  protected void onReleased() {
-    source.release();
-  }
-
-  @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
-    try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
-    }
-  }
-
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
+    super.onDisabled();
   }
 
   @Override
@@ -331,4 +313,13 @@ private void invokeRendererInternalCues(List<Cue> cues) {
     textRenderer.onCues(cues);
   }
 
+  private int getParserIndex(MediaFormat mediaFormat) {
+    for (int i = 0; i < subtitleParsers.length; i++) {
+      if (subtitleParsers[i].canParse(mediaFormat.mimeType)) {
+        return i;
+      }
+    }
+    return -1;
+  }
+
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/eia608/Eia608TrackRenderer.java b/library/src/main/java/com/google/android/exoplayer/text/eia608/Eia608TrackRenderer.java
index ffb9faddbb..316b660cd4 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/eia608/Eia608TrackRenderer.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/eia608/Eia608TrackRenderer.java
@@ -17,10 +17,11 @@
 
 import com.google.android.exoplayer.C;
 import com.google.android.exoplayer.ExoPlaybackException;
+import com.google.android.exoplayer.MediaFormat;
 import com.google.android.exoplayer.MediaFormatHolder;
 import com.google.android.exoplayer.SampleHolder;
 import com.google.android.exoplayer.SampleSource;
-import com.google.android.exoplayer.SampleSource.SampleSourceReader;
+import com.google.android.exoplayer.SampleSourceTrackRenderer;
 import com.google.android.exoplayer.TrackRenderer;
 import com.google.android.exoplayer.text.Cue;
 import com.google.android.exoplayer.text.TextRenderer;
@@ -32,14 +33,13 @@
 import android.os.Looper;
 import android.os.Message;
 
-import java.io.IOException;
 import java.util.Collections;
 import java.util.TreeSet;
 
 /**
  * A {@link TrackRenderer} for EIA-608 closed captions in a media stream.
  */
-public final class Eia608TrackRenderer extends TrackRenderer implements Callback {
+public final class Eia608TrackRenderer extends SampleSourceTrackRenderer implements Callback {
 
   private static final int MSG_INVOKE_RENDERER = 0;
 
@@ -53,7 +53,6 @@
   // The maximum duration that captions are parsed ahead of the current position.
   private static final int MAX_SAMPLE_READAHEAD_US = 5000000;
 
-  private final SampleSourceReader source;
   private final Eia608Parser eia608Parser;
   private final TextRenderer textRenderer;
   private final Handler textRendererHandler;
@@ -62,9 +61,7 @@
   private final StringBuilder captionStringBuilder;
   private final TreeSet<ClosedCaptionList> pendingCaptionLists;
 
-  private int trackIndex;
   private boolean inputStreamEnded;
-
   private int captionMode;
   private int captionRowCount;
   private String caption;
@@ -81,7 +78,7 @@
    */
   public Eia608TrackRenderer(SampleSource source, TextRenderer textRenderer,
       Looper textRendererLooper) {
-    this.source = source.register();
+    super(source);
     this.textRenderer = Assertions.checkNotNull(textRenderer);
     textRendererHandler = textRendererLooper == null ? null : new Handler(textRendererLooper, this);
     eia608Parser = new Eia608Parser();
@@ -92,30 +89,20 @@ public Eia608TrackRenderer(SampleSource source, TextRenderer textRenderer,
   }
 
   @Override
-  protected int doPrepare(long positionUs) {
-    boolean sourcePrepared = source.prepare(positionUs);
-    if (!sourcePrepared) {
-      return TrackRenderer.STATE_UNPREPARED;
-    }
-    int trackCount = source.getTrackCount();
-    for (int i = 0; i < trackCount; i++) {
-      if (eia608Parser.canParse(source.getTrackInfo(i).mimeType)) {
-        trackIndex = i;
-        return TrackRenderer.STATE_PREPARED;
-      }
-    }
-    return TrackRenderer.STATE_IGNORE;
+  protected boolean handlesTrack(MediaFormat mediaFormat) {
+    return eia608Parser.canParse(mediaFormat.mimeType);
   }
 
   @Override
-  protected void onEnabled(long positionUs, boolean joining) {
-    source.enable(trackIndex, positionUs);
+  protected void onEnabled(int track, long positionUs, boolean joining)
+      throws ExoPlaybackException {
+    super.onEnabled(track, positionUs, joining);
     seekToInternal();
   }
 
   @Override
   protected void seekTo(long positionUs) throws ExoPlaybackException {
-    source.seekToUs(positionUs);
+    super.seekTo(positionUs);
     seekToInternal();
   }
 
@@ -130,15 +117,14 @@ private void seekToInternal() {
 
   @Override
   protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPlaybackException {
-    source.continueBuffering(trackIndex, positionUs);
-
+    continueBufferingSource(positionUs);
     if (isSamplePending()) {
       maybeParsePendingSample(positionUs);
     }
 
     int result = inputStreamEnded ? SampleSource.END_OF_STREAM : SampleSource.SAMPLE_READ;
     while (!isSamplePending() && result == SampleSource.SAMPLE_READ) {
-      result = source.readData(trackIndex, positionUs, formatHolder, sampleHolder, false);
+      result = readSource(positionUs, formatHolder, sampleHolder, false);
       if (result == SampleSource.SAMPLE_READ) {
         maybeParsePendingSample(positionUs);
       } else if (result == SampleSource.END_OF_STREAM) {
@@ -161,25 +147,6 @@ protected void doSomeWork(long positionUs, long elapsedRealtimeUs) throws ExoPla
     }
   }
 
-  @Override
-  protected void onDisabled() {
-    source.disable(trackIndex);
-  }
-
-  @Override
-  protected void maybeThrowError() throws ExoPlaybackException {
-    try {
-      source.maybeThrowError();
-    } catch (IOException e) {
-      throw new ExoPlaybackException(e);
-    }
-  }
-
-  @Override
-  protected long getDurationUs() {
-    return source.getTrackInfo(trackIndex).durationUs;
-  }
-
   @Override
   protected long getBufferedPositionUs() {
     return TrackRenderer.END_OF_TRACK_US;
diff --git a/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripParser.java b/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripParser.java
index bfd04df251..7c7c3f3ae1 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripParser.java
@@ -25,6 +25,7 @@
 import android.text.Html;
 import android.text.Spanned;
 import android.text.TextUtils;
+import android.util.Log;
 
 import java.io.BufferedReader;
 import java.io.IOException;
@@ -39,38 +40,73 @@
  */
 public final class SubripParser implements SubtitleParser {
 
-  private static final Pattern SUBRIP_TIMING_LINE = Pattern.compile("(.*)\\s+-->\\s+(.*)");
+  private static final String TAG = "SubripParser";
+
+  private static final Pattern SUBRIP_TIMING_LINE = Pattern.compile("(\\S*)\\s*-->\\s*(\\S*)");
   private static final Pattern SUBRIP_TIMESTAMP =
       Pattern.compile("(?:(\\d+):)?(\\d+):(\\d+),(\\d+)");
 
   private final StringBuilder textBuilder;
+  private final boolean strictParsing;
 
+  /**
+   * Equivalent to {@code SubripParser(false)}.
+   */
   public SubripParser() {
+    this(false);
+  }
+
+  /**
+   * @param strictParsing If true, {@link #parse(InputStream)} will throw a {@link ParserException}
+   *     if the stream contains invalid data. If false, the parser will make a best effort to ignore
+   *     minor errors in the stream. Note however that a {@link ParserException} will still be
+   *     thrown when this is not possible.
+   */
+  public SubripParser(boolean strictParsing) {
+    this.strictParsing = strictParsing;
     textBuilder = new StringBuilder();
   }
 
   @Override
-  public SubripSubtitle parse(InputStream inputStream, String inputEncoding, long startTimeUs)
-      throws IOException {
+  public SubripSubtitle parse(InputStream inputStream) throws IOException {
     ArrayList<Cue> cues = new ArrayList<>();
     LongArray cueTimesUs = new LongArray();
     BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream, C.UTF8_NAME));
+    boolean haveEndTimecode;
     String currentLine;
 
     while ((currentLine = reader.readLine()) != null) {
-      // Parse the numeric counter as a sanity check.
+      if (currentLine.length() == 0) {
+        // Skip blank lines.
+        continue;
+      }
+
+      // Parse the index line as a sanity check.
       try {
         Integer.parseInt(currentLine);
       } catch (NumberFormatException e) {
-        throw new ParserException("Expected numeric counter: " + currentLine);
+        if (!strictParsing) {
+          Log.w(TAG, "Skipping invalid index: " + currentLine);
+          continue;
+        } else {
+          throw new ParserException("Expected numeric counter: " + currentLine);
+        }
       }
 
       // Read and parse the timing line.
+      haveEndTimecode = false;
       currentLine = reader.readLine();
       Matcher matcher = SUBRIP_TIMING_LINE.matcher(currentLine);
       if (matcher.find()) {
-        cueTimesUs.add(startTimeUs + parseTimestampUs(matcher.group(1)));
-        cueTimesUs.add(startTimeUs + parseTimestampUs(matcher.group(2)));
+        cueTimesUs.add(parseTimecode(matcher.group(1)));
+        String endTimecode = matcher.group(2);
+        if (!TextUtils.isEmpty(endTimecode)) {
+          haveEndTimecode = true;
+          cueTimesUs.add(parseTimecode(matcher.group(2)));
+        }
+      } else if (!strictParsing) {
+        Log.w(TAG, "Skipping invalid timing: " + currentLine);
+        continue;
       } else {
         throw new ParserException("Expected timing line: " + currentLine);
       }
@@ -86,12 +122,15 @@ public SubripSubtitle parse(InputStream inputStream, String inputEncoding, long
 
       Spanned text = Html.fromHtml(textBuilder.toString());
       cues.add(new Cue(text));
+      if (haveEndTimecode) {
+        cues.add(null);
+      }
     }
 
     Cue[] cuesArray = new Cue[cues.size()];
     cues.toArray(cuesArray);
     long[] cueTimesUsArray = cueTimesUs.toArray();
-    return new SubripSubtitle(startTimeUs, cuesArray, cueTimesUsArray);
+    return new SubripSubtitle(cuesArray, cueTimesUsArray);
   }
 
   @Override
@@ -99,7 +138,7 @@ public boolean canParse(String mimeType) {
     return MimeTypes.APPLICATION_SUBRIP.equals(mimeType);
   }
 
-  private static long parseTimestampUs(String s) throws NumberFormatException {
+  private static long parseTimecode(String s) throws NumberFormatException {
     Matcher matcher = SUBRIP_TIMESTAMP.matcher(s);
     if (!matcher.matches()) {
       throw new NumberFormatException("has invalid format");
diff --git a/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripSubtitle.java b/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripSubtitle.java
index 9931a1490f..b10804311b 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripSubtitle.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/subrip/SubripSubtitle.java
@@ -28,27 +28,18 @@
  */
 /* package */ final class SubripSubtitle implements Subtitle {
 
-  private final long startTimeUs;
-
   private final Cue[] cues;
   private final long[] cueTimesUs;
 
   /**
-   * @param startTimeUs The start time of the subtitle, in microseconds.
-   * @param cues The cues in the subtitle.
-   * @param cueTimesUs Interleaved cue start and end times, in microseconds.
+   * @param cues The cues in the subtitle. Null entries may be used to represent empty cues.
+   * @param cueTimesUs The cue times, in microseconds.
    */
-  public SubripSubtitle(long startTimeUs, Cue[] cues, long[] cueTimesUs) {
-    this.startTimeUs = startTimeUs;
+  public SubripSubtitle(Cue[] cues, long[] cueTimesUs) {
     this.cues = cues;
     this.cueTimesUs = cueTimesUs;
   }
 
-  @Override
-  public long getStartTime() {
-    return startTimeUs;
-  }
-
   @Override
   public int getNextEventTimeIndex(long timeUs) {
     int index = Util.binarySearchCeil(cueTimesUs, timeUs, false, false);
@@ -78,11 +69,11 @@ public long getLastEventTime() {
   @Override
   public List<Cue> getCues(long timeUs) {
     int index = Util.binarySearchFloor(cueTimesUs, timeUs, true, false);
-    if (index == -1 || index % 2 == 1) {
-      // timeUs is earlier than the start of the first cue, or corresponds to a gap between cues.
+    if (index == -1 || cues[index] == null) {
+      // timeUs is earlier than the start of the first cue, or we have an empty cue.
       return Collections.<Cue>emptyList();
     } else {
-      return Collections.singletonList(cues[index / 2]);
+      return Collections.singletonList(cues[index]);
     }
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlNode.java b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlNode.java
index f476dde013..d393875c57 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlNode.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlNode.java
@@ -20,6 +20,7 @@
 import java.util.ArrayList;
 import java.util.Iterator;
 import java.util.List;
+import java.util.Map;
 import java.util.TreeSet;
 
 /**
@@ -28,7 +29,6 @@
 /* package */ final class TtmlNode {
 
   public static final long UNDEFINED_TIME = -1;
-
   public static final String TAG_TT = "tt";
   public static final String TAG_HEAD = "head";
   public static final String TAG_BODY = "body";
@@ -45,25 +45,57 @@
   public static final String TAG_SMPTE_DATA = "smpte:data";
   public static final String TAG_SMPTE_INFORMATION = "smpte:information";
 
+  public static final String ATTR_ID = "id";
+  public static final String ATTR_TTS_BACKGROUND_COLOR = "backgroundColor";
+  public static final String ATTR_TTS_FONT_STYLE = "fontStyle";
+  public static final String ATTR_TTS_FONT_SIZE = "fontSize";
+  public static final String ATTR_TTS_FONT_FAMILY = "fontFamily";
+  public static final String ATTR_TTS_FONT_WEIGHT = "fontWeight";
+  public static final String ATTR_TTS_COLOR = "color";
+  public static final String ATTR_TTS_TEXT_DECORATION = "textDecoration";
+  public static final String ATTR_TTS_TEXT_ALIGN = "textAlign";
+
+  public static final String LINETHROUGH = "linethrough";
+  public static final String NO_LINETHROUGH = "nolinethrough";
+  public static final String UNDERLINE = "underline";
+  public static final String NO_UNDERLINE = "nounderline";
+  public static final String ITALIC = "italic";
+  public static final String BOLD = "bold";
+
+  public static final String LEFT = "left";
+  public static final String CENTER = "center";
+  public static final String RIGHT = "right";
+  public static final String START = "start";
+  public static final String END = "end";
+
   public final String tag;
   public final String text;
   public final boolean isTextNode;
   public final long startTimeUs;
   public final long endTimeUs;
+  public final TtmlStyle style;
+  private String[] styleIds;
 
   private List<TtmlNode> children;
+  private int start;
+  private int end;
 
   public static TtmlNode buildTextNode(String text) {
-    return new TtmlNode(null, applyTextElementSpacePolicy(text), UNDEFINED_TIME, UNDEFINED_TIME);
+    return new TtmlNode(null, TtmlRenderUtil.applyTextElementSpacePolicy(text), UNDEFINED_TIME,
+        UNDEFINED_TIME, null, null);
   }
 
-  public static TtmlNode buildNode(String tag, long startTimeUs, long endTimeUs) {
-    return new TtmlNode(tag, null, startTimeUs, endTimeUs);
+  public static TtmlNode buildNode(String tag, long startTimeUs, long endTimeUs,
+      TtmlStyle style, String[] styleIds) {
+    return new TtmlNode(tag, null, startTimeUs, endTimeUs, style, styleIds);
   }
 
-  private TtmlNode(String tag, String text, long startTimeUs, long endTimeUs) {
+  private TtmlNode(String tag, String text, long startTimeUs, long endTimeUs,
+      TtmlStyle style, String[] styleIds) {
     this.tag = tag;
     this.text = text;
+    this.style = style;
+    this.styleIds = styleIds;
     this.isTextNode = text != null;
     this.startTimeUs = startTimeUs;
     this.endTimeUs = endTimeUs;
@@ -125,8 +157,14 @@ private void getEventTimes(TreeSet<Long> out, boolean descendsPNode) {
     }
   }
 
-  public CharSequence getText(long timeUs) {
-    SpannableStringBuilder builder = getText(timeUs, new SpannableStringBuilder(), false);
+  public String[] getStyleIds() {
+    return styleIds;
+  }
+
+  public CharSequence getText(long timeUs, Map<String, TtmlStyle> globalStyles) {
+    SpannableStringBuilder builder = new SpannableStringBuilder();
+    traverseForText(timeUs, builder, false);
+    traverseForStyle(builder, globalStyles);
     // Having joined the text elements, we need to do some final cleanup on the result.
     // 1. Collapse multiple consecutive spaces into a single space.
     int builderLength = builder.length();
@@ -168,13 +206,16 @@ public CharSequence getText(long timeUs) {
     // 4. Trim a trailing newline, if there is one.
     if (builderLength > 0 && builder.charAt(builderLength - 1) == '\n') {
       builder.delete(builderLength - 1, builderLength);
-      builderLength--;
+      /*builderLength--;*/
     }
-    return builder.subSequence(0, builderLength);
+
+    return builder;
   }
 
-  private SpannableStringBuilder getText(long timeUs, SpannableStringBuilder builder,
+  private SpannableStringBuilder traverseForText(long timeUs, SpannableStringBuilder builder,
       boolean descendsPNode) {
+    start = builder.length();
+    end = start;
     if (isTextNode && descendsPNode) {
       builder.append(text);
     } else if (TAG_BR.equals(tag) && descendsPNode) {
@@ -184,48 +225,27 @@ private SpannableStringBuilder getText(long timeUs, SpannableStringBuilder build
     } else if (isActive(timeUs)) {
       boolean isPNode = TAG_P.equals(tag);
       for (int i = 0; i < getChildCount(); ++i) {
-        getChild(i).getText(timeUs, builder, descendsPNode || isPNode);
+        getChild(i).traverseForText(timeUs, builder, descendsPNode || isPNode);
       }
       if (isPNode) {
-        endParagraph(builder);
+        TtmlRenderUtil.endParagraph(builder);
       }
+      end = builder.length();
     }
     return builder;
   }
 
-  /**
-   * Invoked when the end of a paragraph is encountered. Adds a newline if there are one or more
-   * non-space characters since the previous newline.
-   *
-   * @param builder The builder.
-   */
-  private static void endParagraph(SpannableStringBuilder builder) {
-    int position = builder.length() - 1;
-    while (position >= 0 && builder.charAt(position) == ' ') {
-      position--;
-    }
-    if (position >= 0 && builder.charAt(position) != '\n') {
-      builder.append('\n');
+  private void traverseForStyle(SpannableStringBuilder builder,
+      Map<String, TtmlStyle> globalStyles) {
+    if (start != end) {
+      TtmlStyle resolvedStyle = TtmlRenderUtil.resolveStyle(style, styleIds, globalStyles);
+      if (resolvedStyle != null) {
+        TtmlRenderUtil.applyStylesToSpan(builder, start, end, resolvedStyle);
+      }
+      for (int i = 0; i < getChildCount(); ++i) {
+        getChild(i).traverseForStyle(builder, globalStyles);
+      }
     }
   }
 
-  /**
-   * Applies the appropriate space policy to the given text element.
-   *
-   * @param in The text element to which the policy should be applied.
-   * @return The result of applying the policy to the text element.
-   */
-  private static String applyTextElementSpacePolicy(String in) {
-    // Removes carriage return followed by line feed. See: http://www.w3.org/TR/xml/#sec-line-ends
-    String out = in.replaceAll("\r\n", "\n");
-    // Apply suppress-at-line-break="auto" and
-    // white-space-treatment="ignore-if-surrounding-linefeed"
-    out = out.replaceAll(" *\n *", "\n");
-    // Apply linefeed-treatment="treat-as-space"
-    out = out.replaceAll("\n", " ");
-    // Apply white-space-collapse="true"
-    out = out.replaceAll("[ \t\\x0B\f\r]+", " ");
-    return out;
-  }
-
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlParser.java b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlParser.java
index 22bc7e1975..a9e6c1b99a 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlParser.java
@@ -20,7 +20,11 @@
 import com.google.android.exoplayer.text.Subtitle;
 import com.google.android.exoplayer.text.SubtitleParser;
 import com.google.android.exoplayer.util.MimeTypes;
+import com.google.android.exoplayer.util.ParserUtil;
+import com.google.android.exoplayer.util.Util;
 
+import android.graphics.Color;
+import android.text.Layout;
 import android.util.Log;
 
 import org.xmlpull.v1.XmlPullParser;
@@ -29,7 +33,9 @@
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.util.HashMap;
 import java.util.LinkedList;
+import java.util.Map;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -61,6 +67,7 @@
   private static final String ATTR_BEGIN = "begin";
   private static final String ATTR_DURATION = "dur";
   private static final String ATTR_END = "end";
+  private static final String ATTR_STYLE = "style";
 
   private static final Pattern CLOCK_TIME =
       Pattern.compile("^([0-9][0-9]+):([0-9][0-9]):([0-9][0-9])"
@@ -84,10 +91,10 @@ public TtmlParser() {
   }
 
   /**
-   * @param strictParsing If true, {@link #parse(InputStream, String, long)} will throw a
-   *     {@link ParserException} if the stream contains invalid data. If false, the parser will
-   *     make a best effort to ignore minor errors in the stream. Note however that a
-   *     {@link ParserException} will still be thrown when this is not possible.
+   * @param strictParsing If true, {@link #parse(InputStream)} will throw a {@link ParserException}
+   *     if the stream contains invalid data. If false, the parser will make a best effort to ignore
+   *     minor errors in the stream. Note however that a {@link ParserException} will still be
+   *     thrown when this is not possible.
    */
   public TtmlParser(boolean strictParsing) {
     this.strictParsing = strictParsing;
@@ -99,11 +106,11 @@ public TtmlParser(boolean strictParsing) {
   }
 
   @Override
-  public Subtitle parse(InputStream inputStream, String inputEncoding, long startTimeUs)
-      throws IOException {
+  public Subtitle parse(InputStream inputStream) throws IOException {
     try {
       XmlPullParser xmlParser = xmlParserFactory.newPullParser();
-      xmlParser.setInput(inputStream, inputEncoding);
+      Map<String, TtmlStyle> globalStyles = new HashMap<>();
+      xmlParser.setInput(inputStream, null);
       TtmlSubtitle ttmlSubtitle = null;
       LinkedList<TtmlNode> nodeStack = new LinkedList<>();
       int unsupportedNodeDepth = 0;
@@ -116,6 +123,8 @@ public Subtitle parse(InputStream inputStream, String inputEncoding, long startT
             if (!isSupportedTag(name)) {
               Log.i(TAG, "Ignoring unsupported tag: " + xmlParser.getName());
               unsupportedNodeDepth++;
+            } else if (TtmlNode.TAG_HEAD.equals(name)) {
+              parseHeader(xmlParser, globalStyles);
             } else {
               try {
                 TtmlNode node = parseNode(xmlParser, parent);
@@ -127,7 +136,7 @@ public Subtitle parse(InputStream inputStream, String inputEncoding, long startT
                 if (strictParsing) {
                   throw e;
                 } else {
-                  Log.e(TAG, "Suppressing parser error", e);
+                  Log.w(TAG, "Suppressing parser error", e);
                   // Treat the node (and by extension, all of its children) as unsupported.
                   unsupportedNodeDepth++;
                 }
@@ -137,7 +146,7 @@ public Subtitle parse(InputStream inputStream, String inputEncoding, long startT
             parent.addChild(TtmlNode.buildTextNode(xmlParser.getText()));
           } else if (eventType == XmlPullParser.END_TAG) {
             if (xmlParser.getName().equals(TtmlNode.TAG_TT)) {
-              ttmlSubtitle = new TtmlSubtitle(nodeStack.getLast(), startTimeUs);
+              ttmlSubtitle = new TtmlSubtitle(nodeStack.getLast(), globalStyles);
             }
             nodeStack.removeLast();
           }
@@ -157,6 +166,121 @@ public Subtitle parse(InputStream inputStream, String inputEncoding, long startT
     }
   }
 
+  private Map<String, TtmlStyle> parseHeader(XmlPullParser xmlParser,
+      Map<String, TtmlStyle> globalStyles)
+      throws IOException, XmlPullParserException {
+
+    do {
+      xmlParser.next();
+      if (ParserUtil.isStartTag(xmlParser, TtmlNode.TAG_STYLE)) {
+        String parentStyleId = xmlParser.getAttributeValue(null, ATTR_STYLE);
+        TtmlStyle style = parseStyleAttributes(xmlParser, new TtmlStyle());
+        if (parentStyleId != null) {
+          String[] ids = parseStyleIds(parentStyleId);
+          for (int i = 0; i < ids.length; i++) {
+            style.chain(globalStyles.get(ids[i]));
+          }
+        }
+        if (style.getId() != null) {
+          globalStyles.put(style.getId(), style);
+        }
+      }
+    } while (!ParserUtil.isEndTag(xmlParser, TtmlNode.TAG_HEAD));
+    return globalStyles;
+  }
+
+  private String[] parseStyleIds(String parentStyleIds) {
+    return parentStyleIds.split("\\s+");
+  }
+
+  private TtmlStyle parseStyleAttributes(XmlPullParser parser, TtmlStyle style) {
+    int attributeCount = parser.getAttributeCount();
+    for (int i = 0; i < attributeCount; i++) {
+      String attributeName = parser.getAttributeName(i);
+      String attributeValue = parser.getAttributeValue(i);
+      switch (ParserUtil.removeNamespacePrefix(attributeName)) {
+        case TtmlNode.ATTR_ID:
+          if (TtmlNode.TAG_STYLE.equals(parser.getName())) {
+            style = createIfNull(style).setId(attributeValue);
+          }
+          break;
+        case TtmlNode.ATTR_TTS_BACKGROUND_COLOR:
+          style = createIfNull(style);
+          try {
+            style.setBackgroundColor(Color.parseColor(attributeValue));
+          } catch (IllegalArgumentException e) {
+            Log.w(TAG, "failed parsing background value: '" + attributeValue + "'");
+          }
+          break;
+        case TtmlNode.ATTR_TTS_COLOR:
+          style = createIfNull(style);
+          try {
+            style.setColor(Color.parseColor(attributeValue));
+          } catch (IllegalArgumentException e) {
+            Log.w(TAG, "failed parsing color value: '" + attributeValue + "'");
+          }
+          break;
+        case TtmlNode.ATTR_TTS_FONT_FAMILY:
+          style = createIfNull(style).setFontFamily(attributeValue);
+          break;
+        case TtmlNode.ATTR_TTS_FONT_SIZE:
+          // TODO: handle size
+          break;
+        case TtmlNode.ATTR_TTS_FONT_WEIGHT:
+          style = createIfNull(style).setBold(
+              TtmlNode.BOLD.equalsIgnoreCase(attributeValue));
+          break;
+        case TtmlNode.ATTR_TTS_FONT_STYLE:
+          style = createIfNull(style).setItalic(
+              TtmlNode.ITALIC.equalsIgnoreCase(attributeValue));
+          break;
+        case TtmlNode.ATTR_TTS_TEXT_ALIGN:
+          switch (Util.toLowerInvariant(attributeValue)) {
+            case TtmlNode.LEFT:
+              style = createIfNull(style).setTextAlign(Layout.Alignment.ALIGN_NORMAL);
+              break;
+            case TtmlNode.START:
+              style = createIfNull(style).setTextAlign(Layout.Alignment.ALIGN_NORMAL);
+              break;
+            case TtmlNode.RIGHT:
+              style = createIfNull(style).setTextAlign(Layout.Alignment.ALIGN_OPPOSITE);
+              break;
+            case TtmlNode.END:
+              style = createIfNull(style).setTextAlign(Layout.Alignment.ALIGN_OPPOSITE);
+              break;
+            case TtmlNode.CENTER:
+              style = createIfNull(style).setTextAlign(Layout.Alignment.ALIGN_CENTER);
+              break;
+          }
+          break;
+        case TtmlNode.ATTR_TTS_TEXT_DECORATION:
+          switch (Util.toLowerInvariant(attributeValue)) {
+            case TtmlNode.LINETHROUGH:
+              style = createIfNull(style).setLinethrough(true);
+              break;
+            case TtmlNode.NO_LINETHROUGH:
+              style = createIfNull(style).setLinethrough(false);
+              break;
+            case TtmlNode.UNDERLINE:
+              style = createIfNull(style).setUnderline(true);
+              break;
+            case TtmlNode.NO_UNDERLINE:
+              style = createIfNull(style).setUnderline(false);
+              break;
+          }
+          break;
+        default:
+          // ignore
+          break;
+      }
+    }
+    return style;
+  }
+
+  private TtmlStyle createIfNull(TtmlStyle style) {
+    return style == null ? new TtmlStyle() : style;
+  }
+
   @Override
   public boolean canParse(String mimeType) {
     return MimeTypes.APPLICATION_TTML.equals(mimeType);
@@ -166,10 +290,11 @@ private TtmlNode parseNode(XmlPullParser parser, TtmlNode parent) throws ParserE
     long duration = 0;
     long startTime = TtmlNode.UNDEFINED_TIME;
     long endTime = TtmlNode.UNDEFINED_TIME;
+    String[] styleIds = null;
     int attributeCount = parser.getAttributeCount();
+    TtmlStyle style = parseStyleAttributes(parser, null);
     for (int i = 0; i < attributeCount; i++) {
-      // TODO: check if it's safe to ignore the namespace of attributes as follows.
-      String attr = parser.getAttributeName(i).replaceFirst("^.*:", "");
+      String attr = ParserUtil.removeNamespacePrefix(parser.getAttributeName(i));
       String value = parser.getAttributeValue(i);
       if (attr.equals(ATTR_BEGIN)) {
         startTime = parseTimeExpression(value,
@@ -180,6 +305,12 @@ private TtmlNode parseNode(XmlPullParser parser, TtmlNode parent) throws ParserE
       } else if (attr.equals(ATTR_DURATION)) {
         duration = parseTimeExpression(value,
             DEFAULT_FRAMERATE, DEFAULT_SUBFRAMERATE, DEFAULT_TICKRATE);
+      } else if (attr.equals(ATTR_STYLE)) {
+        // IDREFS: potentially multiple space delimited ids
+        String[] ids = parseStyleIds(value);
+        if (ids.length > 0) {
+          styleIds = ids;
+        }
       } else {
         // Do nothing.
       }
@@ -201,7 +332,7 @@ private TtmlNode parseNode(XmlPullParser parser, TtmlNode parent) throws ParserE
         endTime = parent.endTimeUs;
       }
     }
-    return TtmlNode.buildNode(parser.getName(), startTime, endTime);
+    return TtmlNode.buildNode(parser.getName(), startTime, endTime, style, styleIds);
   }
 
   private static boolean isSupportedTag(String tag) {
diff --git a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtil.java b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtil.java
new file mode 100644
index 0000000000..638e47d276
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlRenderUtil.java
@@ -0,0 +1,143 @@
+/*
+ * Copyright (C) 2015 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.text.ttml;
+
+import android.text.Spannable;
+import android.text.SpannableStringBuilder;
+import android.text.Spanned;
+import android.text.style.AlignmentSpan;
+import android.text.style.BackgroundColorSpan;
+import android.text.style.ForegroundColorSpan;
+import android.text.style.StrikethroughSpan;
+import android.text.style.StyleSpan;
+import android.text.style.TypefaceSpan;
+import android.text.style.UnderlineSpan;
+
+import java.util.Map;
+
+/**
+ * Package internal utility class to render styled <code>TtmlNode</code>s.
+ */
+/* package */ final class TtmlRenderUtil {
+
+  /* spans which are always the same can be reused to avoid object creation */
+  private static final StrikethroughSpan STRIKETHROUGH_SPAN = new StrikethroughSpan();
+  private static final UnderlineSpan UNDERLINE_SPAN = new UnderlineSpan();
+  private static final StyleSpan[] STYLE_SPANS = new StyleSpan[] {
+    new StyleSpan(TtmlStyle.STYLE_NORMAL),
+    new StyleSpan(TtmlStyle.STYLE_BOLD),
+    new StyleSpan(TtmlStyle.STYLE_ITALIC),
+    new StyleSpan(TtmlStyle.STYLE_BOLD_ITALIC),
+  };
+
+  public static TtmlStyle resolveStyle(TtmlStyle style, String[] styleIds,
+      Map<String, TtmlStyle> globalStyles) {
+    if (style == null && styleIds == null) {
+      // no styles at all
+      return null;
+    } else if (style == null && styleIds.length == 1) {
+      // only one single referential style present
+      return globalStyles.get(styleIds[0]);
+    } else if (style == null && styleIds.length > 1) {
+      // only multiple referential styles present
+      TtmlStyle chainedStyle = new TtmlStyle();
+      for (int i = 0; i < styleIds.length; i++) {
+        chainedStyle.chain(globalStyles.get(styleIds[i]));
+      }
+      return chainedStyle;
+    } else if (style != null && styleIds != null && styleIds.length == 1) {
+      // merge a single referential style into inline style
+      return style.chain(globalStyles.get(styleIds[0]));
+    } else if (style != null && styleIds != null && styleIds.length > 1) {
+      // merge multiple referential styles into inline style
+      for (int i = 0; i < styleIds.length; i++) {
+        style.chain(globalStyles.get(styleIds[i]));
+      }
+      return style;
+    }
+    // only inline styles available
+    return style;
+  }
+
+  public static void applyStylesToSpan(SpannableStringBuilder builder,
+      int start, int end, TtmlStyle style) {
+
+    if (style.getStyle() != TtmlStyle.UNSPECIFIED) {
+      builder.setSpan(STYLE_SPANS[style.getStyle()], start, end,
+          Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.isLinethrough()) {
+      builder.setSpan(STRIKETHROUGH_SPAN, start, end, Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.isUnderline()) {
+      builder.setSpan(UNDERLINE_SPAN, start, end, Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.hasColorSpecified()) {
+      builder.setSpan(new ForegroundColorSpan(style.getColor()), start, end,
+          Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.hasBackgroundColorSpecified()) {
+      builder.setSpan(new BackgroundColorSpan(style.getBackgroundColor()), start, end,
+          Spannable.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.getFontFamily() != null) {
+      builder.setSpan(new TypefaceSpan(style.getFontFamily()), start, end,
+          Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+    if (style.getTextAlign() != null) {
+      builder.setSpan(new AlignmentSpan.Standard(style.getTextAlign()), start, end,
+          Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);
+    }
+  }
+
+  /**
+   * Invoked when the end of a paragraph is encountered. Adds a newline if there are one or more
+   * non-space characters since the previous newline.
+   *
+   * @param builder The builder.
+   */
+  /* package */ static void endParagraph(SpannableStringBuilder builder) {
+    int position = builder.length() - 1;
+    while (position >= 0 && builder.charAt(position) == ' ') {
+      position--;
+    }
+    if (position >= 0 && builder.charAt(position) != '\n') {
+      builder.append('\n');
+    }
+  }
+
+  /**
+   * Applies the appropriate space policy to the given text element.
+   *
+   * @param in The text element to which the policy should be applied.
+   * @return The result of applying the policy to the text element.
+   */
+  /* package */ static String applyTextElementSpacePolicy(String in) {
+    // Removes carriage return followed by line feed. See: http://www.w3.org/TR/xml/#sec-line-ends
+    String out = in.replaceAll("\r\n", "\n");
+    // Apply suppress-at-line-break="auto" and
+    // white-space-treatment="ignore-if-surrounding-linefeed"
+    out = out.replaceAll(" *\n *", "\n");
+    // Apply linefeed-treatment="treat-as-space"
+    out = out.replaceAll("\n", " ");
+    // Apply white-space-collapse="true"
+    out = out.replaceAll("[ \t\\x0B\f\r]+", " ");
+    return out;
+  }
+
+  private TtmlRenderUtil() {}
+
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlStyle.java b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlStyle.java
new file mode 100644
index 0000000000..7bb2891d0e
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlStyle.java
@@ -0,0 +1,224 @@
+/*
+ * Copyright (C) 2015 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.text.ttml;
+
+import com.google.android.exoplayer.util.Assertions;
+
+import android.graphics.Typeface;
+import android.text.Layout;
+
+/**
+ * Style object of a <code>TtmlNode</code>
+ */
+public final class TtmlStyle {
+
+  public static final short UNSPECIFIED = -1;
+
+  public static final short STYLE_NORMAL = Typeface.NORMAL;
+  public static final short STYLE_BOLD = Typeface.BOLD;
+  public static final short STYLE_ITALIC = Typeface.ITALIC;
+  public static final short STYLE_BOLD_ITALIC = Typeface.BOLD_ITALIC;
+
+  private static final short OFF = 0;
+  private static final short ON = 1;
+
+  private String fontFamily;
+  private int color;
+  private boolean colorSpecified;
+  private int backgroundColor;
+  private boolean backgroundColorSpecified;
+  private short linethrough = UNSPECIFIED;
+  private short underline = UNSPECIFIED;
+  private short bold = UNSPECIFIED;
+  private short italic = UNSPECIFIED;
+  private String id;
+  private TtmlStyle inheritableStyle;
+  private Layout.Alignment textAlign;
+
+  /**
+   * Returns the style or <code>UNSPECIFIED</code> when no style information is given.
+   *
+   * @return UNSPECIFIED, STYLE_NORMAL, STYLE_BOLD, STYLE_BOLD or STYLE_BOLD_ITALIC
+   */
+  public short getStyle() {
+    if (bold == UNSPECIFIED && italic == UNSPECIFIED) {
+      return UNSPECIFIED;
+    }
+
+    short style = STYLE_NORMAL;
+    if (bold != UNSPECIFIED) {
+      style += bold;
+    }
+    if (italic != UNSPECIFIED){
+      style += italic;
+    }
+    return style;
+  }
+
+  public boolean isLinethrough() {
+    return linethrough == ON;
+  }
+
+  public TtmlStyle setLinethrough(boolean linethrough) {
+    Assertions.checkState(inheritableStyle == null);
+    this.linethrough = linethrough ? ON : OFF;
+    return this;
+  }
+
+  public boolean isUnderline() {
+    return underline == ON;
+  }
+
+  public TtmlStyle setUnderline(boolean underline) {
+    Assertions.checkState(inheritableStyle == null);
+    this.underline = underline ? ON : OFF;
+    return this;
+  }
+
+  public String getFontFamily() {
+    return fontFamily;
+  }
+
+  public TtmlStyle setFontFamily(String fontFamily) {
+    Assertions.checkState(inheritableStyle == null);
+    this.fontFamily = fontFamily;
+    return this;
+  }
+
+  public int getColor() {
+    return color;
+  }
+
+  public TtmlStyle setColor(int color) {
+    Assertions.checkState(inheritableStyle == null);
+    this.color = color;
+    colorSpecified = true;
+    return this;
+  }
+
+  public boolean hasColorSpecified() {
+    return colorSpecified;
+  }
+
+  public int getBackgroundColor() {
+    return backgroundColor;
+  }
+
+  public TtmlStyle setBackgroundColor(int backgroundColor) {
+    this.backgroundColor = backgroundColor;
+    backgroundColorSpecified = true;
+    return this;
+  }
+
+  public boolean hasBackgroundColorSpecified() {
+    return backgroundColorSpecified;
+  }
+
+  public TtmlStyle setBold(boolean isBold) {
+    Assertions.checkState(inheritableStyle == null);
+    bold = isBold ? STYLE_BOLD : STYLE_NORMAL;
+    return this;
+  }
+
+  public TtmlStyle setItalic(boolean isItalic) {
+    Assertions.checkState(inheritableStyle == null);
+    italic = isItalic ? STYLE_ITALIC : STYLE_NORMAL;
+    return this;
+  }
+
+  public TtmlStyle getInheritableStyle() {
+    if (isFullyInheritable()) {
+      return this;
+    } else if (inheritableStyle == null) {
+      inheritableStyle = new TtmlStyle().inherit(this);
+    }
+    return inheritableStyle;
+  }
+
+  private boolean isFullyInheritable() {
+    return !backgroundColorSpecified;
+  }
+
+  /**
+   * Inherits from an ancestor style. Properties like <i>tts:backgroundColor</i> which
+   * are not inheritable are not inherited as well as properties which are already set locally
+   * are never overridden.
+   *
+   * @param ancestor the ancestor style to inherit from
+   */
+  public TtmlStyle inherit(TtmlStyle ancestor) {
+    return inherit(ancestor, false);
+  }
+
+  /**
+   * Chains this style to referential style. Local properties which are already set
+   * are never overridden.
+   *
+   * @param ancestor the referential style to inherit from
+   */
+  public TtmlStyle chain(TtmlStyle ancestor) {
+    return inherit(ancestor, true);
+  }
+
+  private TtmlStyle inherit(TtmlStyle ancestor, boolean chaining) {
+    if (ancestor != null) {
+      if (!colorSpecified && ancestor.colorSpecified) {
+        setColor(ancestor.color);
+      }
+      if (bold == UNSPECIFIED) {
+        bold = ancestor.bold;
+      }
+      if (italic == UNSPECIFIED) {
+        italic = ancestor.italic;
+      }
+      if (fontFamily == null) {
+        fontFamily = ancestor.fontFamily;
+      }
+      if (linethrough == UNSPECIFIED) {
+        linethrough = ancestor.linethrough;
+      }
+      if (underline == UNSPECIFIED) {
+        underline = ancestor.underline;
+      }
+      if (textAlign == null) {
+        textAlign = ancestor.textAlign;
+      }
+      // attributes not inherited as of http://www.w3.org/TR/ttml1/
+      if (chaining && !backgroundColorSpecified && ancestor.backgroundColorSpecified) {
+        setBackgroundColor(ancestor.backgroundColor);
+      }
+    }
+    return this;
+  }
+
+  public TtmlStyle setId(String id) {
+    this.id = id;
+    return this;
+  }
+
+  public String getId() {
+    return id;
+  }
+
+  public Layout.Alignment getTextAlign() {
+    return textAlign;
+  }
+
+  public TtmlStyle setTextAlign(Layout.Alignment textAlign) {
+    this.textAlign = textAlign;
+    return this;
+  }
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlSubtitle.java b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlSubtitle.java
index cfcd657082..a989bf86f8 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlSubtitle.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/ttml/TtmlSubtitle.java
@@ -21,6 +21,7 @@
 
 import java.util.Collections;
 import java.util.List;
+import java.util.Map;
 
 /**
  * A representation of a TTML subtitle.
@@ -28,23 +29,19 @@
 public final class TtmlSubtitle implements Subtitle {
 
   private final TtmlNode root;
-  private final long startTimeUs;
   private final long[] eventTimesUs;
+  private final Map<String, TtmlStyle> globalStyles;
 
-  public TtmlSubtitle(TtmlNode root, long startTimeUs) {
+  public TtmlSubtitle(TtmlNode root, Map<String, TtmlStyle> globalStyles) {
     this.root = root;
-    this.startTimeUs = startTimeUs;
+    this.globalStyles = globalStyles != null
+        ? Collections.unmodifiableMap(globalStyles) : Collections.<String, TtmlStyle>emptyMap();
     this.eventTimesUs = root.getEventTimesUs();
   }
 
-  @Override
-  public long getStartTime() {
-    return startTimeUs;
-  }
-
   @Override
   public int getNextEventTimeIndex(long timeUs) {
-    int index = Util.binarySearchCeil(eventTimesUs, timeUs - startTimeUs, false, false);
+    int index = Util.binarySearchCeil(eventTimesUs, timeUs, false, false);
     return index < eventTimesUs.length ? index : -1;
   }
 
@@ -55,17 +52,22 @@ public int getEventTimeCount() {
 
   @Override
   public long getEventTime(int index) {
-    return eventTimesUs[index] + startTimeUs;
+    return eventTimesUs[index];
   }
 
   @Override
   public long getLastEventTime() {
-    return (eventTimesUs.length == 0 ? -1 : eventTimesUs[eventTimesUs.length - 1]) + startTimeUs;
+    return (eventTimesUs.length == 0 ? -1 : eventTimesUs[eventTimesUs.length - 1]);
+  }
+
+  /* @VisibleForTesting */
+  /* package */ TtmlNode getRoot() {
+    return root;
   }
 
   @Override
   public List<Cue> getCues(long timeUs) {
-    CharSequence cueText = root.getText(timeUs - startTimeUs);
+    CharSequence cueText = root.getText(timeUs, globalStyles);
     if (cueText == null) {
       return Collections.<Cue>emptyList();
     } else {
@@ -74,4 +76,8 @@ public long getLastEventTime() {
     }
   }
 
+  /* @VisibleForTesting */
+  /* package */ Map<String, TtmlStyle> getGlobalStyles() {
+    return globalStyles;
+  }
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gParser.java b/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gParser.java
index 2d4d04079b..b6f02ff2f4 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gParser.java
@@ -32,11 +32,10 @@
 public final class Tx3gParser implements SubtitleParser {
 
   @Override
-  public Subtitle parse(InputStream inputStream, String inputEncoding, long startTimeUs)
-      throws IOException {
+  public Subtitle parse(InputStream inputStream) throws IOException {
     DataInputStream dataInputStream  = new DataInputStream(inputStream);
     String cueText = dataInputStream.readUTF();
-    return new Tx3gSubtitle(startTimeUs, new Cue(cueText));
+    return new Tx3gSubtitle(new Cue(cueText));
   }
 
   @Override
diff --git a/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gSubtitle.java b/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gSubtitle.java
index dfcaf98863..d3ff90fcda 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gSubtitle.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/tx3g/Tx3gSubtitle.java
@@ -27,22 +27,15 @@
  */
 /* package */ final class Tx3gSubtitle implements Subtitle {
 
-  private final long startTimeUs;
   private final List<Cue> cues;
 
-  public Tx3gSubtitle(long startTimeUs, Cue cue) {
-    this.startTimeUs = startTimeUs;
+  public Tx3gSubtitle(Cue cue) {
     this.cues = Collections.singletonList(cue);
   }
 
-  @Override
-  public long getStartTime() {
-    return startTimeUs;
-  }
-
   @Override
   public int getNextEventTimeIndex(long timeUs) {
-    return timeUs < startTimeUs ? 0 : -1;
+    return timeUs < 0 ? 0 : -1;
   }
 
   @Override
@@ -53,17 +46,17 @@ public int getEventTimeCount() {
   @Override
   public long getEventTime(int index) {
     Assertions.checkArgument(index == 0);
-    return startTimeUs;
+    return 0;
   }
 
   @Override
   public long getLastEventTime() {
-    return startTimeUs;
+    return 0;
   }
 
   @Override
   public List<Cue> getCues(long timeUs) {
-    return timeUs >= startTimeUs ? cues : Collections.<Cue>emptyList();
+    return timeUs >= 0 ? cues : Collections.<Cue>emptyList();
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttCue.java b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttCue.java
index 1d6d3c554a..3b0d233007 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttCue.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttCue.java
@@ -28,16 +28,17 @@
   public final long endTime;
 
   public WebvttCue(CharSequence text) {
-    this(Cue.UNSET_VALUE, Cue.UNSET_VALUE, text);
+    this(0, 0, text);
   }
 
   public WebvttCue(long startTime, long endTime, CharSequence text) {
-    this(startTime, endTime, text, Cue.UNSET_VALUE, Cue.UNSET_VALUE, null, Cue.UNSET_VALUE);
+    this(startTime, endTime, text, null, Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.TYPE_UNSET,
+        Cue.DIMEN_UNSET, Cue.TYPE_UNSET, Cue.DIMEN_UNSET);
   }
 
-  public WebvttCue(long startTime, long endTime, CharSequence text, int line, int position,
-      Alignment alignment, int size) {
-    super(text, line, position, alignment, size);
+  public WebvttCue(long startTime, long endTime, CharSequence text, Alignment textAlignment,
+      float line, int lineType, int lineAnchor, float position, int positionAnchor, float width) {
+    super(text, textAlignment, line, lineType, lineAnchor, position, positionAnchor, width);
     this.startTime = startTime;
     this.endTime = endTime;
   }
@@ -49,7 +50,7 @@ public WebvttCue(long startTime, long endTime, CharSequence text, int line, int
    * @return True if this cue should be placed in the default position; false otherwise.
    */
   public boolean isNormalCue() {
-    return (line == UNSET_VALUE && position == UNSET_VALUE);
+    return (line == DIMEN_UNSET && position == DIMEN_UNSET);
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttParser.java b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttParser.java
index bebf643e82..53510d257b 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttParser.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttParser.java
@@ -38,38 +38,19 @@
  * <p>
  * @see <a href="http://dev.w3.org/html5/webvtt">WebVTT specification</a>
  */
-public class WebvttParser implements SubtitleParser {
+public final class WebvttParser implements SubtitleParser {
 
   private static final String TAG = "WebvttParser";
 
-  private static final long SAMPLING_RATE = 90;
-
-  private static final String WEBVTT_FILE_HEADER_STRING = "^\uFEFF?WEBVTT((\\u0020|\u0009).*)?$";
-  private static final Pattern WEBVTT_FILE_HEADER =
-      Pattern.compile(WEBVTT_FILE_HEADER_STRING);
-
-  private static final String WEBVTT_METADATA_HEADER_STRING = "\\S*[:=]\\S*";
-  private static final Pattern WEBVTT_METADATA_HEADER =
-      Pattern.compile(WEBVTT_METADATA_HEADER_STRING);
-
-  private static final String WEBVTT_CUE_IDENTIFIER_STRING = "^(?!.*(-->)).*$";
-  private static final Pattern WEBVTT_CUE_IDENTIFIER =
-      Pattern.compile(WEBVTT_CUE_IDENTIFIER_STRING);
-
-  private static final String WEBVTT_TIMESTAMP_STRING = "(\\d+:)?[0-5]\\d:[0-5]\\d\\.\\d{3}";
-  private static final Pattern WEBVTT_TIMESTAMP = Pattern.compile(WEBVTT_TIMESTAMP_STRING);
-
-  private static final String WEBVTT_CUE_SETTING_STRING = "\\S*:\\S*";
-  private static final Pattern WEBVTT_CUE_SETTING = Pattern.compile(WEBVTT_CUE_SETTING_STRING);
-
-  private static final Pattern MEDIA_TIMESTAMP_OFFSET =
-      Pattern.compile(C.WEBVTT_EXO_HEADER_OFFSET + "\\-?\\d+");
-  private static final Pattern MEDIA_TIMESTAMP = Pattern.compile("MPEGTS:\\d+");
-
-  private static final String NON_NUMERIC_STRING = ".*[^0-9].*";
+  private static final Pattern HEADER = Pattern.compile("^\uFEFF?WEBVTT((\u0020|\u0009).*)?$");
+  private static final Pattern COMMENT_BLOCK = Pattern.compile("^NOTE((\u0020|\u0009).*)?$");
+  private static final Pattern METADATA_HEADER = Pattern.compile("\\S*[:=]\\S*");
+  private static final Pattern CUE_IDENTIFIER = Pattern.compile("^(?!.*(-->)).*$");
+  private static final Pattern TIMESTAMP = Pattern.compile("(\\d+:)?[0-5]\\d:[0-5]\\d\\.\\d{3}");
+  private static final Pattern CUE_SETTING = Pattern.compile("\\S*:\\S*");
 
+  private final PositionHolder positionHolder;
   private final StringBuilder textBuilder;
-
   private final boolean strictParsing;
 
   /**
@@ -80,47 +61,27 @@ public WebvttParser() {
   }
 
   /**
-   * @param strictParsing If true, {@link #parse(InputStream, String, long)} will throw a
-   *     {@link ParserException} if the stream contains invalid data. If false, the parser will
-   *     make a best effort to ignore minor errors in the stream. Note however that a
-   *     {@link ParserException} will still be thrown when this is not possible.
+   * @param strictParsing If true, {@link #parse(InputStream)} will throw a {@link ParserException}
+   *     if the stream contains invalid data. If false, the parser will make a best effort to ignore
+   *     minor errors in the stream. Note however that a {@link ParserException} will still be
+   *     thrown when this is not possible.
    */
   public WebvttParser(boolean strictParsing) {
     this.strictParsing = strictParsing;
+    positionHolder = new PositionHolder();
     textBuilder = new StringBuilder();
   }
 
   @Override
-  public final WebvttSubtitle parse(InputStream inputStream, String inputEncoding, long startTimeUs)
-      throws IOException {
+  public final WebvttSubtitle parse(InputStream inputStream) throws IOException {
     ArrayList<WebvttCue> subtitles = new ArrayList<>();
-    long mediaTimestampUs = startTimeUs;
-    long mediaTimestampOffsetUs = 0;
 
     BufferedReader webvttData = new BufferedReader(new InputStreamReader(inputStream, C.UTF8_NAME));
     String line;
 
-    // file should start with "WEBVTT" on the first line or "EXO-HEADER"
+    // file should start with "WEBVTT"
     line = webvttData.readLine();
-    if (line == null) {
-      throw new ParserException("Expected WEBVTT or EXO-HEADER. Got null");
-    }
-
-    if (line.startsWith(C.WEBVTT_EXO_HEADER)) {
-      // parse the timestamp offset, if present
-      Matcher matcher = MEDIA_TIMESTAMP_OFFSET.matcher(line);
-      if (matcher.find()) {
-        mediaTimestampOffsetUs = Long.parseLong(matcher.group().substring(7));
-      }
-
-      // read the next line, which should now be WEBVTT
-      line = webvttData.readLine();
-      if (line == null) {
-        throw new ParserException("Expected WEBVTT. Got null");
-      }
-    }
-
-    if (!WEBVTT_FILE_HEADER.matcher(line).matches()) {
+    if (line == null || !HEADER.matcher(line).matches()) {
       throw new ParserException("Expected WEBVTT. Got " + line);
     }
 
@@ -135,50 +96,56 @@ public final WebvttSubtitle parse(InputStream inputStream, String inputEncoding,
         break;
       }
 
-      Matcher matcher = WEBVTT_METADATA_HEADER.matcher(line);
-      if (!matcher.find()) {
-        handleNoncompliantLine(line);
-      }
-
-      if (line.startsWith("X-TIMESTAMP-MAP")) {
-        // parse the media timestamp
-        Matcher timestampMatcher = MEDIA_TIMESTAMP.matcher(line);
-        if (!timestampMatcher.find()) {
-          throw new ParserException("X-TIMESTAMP-MAP doesn't contain media timestamp: " + line);
-        } else {
-          mediaTimestampUs = (Long.parseLong(timestampMatcher.group().substring(7)) * 1000)
-              / SAMPLING_RATE + mediaTimestampOffsetUs;
+      if (strictParsing) {
+        Matcher matcher = METADATA_HEADER.matcher(line);
+        if (!matcher.find()) {
+          throw new ParserException("Unexpected line: " + line);
         }
-        mediaTimestampUs = getAdjustedStartTime(mediaTimestampUs);
       }
     }
 
     // process the cues and text
     while ((line = webvttData.readLine()) != null) {
+      // parse webvtt comment block in case it is present
+      Matcher matcher = COMMENT_BLOCK.matcher(line);
+      if (matcher.find()) {
+        // read lines until finding an empty one (webvtt line terminator: CRLF, or LF or CR)
+        while ((line = webvttData.readLine()) != null && !line.isEmpty()) {
+          // ignore comment text
+        }
+        continue;
+      }
 
       // parse the cue identifier (if present) {
-      Matcher matcher = WEBVTT_CUE_IDENTIFIER.matcher(line);
+      matcher = CUE_IDENTIFIER.matcher(line);
       if (matcher.find()) {
         // ignore the identifier (we currently don't use it) and read the next line
         line = webvttData.readLine();
+        if (line == null) {
+          // end of file
+          break;
+        }
       }
 
-      long startTime = Cue.UNSET_VALUE;
-      long endTime = Cue.UNSET_VALUE;
-      CharSequence text = null;
-      int lineNum = Cue.UNSET_VALUE;
-      int position = Cue.UNSET_VALUE;
-      Alignment alignment = null;
-      int size = Cue.UNSET_VALUE;
+      long cueStartTime;
+      long cueEndTime;
+      CharSequence cueText;
+      Alignment cueTextAlignment = null;
+      float cueLine = Cue.DIMEN_UNSET;
+      int cueLineType = Cue.TYPE_UNSET;
+      int cueLineAnchor = Cue.TYPE_UNSET;
+      float cuePosition = Cue.DIMEN_UNSET;
+      int cuePositionAnchor = Cue.TYPE_UNSET;
+      float cueWidth = Cue.DIMEN_UNSET;
 
       // parse the cue timestamps
-      matcher = WEBVTT_TIMESTAMP.matcher(line);
+      matcher = TIMESTAMP.matcher(line);
 
       // parse start timestamp
       if (!matcher.find()) {
         throw new ParserException("Expected cue start time: " + line);
       } else {
-        startTime = parseTimestampUs(matcher.group()) + mediaTimestampUs;
+        cueStartTime = parseTimestampUs(matcher.group());
       }
 
       // parse end timestamp
@@ -187,12 +154,12 @@ public final WebvttSubtitle parse(InputStream inputStream, String inputEncoding,
         throw new ParserException("Expected cue end time: " + line);
       } else {
         endTimeString = matcher.group();
-        endTime = parseTimestampUs(endTimeString) + mediaTimestampUs;
+        cueEndTime = parseTimestampUs(endTimeString);
       }
 
       // parse the (optional) cue setting list
       line = line.substring(line.indexOf(endTimeString) + endTimeString.length());
-      matcher = WEBVTT_CUE_SETTING.matcher(line);
+      matcher = CUE_SETTING.matcher(line);
       while (matcher.find()) {
         String match = matcher.group();
         String[] parts = match.split(":", 2);
@@ -201,55 +168,48 @@ public final WebvttSubtitle parse(InputStream inputStream, String inputEncoding,
 
         try {
           if ("line".equals(name)) {
-            if (value.endsWith("%")) {
-              lineNum = parseIntPercentage(value);
-            } else if (value.matches(NON_NUMERIC_STRING)) {
-              Log.w(TAG, "Invalid line value: " + value);
-            } else {
-              lineNum = Integer.parseInt(value);
-            }
+            parseLineAttribute(value, positionHolder);
+            cueLine = positionHolder.position;
+            cueLineType = positionHolder.lineType;
+            cueLineAnchor = positionHolder.positionAnchor;
           } else if ("align".equals(name)) {
-            // TODO: handle for RTL languages
-            if ("start".equals(value)) {
-              alignment = Alignment.ALIGN_NORMAL;
-            } else if ("middle".equals(value)) {
-              alignment = Alignment.ALIGN_CENTER;
-            } else if ("end".equals(value)) {
-              alignment = Alignment.ALIGN_OPPOSITE;
-            } else if ("left".equals(value)) {
-              alignment = Alignment.ALIGN_NORMAL;
-            } else if ("right".equals(value)) {
-              alignment = Alignment.ALIGN_OPPOSITE;
-            } else {
-              Log.w(TAG, "Invalid align value: " + value);
-            }
+            cueTextAlignment = parseTextAlignment(value);
           } else if ("position".equals(name)) {
-            position = parseIntPercentage(value);
+            parsePositionAttribute(value, positionHolder);
+            cuePosition = positionHolder.position;
+            cuePositionAnchor = positionHolder.positionAnchor;
           } else if ("size".equals(name)) {
-            size = parseIntPercentage(value);
+            cueWidth = parsePercentage(value);
           } else {
             Log.w(TAG, "Unknown cue setting " + name + ":" + value);
           }
         } catch (NumberFormatException e) {
-          Log.w(TAG, name + " contains an invalid value " + value, e);
+          Log.w(TAG, e.getMessage() + ": " + match);
         }
       }
 
+      if (cuePosition != Cue.DIMEN_UNSET && cuePositionAnchor == Cue.TYPE_UNSET) {
+        // Computed position alignment should be derived from the text alignment if it has not been
+        // set explicitly.
+        cuePositionAnchor = alignmentToAnchor(cueTextAlignment);
+      }
+
       // parse text
       textBuilder.setLength(0);
-      while (((line = webvttData.readLine()) != null) && (!line.isEmpty())) {
+      while ((line = webvttData.readLine()) != null && !line.isEmpty()) {
         if (textBuilder.length() > 0) {
           textBuilder.append("<br>");
         }
         textBuilder.append(line.trim());
       }
-      text = Html.fromHtml(textBuilder.toString());
+      cueText = Html.fromHtml(textBuilder.toString());
 
-      WebvttCue cue = new WebvttCue(startTime, endTime, text, lineNum, position, alignment, size);
+      WebvttCue cue = new WebvttCue(cueStartTime, cueEndTime, cueText, cueTextAlignment, cueLine,
+          cueLineType, cueLineAnchor, cuePosition, cuePositionAnchor, cueWidth);
       subtitles.add(cue);
     }
 
-    return new WebvttSubtitle(subtitles, mediaTimestampUs);
+    return new WebvttSubtitle(subtitles);
   }
 
   @Override
@@ -257,44 +217,116 @@ public final boolean canParse(String mimeType) {
     return MimeTypes.TEXT_VTT.equals(mimeType);
   }
 
-  protected long getAdjustedStartTime(long startTimeUs) {
-    return startTimeUs;
+  private static long parseTimestampUs(String s) throws NumberFormatException {
+    long value = 0;
+    String[] parts = s.split("\\.", 2);
+    String[] subparts = parts[0].split(":");
+    for (int i = 0; i < subparts.length; i++) {
+      value = value * 60 + Long.parseLong(subparts[i]);
+    }
+    return (value * 1000 + Long.parseLong(parts[1])) * 1000;
   }
 
-  protected void handleNoncompliantLine(String line) throws ParserException {
-    if (strictParsing) {
-      throw new ParserException("Unexpected line: " + line);
+  private static void parseLineAttribute(String s, PositionHolder out)
+      throws NumberFormatException {
+    int lineAnchor;
+    int commaPosition = s.indexOf(",");
+    if (commaPosition != -1) {
+      lineAnchor = parsePositionAnchor(s.substring(commaPosition + 1));
+      s = s.substring(0, commaPosition);
+    } else {
+      lineAnchor = Cue.TYPE_UNSET;
+    }
+    float line;
+    int lineType;
+    if (s.endsWith("%")) {
+      line = parsePercentage(s);
+      lineType = Cue.LINE_TYPE_FRACTION;
+    } else {
+      line = Integer.parseInt(s);
+      lineType = Cue.LINE_TYPE_NUMBER;
     }
+    out.position = line;
+    out.positionAnchor = lineAnchor;
+    out.lineType = lineType;
   }
 
-  private static int parseIntPercentage(String s) throws NumberFormatException {
-    if (!s.endsWith("%")) {
-      throw new NumberFormatException(s + " doesn't end with '%'");
+  private static void parsePositionAttribute(String s, PositionHolder out)
+      throws NumberFormatException {
+    int positionAnchor;
+    int commaPosition = s.indexOf(",");
+    if (commaPosition != -1) {
+      positionAnchor = parsePositionAnchor(s.substring(commaPosition + 1));
+      s = s.substring(0, commaPosition);
+    } else {
+      positionAnchor = Cue.TYPE_UNSET;
     }
+    out.position = parsePercentage(s);
+    out.positionAnchor = positionAnchor;
+    out.lineType = Cue.TYPE_UNSET;
+  }
 
-    s = s.substring(0, s.length() - 1);
-    if (s.matches(NON_NUMERIC_STRING)) {
-      throw new NumberFormatException(s + " contains an invalid character");
+  private static float parsePercentage(String s) throws NumberFormatException {
+    if (!s.endsWith("%")) {
+      throw new NumberFormatException("Percentages must end with %");
     }
+    s = s.substring(0, s.length() - 1);
+    return Float.parseFloat(s) / 100;
+  }
 
-    int value = Integer.parseInt(s);
-    if (value < 0 || value > 100) {
-      throw new NumberFormatException(value + " is out of range [0-100]");
+  private static int parsePositionAnchor(String s) {
+    switch (s) {
+      case "start":
+        return Cue.ANCHOR_TYPE_START;
+      case "middle":
+        return Cue.ANCHOR_TYPE_MIDDLE;
+      case "end":
+        return Cue.ANCHOR_TYPE_END;
+      default:
+        Log.w(TAG, "Invalid anchor value: " + s);
+        return Cue.TYPE_UNSET;
     }
-    return value;
   }
 
-  private static long parseTimestampUs(String s) throws NumberFormatException {
-    if (!s.matches(WEBVTT_TIMESTAMP_STRING)) {
-      throw new NumberFormatException("has invalid format");
+  private static Alignment parseTextAlignment(String s) {
+    switch (s) {
+      case "start":
+      case "left":
+        return Alignment.ALIGN_NORMAL;
+      case "middle":
+        return Alignment.ALIGN_CENTER;
+      case "end":
+      case "right":
+        return Alignment.ALIGN_OPPOSITE;
+      default:
+        Log.w(TAG, "Invalid alignment value: " + s);
+        return null;
     }
+  }
 
-    String[] parts = s.split("\\.", 2);
-    long value = 0;
-    for (String group : parts[0].split(":")) {
-      value = value * 60 + Long.parseLong(group);
+  private static int alignmentToAnchor(Alignment alignment) {
+    if (alignment == null) {
+      return Cue.TYPE_UNSET;
     }
-    return (value * 1000 + Long.parseLong(parts[1])) * 1000;
+    switch (alignment) {
+      case ALIGN_NORMAL:
+        return Cue.ANCHOR_TYPE_START;
+      case ALIGN_CENTER:
+        return Cue.ANCHOR_TYPE_MIDDLE;
+      case ALIGN_OPPOSITE:
+        return Cue.ANCHOR_TYPE_END;
+      default:
+        Log.w(TAG, "Unrecognized alignment: " + alignment);
+        return Cue.ANCHOR_TYPE_START;
+    }
+  }
+
+  private static final class PositionHolder {
+
+    public float position;
+    public int positionAnchor;
+    public int lineType;
+
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitle.java b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitle.java
index 3cc7ba6362..1f78a82a7e 100644
--- a/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitle.java
+++ b/library/src/main/java/com/google/android/exoplayer/text/webvtt/WebvttSubtitle.java
@@ -34,18 +34,14 @@
 
   private final List<WebvttCue> cues;
   private final int numCues;
-  private final long startTimeUs;
   private final long[] cueTimesUs;
   private final long[] sortedCueTimesUs;
 
   /**
    * @param cues A list of the cues in this subtitle.
-   * @param startTimeUs The start time of the subtitle.
    */
-  public WebvttSubtitle(List<WebvttCue> cues, long startTimeUs) {
+  public WebvttSubtitle(List<WebvttCue> cues) {
     this.cues = cues;
-    this.startTimeUs = startTimeUs;
-
     numCues = cues.size();
     cueTimesUs = new long[2 * numCues];
     for (int cueIndex = 0; cueIndex < numCues; cueIndex++) {
@@ -58,11 +54,6 @@ public WebvttSubtitle(List<WebvttCue> cues, long startTimeUs) {
     Arrays.sort(sortedCueTimesUs);
   }
 
-  @Override
-  public long getStartTime() {
-    return startTimeUs;
-  }
-
   @Override
   public int getNextEventTimeIndex(long timeUs) {
     Assertions.checkArgument(timeUs >= 0);
diff --git a/library/src/main/java/com/google/android/exoplayer/upstream/DefaultHttpDataSource.java b/library/src/main/java/com/google/android/exoplayer/upstream/DefaultHttpDataSource.java
index 2c70748e28..59d6c2bff2 100644
--- a/library/src/main/java/com/google/android/exoplayer/upstream/DefaultHttpDataSource.java
+++ b/library/src/main/java/com/google/android/exoplayer/upstream/DefaultHttpDataSource.java
@@ -59,7 +59,7 @@
   public static final int DEFAULT_READ_TIMEOUT_MILLIS = 8 * 1000;
 
   private static final int MAX_REDIRECTS = 20; // Same limit as okhttp.
-  private static final String TAG = "HttpDataSource";
+  private static final String TAG = "DefaultHttpDataSource";
   private static final Pattern CONTENT_RANGE_HEADER =
       Pattern.compile("^bytes (\\d+)-(\\d+)/(\\d+)$");
   private static final AtomicReference<byte[]> skipBufferReference = new AtomicReference<>();
@@ -198,7 +198,7 @@ public long open(DataSpec dataSpec) throws HttpDataSourceException {
     try {
       responseCode = connection.getResponseCode();
     } catch (IOException e) {
-      closeConnection();
+      closeConnectionQuietly();
       throw new HttpDataSourceException("Unable to connect to " + dataSpec.uri.toString(), e,
           dataSpec);
     }
@@ -206,14 +206,14 @@ public long open(DataSpec dataSpec) throws HttpDataSourceException {
     // Check for a valid response code.
     if (responseCode < 200 || responseCode > 299) {
       Map<String, List<String>> headers = connection.getHeaderFields();
-      closeConnection();
+      closeConnectionQuietly();
       throw new InvalidResponseCodeException(responseCode, headers, dataSpec);
     }
 
     // Check for a valid content type.
     String contentType = connection.getContentType();
     if (contentTypePredicate != null && !contentTypePredicate.evaluate(contentType)) {
-      closeConnection();
+      closeConnectionQuietly();
       throw new InvalidContentTypeException(contentType, dataSpec);
     }
 
@@ -239,7 +239,7 @@ public long open(DataSpec dataSpec) throws HttpDataSourceException {
     try {
       inputStream = connection.getInputStream();
     } catch (IOException e) {
-      closeConnection();
+      closeConnectionQuietly();
       throw new HttpDataSourceException(e, dataSpec);
     }
 
@@ -274,7 +274,7 @@ public void close() throws HttpDataSourceException {
       }
     } finally {
       inputStream = null;
-      closeConnection();
+      closeConnectionQuietly();
       if (opened) {
         opened = false;
         if (listener != null) {
@@ -566,11 +566,15 @@ private int readInternal(byte[] buffer, int offset, int readLength) throws IOExc
   }
 
   /**
-   * Closes the current connection, if there is one.
+   * Closes the current connection quietly, if there is one.
    */
-  private void closeConnection() {
+  private void closeConnectionQuietly() {
     if (connection != null) {
-      connection.disconnect();
+      try {
+        connection.disconnect();
+      } catch (Exception e) {
+        Log.e(TAG, "Unexpected error while disconnecting", e);
+      }
       connection = null;
     }
   }
diff --git a/library/src/main/java/com/google/android/exoplayer/upstream/UnexpectedLengthException.java b/library/src/main/java/com/google/android/exoplayer/upstream/UnexpectedLengthException.java
deleted file mode 100644
index 6c91601485..0000000000
--- a/library/src/main/java/com/google/android/exoplayer/upstream/UnexpectedLengthException.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Copyright (C) 2014 The Android Open Source Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package com.google.android.exoplayer.upstream;
-
-import java.io.IOException;
-
-/**
- * Thrown when the length of some data does not match an expected length.
- */
-@Deprecated
-public final class UnexpectedLengthException extends IOException {
-
-  /**
-   * The length that was expected, in bytes.
-   */
-  public final long expectedLength;
-
-  /**
-   * The actual length encountered, in bytes.
-   */
-  public final long actualLength;
-
-  /**
-   * @param expectedLength The length that was expected, in bytes.
-   * @param actualLength The actual length encountered, in bytes.
-   */
-  public UnexpectedLengthException(long expectedLength, long actualLength) {
-    super("Expected: " + expectedLength + ", got: " + actualLength);
-    this.expectedLength = expectedLength;
-    this.actualLength = actualLength;
-  }
-
-}
diff --git a/library/src/main/java/com/google/android/exoplayer/util/Ac3Util.java b/library/src/main/java/com/google/android/exoplayer/util/Ac3Util.java
index 01647e22ca..6f1b6764aa 100644
--- a/library/src/main/java/com/google/android/exoplayer/util/Ac3Util.java
+++ b/library/src/main/java/com/google/android/exoplayer/util/Ac3Util.java
@@ -36,8 +36,15 @@
   /**
    * Returns the AC-3 format given {@code data} containing the AC3SpecificBox according to
    * ETSI TS 102 366 Annex F.
+   *
+   * @param data The AC3SpecificBox.
+   * @param trackId The identifier for the track in its container, or {@link MediaFormat#NO_VALUE}.
+   * @param durationUs The duration to set on the format, in microseconds.
+   * @param language The language to set on the format.
+   * @return The AC-3 format parsed from data in the header.
    */
-  public static MediaFormat parseAnnexFAc3Format(ParsableByteArray data) {
+  public static MediaFormat parseAnnexFAc3Format(ParsableByteArray data, int trackId,
+      long durationUs, String language) {
     // fscod (sample rate code)
     int fscod = (data.readUnsignedByte() & 0xC0) >> 6;
     int sampleRate = SAMPLE_RATES[fscod];
@@ -48,15 +55,22 @@ public static MediaFormat parseAnnexFAc3Format(ParsableByteArray data) {
     if ((nextByte & 0x04) != 0) {
       channelCount++;
     }
-    return MediaFormat.createAudioFormat(MimeTypes.AUDIO_AC3, MediaFormat.NO_VALUE,
-        channelCount, sampleRate, null);
+    return MediaFormat.createAudioFormat(trackId, MimeTypes.AUDIO_AC3, MediaFormat.NO_VALUE,
+        MediaFormat.NO_VALUE, durationUs, channelCount, sampleRate, null, language);
   }
 
   /**
-   * Returns the AC-3 format given {@code data} containing the EC3SpecificBox according to
+   * Returns the E-AC-3 format given {@code data} containing the EC3SpecificBox according to
    * ETSI TS 102 366 Annex F.
+   *
+   * @param data The EC3SpecificBox.
+   * @param trackId The identifier for the track in its container, or {@link MediaFormat#NO_VALUE}.
+   * @param durationUs The duration to set on the format, in microseconds.
+   * @param language The language to set on the format.
+   * @return The E-AC-3 format parsed from data in the header.
    */
-  public static MediaFormat parseAnnexFEAc3Format(ParsableByteArray data) {
+  public static MediaFormat parseAnnexFEAc3Format(ParsableByteArray data, int trackId,
+      long durationUs, String language) {
     data.skipBytes(2); // Skip data_rate and num_ind_sub.
 
     // Read only the first substream.
@@ -71,8 +85,8 @@ public static MediaFormat parseAnnexFEAc3Format(ParsableByteArray data) {
     if ((nextByte & 0x01) != 0) {
       channelCount++;
     }
-    return MediaFormat.createAudioFormat(MimeTypes.AUDIO_EC3, MediaFormat.NO_VALUE,
-        channelCount, sampleRate, null);
+    return MediaFormat.createAudioFormat(trackId, MimeTypes.AUDIO_EC3, MediaFormat.NO_VALUE,
+        MediaFormat.NO_VALUE, durationUs, channelCount, sampleRate, null, language);
   }
 
   /**
@@ -80,9 +94,13 @@ public static MediaFormat parseAnnexFEAc3Format(ParsableByteArray data) {
    * word.
    *
    * @param data Data to parse, positioned at the start of the syncword.
-   * @return AC-3 format parsed from data in the header.
+   * @param trackId The identifier for the track in its container, or {@link MediaFormat#NO_VALUE}.
+   * @param durationUs The duration to set on the format, in microseconds.
+   * @param language The language to set on the format.
+   * @return The AC-3 format parsed from data in the header.
    */
-  public static MediaFormat parseFrameAc3Format(ParsableBitArray data) {
+  public static MediaFormat parseFrameAc3Format(ParsableBitArray data, int trackId, long durationUs,
+      String language) {
     // Skip syncword and crc1.
     data.skipBits(4 * 8);
 
@@ -99,8 +117,9 @@ public static MediaFormat parseFrameAc3Format(ParsableBitArray data) {
       data.skipBits(2); // dsurmod
     }
     boolean lfeon = data.readBit();
-    return MediaFormat.createAudioFormat(MimeTypes.AUDIO_AC3, MediaFormat.NO_VALUE,
-        CHANNEL_COUNTS[acmod] + (lfeon ? 1 : 0), SAMPLE_RATES[fscod], null);
+    return MediaFormat.createAudioFormat(trackId, MimeTypes.AUDIO_AC3, MediaFormat.NO_VALUE,
+        MediaFormat.NO_VALUE, durationUs, CHANNEL_COUNTS[acmod] + (lfeon ? 1 : 0),
+        SAMPLE_RATES[fscod], null, language);
   }
 
   /**
diff --git a/library/src/main/java/com/google/android/exoplayer/util/CodecSpecificDataUtil.java b/library/src/main/java/com/google/android/exoplayer/util/CodecSpecificDataUtil.java
index fa212d2a19..1ec1cbf9d1 100644
--- a/library/src/main/java/com/google/android/exoplayer/util/CodecSpecificDataUtil.java
+++ b/library/src/main/java/com/google/android/exoplayer/util/CodecSpecificDataUtil.java
@@ -15,8 +15,7 @@
  */
 package com.google.android.exoplayer.util;
 
-import android.annotation.SuppressLint;
-import android.media.MediaCodecInfo.CodecProfileLevel;
+import android.util.Log;
 import android.util.Pair;
 
 import java.util.ArrayList;
@@ -27,6 +26,23 @@
  */
 public final class CodecSpecificDataUtil {
 
+  /**
+   * Holds data parsed from a sequence parameter set NAL unit.
+   */
+  public static final class SpsData {
+
+    public final int width;
+    public final int height;
+    public final float pixelWidthAspectRatio;
+
+    public SpsData(int width, int height, float pixelWidthAspectRatio) {
+      this.width = width;
+      this.height = height;
+      this.pixelWidthAspectRatio = pixelWidthAspectRatio;
+    }
+
+  }
+
   private static final byte[] NAL_START_CODE = new byte[] {0, 0, 0, 1};
 
   private static final int[] AUDIO_SPECIFIC_CONFIG_SAMPLING_RATE_TABLE = new int[] {
@@ -37,7 +53,7 @@
     0, 1, 2, 3, 4, 5, 6, 8
   };
 
-  private static final int SPS_NAL_UNIT_TYPE = 7;
+  private static final String TAG = "CodecSpecificDataUtil";
 
   private CodecSpecificDataUtil() {}
 
@@ -188,88 +204,117 @@ private static boolean isNalStartCode(byte[] data, int index) {
   /**
    * Parses an SPS NAL unit.
    *
-   * @param spsNalUnit The NAL unit.
-   * @return A pair consisting of AVC profile and level constants, as defined in
-   *     {@link CodecProfileLevel}. Null if the input data was not an SPS NAL unit.
+   * @param bitArray A {@link ParsableBitArray} containing the SPS data. The position must to set
+   *     to the start of the data (i.e. the first bit of the profile_idc field).
+   * @return A parsed representation of the SPS data.
    */
-  public static Pair<Integer, Integer> parseSpsNalUnit(byte[] spsNalUnit) {
-    // SPS NAL unit:
-    // - Start prefix (4 bytes)
-    // - Forbidden zero bit (1 bit)
-    // - NAL ref idx (2 bits)
-    // - NAL unit type (5 bits)
-    // - Profile idc (8 bits)
-    // - Constraint bits (3 bits)
-    // - Reserved bits (5 bits)
-    // - Level idx (8 bits)
-    if (isNalStartCode(spsNalUnit, 0) && spsNalUnit.length == 8
-        && (spsNalUnit[5] & 0x1F) == SPS_NAL_UNIT_TYPE) {
-      return Pair.create(parseAvcProfile(spsNalUnit), parseAvcLevel(spsNalUnit));
+  public static SpsData parseSpsNalUnit(ParsableBitArray bitArray) {
+    int profileIdc = bitArray.readBits(8);
+    bitArray.skipBits(16); // constraint bits (6), reserved (2) and level_idc (8)
+    bitArray.readUnsignedExpGolombCodedInt(); // seq_parameter_set_id
+
+    int chromaFormatIdc = 1; // Default is 4:2:0
+    if (profileIdc == 100 || profileIdc == 110 || profileIdc == 122 || profileIdc == 244
+        || profileIdc == 44 || profileIdc == 83 || profileIdc == 86 || profileIdc == 118
+        || profileIdc == 128 || profileIdc == 138) {
+      chromaFormatIdc = bitArray.readUnsignedExpGolombCodedInt();
+      if (chromaFormatIdc == 3) {
+        bitArray.skipBits(1); // separate_colour_plane_flag
+      }
+      bitArray.readUnsignedExpGolombCodedInt(); // bit_depth_luma_minus8
+      bitArray.readUnsignedExpGolombCodedInt(); // bit_depth_chroma_minus8
+      bitArray.skipBits(1); // qpprime_y_zero_transform_bypass_flag
+      boolean seqScalingMatrixPresentFlag = bitArray.readBit();
+      if (seqScalingMatrixPresentFlag) {
+        int limit = (chromaFormatIdc != 3) ? 8 : 12;
+        for (int i = 0; i < limit; i++) {
+          boolean seqScalingListPresentFlag = bitArray.readBit();
+          if (seqScalingListPresentFlag) {
+            skipScalingList(bitArray, i < 6 ? 16 : 64);
+          }
+        }
+      }
     }
-    return null;
-  }
 
-  @SuppressLint("InlinedApi")
-  private static int parseAvcProfile(byte[] data) {
-    int profileIdc = data[6] & 0xFF;
-    switch (profileIdc) {
-      case 0x42:
-        return CodecProfileLevel.AVCProfileBaseline;
-      case 0x4d:
-        return CodecProfileLevel.AVCProfileMain;
-      case 0x58:
-        return CodecProfileLevel.AVCProfileExtended;
-      case 0x64:
-        return CodecProfileLevel.AVCProfileHigh;
-      case 0x6e:
-        return CodecProfileLevel.AVCProfileHigh10;
-      case 0x7a:
-        return CodecProfileLevel.AVCProfileHigh422;
-      case 0xf4:
-        return CodecProfileLevel.AVCProfileHigh444;
-      default:
-        return 0;
+    bitArray.readUnsignedExpGolombCodedInt(); // log2_max_frame_num_minus4
+    long picOrderCntType = bitArray.readUnsignedExpGolombCodedInt();
+    if (picOrderCntType == 0) {
+      bitArray.readUnsignedExpGolombCodedInt(); // log2_max_pic_order_cnt_lsb_minus4
+    } else if (picOrderCntType == 1) {
+      bitArray.skipBits(1); // delta_pic_order_always_zero_flag
+      bitArray.readSignedExpGolombCodedInt(); // offset_for_non_ref_pic
+      bitArray.readSignedExpGolombCodedInt(); // offset_for_top_to_bottom_field
+      long numRefFramesInPicOrderCntCycle = bitArray.readUnsignedExpGolombCodedInt();
+      for (int i = 0; i < numRefFramesInPicOrderCntCycle; i++) {
+        bitArray.readUnsignedExpGolombCodedInt(); // offset_for_ref_frame[i]
+      }
+    }
+    bitArray.readUnsignedExpGolombCodedInt(); // max_num_ref_frames
+    bitArray.skipBits(1); // gaps_in_frame_num_value_allowed_flag
+
+    int picWidthInMbs = bitArray.readUnsignedExpGolombCodedInt() + 1;
+    int picHeightInMapUnits = bitArray.readUnsignedExpGolombCodedInt() + 1;
+    boolean frameMbsOnlyFlag = bitArray.readBit();
+    int frameHeightInMbs = (2 - (frameMbsOnlyFlag ? 1 : 0)) * picHeightInMapUnits;
+    if (!frameMbsOnlyFlag) {
+      bitArray.skipBits(1); // mb_adaptive_frame_field_flag
+    }
+
+    bitArray.skipBits(1); // direct_8x8_inference_flag
+    int frameWidth = picWidthInMbs * 16;
+    int frameHeight = frameHeightInMbs * 16;
+    boolean frameCroppingFlag = bitArray.readBit();
+    if (frameCroppingFlag) {
+      int frameCropLeftOffset = bitArray.readUnsignedExpGolombCodedInt();
+      int frameCropRightOffset = bitArray.readUnsignedExpGolombCodedInt();
+      int frameCropTopOffset = bitArray.readUnsignedExpGolombCodedInt();
+      int frameCropBottomOffset = bitArray.readUnsignedExpGolombCodedInt();
+      int cropUnitX, cropUnitY;
+      if (chromaFormatIdc == 0) {
+        cropUnitX = 1;
+        cropUnitY = 2 - (frameMbsOnlyFlag ? 1 : 0);
+      } else {
+        int subWidthC = (chromaFormatIdc == 3) ? 1 : 2;
+        int subHeightC = (chromaFormatIdc == 1) ? 2 : 1;
+        cropUnitX = subWidthC;
+        cropUnitY = subHeightC * (2 - (frameMbsOnlyFlag ? 1 : 0));
+      }
+      frameWidth -= (frameCropLeftOffset + frameCropRightOffset) * cropUnitX;
+      frameHeight -= (frameCropTopOffset + frameCropBottomOffset) * cropUnitY;
     }
+
+    float pixelWidthHeightRatio = 1;
+    boolean vuiParametersPresentFlag = bitArray.readBit();
+    if (vuiParametersPresentFlag) {
+      boolean aspectRatioInfoPresentFlag = bitArray.readBit();
+      if (aspectRatioInfoPresentFlag) {
+        int aspectRatioIdc = bitArray.readBits(8);
+        if (aspectRatioIdc == NalUnitUtil.EXTENDED_SAR) {
+          int sarWidth = bitArray.readBits(16);
+          int sarHeight = bitArray.readBits(16);
+          if (sarWidth != 0 && sarHeight != 0) {
+            pixelWidthHeightRatio = (float) sarWidth / sarHeight;
+          }
+        } else if (aspectRatioIdc < NalUnitUtil.ASPECT_RATIO_IDC_VALUES.length) {
+          pixelWidthHeightRatio = NalUnitUtil.ASPECT_RATIO_IDC_VALUES[aspectRatioIdc];
+        } else {
+          Log.w(TAG, "Unexpected aspect_ratio_idc value: " + aspectRatioIdc);
+        }
+      }
+    }
+
+    return new SpsData(frameWidth, frameHeight, pixelWidthHeightRatio);
   }
 
-  @SuppressLint("InlinedApi")
-  private static int parseAvcLevel(byte[] data) {
-    int levelIdc = data[8] & 0xFF;
-    switch (levelIdc) {
-      case 9:
-        return CodecProfileLevel.AVCLevel1b;
-      case 10:
-        return CodecProfileLevel.AVCLevel1;
-      case 11:
-        return CodecProfileLevel.AVCLevel11;
-      case 12:
-        return CodecProfileLevel.AVCLevel12;
-      case 13:
-        return CodecProfileLevel.AVCLevel13;
-      case 20:
-        return CodecProfileLevel.AVCLevel2;
-      case 21:
-        return CodecProfileLevel.AVCLevel21;
-      case 22:
-        return CodecProfileLevel.AVCLevel22;
-      case 30:
-        return CodecProfileLevel.AVCLevel3;
-      case 31:
-        return CodecProfileLevel.AVCLevel31;
-      case 32:
-        return CodecProfileLevel.AVCLevel32;
-      case 40:
-        return CodecProfileLevel.AVCLevel4;
-      case 41:
-        return CodecProfileLevel.AVCLevel41;
-      case 42:
-        return CodecProfileLevel.AVCLevel42;
-      case 50:
-        return CodecProfileLevel.AVCLevel5;
-      case 51:
-        return CodecProfileLevel.AVCLevel51;
-      default:
-        return 0;
+  private static void skipScalingList(ParsableBitArray bitArray, int size) {
+    int lastScale = 8;
+    int nextScale = 8;
+    for (int i = 0; i < size; i++) {
+      if (nextScale != 0) {
+        int deltaScale = bitArray.readSignedExpGolombCodedInt();
+        nextScale = (lastScale + deltaScale + 256) % 256;
+      }
+      lastScale = (nextScale == 0) ? lastScale : nextScale;
     }
   }
 
diff --git a/library/src/main/java/com/google/android/exoplayer/util/MimeTypes.java b/library/src/main/java/com/google/android/exoplayer/util/MimeTypes.java
index 7b0d9d0d4c..afb62a5bf5 100644
--- a/library/src/main/java/com/google/android/exoplayer/util/MimeTypes.java
+++ b/library/src/main/java/com/google/android/exoplayer/util/MimeTypes.java
@@ -15,11 +15,6 @@
  */
 package com.google.android.exoplayer.util;
 
-import com.google.android.exoplayer.C;
-import com.google.android.exoplayer.audio.AudioCapabilities;
-
-import android.media.AudioFormat;
-
 /**
  * Defines common MIME types and helper methods.
  */
@@ -30,6 +25,7 @@
   public static final String BASE_TYPE_TEXT = "text";
   public static final String BASE_TYPE_APPLICATION = "application";
 
+  public static final String VIDEO_UNKNOWN = BASE_TYPE_VIDEO + "/x-unknown";
   public static final String VIDEO_MP4 = BASE_TYPE_VIDEO + "/mp4";
   public static final String VIDEO_WEBM = BASE_TYPE_VIDEO + "/webm";
   public static final String VIDEO_H263 = BASE_TYPE_VIDEO + "/3gpp";
@@ -39,22 +35,25 @@
   public static final String VIDEO_VP9 = BASE_TYPE_VIDEO + "/x-vnd.on2.vp9";
   public static final String VIDEO_MP4V = BASE_TYPE_VIDEO + "/mp4v-es";
 
+  public static final String AUDIO_UNKNOWN = BASE_TYPE_AUDIO + "/x-unknown";
   public static final String AUDIO_MP4 = BASE_TYPE_AUDIO + "/mp4";
   public static final String AUDIO_AAC = BASE_TYPE_AUDIO + "/mp4a-latm";
   public static final String AUDIO_WEBM = BASE_TYPE_AUDIO + "/webm";
   public static final String AUDIO_MPEG = BASE_TYPE_AUDIO + "/mpeg";
   public static final String AUDIO_MPEG_L1 = BASE_TYPE_AUDIO + "/mpeg-L1";
   public static final String AUDIO_MPEG_L2 = BASE_TYPE_AUDIO + "/mpeg-L2";
-
   public static final String AUDIO_RAW = BASE_TYPE_AUDIO + "/raw";
   public static final String AUDIO_AC3 = BASE_TYPE_AUDIO + "/ac3";
   public static final String AUDIO_EC3 = BASE_TYPE_AUDIO + "/eac3";
-
+  public static final String AUDIO_DTS = BASE_TYPE_AUDIO + "/vnd.dts";
+  public static final String AUDIO_DTS_HD = BASE_TYPE_AUDIO + "/vnd.dts.hd";
   public static final String AUDIO_VORBIS = BASE_TYPE_AUDIO + "/vorbis";
   public static final String AUDIO_OPUS = BASE_TYPE_AUDIO + "/opus";
 
   public static final String TEXT_VTT = BASE_TYPE_TEXT + "/vtt";
 
+  public static final String APPLICATION_MP4 = BASE_TYPE_APPLICATION + "/mp4";
+  public static final String APPLICATION_WEBM = BASE_TYPE_APPLICATION + "/webm";
   public static final String APPLICATION_ID3 = BASE_TYPE_APPLICATION + "/id3";
   public static final String APPLICATION_EIA608 = BASE_TYPE_APPLICATION + "/eia-608";
   public static final String APPLICATION_SUBRIP = BASE_TYPE_APPLICATION + "/x-subrip";
@@ -64,20 +63,6 @@
 
   private MimeTypes() {}
 
-  /**
-   * Returns the top-level type of {@code mimeType}.
-   *
-   * @param mimeType The mimeType whose top-level type is required.
-   * @return The top-level type.
-   */
-  public static String getTopLevelType(String mimeType) {
-    int indexOfSlash = mimeType.indexOf('/');
-    if (indexOfSlash == -1) {
-      throw new IllegalArgumentException("Invalid mime type: " + mimeType);
-    }
-    return mimeType.substring(0, indexOfSlash);
-  }
-
   /**
    * Whether the top-level type of {@code mimeType} is audio.
    *
@@ -119,46 +104,17 @@ public static boolean isApplication(String mimeType) {
   }
 
   /**
-   * Whether the mimeType is {@link #APPLICATION_TTML}.
-   *
-   * @param mimeType The mimeType to test.
-   * @return Whether the mimeType is {@link #APPLICATION_TTML}.
-   */
-  public static boolean isTtml(String mimeType) {
-    return mimeType.equals(APPLICATION_TTML);
-  }
-
-  /**
-   * Returns the output audio encoding that will result from processing input in {@code mimeType}.
-   * For non-passthrough audio formats, this is always {@link AudioFormat#ENCODING_PCM_16BIT}. For
-   * passthrough formats it will be one of {@link AudioFormat}'s other {@code ENCODING_*} constants.
-   * For non-audio formats, {@link AudioFormat#ENCODING_INVALID} will be returned.
+   * Returns the top-level type of {@code mimeType}.
    *
-   * @param mimeType The MIME type of media that will be decoded (or passed through).
-   * @return The corresponding {@link AudioFormat} encoding.
+   * @param mimeType The mimeType whose top-level type is required.
+   * @return The top-level type.
    */
-  public static int getEncodingForMimeType(String mimeType) {
-    if (AUDIO_AC3.equals(mimeType)) {
-      return C.ENCODING_AC3;
-    }
-    if (AUDIO_EC3.equals(mimeType)) {
-      return C.ENCODING_E_AC3;
+  private static String getTopLevelType(String mimeType) {
+    int indexOfSlash = mimeType.indexOf('/');
+    if (indexOfSlash == -1) {
+      throw new IllegalArgumentException("Invalid mime type: " + mimeType);
     }
-
-    // All other audio formats will be decoded to 16-bit PCM.
-    return isAudio(mimeType) ? AudioFormat.ENCODING_PCM_16BIT : AudioFormat.ENCODING_INVALID;
-  }
-
-  /**
-   * Returns whether the specified {@code mimeType} represents audio that can be played via
-   * passthrough if the device supports it.
-   *
-   * @param mimeType The MIME type of input media.
-   * @return Whether the audio can be played via passthrough. If this method returns {@code true},
-   *     it is still necessary to check the {@link AudioCapabilities} for device support.
-   */
-  public static boolean isPassthroughAudio(String mimeType) {
-    return AUDIO_AC3.equals(mimeType) || AUDIO_EC3.equals(mimeType);
+    return mimeType.substring(0, indexOfSlash);
   }
 
 }
diff --git a/library/src/main/java/com/google/android/exoplayer/util/ParsableBitArray.java b/library/src/main/java/com/google/android/exoplayer/util/ParsableBitArray.java
index a2407d7c64..ff47655598 100644
--- a/library/src/main/java/com/google/android/exoplayer/util/ParsableBitArray.java
+++ b/library/src/main/java/com/google/android/exoplayer/util/ParsableBitArray.java
@@ -127,18 +127,19 @@ public boolean readBit() {
   /**
    * Reads up to 32 bits.
    *
-   * @param n The number of bits to read.
+   * @param numBits The number of bits to read.
    * @return An integer whose bottom n bits hold the read data.
    */
-  public int readBits(int n) {
-    if (n == 0) {
+  public int readBits(int numBits) {
+    if (numBits == 0) {
       return 0;
     }
 
     int returnValue = 0;
 
-    // While n >= 8, read whole bytes.
-    while (n >= 8) {
+    // Read as many whole bytes as we can.
+    int wholeBytes = (numBits / 8);
+    for (int i = 0; i < wholeBytes; i++) {
       int byteValue;
       if (bitOffset != 0) {
         byteValue = ((data[byteOffset] & 0xFF) << bitOffset)
@@ -146,14 +147,15 @@ public int readBits(int n) {
       } else {
         byteValue = data[byteOffset];
       }
-      n -= 8;
-      returnValue |= (byteValue & 0xFF) << n;
+      numBits -= 8;
+      returnValue |= (byteValue & 0xFF) << numBits;
       byteOffset++;
     }
 
-    if (n > 0) {
-      int nextBit = bitOffset + n;
-      byte writeMask = (byte) (0xFF >> (8 - n));
+    // Read any remaining bits.
+    if (numBits > 0) {
+      int nextBit = bitOffset + numBits;
+      byte writeMask = (byte) (0xFF >> (8 - numBits));
 
       if (nextBit > 8) {
         // Combine bits from current byte and next byte.
diff --git a/library/src/main/java/com/google/android/exoplayer/util/ParserUtil.java b/library/src/main/java/com/google/android/exoplayer/util/ParserUtil.java
new file mode 100644
index 0000000000..32136889a7
--- /dev/null
+++ b/library/src/main/java/com/google/android/exoplayer/util/ParserUtil.java
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.util;
+
+import org.xmlpull.v1.XmlPullParser;
+import org.xmlpull.v1.XmlPullParserException;
+
+/**
+ * Parser utility functions.
+ */
+public final class ParserUtil {
+
+  private ParserUtil() {}
+
+  public static boolean isEndTag(XmlPullParser xpp, String name) throws XmlPullParserException {
+    return xpp.getEventType() == XmlPullParser.END_TAG && name.equals(xpp.getName());
+  }
+
+  public static boolean isStartTag(XmlPullParser xpp, String name)
+      throws XmlPullParserException {
+    return xpp.getEventType() == XmlPullParser.START_TAG && name.equals(xpp.getName());
+  }
+
+  public static boolean isStartTag(XmlPullParser xpp) throws XmlPullParserException {
+    return xpp.getEventType() == XmlPullParser.START_TAG;
+  }
+
+  /**
+   * Removes the namespace part ('^.*:') of the attributeName.
+   *
+   * @param attributeName the string to remove the namespace prefix from
+   * @return the name of the attribute without the prefix
+   */
+  public static String removeNamespacePrefix(String attributeName) {
+    return attributeName.replaceFirst("^.*:", "");
+  }
+}
diff --git a/library/src/main/java/com/google/android/exoplayer/util/Util.java b/library/src/main/java/com/google/android/exoplayer/util/Util.java
index c3b449034d..cfbd282c64 100644
--- a/library/src/main/java/com/google/android/exoplayer/util/Util.java
+++ b/library/src/main/java/com/google/android/exoplayer/util/Util.java
@@ -311,6 +311,20 @@ public static int binarySearchCeil(long[] a, long key, boolean inclusive, boolea
     return stayInBounds ? Math.min(list.size() - 1, index) : index;
   }
 
+  /**
+   * Creates an integer array containing the integers from 0 to {@code length - 1}.
+   *
+   * @param length The length of the array.
+   * @return The array.
+   */
+  public static int[] firstIntegersArray(int length) {
+    int[] firstIntegers = new int[length];
+    for (int i = 0; i < length; i++) {
+      firstIntegers[i] = i;
+    }
+    return firstIntegers;
+  }
+
   /**
    * Parses an xs:duration attribute value, returning the parsed duration in milliseconds.
    *
@@ -568,6 +582,27 @@ public static int getIntegerCodeForString(String string) {
     return result;
   }
 
+  /**
+   * Returns the top 32 bits of a long as an integer.
+   */
+  public static int getTopInt(long value) {
+    return (int) (value >>> 32);
+  }
+
+  /**
+   * Returns the bottom 32 bits of a long as an integer.
+   */
+  public static int getBottomInt(long value) {
+    return (int) value;
+  }
+
+  /**
+   * Returns a long created by concatenating the bits of two integers.
+   */
+  public static long getLong(int topInteger, int bottomInteger) {
+    return ((long) topInteger << 32) | (bottomInteger & 0xFFFFFFFFL);
+  }
+
   /**
    * Returns a hex string representation of the data provided.
    *
diff --git a/playbacktests/build.gradle b/playbacktests/build.gradle
new file mode 100644
index 0000000000..5a95cfff41
--- /dev/null
+++ b/playbacktests/build.gradle
@@ -0,0 +1,38 @@
+// Copyright (C) 2014 The Android Open Source Project
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//      http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+apply plugin: 'com.android.application'
+
+android {
+    compileSdkVersion 22
+    buildToolsVersion "22.0.1"
+
+    defaultConfig {
+        minSdkVersion 16
+        targetSdkVersion 22
+    }
+    buildTypes {
+        release {
+            minifyEnabled false
+            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.txt'
+        }
+    }
+
+    lintOptions {
+        abortOnError false
+    }
+}
+
+dependencies {
+    compile project(':library')
+}
diff --git a/playbacktests/src/main/AndroidManifest.xml b/playbacktests/src/main/AndroidManifest.xml
new file mode 100644
index 0000000000..01165915c2
--- /dev/null
+++ b/playbacktests/src/main/AndroidManifest.xml
@@ -0,0 +1,43 @@
+<?xml version="1.0" encoding="utf-8"?>
+<!-- Copyright (C) 2014 The Android Open Source Project
+
+     Licensed under the Apache License, Version 2.0 (the "License");
+     you may not use this file except in compliance with the License.
+     You may obtain a copy of the License at
+
+          http://www.apache.org/licenses/LICENSE-2.0
+
+     Unless required by applicable law or agreed to in writing, software
+     distributed under the License is distributed on an "AS IS" BASIS,
+     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+     See the License for the specific language governing permissions and
+     limitations under the License.
+-->
+
+<manifest xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:tools="http://schemas.android.com/tools"
+    package="com.google.android.exoplayer.playbacktests"
+    android:versionCode="1500"
+    android:versionName="1.5.0">
+
+  <uses-permission android:name="android.permission.INTERNET"/>
+  <uses-permission android:name="android.permission.WAKE_LOCK"/>
+
+  <uses-sdk android:minSdkVersion="9" android:targetSdkVersion="22"/>
+
+  <application android:debuggable="true"
+      android:allowBackup="false"
+      tools:ignore="MissingApplicationIcon,HardcodedDebugMode">
+    <uses-library android:name="android.test.runner"/>
+
+    <activity android:name="com.google.android.exoplayer.playbacktests.util.HostActivity"
+        android:configChanges="keyboardHidden|orientation|screenSize"
+        android:label="ExoPlayerTest"/>
+
+  </application>
+
+  <instrumentation
+      android:targetPackage="com.google.android.exoplayer.playbacktests"
+      android:name="android.test.InstrumentationTestRunner"/>
+
+</manifest>
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/gts/H264DashTest.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/gts/H264DashTest.java
new file mode 100644
index 0000000000..3303abaa6e
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/gts/H264DashTest.java
@@ -0,0 +1,335 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.gts;
+
+import com.google.android.exoplayer.CodecCounters;
+import com.google.android.exoplayer.DefaultLoadControl;
+import com.google.android.exoplayer.ExoPlayer;
+import com.google.android.exoplayer.LoadControl;
+import com.google.android.exoplayer.MediaCodecAudioTrackRenderer;
+import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
+import com.google.android.exoplayer.TrackRenderer;
+import com.google.android.exoplayer.chunk.ChunkSampleSource;
+import com.google.android.exoplayer.chunk.ChunkSource;
+import com.google.android.exoplayer.chunk.FormatEvaluator;
+import com.google.android.exoplayer.dash.DashChunkSource;
+import com.google.android.exoplayer.dash.DashTrackSelector;
+import com.google.android.exoplayer.dash.mpd.AdaptationSet;
+import com.google.android.exoplayer.dash.mpd.MediaPresentationDescription;
+import com.google.android.exoplayer.dash.mpd.MediaPresentationDescriptionParser;
+import com.google.android.exoplayer.dash.mpd.Period;
+import com.google.android.exoplayer.dash.mpd.Representation;
+import com.google.android.exoplayer.playbacktests.util.ActionSchedule;
+import com.google.android.exoplayer.playbacktests.util.CodecCountersUtil;
+import com.google.android.exoplayer.playbacktests.util.ExoHostedTest;
+import com.google.android.exoplayer.playbacktests.util.HostActivity;
+import com.google.android.exoplayer.playbacktests.util.LogcatLogger;
+import com.google.android.exoplayer.playbacktests.util.TestUtil;
+import com.google.android.exoplayer.upstream.DataSource;
+import com.google.android.exoplayer.upstream.DefaultAllocator;
+import com.google.android.exoplayer.upstream.DefaultUriDataSource;
+import com.google.android.exoplayer.util.Assertions;
+import com.google.android.exoplayer.util.Util;
+
+import android.annotation.TargetApi;
+import android.media.MediaCodec;
+import android.os.Handler;
+import android.test.ActivityInstrumentationTestCase2;
+import android.view.Surface;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * Tests H264 DASH playbacks using {@link ExoPlayer}.
+ */
+public final class H264DashTest extends ActivityInstrumentationTestCase2<HostActivity> {
+
+  private static final String TAG = "H264DashTest";
+
+  private static final long MAX_PLAYING_TIME_DISCREPANCY_MS = 2000;
+  private static final float MAX_DROPPED_VIDEO_FRAME_FRACTION = 0.01f;
+
+  private static final long MAX_ADDITIONAL_TIME_MS = 180000;
+  private static final int MIN_LOADABLE_RETRY_COUNT = 10;
+
+  private static final String SOURCE_URL = "https://storage.googleapis.com/exoplayer-test-media-1"
+      + "/gen/screens/dash-vod-single-segment/manifest-baseline.mpd";
+  private static final int SOURCE_VIDEO_FRAME_COUNT = 3840;
+  private static final int SOURCE_AUDIO_FRAME_COUNT = 5524;
+  private static final String AUDIO_REPRESENTATION_ID = "141";
+  private static final String VIDEO_REPRESENTATION_ID_240 = "avc-baseline-240";
+  private static final String VIDEO_REPRESENTATION_ID_480 = "avc-baseline-480";
+
+  public H264DashTest() {
+    super(HostActivity.class);
+  }
+
+  public void testBaseline480() throws IOException {
+    if (Util.SDK_INT < 16) {
+      // Pass.
+      return;
+    }
+    MediaPresentationDescription mpd = TestUtil.loadManifest(getActivity(), SOURCE_URL,
+        new MediaPresentationDescriptionParser());
+    H264DashHostedTest test = new H264DashHostedTest(mpd, true, AUDIO_REPRESENTATION_ID,
+        VIDEO_REPRESENTATION_ID_480);
+    getActivity().runTest(test, mpd.duration + MAX_ADDITIONAL_TIME_MS);
+  }
+
+  public void testBaselineAdaptive() throws IOException {
+    if (Util.SDK_INT < 16) {
+      // Pass.
+      return;
+    }
+    MediaPresentationDescription mpd = TestUtil.loadManifest(getActivity(), SOURCE_URL,
+        new MediaPresentationDescriptionParser());
+    H264DashHostedTest test = new H264DashHostedTest(mpd, true, AUDIO_REPRESENTATION_ID,
+        VIDEO_REPRESENTATION_ID_240, VIDEO_REPRESENTATION_ID_480);
+    getActivity().runTest(test, mpd.duration + MAX_ADDITIONAL_TIME_MS);
+  }
+
+  public void testBaselineAdaptiveWithSeeking() throws IOException {
+    if (Util.SDK_INT < 16) {
+      // Pass.
+      return;
+    }
+    MediaPresentationDescription mpd = TestUtil.loadManifest(getActivity(), SOURCE_URL,
+        new MediaPresentationDescriptionParser());
+    H264DashHostedTest test = new H264DashHostedTest(mpd, false, AUDIO_REPRESENTATION_ID,
+        VIDEO_REPRESENTATION_ID_240, VIDEO_REPRESENTATION_ID_480);
+    test.setSchedule(new ActionSchedule.Builder(TAG)
+        .delay(10000).seek(15000)
+        .delay(10000).seek(30000).seek(31000).seek(32000).seek(33000).seek(34000)
+        .delay(1000).pause().delay(1000).play()
+        .delay(1000).pause().seek(100000).delay(1000).play()
+        .build());
+    getActivity().runTest(test, mpd.duration + MAX_ADDITIONAL_TIME_MS);
+  }
+
+  public void testBaselineAdaptiveWithRendererDisabling() throws IOException {
+    if (Util.SDK_INT < 16) {
+      // Pass.
+      return;
+    }
+    MediaPresentationDescription mpd = TestUtil.loadManifest(getActivity(), SOURCE_URL,
+        new MediaPresentationDescriptionParser());
+    H264DashHostedTest test = new H264DashHostedTest(mpd, false, AUDIO_REPRESENTATION_ID,
+        VIDEO_REPRESENTATION_ID_240, VIDEO_REPRESENTATION_ID_480);
+    test.setSchedule(new ActionSchedule.Builder(TAG)
+        // Wait 10 seconds, disable the video renderer, wait another 5 seconds and enable it again.
+        .delay(10000).disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+        .delay(10000).enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+        // Ditto for the audio renderer.
+        .delay(10000).disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+        .delay(10000).enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+        // Wait 10 seconds, then disable and enable the video renderer 5 times in quick succession.
+        .delay(10000).disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.VIDEO_RENDERER_INDEX)
+        // Ditto for the audio renderer.
+        .delay(10000).disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .disableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+            .enableRenderer(H264DashHostedTest.AUDIO_RENDERER_INDEX)
+        .build());
+    getActivity().runTest(test, mpd.duration + MAX_ADDITIONAL_TIME_MS);
+  }
+
+  @TargetApi(16)
+  private static class H264DashHostedTest extends ExoHostedTest {
+
+    private static final int RENDERER_COUNT = 2;
+    private static final int VIDEO_RENDERER_INDEX = 0;
+    private static final int AUDIO_RENDERER_INDEX = 1;
+
+    private static final int BUFFER_SEGMENT_SIZE = 64 * 1024;
+    private static final int VIDEO_BUFFER_SEGMENTS = 200;
+    private static final int AUDIO_BUFFER_SEGMENTS = 60;
+
+    private static final String VIDEO_TAG = "Video";
+    private static final String AUDIO_TAG = "Audio";
+    private static final int VIDEO_EVENT_ID = 0;
+    private static final int AUDIO_EVENT_ID = 1;
+
+    private final MediaPresentationDescription mpd;
+    private final boolean fullPlaybackNoSeeking;
+    private String[] audioFormats;
+    private String[] videoFormats;
+
+    private CodecCounters videoCounters;
+    private CodecCounters audioCounters;
+
+    /**
+     * @param mpd The manifest.
+     * @param fullPlaybackNoSeeking True if the test will play the entire source with no seeking.
+     *     False otherwise.
+     * @param audioFormat The audio format.
+     * @param videoFormats The video formats.
+     */
+    public H264DashHostedTest(MediaPresentationDescription mpd, boolean fullPlaybackNoSeeking,
+        String audioFormat, String... videoFormats) {
+      super(RENDERER_COUNT);
+      this.mpd = Assertions.checkNotNull(mpd);
+      this.fullPlaybackNoSeeking = fullPlaybackNoSeeking;
+      this.audioFormats = new String[] {audioFormat};
+      this.videoFormats = videoFormats;
+    }
+
+    @Override
+    public TrackRenderer[] buildRenderers(HostActivity host, ExoPlayer player, Surface surface) {
+      Handler handler = new Handler();
+      LogcatLogger logger = new LogcatLogger(TAG, player);
+      LoadControl loadControl = new DefaultLoadControl(new DefaultAllocator(BUFFER_SEGMENT_SIZE));
+      String userAgent = TestUtil.getUserAgent(host);
+
+      // Build the video renderer.
+      DataSource videoDataSource = new DefaultUriDataSource(host, null, userAgent);
+      TrackSelector videoTrackSelector = new TrackSelector(AdaptationSet.TYPE_VIDEO, videoFormats);
+      ChunkSource videoChunkSource = new DashChunkSource(mpd, videoTrackSelector, videoDataSource,
+          new FormatEvaluator.RandomEvaluator(0));
+      ChunkSampleSource videoSampleSource = new ChunkSampleSource(videoChunkSource, loadControl,
+          VIDEO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, handler, logger, VIDEO_EVENT_ID,
+          MIN_LOADABLE_RETRY_COUNT);
+      MediaCodecVideoTrackRenderer videoRenderer = new MediaCodecVideoTrackRenderer(
+          videoSampleSource, MediaCodec.VIDEO_SCALING_MODE_SCALE_TO_FIT, 0, handler, logger, 50);
+      videoCounters = videoRenderer.codecCounters;
+      player.sendMessage(videoRenderer, MediaCodecVideoTrackRenderer.MSG_SET_SURFACE, surface);
+
+      // Build the audio renderer.
+      DataSource audioDataSource = new DefaultUriDataSource(host, null, userAgent);
+      TrackSelector audioTrackSelector = new TrackSelector(AdaptationSet.TYPE_AUDIO, audioFormats);
+      ChunkSource audioChunkSource = new DashChunkSource(mpd, audioTrackSelector, audioDataSource,
+          null);
+      ChunkSampleSource audioSampleSource = new ChunkSampleSource(audioChunkSource, loadControl,
+          AUDIO_BUFFER_SEGMENTS * BUFFER_SEGMENT_SIZE, handler, logger, AUDIO_EVENT_ID,
+          MIN_LOADABLE_RETRY_COUNT);
+      MediaCodecAudioTrackRenderer audioRenderer = new MediaCodecAudioTrackRenderer(
+          audioSampleSource, handler, logger);
+      audioCounters = audioRenderer.codecCounters;
+
+      TrackRenderer[] renderers = new TrackRenderer[RENDERER_COUNT];
+      renderers[VIDEO_RENDERER_INDEX] = videoRenderer;
+      renderers[AUDIO_RENDERER_INDEX] = audioRenderer;
+      return renderers;
+    }
+
+    @Override
+    protected void assertPassedInternal() {
+      if (fullPlaybackNoSeeking) {
+        // Audio is not adaptive and we didn't seek (which can re-instantiate the audio decoder
+        // in ExoPlayer), so the decoder output format should have changed exactly once. The output
+        // buffers should have changed 0 or 1 times.
+        CodecCountersUtil.assertOutputFormatChangedCount(AUDIO_TAG, audioCounters, 1);
+        CodecCountersUtil.assertOutputBuffersChangedLimit(AUDIO_TAG, audioCounters, 1);
+
+        if (videoFormats.length == 1) {
+          // Video is not adaptive, so the decoder output format should have changed exactly once.
+          // The output buffers should have changed 0 or 1 times.
+          CodecCountersUtil.assertOutputFormatChangedCount(VIDEO_TAG, videoCounters, 1);
+          CodecCountersUtil.assertOutputBuffersChangedLimit(VIDEO_TAG, videoCounters, 1);
+        }
+
+        // We shouldn't have skipped any output buffers.
+        CodecCountersUtil.assertSkippedOutputBufferCount(AUDIO_TAG, audioCounters, 0);
+        CodecCountersUtil.assertSkippedOutputBufferCount(VIDEO_TAG, videoCounters, 0);
+
+        // We allow one fewer output buffer due to the way that MediaCodecTrackRenderer and the
+        // underlying decoders handle the end of stream. This should be tightened up in the future.
+        CodecCountersUtil.assertTotalOutputBufferCount(VIDEO_TAG, videoCounters,
+            SOURCE_VIDEO_FRAME_COUNT - 1, SOURCE_VIDEO_FRAME_COUNT);
+        CodecCountersUtil.assertTotalOutputBufferCount(AUDIO_TAG, audioCounters,
+            SOURCE_AUDIO_FRAME_COUNT - 1, SOURCE_AUDIO_FRAME_COUNT);
+
+        // The total playing time should match the source duration.
+        long sourceDuration = mpd.duration;
+        long minAllowedActualPlayingTime = sourceDuration - MAX_PLAYING_TIME_DISCREPANCY_MS;
+        long maxAllowedActualPlayingTime = sourceDuration + MAX_PLAYING_TIME_DISCREPANCY_MS;
+        long actualPlayingTime = getTotalPlayingTimeMs();
+        assertTrue("Total playing time: " + actualPlayingTime + ". Actual media duration: "
+            + sourceDuration, minAllowedActualPlayingTime <= actualPlayingTime
+            && actualPlayingTime <= maxAllowedActualPlayingTime);
+      }
+
+      // Assert that the level of performance was acceptable.
+      int droppedFrameLimit = (int) Math.ceil(MAX_DROPPED_VIDEO_FRAME_FRACTION
+          * CodecCountersUtil.getTotalOutputBuffers(videoCounters));
+      CodecCountersUtil.assertDroppedOutputBufferLimit(VIDEO_TAG, videoCounters, droppedFrameLimit);
+    }
+
+    private static final class TrackSelector implements DashTrackSelector {
+
+      private final int adaptationSetType;
+      private final String[] representationIds;
+
+      private TrackSelector(int adaptationSetType, String[] representationIds) {
+        this.adaptationSetType = adaptationSetType;
+        this.representationIds = representationIds;
+      }
+
+      @Override
+      public void selectTracks(MediaPresentationDescription manifest, int periodIndex,
+          Output output) throws IOException {
+        Period period = manifest.getPeriod(periodIndex);
+        int adaptationSetIndex = period.getAdaptationSetIndex(adaptationSetType);
+        AdaptationSet adaptationSet = period.adaptationSets.get(adaptationSetIndex);
+        int[] representationIndices = getRepresentationIndices(representationIds, adaptationSet);
+        if (adaptationSetType == AdaptationSet.TYPE_VIDEO) {
+          output.adaptiveTrack(manifest, periodIndex, adaptationSetIndex, representationIndices);
+        }
+        for (int i = 0; i < representationIndices.length; i++) {
+          output.fixedTrack(manifest, periodIndex, adaptationSetIndex, representationIndices[i]);
+        }
+      }
+
+      private static int[] getRepresentationIndices(String[] representationIds,
+          AdaptationSet adaptationSet) {
+        List<Representation> representations = adaptationSet.representations;
+        int[] representationIndices = new int[representationIds.length];
+        for (int i = 0; i < representationIds.length; i++) {
+          String representationId = representationIds[i];
+          boolean foundIndex = false;
+          for (int j = 0; j < representations.size() && !foundIndex; j++) {
+            if (representations.get(j).format.id.equals(representationId)) {
+              representationIndices[i] = j;
+              foundIndex = true;
+            }
+          }
+          if (!foundIndex) {
+            throw new IllegalStateException("Representation " + representationId + " not found.");
+          }
+        }
+        return representationIndices;
+      }
+
+    }
+
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/Action.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/Action.java
new file mode 100644
index 0000000000..307380332f
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/Action.java
@@ -0,0 +1,147 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.ExoPlayer;
+
+import android.util.Log;
+
+/**
+ * Base class for actions to perform during playback tests.
+ */
+public abstract class Action {
+
+  private final String tag;
+  private final String description;
+
+  /**
+   * @param tag A tag to use for logging.
+   * @param description A description to be logged when the action is executed.
+   */
+  public Action(String tag, String description) {
+    this.tag = tag;
+    this.description = description;
+  }
+
+  /**
+   * Executes the action.
+   *
+   * @param player An {@link ExoPlayer} on which the action is executed.
+   */
+  public final void doAction(ExoPlayer player) {
+    Log.i(tag, description);
+    doActionImpl(player);
+  }
+
+  /**
+   * Called by {@link #doAction(ExoPlayer)} do actually perform the action.
+   *
+   * @param player An {@link ExoPlayer} on which the action is executed.
+   */
+  protected abstract void doActionImpl(ExoPlayer player);
+
+  /**
+   * Calls {@link ExoPlayer#seekTo(long)}.
+   */
+  public static final class Seek extends Action {
+
+    private final long positionMs;
+
+    /**
+     * @param tag A tag to use for logging.
+     * @param positionMs The seek position.
+     */
+    public Seek(String tag, long positionMs) {
+      super(tag, "Seek:" + positionMs);
+      this.positionMs = positionMs;
+    }
+
+    @Override
+    protected void doActionImpl(ExoPlayer player) {
+      player.seekTo(positionMs);
+    }
+
+  }
+
+  /**
+   * Calls {@link ExoPlayer#stop()}.
+   */
+  public static final class Stop extends Action {
+
+    /**
+     * @param tag A tag to use for logging.
+     */
+    public Stop(String tag) {
+      super(tag, "Stop");
+    }
+
+    @Override
+    protected void doActionImpl(ExoPlayer player) {
+      player.stop();
+    }
+
+  }
+
+  /**
+   * Calls {@link ExoPlayer#setPlayWhenReady(boolean)}.
+   */
+  public static final class SetPlayWhenReady extends Action {
+
+    private final boolean playWhenReady;
+
+    /**
+     * @param tag A tag to use for logging.
+     * @param playWhenReady The value to pass.
+     */
+    public SetPlayWhenReady(String tag, boolean playWhenReady) {
+      super(tag, playWhenReady ? "Play" : "Pause");
+      this.playWhenReady = playWhenReady;
+    }
+
+    @Override
+    protected void doActionImpl(ExoPlayer player) {
+      player.setPlayWhenReady(playWhenReady);
+    }
+
+  }
+
+  /**
+   * Calls {@link ExoPlayer#setSelectedTrack(int, int)}.
+   */
+  public static final class SetSelectedTrack extends Action {
+
+    private final int rendererIndex;
+    private final int trackIndex;
+
+    /**
+     * @param tag A tag to use for logging.
+     * @param rendererIndex The index of the renderer.
+     * @param trackIndex The index of the track.
+     */
+    public SetSelectedTrack(String tag, int rendererIndex, int trackIndex) {
+      super(tag, "SelectedTrack:" + rendererIndex + ":" + trackIndex);
+      this.rendererIndex = rendererIndex;
+      this.trackIndex = trackIndex;
+    }
+
+    @Override
+    protected void doActionImpl(ExoPlayer player) {
+      player.setSelectedTrack(rendererIndex, trackIndex);
+    }
+
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ActionSchedule.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ActionSchedule.java
new file mode 100644
index 0000000000..b78057aa39
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ActionSchedule.java
@@ -0,0 +1,226 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.ExoPlayer;
+import com.google.android.exoplayer.playbacktests.util.Action.Seek;
+import com.google.android.exoplayer.playbacktests.util.Action.SetPlayWhenReady;
+import com.google.android.exoplayer.playbacktests.util.Action.SetSelectedTrack;
+import com.google.android.exoplayer.playbacktests.util.Action.Stop;
+
+import android.os.Handler;
+
+/**
+ * Schedules a sequence of {@link Action}s for execution during a test.
+ */
+public final class ActionSchedule {
+
+  private final ActionNode rootNode;
+
+  /**
+   * @param rootNode The first node in the sequence.
+   */
+  private ActionSchedule(ActionNode rootNode) {
+    this.rootNode = rootNode;
+  }
+
+  /**
+   * Starts execution of the schedule.
+   *
+   * @param player The player to which each {@link Action} should be applied.
+   * @param mainHandler A handler associated with the main thread of the host activity.
+   */
+  /* package */ void start(ExoPlayer player, Handler mainHandler) {
+    rootNode.schedule(player, mainHandler);
+  }
+
+  /**
+   * A builder for {@link ActionSchedule} instances.
+   */
+  public static final class Builder {
+
+    private final String tag;
+    private final ActionNode rootNode;
+    private long currentDelayMs;
+
+    private ActionNode previousNode;
+
+    /**
+     * @param tag A tag to use for logging.
+     */
+    public Builder(String tag) {
+      this.tag = tag;
+      rootNode = new ActionNode(new RootAction(tag), 0);
+      previousNode = rootNode;
+    }
+
+    /**
+     * Schedules a delay between executing any previous actions and any subsequent ones.
+     *
+     * @param delayMs The delay in milliseconds.
+     * @return The builder, for convenience.
+     */
+    public Builder delay(long delayMs) {
+      currentDelayMs += delayMs;
+      return this;
+    }
+
+    /**
+     * Schedules an action to be executed.
+     *
+     * @param action The action to schedule.
+     * @return The builder, for convenience.
+     */
+    public Builder apply(Action action) {
+      ActionNode next = new ActionNode(action, currentDelayMs);
+      previousNode.setNext(next);
+      previousNode = next;
+      currentDelayMs = 0;
+      return this;
+    }
+
+    /**
+     * Schedules a seek action to be executed.
+     *
+     * @param positionMs The seek position.
+     * @return The builder, for convenience.
+     */
+    public Builder seek(long positionMs) {
+      return apply(new Seek(tag, positionMs));
+    }
+
+    /**
+     * Schedules a stop action to be executed.
+     *
+     * @return The builder, for convenience.
+     */
+    public Builder stop() {
+      return apply(new Stop(tag));
+    }
+
+    /**
+     * Schedules a play action to be executed.
+     *
+     * @return The builder, for convenience.
+     */
+    public Builder play() {
+      return apply(new SetPlayWhenReady(tag, true));
+    }
+
+    /**
+     * Schedules a pause action to be executed.
+     *
+     * @return The builder, for convenience.
+     */
+    public Builder pause() {
+      return apply(new SetPlayWhenReady(tag, false));
+    }
+
+    /**
+     * Schedules a renderer enable action to be executed.
+     *
+     * @return The builder, for convenience.
+     */
+    public Builder enableRenderer(int index) {
+      return apply(new SetSelectedTrack(tag, index, ExoPlayer.TRACK_DEFAULT));
+    }
+
+    /**
+     * Schedules a renderer disable action to be executed.
+     *
+     * @return The builder, for convenience.
+     */
+    public Builder disableRenderer(int index) {
+      return apply(new SetSelectedTrack(tag, index, ExoPlayer.TRACK_DISABLED));
+    }
+
+    public ActionSchedule build() {
+      return new ActionSchedule(rootNode);
+    }
+
+  }
+
+  /**
+   * Wraps an {@link Action}, allowing a delay and a next {@link Action} to be specified.
+   */
+  private static final class ActionNode implements Runnable {
+
+    private final Action action;
+    private final long delayMs;
+
+    private ActionNode next;
+
+    private ExoPlayer player;
+    private Handler mainHandler;
+
+    /**
+     * @param action The wrapped action.
+     * @param delayMs The delay between the node being scheduled and the action being executed.
+     */
+    public ActionNode(Action action, long delayMs) {
+      this.action = action;
+      this.delayMs = delayMs;
+    }
+
+    /**
+     * Sets the next action.
+     *
+     * @param next The next {@link Action}.
+     */
+    public void setNext(ActionNode next) {
+      this.next = next;
+    }
+
+    /**
+     * Schedules {@link #action} to be executed after {@link #delayMs}. The {@link #next} node
+     * will be scheduled immediately after {@link #action} is executed.
+     *
+     * @param player The player to which each {@link Action} should be applied.
+     * @param mainHandler A handler associated with the main thread of the host activity.
+     */
+    public void schedule(ExoPlayer player, Handler mainHandler) {
+      this.player = player;
+      this.mainHandler = mainHandler;
+      mainHandler.postDelayed(this, delayMs);
+    }
+
+    @Override
+    public void run() {
+      action.doAction(player);
+      if (next != null) {
+        next.schedule(player, mainHandler);
+      }
+    }
+
+  }
+
+  /**
+   * A no-op root action.
+   */
+  private static final class RootAction extends Action {
+
+    public RootAction(String tag) {
+      super(tag, "Root");
+    }
+
+    @Override
+    protected void doActionImpl(ExoPlayer player) {
+      // Do nothing.
+    }
+
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/CodecCountersUtil.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/CodecCountersUtil.java
new file mode 100644
index 0000000000..949b63d5c6
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/CodecCountersUtil.java
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.CodecCounters;
+
+import junit.framework.TestCase;
+
+/**
+ * Assertions for {@link CodecCounters}.
+ */
+public final class CodecCountersUtil {
+
+  private CodecCountersUtil() {}
+
+  /**
+   * Returns the sum of the skipped, dropped and rendered buffers.
+   *
+   * @param counters The counters for which the total should be calculated.
+   * @return The sum of the skipped, dropped and rendered buffers.
+   */
+  public static int getTotalOutputBuffers(CodecCounters counters) {
+    return counters.skippedOutputBufferCount + counters.droppedOutputBufferCount
+        + counters.renderedOutputBufferCount;
+  }
+
+  public static void assertOutputFormatChangedCount(String name, CodecCounters counters,
+      int expected) {
+    counters.ensureUpdated();
+    int actual = counters.outputFormatChangedCount;
+    TestCase.assertEquals("Codec(" + name + ") output format changed " + actual + " times. "
+        + "Expected " + expected + " times.", expected, actual);
+  }
+
+  public static void assertOutputBuffersChangedLimit(String name, CodecCounters counters,
+      int limit) {
+    counters.ensureUpdated();
+    int actual = counters.outputBuffersChangedCount;
+    TestCase.assertTrue("Codec(" + name + ") output buffers changed " + actual + " times. "
+        + "Limit: " + limit + ".", actual <= limit);
+  }
+
+  public static void assertSkippedOutputBufferCount(String name, CodecCounters counters,
+      int expected) {
+    counters.ensureUpdated();
+    int actual = counters.skippedOutputBufferCount;
+    TestCase.assertEquals("Codec(" + name + ") skipped " + actual + " buffers. Expected "
+        + expected + ".", expected, actual);
+  }
+
+  public static void assertTotalOutputBufferCount(String name, CodecCounters counters,
+      int minCount, int maxCount) {
+    counters.ensureUpdated();
+    int actual = getTotalOutputBuffers(counters);
+    TestCase.assertTrue("Codec(" + name + ") output " + actual + " buffers. Expected in range ["
+        + minCount + ", " + maxCount + "].", minCount <= actual && actual <= maxCount);
+  }
+
+  public static void assertDroppedOutputBufferLimit(String name, CodecCounters counters,
+      int limit) {
+    counters.ensureUpdated();
+    int actual = counters.droppedOutputBufferCount;
+    TestCase.assertTrue("Codec(" + name + ") was late decoding: " + actual + " buffers. "
+        + "Limit: " + limit + ".", actual <= limit);
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ExoHostedTest.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ExoHostedTest.java
new file mode 100644
index 0000000000..a21ffffa30
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/ExoHostedTest.java
@@ -0,0 +1,177 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.ExoPlaybackException;
+import com.google.android.exoplayer.ExoPlayer;
+import com.google.android.exoplayer.TrackRenderer;
+import com.google.android.exoplayer.audio.AudioTrack;
+import com.google.android.exoplayer.playbacktests.util.HostActivity.HostedTest;
+
+import android.os.Handler;
+import android.os.SystemClock;
+import android.view.Surface;
+
+/**
+ * A {@link HostedTest} for {@link ExoPlayer} playback tests.
+ */
+public abstract class ExoHostedTest implements HostedTest, ExoPlayer.Listener {
+
+  static {
+    // ExoPlayer's AudioTrack class is able to work around spurious timestamps reported by the
+    // platform (by ignoring them). Disable this workaround, since we're interested in testing
+    // that the underlying platform is behaving correctly.
+    AudioTrack.failOnSpuriousAudioTimestamp = true;
+  }
+
+  private final int rendererCount;
+  private final boolean failOnPlayerError;
+
+  private ActionSchedule pendingSchedule;
+  private Handler actionHandler;
+  private ExoPlayer player;
+  private ExoPlaybackException playerError;
+  private boolean playerWasPrepared;
+  private boolean playerFinished;
+  private boolean playing;
+  private long totalPlayingTimeMs;
+  private long lastPlayingStartTimeMs;
+
+  /**
+   * Constructs a test that fails if a player error occurs.
+   *
+   * @param rendererCount The number of renderers that will be injected into the player.
+   */
+  public ExoHostedTest(int rendererCount) {
+    this(rendererCount, true);
+  }
+
+  /**
+   * @param rendererCount The number of renderers that will be injected into the player.
+   * @param failOnPlayerError True if a player error should be considered a test failure. False
+   *     otherwise.
+   */
+  public ExoHostedTest(int rendererCount, boolean failOnPlayerError) {
+    this.rendererCount = rendererCount;
+    this.failOnPlayerError = failOnPlayerError;
+  }
+
+  /**
+   * Sets a schedule to be applied during the test.
+   *
+   * @param schedule The schedule.
+   */
+  public final void setSchedule(ActionSchedule schedule) {
+    if (player == null) {
+      pendingSchedule = schedule;
+    } else {
+      schedule.start(player, actionHandler);
+    }
+  }
+
+  // HostedTest implementation
+
+  @Override
+  public final void initialize(HostActivity host, Surface surface) {
+    // Build the player.
+    player = ExoPlayer.Factory.newInstance(rendererCount);
+    player.addListener(this);
+    player.prepare(buildRenderers(host, player, surface));
+    player.setPlayWhenReady(true);
+    actionHandler = new Handler();
+    // Schedule any pending actions.
+    if (pendingSchedule != null) {
+      pendingSchedule.start(player, actionHandler);
+      pendingSchedule = null;
+    }
+  }
+
+  @Override
+  public final void release() {
+    actionHandler.removeCallbacksAndMessages(null);
+    player.release();
+    player = null;
+  }
+
+  @Override
+  public final boolean isFinished() {
+    return playerFinished;
+  }
+
+  @Override
+  public final void assertPassed() {
+    if (failOnPlayerError && playerError != null) {
+      throw new Error(playerError);
+    }
+    assertPassedInternal();
+  }
+
+  // ExoPlayer.Listener
+
+  @Override
+  public final void onPlayerStateChanged(boolean playWhenReady, int playbackState) {
+    playerWasPrepared |= playbackState != ExoPlayer.STATE_IDLE;
+    if (playbackState == ExoPlayer.STATE_ENDED
+        || (playbackState == ExoPlayer.STATE_IDLE && playerWasPrepared)) {
+      playerFinished = true;
+    }
+    boolean playing = playWhenReady && playbackState == ExoPlayer.STATE_READY;
+    if (!this.playing && playing) {
+      lastPlayingStartTimeMs = SystemClock.elapsedRealtime();
+    } else if (this.playing && !playing) {
+      totalPlayingTimeMs += SystemClock.elapsedRealtime() - lastPlayingStartTimeMs;
+    }
+    this.playing = playing;
+  }
+
+  @Override
+  public final void onPlayerError(ExoPlaybackException error) {
+    playerWasPrepared = true;
+    playerError = error;
+    onPlayerErrorInternal(error);
+  }
+
+  @Override
+  public final void onPlayWhenReadyCommitted() {
+    // Do nothing.
+  }
+
+  // Internal logic
+
+  @SuppressWarnings("unused")
+  protected abstract TrackRenderer[] buildRenderers(HostActivity host, ExoPlayer player,
+      Surface surface) throws IllegalStateException;
+
+  @SuppressWarnings("unused")
+  protected void onPlayerErrorInternal(ExoPlaybackException error) {
+    // Do nothing. Interested subclasses may override.
+  }
+
+  protected void assertPassedInternal() {
+    // Do nothing. Subclasses may override to add additional assertions.
+  }
+
+  // Utility methods and actions for subclasses.
+
+  protected final long getTotalPlayingTimeMs() {
+    return totalPlayingTimeMs;
+  }
+
+  protected final ExoPlaybackException getError() {
+    return playerError;
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/HostActivity.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/HostActivity.java
new file mode 100644
index 0000000000..83c1b51943
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/HostActivity.java
@@ -0,0 +1,249 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import static junit.framework.Assert.fail;
+
+import com.google.android.exoplayer.playbacktests.R;
+import com.google.android.exoplayer.util.Assertions;
+import com.google.android.exoplayer.util.Util;
+
+import android.annotation.SuppressLint;
+import android.app.Activity;
+import android.content.Context;
+import android.net.wifi.WifiManager;
+import android.net.wifi.WifiManager.WifiLock;
+import android.os.Bundle;
+import android.os.ConditionVariable;
+import android.os.Handler;
+import android.os.PowerManager;
+import android.os.PowerManager.WakeLock;
+import android.util.Log;
+import android.view.Surface;
+import android.view.SurfaceHolder;
+import android.view.SurfaceView;
+import android.view.Window;
+
+/**
+ * A host activity for performing playback tests.
+ */
+public final class HostActivity extends Activity implements SurfaceHolder.Callback {
+
+  /**
+   * Interface for tests that run inside of a {@link HostActivity}.
+   */
+  public interface HostedTest {
+
+    /**
+     * Called once the activity has been resumed and its surface has been created.
+     * <p>
+     * Called on the main thread.
+     *
+     * @param host The host in which the test is being run.
+     * @param surface The created surface.
+     */
+    void initialize(HostActivity host, Surface surface);
+
+    /**
+     * Called when the test has finished, or if the activity is paused or its surface is destroyed.
+     * <p>
+     * Called on the main thread.
+     */
+    void release();
+
+    /**
+     * Called periodically to check whether the test has finished.
+     * <p>
+     * Called on the main thread.
+     *
+     * @return True if the test has finished. False otherwise.
+     */
+    boolean isFinished();
+
+    /**
+     * Asserts that the test passed.
+     * <p>
+     * Called on the test thread once the test has reported that it's finished and after the test
+     * has been released.
+     */
+    void assertPassed();
+
+  }
+
+  private static final String TAG = "HostActivity";
+
+  private WakeLock wakeLock;
+  private WifiLock wifiLock;
+
+  private SurfaceView surfaceView;
+  private Handler mainHandler;
+  private CheckFinishedRunnable checkFinishedRunnable;
+
+  private HostedTest hostedTest;
+  private ConditionVariable hostedTestReleasedCondition;
+  private boolean hostedTestInitialized;
+  private boolean hostedTestFinished;
+
+  /**
+   * Executes a {@link HostedTest} inside the host.
+   * <p>
+   * Must only be called once on each instance. Must be called from the test thread.
+   *
+   * @param hostedTest The test to execute.
+   * @param timeoutMs The number of milliseconds to wait for the test to finish. If the timeout
+   *     is exceeded then the test will fail.
+   */
+  public void runTest(final HostedTest hostedTest, long timeoutMs) {
+    Assertions.checkArgument(timeoutMs > 0);
+    Assertions.checkState(Thread.currentThread() != getMainLooper().getThread());
+    runOnUiThread(new Runnable() {
+      @Override
+      public void run() {
+        Assertions.checkState(HostActivity.this.hostedTest == null);
+        HostActivity.this.hostedTest = Assertions.checkNotNull(hostedTest);
+        maybeInitializeHostedTest();
+      }
+    });
+    if (hostedTestReleasedCondition.block(timeoutMs)) {
+      if (hostedTestFinished) {
+        Log.d(TAG, "Test finished. Checking pass conditions.");
+        hostedTest.assertPassed();
+        Log.d(TAG, "Pass conditions checked.");
+      } else {
+        Log.e(TAG, "Test released before it finished. Activity may have been paused whilst test "
+            + "was in progress.");
+        fail();
+      }
+    } else {
+      Log.e(TAG, "Test timed out after " + timeoutMs + " ms.");
+      fail();
+    }
+  }
+
+  // Activity lifecycle
+
+  @Override
+  public void onCreate(Bundle savedInstanceState) {
+    super.onCreate(savedInstanceState);
+    requestWindowFeature(Window.FEATURE_NO_TITLE);
+    setContentView(R.layout.host_activity);
+    surfaceView = (SurfaceView) findViewById(R.id.surface_view);
+    surfaceView.getHolder().addCallback(this);
+    mainHandler = new Handler();
+    hostedTestReleasedCondition = new ConditionVariable();
+    checkFinishedRunnable = new CheckFinishedRunnable();
+  }
+
+  @Override
+  public void onStart() {
+    Context appContext = getApplicationContext();
+    WifiManager wifiManager = (WifiManager) appContext.getSystemService(Context.WIFI_SERVICE);
+    wifiLock = wifiManager.createWifiLock(getWifiLockMode(), TAG);
+    wifiLock.acquire();
+    PowerManager powerManager = (PowerManager) appContext.getSystemService(Context.POWER_SERVICE);
+    wakeLock = powerManager.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, TAG);
+    wakeLock.acquire();
+    super.onStart();
+  }
+
+  @Override
+  public void onResume() {
+    super.onResume();
+    maybeInitializeHostedTest();
+  }
+
+  @Override
+  public void onPause() {
+    super.onPause();
+    maybeReleaseHostedTest();
+  }
+
+  @Override
+  public void onStop() {
+    super.onStop();
+    wakeLock.release();
+    wakeLock = null;
+    wifiLock.release();
+    wifiLock = null;
+  }
+
+  // SurfaceHolder.Callback
+
+  @Override
+  public void surfaceCreated(SurfaceHolder holder) {
+    maybeInitializeHostedTest();
+  }
+
+  @Override
+  public void surfaceDestroyed(SurfaceHolder holder) {
+    maybeReleaseHostedTest();
+  }
+
+  @Override
+  public void surfaceChanged(SurfaceHolder holder, int format, int width, int height) {
+    // Do nothing.
+  }
+
+  // Internal logic
+
+  private void maybeInitializeHostedTest() {
+    if (hostedTest == null || hostedTestInitialized) {
+      return;
+    }
+    Surface surface = surfaceView.getHolder().getSurface();
+    if (surface != null && surface.isValid()) {
+      hostedTestInitialized = true;
+      Log.d(TAG, "Initializing test.");
+      hostedTest.initialize(this, surface);
+      checkFinishedRunnable.startChecking();
+    }
+  }
+
+  private void maybeReleaseHostedTest() {
+    if (hostedTest != null && hostedTestInitialized) {
+      hostedTest.release();
+      hostedTest = null;
+      mainHandler.removeCallbacks(checkFinishedRunnable);
+      hostedTestReleasedCondition.open();
+    }
+  }
+
+  @SuppressLint("InlinedApi")
+  private static final int getWifiLockMode() {
+    return Util.SDK_INT < 12 ? WifiManager.WIFI_MODE_FULL : WifiManager.WIFI_MODE_FULL_HIGH_PERF;
+  }
+
+  private final class CheckFinishedRunnable implements Runnable {
+
+    private static final long CHECK_INTERVAL_MS = 1000;
+
+    private void startChecking() {
+      mainHandler.post(this);
+    }
+
+    @Override
+    public void run() {
+      if (hostedTest.isFinished()) {
+        hostedTestFinished = true;
+        finish();
+      } else {
+        mainHandler.postDelayed(this, CHECK_INTERVAL_MS);
+      }
+    }
+
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/LogcatLogger.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/LogcatLogger.java
new file mode 100644
index 0000000000..320af8e924
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/LogcatLogger.java
@@ -0,0 +1,169 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.ExoPlaybackException;
+import com.google.android.exoplayer.ExoPlayer;
+import com.google.android.exoplayer.MediaCodecAudioTrackRenderer;
+import com.google.android.exoplayer.MediaCodecTrackRenderer.DecoderInitializationException;
+import com.google.android.exoplayer.MediaCodecVideoTrackRenderer;
+import com.google.android.exoplayer.audio.AudioTrack.InitializationException;
+import com.google.android.exoplayer.audio.AudioTrack.WriteException;
+import com.google.android.exoplayer.chunk.ChunkSampleSource;
+import com.google.android.exoplayer.chunk.Format;
+import com.google.android.exoplayer.hls.HlsSampleSource;
+
+import android.media.MediaCodec.CryptoException;
+import android.util.Log;
+import android.view.Surface;
+
+import java.io.IOException;
+import java.text.NumberFormat;
+import java.util.Locale;
+
+/**
+ * Logs information reported by an {@link ExoPlayer} instance and various player components.
+ */
+public final class LogcatLogger implements ExoPlayer.Listener,
+    MediaCodecVideoTrackRenderer.EventListener, MediaCodecAudioTrackRenderer.EventListener,
+    ChunkSampleSource.EventListener, HlsSampleSource.EventListener {
+
+  private static final NumberFormat TIME_FORMAT;
+  static {
+    TIME_FORMAT = NumberFormat.getInstance(Locale.US);
+    TIME_FORMAT.setMinimumFractionDigits(2);
+    TIME_FORMAT.setMaximumFractionDigits(2);
+  }
+
+  private final String tag;
+  private final ExoPlayer player;
+
+  /**
+   * @param tag A tag to use for logging.
+   * @param player The player.
+   */
+  public LogcatLogger(String tag, ExoPlayer player) {
+    this.tag = tag;
+    this.player = player;
+    player.addListener(this);
+  }
+
+  // ExoPlayer.Listener.
+
+  @Override
+  public final void onPlayerStateChanged(boolean playWhenReady, int playbackState) {
+    Log.i(tag, "Player state: " + getTimeString(player.getCurrentPosition()) + ", "
+        + playWhenReady + ", " + getStateString(playbackState));
+  }
+
+  @Override
+  public final void onPlayerError(ExoPlaybackException e) {
+    Log.e(tag, "Player failed", e);
+  }
+
+  @Override
+  public void onPlayWhenReadyCommitted() {}
+
+  // Component listeners.
+
+  @Override
+  public void onDecoderInitializationError(DecoderInitializationException e) {
+    Log.e(tag, "Decoder initialization error", e);
+  }
+
+  @Override
+  public void onCryptoError(CryptoException e) {
+    Log.e(tag, "Crypto error", e);
+  }
+
+  @Override
+  public void onLoadError(int sourceId, IOException e) {
+    Log.e(tag, "Load error (" + sourceId + ")", e);
+  }
+
+  @Override
+  public void onAudioTrackInitializationError(InitializationException e) {
+    Log.e(tag, "Audio track initialization error", e);
+  }
+
+  @Override
+  public void onAudioTrackWriteError(WriteException e) {
+    Log.e(tag, "Audio track write error", e);
+  }
+
+  @Override
+  public void onDroppedFrames(int count, long elapsed) {
+    Log.w(tag, "Dropped frames (" + count + ")");
+  }
+
+  @Override
+  public void onDecoderInitialized(String decoderName, long elapsedRealtimeMs,
+      long initializationDurationMs) {
+    Log.i(tag, "Initialized decoder: " + decoderName);
+  }
+
+  @Override
+  public void onDownstreamFormatChanged(int sourceId, Format format, int trigger,
+      long mediaTimeMs) {
+    Log.i(tag, "Downstream format changed (" + sourceId + "): " + format.id);
+  }
+
+  @Override
+  public void onVideoSizeChanged(int width, int height, int unappliedRotationDegrees,
+      float pixelWidthHeightRatio) {
+    Log.i(tag, "Video size changed: " + width + "x" + height);
+  }
+
+  @Override
+  public void onLoadStarted(int sourceId, long length, int type, int trigger, Format format,
+      long mediaStartTimeMs, long mediaEndTimeMs) {}
+
+  @Override
+  public void onLoadCompleted(int sourceId, long bytesLoaded, int type, int trigger,
+      Format format, long mediaStartTimeMs, long mediaEndTimeMs, long elapsedRealtimeMs,
+      long loadDurationMs) {}
+
+  @Override
+  public void onLoadCanceled(int sourceId, long bytesLoaded) {}
+
+  @Override
+  public void onUpstreamDiscarded(int sourceId, long mediaStartTimeMs, long mediaEndTimeMs) {}
+
+  @Override
+  public void onDrawnToSurface(Surface surface) {}
+
+  private static String getStateString(int state) {
+    switch (state) {
+      case ExoPlayer.STATE_BUFFERING:
+        return "B";
+      case ExoPlayer.STATE_ENDED:
+        return "E";
+      case ExoPlayer.STATE_IDLE:
+        return "I";
+      case ExoPlayer.STATE_PREPARING:
+        return "P";
+      case ExoPlayer.STATE_READY:
+        return "R";
+      default:
+        return "?";
+    }
+  }
+
+  private static String getTimeString(long timeMs) {
+    return TIME_FORMAT.format((timeMs) / 1000f);
+  }
+
+}
diff --git a/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/TestUtil.java b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/TestUtil.java
new file mode 100644
index 0000000000..b5027b9309
--- /dev/null
+++ b/playbacktests/src/main/java/com/google/android/exoplayer/playbacktests/util/TestUtil.java
@@ -0,0 +1,110 @@
+/*
+ * Copyright (C) 2014 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package com.google.android.exoplayer.playbacktests.util;
+
+import com.google.android.exoplayer.upstream.DefaultUriDataSource;
+import com.google.android.exoplayer.upstream.UriLoadable;
+import com.google.android.exoplayer.util.ManifestFetcher;
+import com.google.android.exoplayer.util.ManifestFetcher.ManifestCallback;
+import com.google.android.exoplayer.util.Util;
+
+import android.content.Context;
+import android.os.ConditionVariable;
+
+import java.io.IOException;
+
+/**
+ * Utility methods for ExoPlayer playback tests.
+ */
+public final class TestUtil {
+
+  private TestUtil() {}
+
+  /**
+   * Gets a suitable user agent string for ExoPlayer playback tests.
+   *
+   * @param context A context.
+   * @return The user agent.
+   */
+  public static String getUserAgent(Context context) {
+    return Util.getUserAgent(context, "ExoPlayerPlaybackTests");
+  }
+
+  /**
+   * Loads a manifest.
+   *
+   * @param context A context.
+   * @param url The manifest url.
+   * @param parser A suitable parser for the manifest.
+   * @return The parser manifest.
+   * @throws IOException If an error occurs loading the manifest.
+   */
+  public static <T> T loadManifest(Context context, String url, UriLoadable.Parser<T> parser)
+      throws IOException {
+    String userAgent = getUserAgent(context);
+    DefaultUriDataSource manifestDataSource = new DefaultUriDataSource(context, userAgent);
+    ManifestFetcher<T> manifestFetcher = new ManifestFetcher<>(url, manifestDataSource, parser);
+    SyncManifestCallback<T> callback = new SyncManifestCallback<>();
+    manifestFetcher.singleLoad(context.getMainLooper(), callback);
+    return callback.getResult();
+  }
+
+  /**
+   * A {@link ManifestCallback} that provides a blocking {@link #getResult()} method for retrieving
+   * the result.
+   *
+   * @param <T> The type of the manifest.
+   */
+  private static final class SyncManifestCallback<T> implements ManifestCallback<T> {
+
+    private final ConditionVariable haveResultCondition;
+
+    private T result;
+    private IOException error;
+
+    public SyncManifestCallback() {
+      haveResultCondition = new ConditionVariable();
+    }
+
+    @Override
+    public void onSingleManifest(T manifest) {
+      result = manifest;
+      haveResultCondition.open();
+
+    }
+    @Override
+    public void onSingleManifestError(IOException e) {
+      error = e;
+      haveResultCondition.open();
+    }
+
+    /**
+     * Blocks for the result.
+     *
+     * @return The loaded manifest.
+     * @throws IOException If an error occurred loading the manifest.
+     */
+    public T getResult() throws IOException {
+      haveResultCondition.block();
+      if (error != null) {
+        throw error;
+      }
+      return result;
+    }
+
+  }
+
+}
diff --git a/playbacktests/src/main/project.properties b/playbacktests/src/main/project.properties
new file mode 100644
index 0000000000..4fdc858b92
--- /dev/null
+++ b/playbacktests/src/main/project.properties
@@ -0,0 +1,13 @@
+# This file is automatically generated by Android Tools.
+# Do not modify this file -- YOUR CHANGES WILL BE ERASED!
+#
+# This file must be checked in Version Control Systems.
+#
+# To customize properties used by the Ant build system use,
+# "ant.properties", and override values to adapt the script to your
+# project structure.
+
+# Project target.
+target=android-22
+android.library=false
+android.library.reference.1=../../../library/src/main
diff --git a/playbacktests/src/main/res/layout/host_activity.xml b/playbacktests/src/main/res/layout/host_activity.xml
new file mode 100644
index 0000000000..75a88b823e
--- /dev/null
+++ b/playbacktests/src/main/res/layout/host_activity.xml
@@ -0,0 +1,28 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!-- Copyright (C) 2014 The Android Open Source Project
+
+     Licensed under the Apache License, Version 2.0 (the "License");
+     you may not use this file except in compliance with the License.
+     You may obtain a copy of the License at
+
+          http://www.apache.org/licenses/LICENSE-2.0
+
+     Unless required by applicable law or agreed to in writing, software
+     distributed under the License is distributed on an "AS IS" BASIS,
+     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+     See the License for the specific language governing permissions and
+     limitations under the License.
+-->
+<FrameLayout xmlns:android="http://schemas.android.com/apk/res/android"
+    android:id="@+id/root"
+    android:focusable="true"
+    android:layout_width="match_parent"
+    android:layout_height="match_parent"
+    android:keepScreenOn="true">
+
+  <SurfaceView android:id="@+id/surface_view"
+      android:layout_width="match_parent"
+      android:layout_height="match_parent"
+      android:layout_gravity="center"/>
+
+</FrameLayout>
diff --git a/settings.gradle b/settings.gradle
index 7441d135d4..70fb45ca11 100644
--- a/settings.gradle
+++ b/settings.gradle
@@ -13,6 +13,7 @@
 // limitations under the License.
 include ':library'
 include ':demo'
+include ':playbacktests'
 include ':opus-extension'
 include ':vp9-extension'
 include ':webm-sw-demo'
