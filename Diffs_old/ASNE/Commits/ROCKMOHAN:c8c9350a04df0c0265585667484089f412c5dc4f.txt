diff --git a/3A_1st_DNN.ipynb b/3A_1st_DNN.ipynb
deleted file mode 100644
index 7ed6356..0000000
--- a/3A_1st_DNN.ipynb
+++ /dev/null
@@ -1,768 +0,0 @@
-{
-  "nbformat": 4,
-  "nbformat_minor": 0,
-  "metadata": {
-    "colab": {
-      "name": "3A - 1st DNN.ipynb",
-      "version": "0.3.2",
-      "provenance": [],
-      "collapsed_sections": []
-    },
-    "kernelspec": {
-      "name": "python3",
-      "display_name": "Python 3"
-    },
-    "accelerator": "GPU"
-  },
-  "cells": [
-    {
-      "metadata": {
-        "id": "aNyZv-Ec52ot",
-        "colab_type": "text"
-      },
-      "cell_type": "markdown",
-      "source": [
-        "# **Import Libraries and modules**"
-      ]
-    },
-    {
-      "metadata": {
-        "id": "3m3w1Cw49Zkt",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "# https://keras.io/\n",
-        "# !pip install -q keras\n",
-        "import keras"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "Eso6UHE080D4",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "import numpy as np\n",
-        "\n",
-        "from keras.models import Sequential\n",
-        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
-        "from keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
-        "from keras.utils import np_utils\n",
-        "\n",
-        "from keras.datasets import mnist"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "zByEi95J86RD",
-        "colab_type": "text"
-      },
-      "cell_type": "markdown",
-      "source": [
-        "### Load pre-shuffled MNIST data into train and test sets"
-      ]
-    },
-    {
-      "metadata": {
-        "id": "7eRM0QWN83PV",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "4a4Be72j8-ZC",
-        "colab_type": "code",
-        "outputId": "0f16c5c8-2758-4467-996f-6f399d18d68f",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 299
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "print (X_train.shape)\n",
-        "from matplotlib import pyplot as plt\n",
-        "%matplotlib inline\n",
-        "plt.imshow(X_train[0])"
-      ],
-      "execution_count": 102,
-      "outputs": [
-        {
-          "output_type": "stream",
-          "text": [
-            "(60000, 28, 28)\n"
-          ],
-          "name": "stdout"
-        },
-        {
-          "output_type": "execute_result",
-          "data": {
-            "text/plain": [
-              "<matplotlib.image.AxesImage at 0x7fddb030c668>"
-            ]
-          },
-          "metadata": {
-            "tags": []
-          },
-          "execution_count": 102
-        },
-        {
-          "output_type": "display_data",
-          "data": {
-            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
-            "text/plain": [
-              "<Figure size 432x288 with 1 Axes>"
-            ]
-          },
-          "metadata": {
-            "tags": []
-          }
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "dkmprriw9AnZ",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
-        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "X2m4YS4E9CRh",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "X_train = X_train.astype('float32')\n",
-        "X_test = X_test.astype('float32')\n",
-        "X_train /= 255\n",
-        "X_test /= 255"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "0Mn0vAYD9DvB",
-        "colab_type": "code",
-        "outputId": "6b71dc2e-51d4-4b1b-8999-ad0815a9b7be",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 34
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "y_train[:10]"
-      ],
-      "execution_count": 105,
-      "outputs": [
-        {
-          "output_type": "execute_result",
-          "data": {
-            "text/plain": [
-              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
-            ]
-          },
-          "metadata": {
-            "tags": []
-          },
-          "execution_count": 105
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "ZG8JiXR39FHC",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
-        "Y_train = np_utils.to_categorical(y_train, 10)\n",
-        "Y_test = np_utils.to_categorical(y_test, 10)"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "fYlFRvKS9HMB",
-        "colab_type": "code",
-        "outputId": "483ea2e9-b333-439c-d1e3-9a4a0eb9dff3",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 187
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "Y_train[:10]"
-      ],
-      "execution_count": 107,
-      "outputs": [
-        {
-          "output_type": "execute_result",
-          "data": {
-            "text/plain": [
-              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
-              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
-              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
-              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
-              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
-            ]
-          },
-          "metadata": {
-            "tags": []
-          },
-          "execution_count": 107
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "osKqT73Q9JJB",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "from keras.layers import Activation\n",
-        "from keras.layers import Conv2D, MaxPooling2D\n",
-        "\n",
-        "model = Sequential()\n",
-        "\n",
-        "model = Sequential()\n",
-        "\n",
-        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
-        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
-        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
-        "#model.add(Conv2D(16, (3, 3), activation='relu'))\n",
-        "model.add(Conv2D(10, (3, 3), activation='relu'))\n",
-        "\n",
-        "model.add(GlobalAveragePooling2D())#, activation='softmax')\n",
-        "model.add(Activation('softmax'))\n",
-        " "
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "TzdAYg1k9K7Z",
-        "colab_type": "code",
-        "outputId": "e455175e-dc44-4e0e-f0ea-1e694f55f275",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 340
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "model.summary()"
-      ],
-      "execution_count": 110,
-      "outputs": [
-        {
-          "output_type": "stream",
-          "text": [
-            "_________________________________________________________________\n",
-            "Layer (type)                 Output Shape              Param #   \n",
-            "=================================================================\n",
-            "conv2d_64 (Conv2D)           (None, 26, 26, 32)        320       \n",
-            "_________________________________________________________________\n",
-            "conv2d_65 (Conv2D)           (None, 24, 24, 16)        4624      \n",
-            "_________________________________________________________________\n",
-            "conv2d_66 (Conv2D)           (None, 22, 22, 32)        4640      \n",
-            "_________________________________________________________________\n",
-            "conv2d_67 (Conv2D)           (None, 20, 20, 10)        2890      \n",
-            "_________________________________________________________________\n",
-            "global_average_pooling2d_6 ( (None, 10)                0         \n",
-            "_________________________________________________________________\n",
-            "activation_17 (Activation)   (None, 10)                0         \n",
-            "=================================================================\n",
-            "Total params: 12,474\n",
-            "Trainable params: 12,474\n",
-            "Non-trainable params: 0\n",
-            "_________________________________________________________________\n"
-          ],
-          "name": "stdout"
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "Zp6SuGrL9M3h",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "model.compile(loss='categorical_crossentropy',\n",
-        "             optimizer='adam',\n",
-        "             metrics=['accuracy'])"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "4xWoKhPY9Of5",
-        "colab_type": "code",
-        "outputId": "e10fc69f-e778-4b20-d6ef-ad99b5ea9f3b",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 5117
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "history = model.fit(X_train, Y_train, batch_size=50, epochs=150, verbose=1)"
-      ],
-      "execution_count": 112,
-      "outputs": [
-        {
-          "output_type": "stream",
-          "text": [
-            "Epoch 1/150\n",
-            "60000/60000 [==============================] - 13s 214us/step - loss: 1.0537 - acc: 0.6476\n",
-            "Epoch 2/150\n",
-            "60000/60000 [==============================] - 12s 193us/step - loss: 0.4425 - acc: 0.8691\n",
-            "Epoch 3/150\n",
-            "60000/60000 [==============================] - 12s 196us/step - loss: 0.3269 - acc: 0.9021\n",
-            "Epoch 4/150\n",
-            "60000/60000 [==============================] - 12s 192us/step - loss: 0.2719 - acc: 0.9189\n",
-            "Epoch 5/150\n",
-            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2308 - acc: 0.9315\n",
-            "Epoch 6/150\n",
-            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2060 - acc: 0.9387\n",
-            "Epoch 7/150\n",
-            "60000/60000 [==============================] - 12s 192us/step - loss: 0.1871 - acc: 0.9446\n",
-            "Epoch 8/150\n",
-            "60000/60000 [==============================] - 11s 192us/step - loss: 0.1772 - acc: 0.9479\n",
-            "Epoch 9/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.1617 - acc: 0.9523\n",
-            "Epoch 10/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.1509 - acc: 0.9562\n",
-            "Epoch 11/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.1400 - acc: 0.9579\n",
-            "Epoch 12/150\n",
-            "60000/60000 [==============================] - 11s 192us/step - loss: 0.1325 - acc: 0.9604\n",
-            "Epoch 13/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.1289 - acc: 0.9612\n",
-            "Epoch 14/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.1183 - acc: 0.9636\n",
-            "Epoch 15/150\n",
-            "60000/60000 [==============================] - 11s 191us/step - loss: 0.1160 - acc: 0.9653\n",
-            "Epoch 16/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.1082 - acc: 0.9675\n",
-            "Epoch 17/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.1057 - acc: 0.9681\n",
-            "Epoch 18/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0992 - acc: 0.9703\n",
-            "Epoch 19/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0972 - acc: 0.9712\n",
-            "Epoch 20/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0942 - acc: 0.9703\n",
-            "Epoch 21/150\n",
-            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0876 - acc: 0.9729\n",
-            "Epoch 22/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0845 - acc: 0.9746\n",
-            "Epoch 23/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0805 - acc: 0.9757\n",
-            "Epoch 24/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0807 - acc: 0.9754\n",
-            "Epoch 25/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0768 - acc: 0.9757\n",
-            "Epoch 26/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0736 - acc: 0.9776\n",
-            "Epoch 27/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0719 - acc: 0.9778\n",
-            "Epoch 28/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0710 - acc: 0.9778\n",
-            "Epoch 29/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0681 - acc: 0.9786\n",
-            "Epoch 30/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0681 - acc: 0.9787\n",
-            "Epoch 31/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0636 - acc: 0.9805\n",
-            "Epoch 32/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0632 - acc: 0.9801\n",
-            "Epoch 33/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0616 - acc: 0.9806\n",
-            "Epoch 34/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0597 - acc: 0.9811\n",
-            "Epoch 35/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0586 - acc: 0.9819\n",
-            "Epoch 36/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0568 - acc: 0.9820\n",
-            "Epoch 37/150\n",
-            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0559 - acc: 0.9827\n",
-            "Epoch 38/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0551 - acc: 0.9826\n",
-            "Epoch 39/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0533 - acc: 0.9838\n",
-            "Epoch 40/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0512 - acc: 0.9843\n",
-            "Epoch 41/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0519 - acc: 0.9845\n",
-            "Epoch 42/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0505 - acc: 0.9842\n",
-            "Epoch 43/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0497 - acc: 0.9844\n",
-            "Epoch 44/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0481 - acc: 0.9850\n",
-            "Epoch 45/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0479 - acc: 0.9851\n",
-            "Epoch 46/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0460 - acc: 0.9854\n",
-            "Epoch 47/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0465 - acc: 0.9852\n",
-            "Epoch 48/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0463 - acc: 0.9855\n",
-            "Epoch 49/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0449 - acc: 0.9860\n",
-            "Epoch 50/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0441 - acc: 0.9862\n",
-            "Epoch 51/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0432 - acc: 0.9861\n",
-            "Epoch 52/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0418 - acc: 0.9871\n",
-            "Epoch 53/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0416 - acc: 0.9872\n",
-            "Epoch 54/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0404 - acc: 0.9875\n",
-            "Epoch 55/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0409 - acc: 0.9873\n",
-            "Epoch 56/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0408 - acc: 0.9872\n",
-            "Epoch 57/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0387 - acc: 0.9877\n",
-            "Epoch 58/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0384 - acc: 0.9881\n",
-            "Epoch 59/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0397 - acc: 0.9874\n",
-            "Epoch 60/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0386 - acc: 0.9880\n",
-            "Epoch 61/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0381 - acc: 0.9882\n",
-            "Epoch 62/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0376 - acc: 0.9882\n",
-            "Epoch 63/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0360 - acc: 0.9891\n",
-            "Epoch 64/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0360 - acc: 0.9887\n",
-            "Epoch 65/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0355 - acc: 0.9890\n",
-            "Epoch 66/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0349 - acc: 0.9889\n",
-            "Epoch 67/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0351 - acc: 0.9890\n",
-            "Epoch 68/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0335 - acc: 0.9893\n",
-            "Epoch 69/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0346 - acc: 0.9890\n",
-            "Epoch 70/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0340 - acc: 0.9892\n",
-            "Epoch 71/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0336 - acc: 0.9894\n",
-            "Epoch 72/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0331 - acc: 0.9895\n",
-            "Epoch 73/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0319 - acc: 0.9897\n",
-            "Epoch 74/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0313 - acc: 0.9898\n",
-            "Epoch 75/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0321 - acc: 0.9897\n",
-            "Epoch 76/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0304 - acc: 0.9903\n",
-            "Epoch 77/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0311 - acc: 0.9905\n",
-            "Epoch 78/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0290 - acc: 0.9908\n",
-            "Epoch 79/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0301 - acc: 0.9905\n",
-            "Epoch 80/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0307 - acc: 0.9903\n",
-            "Epoch 81/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0298 - acc: 0.9900\n",
-            "Epoch 82/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0282 - acc: 0.9907\n",
-            "Epoch 83/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0290 - acc: 0.9907\n",
-            "Epoch 84/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0277 - acc: 0.9911\n",
-            "Epoch 85/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0279 - acc: 0.9911\n",
-            "Epoch 86/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0270 - acc: 0.9912\n",
-            "Epoch 87/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0276 - acc: 0.9912\n",
-            "Epoch 88/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0266 - acc: 0.9912\n",
-            "Epoch 89/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0267 - acc: 0.9916\n",
-            "Epoch 90/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0256 - acc: 0.9919\n",
-            "Epoch 91/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0258 - acc: 0.9917\n",
-            "Epoch 92/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0249 - acc: 0.9923\n",
-            "Epoch 93/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0254 - acc: 0.9920\n",
-            "Epoch 94/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0255 - acc: 0.9917\n",
-            "Epoch 95/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0242 - acc: 0.9918\n",
-            "Epoch 96/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0244 - acc: 0.9921\n",
-            "Epoch 97/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0243 - acc: 0.9924\n",
-            "Epoch 98/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0235 - acc: 0.9922\n",
-            "Epoch 99/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0242 - acc: 0.9921\n",
-            "Epoch 100/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0231 - acc: 0.9919\n",
-            "Epoch 101/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0237 - acc: 0.9920\n",
-            "Epoch 102/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0225 - acc: 0.9930\n",
-            "Epoch 103/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0225 - acc: 0.9922\n",
-            "Epoch 104/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0216 - acc: 0.9933\n",
-            "Epoch 105/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0220 - acc: 0.9927\n",
-            "Epoch 106/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0212 - acc: 0.9930\n",
-            "Epoch 107/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0215 - acc: 0.9927\n",
-            "Epoch 108/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0211 - acc: 0.9928\n",
-            "Epoch 109/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0205 - acc: 0.9935\n",
-            "Epoch 110/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0217 - acc: 0.9929\n",
-            "Epoch 111/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0199 - acc: 0.9936\n",
-            "Epoch 112/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0205 - acc: 0.9933\n",
-            "Epoch 113/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0211 - acc: 0.9931\n",
-            "Epoch 114/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0191 - acc: 0.9936\n",
-            "Epoch 115/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0201 - acc: 0.9933\n",
-            "Epoch 116/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0188 - acc: 0.9938\n",
-            "Epoch 117/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0195 - acc: 0.9937\n",
-            "Epoch 118/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0194 - acc: 0.9934\n",
-            "Epoch 119/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0181 - acc: 0.9940\n",
-            "Epoch 120/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0182 - acc: 0.9939\n",
-            "Epoch 121/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0174 - acc: 0.9940\n",
-            "Epoch 122/150\n",
-            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0167 - acc: 0.9948\n",
-            "Epoch 123/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0173 - acc: 0.9945\n",
-            "Epoch 124/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0168 - acc: 0.9945\n",
-            "Epoch 125/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0189 - acc: 0.9937\n",
-            "Epoch 126/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0165 - acc: 0.9943\n",
-            "Epoch 127/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0180 - acc: 0.9936\n",
-            "Epoch 128/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0166 - acc: 0.9946\n",
-            "Epoch 129/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0161 - acc: 0.9943\n",
-            "Epoch 130/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0165 - acc: 0.9947\n",
-            "Epoch 131/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0162 - acc: 0.9948\n",
-            "Epoch 132/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0147 - acc: 0.9952\n",
-            "Epoch 133/150\n",
-            "60000/60000 [==============================] - 12s 193us/step - loss: 0.0156 - acc: 0.9948\n",
-            "Epoch 134/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0153 - acc: 0.9951\n",
-            "Epoch 135/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0157 - acc: 0.9946\n",
-            "Epoch 136/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0157 - acc: 0.9949\n",
-            "Epoch 137/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0154 - acc: 0.9946\n",
-            "Epoch 138/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0153 - acc: 0.9949\n",
-            "Epoch 139/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0144 - acc: 0.9951\n",
-            "Epoch 140/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0146 - acc: 0.9950\n",
-            "Epoch 141/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0144 - acc: 0.9949\n",
-            "Epoch 142/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0147 - acc: 0.9950\n",
-            "Epoch 143/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0133 - acc: 0.9953\n",
-            "Epoch 144/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0148 - acc: 0.9948\n",
-            "Epoch 145/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0154 - acc: 0.9948\n",
-            "Epoch 146/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0130 - acc: 0.9956\n",
-            "Epoch 147/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0133 - acc: 0.9958\n",
-            "Epoch 148/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0131 - acc: 0.9958\n",
-            "Epoch 149/150\n",
-            "60000/60000 [==============================] - 11s 190us/step - loss: 0.0141 - acc: 0.9954\n",
-            "Epoch 150/150\n",
-            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0116 - acc: 0.9960\n"
-          ],
-          "name": "stdout"
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "_XGnVnRxalMO",
-        "colab_type": "text"
-      },
-      "cell_type": "markdown",
-      "source": [
-        "## Validation Accuracy is 99.6 % with just 12,474 parameters"
-      ]
-    },
-    {
-      "metadata": {
-        "id": "AtsH-lLk-eLb",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "score = model.evaluate(X_test, Y_test, verbose=0)"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "mkX8JMv79q9r",
-        "colab_type": "code",
-        "outputId": "b7ce3dee-9b45-42de-e2d2-1cd8a82e9fd9",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 34
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "print(score)"
-      ],
-      "execution_count": 116,
-      "outputs": [
-        {
-          "output_type": "stream",
-          "text": [
-            "[0.05783479690950317, 0.9868]\n"
-          ],
-          "name": "stdout"
-        }
-      ]
-    },
-    {
-      "metadata": {
-        "id": "OCWoJkwE9suh",
-        "colab_type": "code",
-        "colab": {}
-      },
-      "cell_type": "code",
-      "source": [
-        "y_pred = model.predict(X_test)"
-      ],
-      "execution_count": 0,
-      "outputs": []
-    },
-    {
-      "metadata": {
-        "id": "Ym7iCFBm9uBs",
-        "colab_type": "code",
-        "outputId": "06e58fcf-2c1f-4449-d0e3-c64ea3f2c4ae",
-        "colab": {
-          "base_uri": "https://localhost:8080/",
-          "height": 340
-        }
-      },
-      "cell_type": "code",
-      "source": [
-        "print(y_pred[:9])\n",
-        "print(y_test[:9])"
-      ],
-      "execution_count": 118,
-      "outputs": [
-        {
-          "output_type": "stream",
-          "text": [
-            "[[2.0113804e-09 2.2963543e-13 7.1409495e-10 1.8643076e-09 6.6712911e-12\n",
-            "  2.5056561e-11 1.1452436e-13 1.0000000e+00 2.9900859e-16 7.9752782e-09]\n",
-            " [2.8820786e-11 4.9045285e-10 9.9999988e-01 1.0373712e-07 2.0232037e-13\n",
-            "  5.2549538e-09 2.1008651e-12 2.6911887e-14 8.8237355e-13 2.6087266e-15]\n",
-            " [8.2610939e-11 9.9999988e-01 5.7164421e-12 6.7680487e-14 2.3621145e-09\n",
-            "  3.5418693e-10 1.7245912e-12 1.0346562e-07 6.7182486e-14 4.2532536e-13]\n",
-            " [9.9999964e-01 4.8751883e-09 1.9134829e-08 4.9850271e-12 3.4036247e-09\n",
-            "  4.7281876e-09 4.0444536e-07 2.0952951e-11 4.3301174e-08 8.8720506e-09]\n",
-            " [8.7199439e-09 2.4482864e-07 2.2329209e-12 3.1905537e-12 9.9999475e-01\n",
-            "  2.0207956e-12 3.3847621e-13 2.5435241e-07 1.1284983e-12 4.7335675e-06]\n",
-            " [4.0540167e-12 9.9999881e-01 2.3449415e-13 1.6872253e-15 4.0278675e-07\n",
-            "  7.4699646e-14 6.2679956e-13 8.2387106e-07 6.8426764e-14 5.5581015e-11]\n",
-            " [5.4314872e-11 1.1889138e-11 2.7206401e-12 1.0051193e-18 9.9999595e-01\n",
-            "  2.8753611e-16 1.9836561e-12 9.0154009e-11 8.8972883e-12 4.0034706e-06]\n",
-            " [9.3451957e-04 8.0361752e-11 5.0830904e-02 5.6517829e-11 1.6862838e-07\n",
-            "  2.4849310e-08 4.3989846e-08 1.4605346e-11 1.2572265e-03 9.4697708e-01]\n",
-            " [2.2249635e-06 3.0644573e-20 8.4761482e-01 1.1292945e-08 2.2081856e-08\n",
-            "  1.5155907e-01 8.2366582e-04 8.1400984e-14 2.2510608e-07 9.7967456e-09]]\n",
-            "[7 2 1 0 4 1 4 9 5]\n"
-          ],
-          "name": "stdout"
-        }
-      ]
-    }
-  ]
-}
\ No newline at end of file
